{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading explanations and comparing groups\n",
    "\n",
    "One hundred randomly selected observations from the validation data were given \"explanations\" using the LIME algorithm. These explanations are contained in a dictionary which I load here, along with two files containing the indices and the predicted values. I also load another file that contains the names and descriptions of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (9,6)\n",
    "#%config InlineBackend.figure_format = 'retina' # Uncomment if using a retina display\n",
    "plt.rc('pdf', fonttype=42)\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "#plt.rcParams['text.usetex'] = True # Uncomment if LaTeX installed to render plots in LaTeX\n",
    "#plt.rcParams['font.serif'] = 'Times'\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams.update({'figure.autolayout': False})\n",
    "plt.rcParams[\"figure.figsize\"] = (12,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pickle.load(open('../../output/lime_explanations_dict.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data have been loaded I first do some basic analysis to see the range of variables that are present in the explanations.\n",
    "\n",
    "First I convert the explanations to a dictionary, which is an easier format to process than that returned by LIME. I then convert them to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = {}\n",
    "for k,v in exp.items():\n",
    "    user_exp = {}\n",
    "    for x in v:\n",
    "        user_exp[x[0]] = x[1]\n",
    "    explanations[k] = user_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect a given element of the dictionary to see the explanation for a particular observation. For example the sub-dictionary below contains the explanation for observation 15. The keys in this dictionary are a combination of variables and values. For example the first key `f3d3a_5_1.0 <= 0.00` denotes the variable `f3d3a_5`, corresponding to the question posted to the father of the child in year 3 of the survey: \"Who could you trust: child's sibling?\". The second part of the key denotes that the response category `1.0` was less than or equal to `0`. Looking this up in the [survey documentation](https://fragilefamilies.princeton.edu/sites/fragilefamilies/files/ff_dad_cb3.txt) indicates that `1.0` indicates an answer of `Yes` to the question. While this syntax is somewhat confusing it indicates that this particular dummy variable had a value of 0 for this respondent. This therefore indicates that the child's rather did not answer yes to this particular question. The value of this element of the dictionary is a local coefficient generated by LIME that indicates the weight that this variable contributed to the local prediction. In this case the predictor was positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now convert this dictionary into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(explanations, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to get a sense of the important variables I can simplify the columns by extracting the variable names and creating a new dataframe. Apologies for the rather ugly code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variable_name(s):\n",
    "    \"\"\"\n",
    "    This function parses the column names in the explanations to extract the variable name\n",
    "    from the FF survey.\n",
    "    \n",
    "    I have left in the comments to illustrate how the algorithm is working.\"\"\"\n",
    "    components = s.split()\n",
    "    print(s)\n",
    "    try: \n",
    "        float(components[0]) # if first component can be case to a float then var name in 2nd\n",
    "        print('First component is a float')\n",
    "        var = components[2]\n",
    "        print('Name is in ', var)\n",
    "    except ValueError:\n",
    "        var = components[0]\n",
    "        print('Name is in ', var)\n",
    "        \n",
    "    if '_' in var:\n",
    "        subcomponents = var.split('_')\n",
    "        if var.count('_') == 1:\n",
    "            # if substring after the _ can't be cast to float then it is part of the name\n",
    "            try:\n",
    "                float(subcomponents[1])\n",
    "                varname = subcomponents[0]\n",
    "            except ValueError:\n",
    "                varname = var\n",
    "        elif var.count('_') > 1:\n",
    "            print(\"More than one underscore in \", var)\n",
    "            varname = subcomponents[0]+'_'+subcomponents[1]\n",
    "            print(\"Variable name is \", varname)\n",
    "            \n",
    "    else:\n",
    "        varname = var\n",
    "    print(varname)\n",
    "    return varname \n",
    "\n",
    "explanations_2 = {}\n",
    "for k,v in explanations.items():\n",
    "    user_exp = {}\n",
    "    for x, v in v.items():\n",
    "        var = extract_variable_name(x)\n",
    "        user_exp[var] = v\n",
    "    explanations_2[k] = user_exp\n",
    "    \n",
    "df_names = pd.DataFrame.from_dict(explanations_2, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df_names.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also defining a new dataframe and a function to count the number of observations each variable occurs in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names_counts = df_names.notnull()*1\n",
    "\n",
    "def count_occurrences(var):\n",
    "    return df_names_counts[var].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting variable metadata\n",
    "\n",
    "To get metadata for these variables there are a number of different steps. During the challenge, participant Connor Gilroy created a meta-data csv file that contains some information on each variable; since the challenge the Fragile Families team have built an API to programmatically get metadata. I mostly rely on the API below but use Gilroy's csv when metadata is not available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Gilroy's file from Github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/fragilefamilieschallenge/variables-metadata/master/ffc_variable_types.csv'\n",
    "meta = pd.read_csv(url)\n",
    "meta.index = meta['variable']\n",
    "del meta['variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying over [code](https://github.com/fragilefamilieschallenge/ffmetadata-py/blob/master/ff.py) from the challenge github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "BASE_URL = 'http://api.metadata.fragilefamilies.princeton.edu'\n",
    "\n",
    "\n",
    "def select(var_name, attr_name=None):\n",
    "    \"\"\"\n",
    "    Return attribute(s) of a variable given the variable name and an optional field name, or list of attribute name(s)\n",
    "    :param var_name: Name of the variable we're interested in.\n",
    "    :param attr_name: A string representing the name of the attribute whose value we want to fetch. This can also be\n",
    "        a list of strings in case of multiple attributes. If None, all attributes of the variable are returned.\n",
    "    :return: A dictionary of attribute => value mappings if multiple attributes were requested (i.e. attr_name is a\n",
    "        list), or a string value if a single attribute name was requested (i.e. attr_name is a string)\n",
    "    \"\"\"\n",
    "    single = isinstance(attr_name, str)\n",
    "    if attr_name is not None:\n",
    "        if single:\n",
    "            params = {attr_name: attr_name}\n",
    "        else:\n",
    "            params = dict([(f, f) for f in attr_name])\n",
    "    else:\n",
    "        params = None\n",
    "\n",
    "    endpoint = 'variable/%s' % var_name\n",
    "    data = _get(endpoint, params)\n",
    "\n",
    "    return data[attr_name] if single else data\n",
    "\n",
    "\n",
    "def search(filters=None):\n",
    "    \"\"\"\n",
    "    Search for variable names given a list or dictionary of 'filter(s)'.\n",
    "    A 'filter' is defined as a dictionary with keys 'name','op','val' representing the attribute name, a comparison\n",
    "    operator, and the value for comparison.\n",
    "    If multiple filters are specified as a list, they're combined using the AND operator.\n",
    "    Filters can also be specified as a dictionary, keyed with 'and' or 'or', and the values being a list of individual\n",
    "    'filters'.\n",
    "    See examples of usage in this module. Note that this function doesn't do any advanced processing whatsoever, but\n",
    "    passes on the filters 'as-is' to the server.\n",
    "    :param filters: A list of filters, or a dictionary with key 'and' or 'or', and the values as a list of filters.\n",
    "    :return: A list of variable names corresponding to the search criteria.\n",
    "    \"\"\"\n",
    "    filters = filters or []\n",
    "    query_string_dict = {'filters': filters}\n",
    "    query_string = urllib.parse.quote(json.dumps(query_string_dict))\n",
    "    return _get('variable?q=%s' % query_string)\n",
    "\n",
    "\n",
    "def _get(endpoint, params=None):\n",
    "    \"\"\"Return a dictionary of attribute => value mapping for JSON results\n",
    "    obtained at a specified endpoint, with optional query parameters.\n",
    "    Raises SystemError on 5xx responses or RuntimeError on 4xx responses\n",
    "    \"\"\"\n",
    "    url = '%s/%s' % (BASE_URL, endpoint)\n",
    "    url = requests.Request('GET', url, params=params).prepare().url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if 500 <= response.status_code < 600:\n",
    "        raise SystemError(\"Internal Error on Server\")\n",
    "\n",
    "    d = response.json()\n",
    "    if 400 <= response.status_code < 500:\n",
    "        raise RuntimeError(d['message'])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of some of the variables used in the challenge have changed so they cannot be found in the API. This section creates a dictionary mapping the old names to the new names. Note that some variables from the challenge are not in the metadata so may still fail to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the raw metadata file and creating a name conversion dictionary\n",
    "url = \"http://metadata.fragilefamilies.princeton.edu/get_metadata\"\n",
    "df = pd.read_csv(url, encoding=\"latin1\")\n",
    "old_name_to_new_name = {}\n",
    "for _, r in df.iterrows():\n",
    "  old_name_to_new_name[r['old_name']] = r['new_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that some of the variables have been renamed multiple times and cannot easily be found in the metadata, either in the new API or in Connor Gilroy's file. After discussion on Github it appears that almost all of these come from the in-house survey. The following function can be used to convert these to get names that can be used to get metadata from the new API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToNew(var):\n",
    "    \"\"\"Takes an old variable name from the in house survey and converts it to a new one.\"\"\"\n",
    "    chars = [x for x in string.ascii_lowercase]\n",
    "    if not var.startswith('hv'):\n",
    "        print(\"This variable does not start with hv\")\n",
    "        return\n",
    "    else:\n",
    "        var = var[2:] # Remove hv prefix\n",
    "        if var[1] in chars[:14]: #if [a-n]\n",
    "            return 'p'+var\n",
    "        elif var[1] in chars[14:22]: #if [p-v]\n",
    "            if var[2] in chars: # if next element is another character\n",
    "                return 'ch'+var \n",
    "            else: # if not assign o prefix\n",
    "                return 'o'+var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can finally iterate through the names and get as much metadata as possible. The code before first checks the API for the raw variable name. If this fails it uses the dictionary to get the old name and then checks the API again. If this still fails it either uses the above function to get the new name (if the variable prefix is 'hv') or uses Gilroy's metadata. If either of these fail then it sets the metadata to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "meta_data = {}\n",
    "count_by_new_name = {} # A dictionary mapping the new name to the number of observations var occurs in\n",
    "for i in names:\n",
    "    try: # Try to directly query metadata\n",
    "        m = select(i)\n",
    "        meta_data[i] = m\n",
    "        count_by_new_name[i] = count_occurrences(i)\n",
    "        print(\"Obtained metadata for \", i)\n",
    "    except: # If that doesn't work try using the new name\n",
    "        try:\n",
    "            n = old_name_to_new_name[i]\n",
    "            m = select(n)\n",
    "            meta_data[n] = m\n",
    "            count_by_new_name[n] = count_occurrences(i)\n",
    "            print(\"Obtained metadata for \", i, \" using new name \", n)\n",
    "        except: # If this fails\n",
    "\n",
    "            try:\n",
    "                if i.startswith('hv'):\n",
    "                    n = convertToNew(i)\n",
    "                    m = select(n)\n",
    "                    meta_data[n] = m\n",
    "                    count_by_new_name[n] = count_occurrences(i)\n",
    "                else:\n",
    "                    print(\"Getting information from original metadata for \",i)\n",
    "                    meta_data[i] = meta.loc[i]\n",
    "                    count_by_new_name[i] = count_occurrences(i)\n",
    "            except:\n",
    "                print(\"Unable to obtain metadata for \",i)\n",
    "                meta_data[i] = None\n",
    "                count_by_new_name[i] = count_occurrences(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in meta_data.keys() if meta_data[x] is None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this procedure the metadata has been obtained for all but 8 of these variables. These are ignored in the analysis below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to consider analysis to summarize the findings:\n",
    "\n",
    "- Top K most frequently occuring values\n",
    "- Histogram of relevant waves\n",
    "- Histogram of respondents\n",
    "- Histogram of topic / umbrella topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 25 most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in sorted(count_by_new_name.items(), key=lambda x: x[1], reverse=True)[:25]:\n",
    "    print(meta_data[i]['label'], j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a table summarizing all of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = {}\n",
    "for k,v in meta_data.items():\n",
    "    try:\n",
    "        wave = v['wave']\n",
    "        respondent = v['respondent']\n",
    "        topics = v['topics'].split(';')\n",
    "        topic1 = topics[0].strip()\n",
    "        if len(topics) > 1:\n",
    "            topic2 = topics[1].strip()\n",
    "            table_data[k] = {'Count in LIME exp.': count_by_new_name[k],'Wave':wave, 'Respondent': respondent,\n",
    "                        'topic 1': topic1, 'topic 2': topic2}\n",
    "        else:\n",
    "            table_data[k] = {'Count in LIME exp.': count_by_new_name[k],'Wave':wave, 'Respondent': respondent,\n",
    "                        'topic 1': topic1}\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_and_metadata = pd.DataFrame.from_dict(table_data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_and_metadata = results_and_metadata.fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_and_metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_and_metadata.to_csv('../../output/lime_results_and_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_count = defaultdict(int)\n",
    "for _, r in results_and_metadata.iterrows():\n",
    "    wave_count[r['Wave']] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(wave_count.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(wave_count.items(), key=lambda x: x[0]))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, [x/500 for x in freq], color='b')\n",
    "plt.xticks(indices, word, rotation='vertical')\n",
    "plt.title('LIME identified variables by survey wave',size=18)\n",
    "plt.ylabel('Proportion of variables',size=16)\n",
    "plt.xlabel('Wave', size=16)\n",
    "plt.xticks(size=14, rotation=360)\n",
    "plt.yticks(size=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_count = defaultdict(int)\n",
    "for _, r in results_and_metadata.iterrows():\n",
    "    respondent_count[r['Respondent']] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(respondent_count.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(respondent_count.items(), key=lambda x: x[1], reverse=True))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, [x/500 for x in freq], color='b')\n",
    "plt.xticks(indices, word, rotation='vertical', size=14)\n",
    "plt.title('LIME identified variables by survey respondent',size=18)\n",
    "plt.ylabel('Proportion of variables',size=16)\n",
    "plt.xlabel('Respondent', size=16)\n",
    "plt.tight_layout()\n",
    "plt.yticks(size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count = defaultdict(int)\n",
    "umbrella_count = defaultdict(int)\n",
    "for k,v in meta_data.items():\n",
    "    try:\n",
    "        for t in v['topics']:\n",
    "            topic_count[t['topic']] += count_by_new_name[k]\n",
    "            if t['umbrella'] == 'Parenting':\n",
    "                print(v['label'])\n",
    "            umbrella_count[t['umbrella']] += count_by_new_name[k]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count = defaultdict(int)\n",
    "for _, r in results_and_metadata.iterrows():\n",
    "    try:\n",
    "        topic_count[r['topic 2']] +=1\n",
    "        topic_count[r['topic 1']] +=1\n",
    "    except:\n",
    "        topic_count[r['topic 1']] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(topic_count.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del topic_count['N/A'] # Remove missing observations as they simply indicate no second topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(topic_count.items(), key=lambda x: x[1], reverse=True))[:25]\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,9)\n",
    "plt.bar(indices, [x/500 for x in freq], color='b')\n",
    "plt.xticks(indices, word, rotation='vertical',size=14)\n",
    "plt.title('LIME identified variables by topic',size=18)\n",
    "plt.ylabel('Proportion of variables',size=16)\n",
    "plt.xlabel('Topic', size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.savefig('../../figures/topic_lime_proportions.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences in proportions and ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding proportion of questions in each wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['wave'] != 'Year 15'] # We do not want to include Year 15 waves as they were not used in the Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['new_name'] != 'idnum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_count_full = dict(Counter(list(df['wave'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_count_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(wave_count_full.items(), key=lambda x: x[0]))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, [x/df.shape[0] for x in freq], color='blue')\n",
    "plt.xticks(indices, word, rotation='vertical',size=14)\n",
    "plt.title('Proportion of variables by wave in entire survey',size=18)\n",
    "plt.ylabel('Proportion of variables',size=16)\n",
    "plt.xlabel('Wave', size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to take the difference between the proportion in my results and the proportion in the survey overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_counts_mod = {}\n",
    "for k,v in wave_count.items():\n",
    "    prop_observed = v/500\n",
    "    prop_in_survey = wave_count_full[k]/df.shape[0]\n",
    "    wave_counts_mod[k] = prop_observed-prop_in_survey # Diff in proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_counts_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsignif = {}\n",
    "for k,v in wave_count.items():\n",
    "    count = np.array([v, wave_count_full[k]])\n",
    "    nobs = np.array([500, df.shape[0]])\n",
    "    stat, pval = proportions_ztest(count, nobs)\n",
    "    if pval > 0.05:\n",
    "        wsignif[k] = ''\n",
    "    elif pval <= 0.05 and pval > 0.01:\n",
    "        wsignif[k] = '*'\n",
    "    elif pval <= 0.01 and pval > 0.001:\n",
    "        wsignif[k] = '**'\n",
    "    elif pval <= 0.001:\n",
    "        wsignif[k] = '***'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(wave_counts_mod.items(), key=lambda x: x[0]))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, freq, color='blue')\n",
    "plt.xticks(indices, [wsignif[x] + ' ' + x for x in word], rotation='vertical',size=14)\n",
    "plt.title('Proportion of LIME identified variables by wave relative to survey',size=18)\n",
    "plt.ylabel('Difference in proportions',size=16)\n",
    "plt.xlabel('Wave', size=16)\n",
    "plt.ylim(-0.15, 0.032)\n",
    "plt.yticks(size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_counts_mod = {}\n",
    "for k,v in wave_count.items():\n",
    "    prop_observed = v/500\n",
    "    prop_in_survey = wave_count_full[k]/df.shape[0]\n",
    "    wave_counts_mod[k] = prop_observed/prop_in_survey # Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(wave_counts_mod.items(), key=lambda x: x[0]))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, freq, color='blue')\n",
    "plt.xticks(indices, [wsignif[x] + ' ' + x for x in word], rotation='vertical',size=14)\n",
    "plt.title('Ratio LIME identified variables to overall survey by wave',size=18)\n",
    "plt.ylabel('Ratio',size=16)\n",
    "plt.xlabel('Wave', size=16)\n",
    "#plt.ylim(-0.10, 0.032)\n",
    "plt.yticks(size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to do the same for respondents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_count_full = {}\n",
    "for k,v in dict(Counter(list(df['respondent']))).items():\n",
    "    resp_count_full[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(resp_count_full.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_resp = data[0][1] # Replace nan category with N/A\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, ('N/A', no_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_count_full = dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, [x/df.shape[0] for x in freq], color='blue')\n",
    "plt.xticks(indices, word, rotation='vertical',size=14)\n",
    "plt.title('Proportion of variables by respondent',size=18)\n",
    "plt.ylabel('Proportion of variables',size=16)\n",
    "plt.xlabel('Wave', size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_counts_mod = {}\n",
    "for k,v in respondent_count.items():\n",
    "    prop_observed = v/500\n",
    "    prop_in_survey = resp_count_full[k]/df.shape[0]\n",
    "    resp_counts_mod[k] = prop_observed-prop_in_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_counts_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsignif = {}\n",
    "for k,v in respondent_count.items():\n",
    "    count = np.array([v, resp_count_full[k]])\n",
    "    nobs = np.array([500, df.shape[0]])\n",
    "    stat, pval = proportions_ztest(count, nobs)\n",
    "    if pval > 0.05:\n",
    "        rsignif[k] = ''\n",
    "    elif pval <= 0.05 and pval > 0.01:\n",
    "        rsignif[k] = '*'\n",
    "    elif pval <= 0.01 and pval > 0.001:\n",
    "        rsignif[k] = '**'\n",
    "    elif pval <= 0.001:\n",
    "        rsignif[k] = '***'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(resp_counts_mod.items(), key=lambda x: x[1]))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, freq, color='blue')\n",
    "plt.xticks(indices, [rsignif[x]+' '+ x for x in word], rotation='vertical',size=14)\n",
    "plt.title('Proportion of LIME identified variables \\n by respondent relative to entire survey',size=18)\n",
    "plt.ylabel('Difference in proportions',size=16)\n",
    "plt.xlabel('Respondent', size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.ylim(-0.1,0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_counts_mod = {}\n",
    "for k,v in respondent_count.items():\n",
    "    prop_observed = v/500\n",
    "    prop_in_survey = resp_count_full[k]/df.shape[0]\n",
    "    resp_counts_mod[k] = prop_observed/prop_in_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(resp_counts_mod.items(), key=lambda x: x[1]))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, freq, color='blue')\n",
    "plt.xticks(indices, [rsignif[x]+' '+ x for x in word], rotation='vertical',size=14)\n",
    "plt.title('Ratio of LIME identified variables \\n by respondent relative to entire survey',size=18)\n",
    "plt.ylabel('Ratio',size=16)\n",
    "plt.xlabel('Respondent', size=16)\n",
    "plt.yticks(size=14)\n",
    "#plt.ylim(-0.1,0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now getting the same for topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count_full = defaultdict(int)\n",
    "topics = list(df['topics'])\n",
    "for t in topics:\n",
    "    x = t.split(';')\n",
    "    for i in x:\n",
    "        topic_count_full[i.strip()] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts_mod = {}\n",
    "for k,v in topic_count.items():\n",
    "    prop_observed = v/500\n",
    "    prop_in_survey = topic_count_full[k]/df.shape[0]\n",
    "    topic_counts_mod[k] = prop_observed-prop_in_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsignif = {}\n",
    "for k,v in topic_count.items():\n",
    "    count = np.array([v, topic_count_full[k]])\n",
    "    nobs = np.array([500, df.shape[0]])\n",
    "    stat, pval = proportions_ztest(count, nobs)\n",
    "    if pval > 0.05:\n",
    "        tsignif[k] = ''\n",
    "    elif pval <= 0.05 and pval > 0.01:\n",
    "        tsignif[k] = '*'\n",
    "    elif pval <= 0.01 and pval > 0.001:\n",
    "        tsignif[k] = '**'\n",
    "    elif pval <= 0.001:\n",
    "        tsignif[k] = '***'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(topic_counts_mod.items(), key=lambda x: x[1], reverse=True))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, freq, color='blue')\n",
    "plt.xticks(indices, [tsignif[x] + ' ' + x for x in word], rotation='vertical',size=14)\n",
    "plt.title('LIME identified variables by respondent compared to survey',size=18)\n",
    "plt.ylabel('Difference in proportions',size=16)\n",
    "plt.xlabel('Topic', size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.ylim(-0.13,0.13)\n",
    "plt.savefig('../../figures/relative_topic_proportions.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts_mod_ratio = {}\n",
    "for k,v in topic_count.items():\n",
    "    prop_observed = v/500\n",
    "    prop_in_survey = topic_count_full[k]/df.shape[0]\n",
    "    topic_counts_mod_ratio[k] = prop_observed/prop_in_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sorted(topic_counts_mod_ratio.items(), key=lambda x: x[1],reverse=True))\n",
    "word, freq = zip(*data)\n",
    "indices = np.arange(len(data))\n",
    "plt.bar(indices, freq, color='blue')\n",
    "plt.xticks(indices, [tsignif[x]+' '+x for x in word], rotation='vertical',size=14)\n",
    "plt.title('Ratio of umbrella topics in LIME identified variables \\n relative to entire survey',size=18)\n",
    "plt.ylabel('Ratio',size=16)\n",
    "plt.xlabel('Umbrella topic', size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../figures/relative_topic_ratio.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
