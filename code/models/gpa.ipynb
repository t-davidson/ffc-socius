{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GPA with Deep Learning\n",
    "This notebook reproduces the models and all figures and tables contained in my paper on the Fragile Familes Challenge.\n",
    "\n",
    "***Please note the following if you intend to run this notebook***\n",
    "\n",
    "- To the best of my knowledge this notebook will reproduce all the results accurately but due to stochastic nature of many of the processes used the results may differ. Where possible I have created static copies of objects that can be loaded directly. Some of these are too large to store on Github, for example the pickled versions of the final 5 classifiers. Please email me directly if you would like copies of these.\n",
    "\n",
    "- This notebook is contains process that are computationally intensive and take some time to run. As is it will take at least 24 hours to run on a top spec laptop computer. I have noted the cells that take most time to run. If possible you may consider editing the notebook where appropriate to run processes in paraellel or using a GPU.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Set up to ensure reproducibility following https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(67891)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "random.seed(54321)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "tf.set_random_seed(56789)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "seed = 13579 # used below to seed sklearn functions\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, History\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the files\n",
    "\n",
    "***Note: These data cannot be provided on Github and I will delete my copies in accordance with the FFC agreement. If you would like copies of the data to replicate these analyses please consult the Fragile Families and Child Wellbeing Survey [website](https://fragilefamilies.princeton.edu/documentation).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../../FFChallenge_v2/train.csv',low_memory=False, index_col='challengeID')\n",
    "predictions=pd.read_csv('../../FFChallenge_v2/prediction.csv',low_memory=False, index_col='challengeID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate `full_imputed.p` the script `clean_files.py` must first be run. If necessary it can be executed by uncommenting (deleting the #) and running the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! PYTHONHASHSEED=0 python3 ../preprocess/clean_files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../../ff_files/full_imputed.csv') # load imputed data output after running the clean_files.py\n",
    "data = pd.read_csv('../data/full_imputed.csv') # load imputed data output after running the clean_files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4242, 4569)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challengeID</th>\n",
       "      <th>m1lenmin</th>\n",
       "      <th>m1citywt</th>\n",
       "      <th>m1e1d1</th>\n",
       "      <th>m1e1d2</th>\n",
       "      <th>m1e1d3</th>\n",
       "      <th>m1i2a</th>\n",
       "      <th>m1i2b</th>\n",
       "      <th>m1j2a</th>\n",
       "      <th>m1j2b</th>\n",
       "      <th>...</th>\n",
       "      <th>hv4mflag</th>\n",
       "      <th>hv4mompreg</th>\n",
       "      <th>hv4selfht</th>\n",
       "      <th>hv4selfwt</th>\n",
       "      <th>gpa</th>\n",
       "      <th>grit</th>\n",
       "      <th>materialHardship</th>\n",
       "      <th>eviction</th>\n",
       "      <th>layoff</th>\n",
       "      <th>jobTraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>202.485367</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.723174</td>\n",
       "      <td>13.260396</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1682.415602</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>2.211822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.608219</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3050.504448</td>\n",
       "      <td>0.110909</td>\n",
       "      <td>1.985703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.060299</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.158179</td>\n",
       "      <td>1.386592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.304855</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.169628</td>\n",
       "      <td>5.699719</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.165048</td>\n",
       "      <td>1.157385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.518272</td>\n",
       "      <td>90.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1974.812374</td>\n",
       "      <td>12.212538</td>\n",
       "      <td>2.965919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   challengeID  m1lenmin    m1citywt  m1e1d1     m1e1d2     m1e1d3  m1i2a  \\\n",
       "0            1      40.0  202.485367    25.0   6.723174  13.260396   38.0   \n",
       "1            2      40.0   45.608219    43.0  16.000000   3.000000   25.0   \n",
       "2            3      35.0   39.060299    49.0  46.000000  23.000000   20.0   \n",
       "3            4      30.0   22.304855    23.0  23.169628   5.699719   20.0   \n",
       "4            5      25.0   35.518272    90.0  64.000000  58.000000   12.0   \n",
       "\n",
       "         m1i2b      m1j2a     m1j2b     ...       hv4mflag  hv4mompreg  \\\n",
       "0  1682.415602   0.038262  2.211822     ...            0.0         0.0   \n",
       "1  3050.504448   0.110909  1.985703     ...            0.0         1.0   \n",
       "2     0.000000  12.158179  1.386592     ...            0.0         0.0   \n",
       "3     0.000000   4.165048  1.157385     ...            0.0         0.0   \n",
       "4  1974.812374  12.212538  2.965919     ...            0.0         0.0   \n",
       "\n",
       "   hv4selfht  hv4selfwt  gpa  grit  materialHardship  eviction  layoff  \\\n",
       "0        0.0        0.0  2.5  3.50          0.090909       0.0     0.0   \n",
       "1        0.0        0.0  2.5  3.25          0.181818       0.0     0.0   \n",
       "2        0.0        0.0  2.5  3.00          0.000000       0.0     0.0   \n",
       "3        0.0        0.0  2.5  3.50          0.090909       0.0     0.0   \n",
       "4        0.0        0.0  2.5  3.50          0.090909       0.0     0.0   \n",
       "\n",
       "   jobTraining  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 4569 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data['challengeID']\n",
    "del data['challengeID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the outcomes from the imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['gpa','grit','materialHardship','eviction','layoff','jobTraining']]\n",
    "X = data\n",
    "for c in X.columns:\n",
    "    if c in list(y.columns):\n",
    "        del X[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "Before modelling the data there are two types of transformations that I use to optimize them for the neural network.\n",
    "\n",
    "Categorical variables are transformed using one-hot encoding. Continuous variables are also normalized to have a mean of zero.\n",
    "\n",
    "To identify which columns belong to which group I use same heuristic as in the imputation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "cat_cols = []\n",
    "non_cat_cols = []\n",
    "for i, c in enumerate(X.columns):\n",
    "    is_categorical = False\n",
    "    vals = set(list(X[c]))\n",
    "    vals = {x for x in vals if x==x} # Removes nans, otherwise treated as unique\n",
    "    if X[c].dtype == 'float64': # if float and low num distinct then treat as cat\n",
    "        if len(vals) <= 20:\n",
    "            is_categorical = True\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        is_categorical = True\n",
    "    \n",
    "    # Now append to relevant list of columns\n",
    "    if is_categorical:\n",
    "        cat_cols.append(c)\n",
    "        \n",
    "    else:\n",
    "        non_cat_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X, columns=cat_cols)\n",
    "# Note that sklearn also has one-hot encoding but doesn't relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1lenmin</th>\n",
       "      <th>m1citywt</th>\n",
       "      <th>m1e1d1</th>\n",
       "      <th>m1e1d2</th>\n",
       "      <th>m1e1d3</th>\n",
       "      <th>m1i2a</th>\n",
       "      <th>m1i2b</th>\n",
       "      <th>m1j2a</th>\n",
       "      <th>m1j2b</th>\n",
       "      <th>cm1hhinc</th>\n",
       "      <th>...</th>\n",
       "      <th>hv4mflag_1.0</th>\n",
       "      <th>hv4mflag_2.0</th>\n",
       "      <th>hv4mflag_3.0</th>\n",
       "      <th>hv4mompreg_0.0</th>\n",
       "      <th>hv4mompreg_1.0</th>\n",
       "      <th>hv4selfht_0.0</th>\n",
       "      <th>hv4selfht_1.0</th>\n",
       "      <th>hv4selfht_2.0</th>\n",
       "      <th>hv4selfwt_0.0</th>\n",
       "      <th>hv4selfwt_1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>challengeID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>202.485367</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.723174</td>\n",
       "      <td>13.260396</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1682.415602</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>2.211822</td>\n",
       "      <td>29579.694329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>45.608219</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3050.504448</td>\n",
       "      <td>0.110909</td>\n",
       "      <td>1.985703</td>\n",
       "      <td>20829.093487</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>39.060299</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.158179</td>\n",
       "      <td>1.386592</td>\n",
       "      <td>132483.450592</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>22.304855</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.169628</td>\n",
       "      <td>5.699719</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.165048</td>\n",
       "      <td>1.157385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>35.518272</td>\n",
       "      <td>90.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1974.812374</td>\n",
       "      <td>12.212538</td>\n",
       "      <td>2.965919</td>\n",
       "      <td>49026.982561</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             m1lenmin    m1citywt  m1e1d1     m1e1d2     m1e1d3  m1i2a  \\\n",
       "challengeID                                                              \n",
       "1                40.0  202.485367    25.0   6.723174  13.260396   38.0   \n",
       "2                40.0   45.608219    43.0  16.000000   3.000000   25.0   \n",
       "3                35.0   39.060299    49.0  46.000000  23.000000   20.0   \n",
       "4                30.0   22.304855    23.0  23.169628   5.699719   20.0   \n",
       "5                25.0   35.518272    90.0  64.000000  58.000000   12.0   \n",
       "\n",
       "                   m1i2b      m1j2a     m1j2b       cm1hhinc      ...        \\\n",
       "challengeID                                                       ...         \n",
       "1            1682.415602   0.038262  2.211822   29579.694329      ...         \n",
       "2            3050.504448   0.110909  1.985703   20829.093487      ...         \n",
       "3               0.000000  12.158179  1.386592  132483.450592      ...         \n",
       "4               0.000000   4.165048  1.157385       0.000000      ...         \n",
       "5            1974.812374  12.212538  2.965919   49026.982561      ...         \n",
       "\n",
       "             hv4mflag_1.0  hv4mflag_2.0  hv4mflag_3.0  hv4mompreg_0.0  \\\n",
       "challengeID                                                             \n",
       "1                       0             0             0               1   \n",
       "2                       0             0             0               0   \n",
       "3                       0             0             0               1   \n",
       "4                       0             0             0               1   \n",
       "5                       0             0             0               1   \n",
       "\n",
       "             hv4mompreg_1.0  hv4selfht_0.0  hv4selfht_1.0  hv4selfht_2.0  \\\n",
       "challengeID                                                                \n",
       "1                         0              1              0              0   \n",
       "2                         1              1              0              0   \n",
       "3                         0              1              0              0   \n",
       "4                         0              1              0              0   \n",
       "5                         0              1              0              0   \n",
       "\n",
       "             hv4selfwt_0.0  hv4selfwt_1.0  \n",
       "challengeID                                \n",
       "1                        1              0  \n",
       "2                        1              0  \n",
       "3                        1              0  \n",
       "4                        1              0  \n",
       "5                        1              0  \n",
       "\n",
       "[5 rows x 16391 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "for c in non_cat_cols:\n",
    "    normed = normalizer.fit_transform(X_dummies[c].values.reshape(-1,1))\n",
    "    X_dummies[c] = normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1lenmin</th>\n",
       "      <th>m1citywt</th>\n",
       "      <th>m1e1d1</th>\n",
       "      <th>m1e1d2</th>\n",
       "      <th>m1e1d3</th>\n",
       "      <th>m1i2a</th>\n",
       "      <th>m1i2b</th>\n",
       "      <th>m1j2a</th>\n",
       "      <th>m1j2b</th>\n",
       "      <th>cm1hhinc</th>\n",
       "      <th>...</th>\n",
       "      <th>hv4mflag_1.0</th>\n",
       "      <th>hv4mflag_2.0</th>\n",
       "      <th>hv4mflag_3.0</th>\n",
       "      <th>hv4mompreg_0.0</th>\n",
       "      <th>hv4mompreg_1.0</th>\n",
       "      <th>hv4selfht_0.0</th>\n",
       "      <th>hv4selfht_1.0</th>\n",
       "      <th>hv4selfht_2.0</th>\n",
       "      <th>hv4selfwt_0.0</th>\n",
       "      <th>hv4selfwt_1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>challengeID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364267</td>\n",
       "      <td>0.675623</td>\n",
       "      <td>-0.545055</td>\n",
       "      <td>-0.788818</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>0.255698</td>\n",
       "      <td>-0.245954</td>\n",
       "      <td>-1.512365</td>\n",
       "      <td>0.017524</td>\n",
       "      <td>-0.105330</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.364267</td>\n",
       "      <td>-0.197911</td>\n",
       "      <td>0.606432</td>\n",
       "      <td>-0.149595</td>\n",
       "      <td>-1.041256</td>\n",
       "      <td>-0.986483</td>\n",
       "      <td>-0.080941</td>\n",
       "      <td>-1.497946</td>\n",
       "      <td>-0.168142</td>\n",
       "      <td>-0.377045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.071568</td>\n",
       "      <td>-0.234372</td>\n",
       "      <td>0.990261</td>\n",
       "      <td>1.917563</td>\n",
       "      <td>1.345718</td>\n",
       "      <td>-1.464245</td>\n",
       "      <td>-0.448880</td>\n",
       "      <td>0.893159</td>\n",
       "      <td>-0.660072</td>\n",
       "      <td>3.089933</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.507403</td>\n",
       "      <td>-0.327670</td>\n",
       "      <td>-0.672998</td>\n",
       "      <td>0.344430</td>\n",
       "      <td>-0.719048</td>\n",
       "      <td>-1.464245</td>\n",
       "      <td>-0.448880</td>\n",
       "      <td>-0.693293</td>\n",
       "      <td>-0.848273</td>\n",
       "      <td>-1.023809</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.943238</td>\n",
       "      <td>-0.254094</td>\n",
       "      <td>3.613094</td>\n",
       "      <td>3.157858</td>\n",
       "      <td>5.522921</td>\n",
       "      <td>-2.228664</td>\n",
       "      <td>-0.210687</td>\n",
       "      <td>0.903948</td>\n",
       "      <td>0.636712</td>\n",
       "      <td>0.498527</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             m1lenmin  m1citywt    m1e1d1    m1e1d2    m1e1d3     m1i2a  \\\n",
       "challengeID                                                               \n",
       "1            0.364267  0.675623 -0.545055 -0.788818  0.183309  0.255698   \n",
       "2            0.364267 -0.197911  0.606432 -0.149595 -1.041256 -0.986483   \n",
       "3           -0.071568 -0.234372  0.990261  1.917563  1.345718 -1.464245   \n",
       "4           -0.507403 -0.327670 -0.672998  0.344430 -0.719048 -1.464245   \n",
       "5           -0.943238 -0.254094  3.613094  3.157858  5.522921 -2.228664   \n",
       "\n",
       "                m1i2b     m1j2a     m1j2b  cm1hhinc      ...        \\\n",
       "challengeID                                              ...         \n",
       "1           -0.245954 -1.512365  0.017524 -0.105330      ...         \n",
       "2           -0.080941 -1.497946 -0.168142 -0.377045      ...         \n",
       "3           -0.448880  0.893159 -0.660072  3.089933      ...         \n",
       "4           -0.448880 -0.693293 -0.848273 -1.023809      ...         \n",
       "5           -0.210687  0.903948  0.636712  0.498527      ...         \n",
       "\n",
       "             hv4mflag_1.0  hv4mflag_2.0  hv4mflag_3.0  hv4mompreg_0.0  \\\n",
       "challengeID                                                             \n",
       "1                       0             0             0               1   \n",
       "2                       0             0             0               0   \n",
       "3                       0             0             0               1   \n",
       "4                       0             0             0               1   \n",
       "5                       0             0             0               1   \n",
       "\n",
       "             hv4mompreg_1.0  hv4selfht_0.0  hv4selfht_1.0  hv4selfht_2.0  \\\n",
       "challengeID                                                                \n",
       "1                         0              1              0              0   \n",
       "2                         1              1              0              0   \n",
       "3                         0              1              0              0   \n",
       "4                         0              1              0              0   \n",
       "5                         0              1              0              0   \n",
       "\n",
       "             hv4selfwt_0.0  hv4selfwt_1.0  \n",
       "challengeID                                \n",
       "1                        1              0  \n",
       "2                        1              0  \n",
       "3                        1              0  \n",
       "4                        1              0  \n",
       "5                        1              0  \n",
       "\n",
       "[5 rows x 16391 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_dummies # rename X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now splitting the X and y matrices to separate cases in the training set and the prediction set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=X.loc[X.index.isin(train.index)]\n",
    "X_pred=X.loc[~X.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training=y.loc[y.index.isin(train.index)]\n",
    "y_pred=y.loc[~y.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly splitting the data into training and test sets, where 20% of data is held out for validation and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training.gpa, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing these files for later\n",
    "X_test.to_csv('../data/X_test.csv')\n",
    "pd.Series(cat_cols).to_csv('../data/cat_cols.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function that can be used to return Keras models with different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(activation_function, num_hidden_layers, hidden_layer_size):\n",
    "    '''\n",
    "    A function to create a Keras sequential model based on input parameters.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        activation_function: str\n",
    "            Activation function to be used in model.\n",
    "        \n",
    "        num_hidden_layers: int\n",
    "            Number of hidden layers in model\n",
    "        \n",
    "        hidden_layer_size: int\n",
    "            Number of units/neurons in each hidden layer\n",
    "            \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    Keras Sequential model object\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    # Single layer model\n",
    "    if num_hidden_layers == 0: # then just specify a single layer, 1 is size of output\n",
    "        model.add(Dense(1, \n",
    "                        input_dim=X_train.shape[1], \n",
    "                        activation=activation_function,\n",
    "                        use_bias=True,\n",
    "                        kernel_initializer=glorot_uniform(seed=seed)\n",
    "                      ))\n",
    "        \n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # Specify initial layer with a hidden layer\n",
    "    if num_hidden_layers >= 1: \n",
    "        model.add(Dense(hidden_layer_size, \n",
    "                        input_dim=X_train.shape[1], \n",
    "                        activation=activation_function,\n",
    "                        use_bias=True,\n",
    "                        kernel_initializer=glorot_uniform(seed=seed)\n",
    "                       ))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # Now add additional hidden layers\n",
    "    for i in range(0,num_hidden_layers-1):\n",
    "        model.add(Dense(hidden_layer_size, \n",
    "                        activation=activation_function, \n",
    "                        use_bias=True,\n",
    "                        kernel_initializer=glorot_uniform(seed=seed)\n",
    "                       ))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    if num_hidden_layers > 0:       \n",
    "        model.add(Dense(1)) # Final output layer, don't add if no hidden layers\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I take the model object and use it to initialize a classifier using the scikit-learn Keras wrapped object `KerasRegressor`.\n",
    "\n",
    "I then define the parameter space to search over and pass both to a `GridSearchCV` object. \n",
    "\n",
    "Once the `fit` method is called the grid search will begin and a model will fit for every parameter combination and fold (40 x 5). \n",
    "\n",
    "***Note: This will take 12 hours or more to complete***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 1s 709us/step - loss: 6.4296 - val_loss: 4.8262\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s 331us/step - loss: 4.9436 - val_loss: 4.2420\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s 320us/step - loss: 4.4581 - val_loss: 1.7558\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s 309us/step - loss: 4.4953 - val_loss: 2.5836\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s 315us/step - loss: 4.1684 - val_loss: 2.0484\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s 300us/step - loss: 4.1964 - val_loss: 3.6912\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s 301us/step - loss: 4.2806 - val_loss: 2.3024\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s 295us/step - loss: 4.1932 - val_loss: 1.4968\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s 295us/step - loss: 4.0827 - val_loss: 2.4534\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s 288us/step - loss: 4.3869 - val_loss: 3.2989\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s 279us/step - loss: 4.3084 - val_loss: 3.0933\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s 279us/step - loss: 4.7422 - val_loss: 2.8316\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s 284us/step - loss: 4.4338 - val_loss: 1.3228\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s 279us/step - loss: 5.1249 - val_loss: 1.5799\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s 287us/step - loss: 5.0591 - val_loss: 1.6840\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 5.2763 - val_loss: 0.6092\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s 289us/step - loss: 6.5143 - val_loss: 1.9324\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s 285us/step - loss: 5.5017 - val_loss: 3.5142\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s 287us/step - loss: 5.1971 - val_loss: 2.0613\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s 286us/step - loss: 4.7897 - val_loss: 2.5431\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s 291us/step - loss: 4.8283 - val_loss: 3.2788\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s 287us/step - loss: 4.3368 - val_loss: 1.5934\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s 286us/step - loss: 4.2965 - val_loss: 1.5069\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.3838 - val_loss: 2.0729\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.4691 - val_loss: 2.5318\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s 280us/step - loss: 4.3392 - val_loss: 2.7126\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 0s 289us/step - loss: 4.3060 - val_loss: 2.7903\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 0s 300us/step - loss: 4.3425 - val_loss: 3.7025\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 0s 288us/step - loss: 4.2502 - val_loss: 2.6415\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 0s 284us/step - loss: 4.5320 - val_loss: 2.2865\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.4807 - val_loss: 3.5155\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 0s 296us/step - loss: 4.1244 - val_loss: 2.9809\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 0s 291us/step - loss: 4.3095 - val_loss: 2.4829\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 0s 286us/step - loss: 4.1562 - val_loss: 3.3211\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.2728 - val_loss: 2.1937\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 0s 282us/step - loss: 4.4128 - val_loss: 2.0268\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 0s 293us/step - loss: 4.2515 - val_loss: 2.0236\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 0s 296us/step - loss: 4.4300 - val_loss: 1.8666\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 0s 282us/step - loss: 4.1950 - val_loss: 3.9526\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 0s 287us/step - loss: 4.4756 - val_loss: 1.4535\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 0s 279us/step - loss: 4.6788 - val_loss: 2.4403\n",
      "Epoch 00041: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  18.1s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 688us/step - loss: 6.0957 - val_loss: 3.0506\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 279us/step - loss: 4.6036 - val_loss: 1.8168\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.2620 - val_loss: 1.5800\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.3479 - val_loss: 2.4660\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 278us/step - loss: 4.2227 - val_loss: 1.6709\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.3238 - val_loss: 1.6910\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.0148 - val_loss: 2.2708\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 276us/step - loss: 4.4484 - val_loss: 2.1535\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.5484 - val_loss: 1.3061\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.4454 - val_loss: 1.4654\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.8468 - val_loss: 2.9616\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.9405 - val_loss: 3.1663\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 5.1754 - val_loss: 2.5929\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 5.1112 - val_loss: 2.0359\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.9491 - val_loss: 4.8229\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.6955 - val_loss: 2.8437\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 273us/step - loss: 4.8583 - val_loss: 4.2527\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 5.0394 - val_loss: 2.7766\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 6.0597 - val_loss: 5.1036\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 284us/step - loss: 6.0829 - val_loss: 0.6542\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 281us/step - loss: 5.9698 - val_loss: 1.8770\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 5.5247 - val_loss: 4.9476\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 5.1825 - val_loss: 4.1295\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 5.0359 - val_loss: 1.2279\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.9013 - val_loss: 1.9758\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.4486 - val_loss: 2.4892\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 4.4763 - val_loss: 1.9675\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.1825 - val_loss: 3.0752\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.2517 - val_loss: 2.7703\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.0978 - val_loss: 2.2182\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s 317us/step - loss: 4.0112 - val_loss: 2.1697\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.0722 - val_loss: 2.2874\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.1092 - val_loss: 2.6774\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.0504 - val_loss: 2.2329\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.0351 - val_loss: 2.5919\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 4.1682 - val_loss: 2.1488\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.0856 - val_loss: 2.7706\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.1142 - val_loss: 2.8750\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 3.9796 - val_loss: 2.1531\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.0489 - val_loss: 2.5090\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 4.0170 - val_loss: 2.0601\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.1897 - val_loss: 2.6758\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 0s 278us/step - loss: 4.1340 - val_loss: 2.3129\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.1141 - val_loss: 1.4139\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.2575 - val_loss: 2.0615\n",
      "Epoch 00045: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  19.5s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 715us/step - loss: 5.7260 - val_loss: 1.2340\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.6184 - val_loss: 3.0465\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.5468 - val_loss: 2.0166\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.5208 - val_loss: 2.1439\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.4349 - val_loss: 4.7781\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 284us/step - loss: 4.6787 - val_loss: 2.0187\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.7371 - val_loss: 2.6088\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.6978 - val_loss: 5.4047\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5120 - val_loss: 1.7353\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.5539 - val_loss: 2.6829\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.5442 - val_loss: 3.2628\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 270us/step - loss: 4.6933 - val_loss: 2.5080\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 277us/step - loss: 4.6252 - val_loss: 2.0240\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 281us/step - loss: 4.3409 - val_loss: 1.6432\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.7881 - val_loss: 2.5775\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.7599 - val_loss: 2.1059\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.7272 - val_loss: 2.1487\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.5518 - val_loss: 2.5710\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.4124 - val_loss: 3.1633\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5803 - val_loss: 4.2107\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.9522 - val_loss: 2.9285\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.7888 - val_loss: 1.8311\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.8988 - val_loss: 2.3185\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.6205 - val_loss: 1.1632\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 4.6776 - val_loss: 1.4685\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.7133 - val_loss: 1.8746\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.7328 - val_loss: 2.1417\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.5022 - val_loss: 2.1189\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.5963 - val_loss: 3.3747\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.8392 - val_loss: 2.1718\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s 321us/step - loss: 4.8322 - val_loss: 5.2210\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s 311us/step - loss: 4.9672 - val_loss: 1.9668\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.8879 - val_loss: 3.0170\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.9058 - val_loss: 3.1592\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s 334us/step - loss: 4.9393 - val_loss: 5.9438\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s 345us/step - loss: 6.0738 - val_loss: 4.2573\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s 348us/step - loss: 5.6355 - val_loss: 2.4074\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s 316us/step - loss: 5.8021 - val_loss: 2.9422\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 5.2298 - val_loss: 2.3809\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.5340 - val_loss: 3.7318\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.7734 - val_loss: 2.4886\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.4614 - val_loss: 3.2783\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.2254 - val_loss: 1.3642\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.4882 - val_loss: 2.7658\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.2376 - val_loss: 2.7125\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.2442 - val_loss: 2.9568\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.0820 - val_loss: 2.2499\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.3347 - val_loss: 3.5581\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.3182 - val_loss: 1.4221\n",
      "Epoch 00049: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  21.9s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 752us/step - loss: 5.8825 - val_loss: 2.8513\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.4133 - val_loss: 1.5649\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.2626 - val_loss: 3.4279\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 305us/step - loss: 4.4628 - val_loss: 2.1712\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.3042 - val_loss: 1.3883\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.2191 - val_loss: 2.0117\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.1325 - val_loss: 1.1577\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.1025 - val_loss: 1.6815\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.4804 - val_loss: 2.1522\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 264us/step - loss: 4.4328 - val_loss: 3.5872\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.2831 - val_loss: 2.0882\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5053 - val_loss: 2.2726\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.4707 - val_loss: 2.3389\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.5785 - val_loss: 3.8920\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 5.4914 - val_loss: 0.5253\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 5.6697 - val_loss: 3.5777\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 5.0264 - val_loss: 2.5298\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 4.7602 - val_loss: 2.7118\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 5.3218 - val_loss: 4.5590\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 5.8243 - val_loss: 1.8221\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 5.7894 - val_loss: 1.8710\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 6.1337 - val_loss: 1.6971\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 5.6464 - val_loss: 2.2763\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 305us/step - loss: 4.9792 - val_loss: 0.9694\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.6987 - val_loss: 2.8539\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.5228 - val_loss: 2.8801\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.5632 - val_loss: 3.1735\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 3.9775 - val_loss: 2.5664\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.1555 - val_loss: 2.8610\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.4003 - val_loss: 2.6656\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s 278us/step - loss: 4.2405 - val_loss: 2.0534\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s 284us/step - loss: 4.2675 - val_loss: 2.9763\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.3367 - val_loss: 2.1770\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 3.9194 - val_loss: 2.6684\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.1111 - val_loss: 2.0701\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.0825 - val_loss: 2.6278\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.1228 - val_loss: 1.9177\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 3.8346 - val_loss: 2.4136\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 4.3219 - val_loss: 2.4609\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 4.1983 - val_loss: 3.3771\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  18.0s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 756us/step - loss: 6.2098 - val_loss: 3.6645\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.5596 - val_loss: 2.0642\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.3761 - val_loss: 2.0886\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 3.9886 - val_loss: 2.2863\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.2754 - val_loss: 2.0627\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.3819 - val_loss: 2.5320\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.1754 - val_loss: 3.2551\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.5497 - val_loss: 3.2580\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.1644 - val_loss: 1.7073\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.0456 - val_loss: 2.3010\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.3271 - val_loss: 2.1397\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.3089 - val_loss: 3.2785\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 305us/step - loss: 4.2859 - val_loss: 1.3657\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 0s 277us/step - loss: 4.7685 - val_loss: 1.0619\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.9116 - val_loss: 1.4717\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 277us/step - loss: 5.2904 - val_loss: 2.4846\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 6.5040 - val_loss: 3.2400\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 5.3430 - val_loss: 1.1114\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 5.3037 - val_loss: 2.7500\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 5.0563 - val_loss: 3.4381\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 4.6876 - val_loss: 2.9994\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.4423 - val_loss: 2.6856\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.7595 - val_loss: 1.7636\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.5022 - val_loss: 2.4071\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 322us/step - loss: 4.2910 - val_loss: 3.1859\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5631 - val_loss: 2.8529\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.4431 - val_loss: 3.0891\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.3989 - val_loss: 3.0446\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.5420 - val_loss: 2.6053\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s 284us/step - loss: 4.4380 - val_loss: 2.6949\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.1998 - val_loss: 1.7766\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s 301us/step - loss: 4.2304 - val_loss: 3.8685\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.5542 - val_loss: 1.9707\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.4798 - val_loss: 3.9891\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.5478 - val_loss: 3.1454\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s 281us/step - loss: 4.9496 - val_loss: 2.0272\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 5.1399 - val_loss: 2.3346\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s 310us/step - loss: 5.1239 - val_loss: 1.9422\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s 311us/step - loss: 5.4199 - val_loss: 1.2660\n",
      "Epoch 00039: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  17.6s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 1s 791us/step - loss: 4.5800 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s 293us/step - loss: 4.2786 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s 296us/step - loss: 4.3390 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s 288us/step - loss: 4.3442 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s 295us/step - loss: 4.7454 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s 292us/step - loss: 4.5345 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s 300us/step - loss: 4.4836 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s 297us/step - loss: 4.3472 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s 292us/step - loss: 4.4157 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s 288us/step - loss: 4.3258 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s 291us/step - loss: 4.4659 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s 305us/step - loss: 4.4379 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s 296us/step - loss: 4.4106 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s 306us/step - loss: 4.5367 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s 286us/step - loss: 4.4430 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.4806 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.4438 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s 292us/step - loss: 4.4644 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s 295us/step - loss: 4.5028 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s 309us/step - loss: 4.3361 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.4563 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s 292us/step - loss: 4.4836 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s 289us/step - loss: 4.6753 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s 287us/step - loss: 4.4482 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.4408 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s 289us/step - loss: 4.3582 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=  12.6s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 813us/step - loss: 4.4738 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.3949 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.4575 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.4406 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.4008 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.2468 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5312 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.3588 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.4163 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.3050 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.4281 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.2269 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 284us/step - loss: 4.3625 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.4074 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 4.3558 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.3787 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.3278 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.4855 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.3492 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.3949 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.3212 - val_loss: 3.4269\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 0s 305us/step - loss: 4.2497 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 309us/step - loss: 4.5128 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 314us/step - loss: 4.4995 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 326us/step - loss: 4.3028 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 4.4480 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=  12.5s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 861us/step - loss: 4.3690 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.5193 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.4183 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 4.5945 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.2739 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.3063 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.4788 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.4021 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 316us/step - loss: 4.2599 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 310us/step - loss: 4.4906 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.3144 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3520 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 278us/step - loss: 4.3056 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.5171 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.2046 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.3579 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.4397 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.3741 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.4132 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 324us/step - loss: 4.4574 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.4124 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 315us/step - loss: 4.4264 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.4721 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3174 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.5105 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.3417 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=  12.7s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 879us/step - loss: 4.5608 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 301us/step - loss: 4.2562 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 309us/step - loss: 4.2503 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 313us/step - loss: 4.4632 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.2282 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.4854 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 4.4890 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.2849 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.5163 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.5001 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 313us/step - loss: 4.5001 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.2215 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.3903 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.3402 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.4728 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.5546 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3638 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.3873 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.4279 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.3940 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.3726 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.3446 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 277us/step - loss: 4.3918 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 279us/step - loss: 4.4013 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.5156 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 281us/step - loss: 4.2982 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=  12.9s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 906us/step - loss: 4.4502 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 305us/step - loss: 4.2884 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.3731 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3532 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.4527 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.4490 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 301us/step - loss: 4.3996 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.3171 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.4276 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.2722 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.3547 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.4350 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.2898 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.4836 - val_loss: 3.4269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.5190 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 301us/step - loss: 4.6487 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.2965 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.3061 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.3716 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 4.2559 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.3024 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.3945 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.5249 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.3230 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.4785 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.3311 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=  12.7s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 1s 940us/step - loss: 8.0421 - val_loss: 8.0093\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s 358us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s 327us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s 328us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s 351us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s 343us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s 347us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s 318us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s 325us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s 362us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s 313us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s 309us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s 320us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s 321us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s 292us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s 301us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s 341us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s 331us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s 306us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s 316us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s 300us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s 303us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s 297us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s 315us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s 336us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s 340us/step - loss: 8.0020 - val_loss: 8.0093\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  13.8s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 983us/step - loss: 8.2067 - val_loss: 8.0093\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 324us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 313us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 330us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 318us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 333us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 339us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 341us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 314us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 326us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 320us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 335us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 348us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 334us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 313us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 319us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 316us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 317us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 306us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 342us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 333us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 327us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 335us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 351us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 353us/step - loss: 7.9704 - val_loss: 8.0093\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  14.0s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 1ms/step - loss: 8.1150 - val_loss: 8.0093\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 348us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 360us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 365us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 339us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 346us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 337us/step - loss: 8.0226 - val_loss: 8.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 351us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 368us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 336us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 361us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 354us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 331us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 316us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 361us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 335us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 331us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 314us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 351us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 323us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 346us/step - loss: 8.0226 - val_loss: 8.0093\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  14.3s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 1ms/step - loss: 8.1692 - val_loss: 8.0093\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 334us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 333us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 340us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 346us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 330us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 340us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 340us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 333us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 344us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s 372us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 345us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 328us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 322us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 334us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 326us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 311us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 339us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 335us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 351us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 344us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 329us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 344us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 366us/step - loss: 7.9437 - val_loss: 8.0093\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  14.6s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 1ms/step - loss: 8.2564 - val_loss: 8.0093\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 346us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 345us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 360us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 357us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 364us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s 370us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 341us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 346us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 330us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 352us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 352us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 340us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 305us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 327us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 344us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 333us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 353us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s 374us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 368us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 345us/step - loss: 7.9457 - val_loss: 8.0093\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  14.5s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 1s 1ms/step - loss: 4.4823 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s 277us/step - loss: 4.3560 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s 284us/step - loss: 4.4062 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s 289us/step - loss: 4.5013 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s 294us/step - loss: 4.5087 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s 278us/step - loss: 4.4393 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s 285us/step - loss: 4.2491 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.4770 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s 288us/step - loss: 4.5448 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s 287us/step - loss: 4.3368 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.4194 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s 276us/step - loss: 4.4924 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.5212 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s 284us/step - loss: 4.5743 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s 294us/step - loss: 4.4423 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s 291us/step - loss: 4.4954 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s 302us/step - loss: 4.2100 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s 294us/step - loss: 4.5079 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.7594 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s 293us/step - loss: 4.4622 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s 290us/step - loss: 4.2801 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s 296us/step - loss: 4.5964 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s 283us/step - loss: 4.3767 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s 292us/step - loss: 4.4725 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s 289us/step - loss: 4.3118 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s 301us/step - loss: 4.5537 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  12.8s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 1ms/step - loss: 4.5648 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.3684 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.4561 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 275us/step - loss: 4.3411 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3610 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 283us/step - loss: 4.4369 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.5091 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 278us/step - loss: 4.4509 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.4391 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 293us/step - loss: 4.3448 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.5710 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.5040 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.4944 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.5379 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 288us/step - loss: 4.3728 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.4325 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.2821 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 287us/step - loss: 4.3551 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 274us/step - loss: 4.2505 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 279us/step - loss: 4.3890 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.5165 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.5099 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 277us/step - loss: 4.4185 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.2328 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 284us/step - loss: 4.3706 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.4281 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  12.8s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s 1ms/step - loss: 4.4528 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.3719 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.5385 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 280us/step - loss: 4.6490 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5267 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.3491 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 301us/step - loss: 4.4522 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.6217 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.3638 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 304us/step - loss: 4.3402 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 309us/step - loss: 4.4441 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.5687 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.2444 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.4994 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 309us/step - loss: 4.5414 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.4552 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.4589 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.4272 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.5164 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.3741 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.2732 - val_loss: 3.4269\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.2194 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 286us/step - loss: 4.2798 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.5031 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 313us/step - loss: 4.4817 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 313us/step - loss: 4.5171 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  13.2s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.4701 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.2252 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.1508 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.4028 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 310us/step - loss: 4.3004 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.6055 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 4.4492 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.3792 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 307us/step - loss: 4.2068 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 303us/step - loss: 4.4168 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 323us/step - loss: 4.3181 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 335us/step - loss: 4.4006 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.1751 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.3579 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 298us/step - loss: 4.4795 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 304us/step - loss: 4.4242 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.1353 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.2694 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 285us/step - loss: 4.3918 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.4544 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 282us/step - loss: 4.2820 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 290us/step - loss: 4.4640 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.5310 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.2842 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 296us/step - loss: 4.3512 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 314us/step - loss: 4.3372 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  13.6s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.4872 - val_loss: 3.4269\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.4755 - val_loss: 3.4269\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.3237 - val_loss: 3.4269\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s 306us/step - loss: 4.4586 - val_loss: 3.4269\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s 302us/step - loss: 4.3304 - val_loss: 3.4269\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s 310us/step - loss: 4.3444 - val_loss: 3.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s 318us/step - loss: 4.3149 - val_loss: 3.4269\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s 304us/step - loss: 4.3156 - val_loss: 3.4269\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s 299us/step - loss: 4.3834 - val_loss: 3.4269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3237 - val_loss: 3.4269\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.4579 - val_loss: 3.4269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.4210 - val_loss: 3.4269\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s 289us/step - loss: 4.2147 - val_loss: 3.4269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.6686 - val_loss: 3.4269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s 292us/step - loss: 4.5013 - val_loss: 3.4269\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s 297us/step - loss: 4.2523 - val_loss: 3.4269\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s 301us/step - loss: 4.5301 - val_loss: 3.4269\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3296 - val_loss: 3.4269\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s 300us/step - loss: 4.4100 - val_loss: 3.4269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s 295us/step - loss: 4.3517 - val_loss: 3.4269\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 4.2869 - val_loss: 3.4269\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s 294us/step - loss: 4.3127 - val_loss: 3.4269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s 291us/step - loss: 4.4299 - val_loss: 3.4269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s 281us/step - loss: 4.4055 - val_loss: 3.4269\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s 308us/step - loss: 4.4313 - val_loss: 3.4269\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s 316us/step - loss: 4.2817 - val_loss: 3.4269\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  13.3s\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 3s 3ms/step - loss: 139.5937 - val_loss: 9.6590\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 10.5940 - val_loss: 1.7844\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 5.3475 - val_loss: 1.2201\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.7722 - val_loss: 0.8204\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.8944 - val_loss: 0.6853\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.0631 - val_loss: 0.6478\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.9207 - val_loss: 1.0529\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.8735 - val_loss: 0.6657\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.7627 - val_loss: 0.6215\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.9667 - val_loss: 0.7694\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.9267 - val_loss: 3.6839\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.5570 - val_loss: 0.8694\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.4964 - val_loss: 1.1888\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.8344 - val_loss: 0.7548\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 2s 1ms/step - loss: 3.1400 - val_loss: 1.0749\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.8403 - val_loss: 0.6830\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.8642 - val_loss: 2.0848\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 3.6743 - val_loss: 1.6575\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 10.2814 - val_loss: 3.9179\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 8.8639 - val_loss: 1.6375\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 6.5068 - val_loss: 3.2331\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 3.5001 - val_loss: 0.6317\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.2566 - val_loss: 3.1782\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.2154 - val_loss: 0.5232\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.9935 - val_loss: 0.9671\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 2.2522 - val_loss: 1.1745\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.8550 - val_loss: 0.9021\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.3260 - val_loss: 0.8252\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.4952 - val_loss: 0.6137\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.2522 - val_loss: 0.8853\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.4079 - val_loss: 0.5607\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.1848 - val_loss: 0.3631\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.0903 - val_loss: 0.4161\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.9150 - val_loss: 0.6282\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.0062 - val_loss: 1.0631\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 1.1059 - val_loss: 0.3255\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.8247 - val_loss: 0.3974\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.7335 - val_loss: 0.4028\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.7962 - val_loss: 0.4182\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.9058 - val_loss: 0.3259\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6741 - val_loss: 0.3940\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.7280 - val_loss: 0.3292\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6412 - val_loss: 0.3705\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.7806 - val_loss: 0.3223\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.8540 - val_loss: 0.5937\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6833 - val_loss: 0.2755\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5810 - val_loss: 0.6024\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5521 - val_loss: 0.2783\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.4942 - val_loss: 0.2667\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5351 - val_loss: 0.4976\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5171 - val_loss: 0.2862\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5036 - val_loss: 0.2638\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.4154 - val_loss: 0.2679\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.4267 - val_loss: 0.4914\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.4280 - val_loss: 0.2635\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3969 - val_loss: 0.2571\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.4032 - val_loss: 0.2537\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3480 - val_loss: 0.2477\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3447 - val_loss: 0.2278\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3837 - val_loss: 0.2362\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3464 - val_loss: 0.3126\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3522 - val_loss: 0.2636\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3313 - val_loss: 0.2227\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3505 - val_loss: 0.5359\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3587 - val_loss: 0.2229\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2770 - val_loss: 0.2749\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.3298 - val_loss: 0.2266\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2895 - val_loss: 0.2659\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2847 - val_loss: 0.2153\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2414 - val_loss: 0.2015\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2420 - val_loss: 0.2540\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2645 - val_loss: 0.2510\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2585 - val_loss: 0.2074\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2118 - val_loss: 0.2067\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2255 - val_loss: 0.2370\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2390 - val_loss: 0.2260\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2277 - val_loss: 0.2059\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2397 - val_loss: 0.2514\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2102 - val_loss: 0.2472\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2037 - val_loss: 0.2062\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2124 - val_loss: 0.1988\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2122 - val_loss: 0.2091\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2025 - val_loss: 0.2072\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1967 - val_loss: 0.2045\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2096 - val_loss: 0.2266\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1979 - val_loss: 0.2116\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2127 - val_loss: 0.3480\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.2512 - val_loss: 0.2289\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1938 - val_loss: 0.1916\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1843 - val_loss: 0.2216\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1859 - val_loss: 0.1956\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1720 - val_loss: 0.1902\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1697 - val_loss: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1651 - val_loss: 0.1962\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1672 - val_loss: 0.2181\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1719 - val_loss: 0.1950\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1555 - val_loss: 0.2085\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1517 - val_loss: 0.2142\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1665 - val_loss: 0.1884\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1460 - val_loss: 0.1907\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1554 - val_loss: 0.1908\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1762 - val_loss: 0.2127\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1682 - val_loss: 0.2005\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1560 - val_loss: 0.1869\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1455 - val_loss: 0.1940\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1459 - val_loss: 0.1882\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1442 - val_loss: 0.1845\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1562 - val_loss: 0.1882\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1304 - val_loss: 0.1911\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1561 - val_loss: 0.2420\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1744 - val_loss: 0.1917\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1410 - val_loss: 0.1934\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1340 - val_loss: 0.1918\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1189 - val_loss: 0.1934\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1382 - val_loss: 0.1882\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1297 - val_loss: 0.1930\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1302 - val_loss: 0.1881\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1262 - val_loss: 0.1900\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1278 - val_loss: 0.1910\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1354 - val_loss: 0.1934\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1348 - val_loss: 0.1896\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1334 - val_loss: 0.1904\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1347 - val_loss: 0.1852\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1292 - val_loss: 0.1920\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1192 - val_loss: 0.2046\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1232 - val_loss: 0.2026\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1313 - val_loss: 0.1925\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1220 - val_loss: 0.1893\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1239 - val_loss: 0.1918\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1219 - val_loss: 0.1875\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1127 - val_loss: 0.1963\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.1212 - val_loss: 0.2044\n",
      "Epoch 00132: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s 3ms/step - loss: 151.2870 - val_loss: 5.7299\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 12.4487 - val_loss: 2.6415\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.6505 - val_loss: 1.0614\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.7719 - val_loss: 0.7609\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.0392 - val_loss: 1.0372\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.0402 - val_loss: 0.8573\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.8651 - val_loss: 1.6753\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.2812 - val_loss: 0.7920\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9584 - val_loss: 1.6197\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9027 - val_loss: 1.2415\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.2986 - val_loss: 1.3465\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.7807 - val_loss: 0.6694\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.9620 - val_loss: 2.7207\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.2451 - val_loss: 1.0317\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.2734 - val_loss: 1.6146\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.7675 - val_loss: 1.4619\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.5272 - val_loss: 1.8546\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.0709 - val_loss: 6.5791\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 10.6198 - val_loss: 10.8122\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 18.6921 - val_loss: 7.3133\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 9.5515 - val_loss: 10.8551\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.1930 - val_loss: 2.7001\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.0872 - val_loss: 1.0227\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.2823 - val_loss: 0.4919\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.2292 - val_loss: 1.7191\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 5.0343 - val_loss: 1.5843\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.8146 - val_loss: 0.4346\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.2430 - val_loss: 0.3751\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.3582 - val_loss: 0.6705\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.2992 - val_loss: 0.5465\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0623 - val_loss: 0.4275\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9518 - val_loss: 0.3738\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.2744 - val_loss: 0.5016\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.6886 - val_loss: 1.1333\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.5277 - val_loss: 0.3614\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9779 - val_loss: 0.5738\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8776 - val_loss: 0.3513\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7300 - val_loss: 0.3241\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9750 - val_loss: 0.5352\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6988 - val_loss: 0.3299\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6027 - val_loss: 0.3274\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6456 - val_loss: 0.3166\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5771 - val_loss: 0.3026\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4775 - val_loss: 0.3287\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5565 - val_loss: 0.3465\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5533 - val_loss: 0.3519\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6279 - val_loss: 0.2748\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5553 - val_loss: 0.3513\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5066 - val_loss: 0.3414\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5231 - val_loss: 0.4668\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5103 - val_loss: 0.2927\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6612 - val_loss: 0.3326\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4965 - val_loss: 0.3069\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4693 - val_loss: 0.2804\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3863 - val_loss: 0.2550\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4186 - val_loss: 0.3612\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4424 - val_loss: 0.5740\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4449 - val_loss: 0.2702\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4437 - val_loss: 0.4973\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4005 - val_loss: 0.2582\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3858 - val_loss: 0.2486\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4290 - val_loss: 0.3599\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4161 - val_loss: 0.3167\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4918 - val_loss: 0.3213\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5774 - val_loss: 0.8828\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5843 - val_loss: 0.2687\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4896 - val_loss: 0.2558\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4528 - val_loss: 0.6727\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3733 - val_loss: 0.2816\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3420 - val_loss: 0.2707\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2961 - val_loss: 0.2192\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2536 - val_loss: 0.2080\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2740 - val_loss: 0.2589\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2778 - val_loss: 0.2209\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2843 - val_loss: 0.2126\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2601 - val_loss: 0.2320\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2710 - val_loss: 0.2692\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2463 - val_loss: 0.2146\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2285 - val_loss: 0.2321\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2317 - val_loss: 0.2808\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2220 - val_loss: 0.2186\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2795 - val_loss: 0.2143\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2320 - val_loss: 0.2209\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2383 - val_loss: 0.2207\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2258 - val_loss: 0.2029\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2164 - val_loss: 0.2087\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2053 - val_loss: 0.2208\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2089 - val_loss: 0.2068\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2158 - val_loss: 0.2008\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2031 - val_loss: 0.2216\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1874 - val_loss: 0.1945\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1954 - val_loss: 0.2539\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1846 - val_loss: 0.2038\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1780 - val_loss: 0.1941\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1763 - val_loss: 0.2057\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1736 - val_loss: 0.2043\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1904 - val_loss: 0.2140\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1641 - val_loss: 0.2117\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1738 - val_loss: 0.2666\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1729 - val_loss: 0.2154\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1903 - val_loss: 0.2048\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1574 - val_loss: 0.2280\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1650 - val_loss: 0.2104\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1621 - val_loss: 0.2180\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1516 - val_loss: 0.1911\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1530 - val_loss: 0.2142\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1427 - val_loss: 0.1919\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1446 - val_loss: 0.2096\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1639 - val_loss: 0.1901\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1813 - val_loss: 0.2158\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1400 - val_loss: 0.1908\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1476 - val_loss: 0.1874\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1545 - val_loss: 0.1909\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1476 - val_loss: 0.1858\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1291 - val_loss: 0.2252\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1565 - val_loss: 0.1847\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1501 - val_loss: 0.2051\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1443 - val_loss: 0.2120\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1441 - val_loss: 0.1860\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1407 - val_loss: 0.1891\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1278 - val_loss: 0.2030\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1245 - val_loss: 0.1970\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1388 - val_loss: 0.1873\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1373 - val_loss: 0.1827\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1257 - val_loss: 0.1805\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1323 - val_loss: 0.1820\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1411 - val_loss: 0.2080\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1233 - val_loss: 0.1998\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1275 - val_loss: 0.1955\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1249 - val_loss: 0.1802\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1187 - val_loss: 0.1980\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1204 - val_loss: 0.1803\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1248 - val_loss: 0.1820\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1189 - val_loss: 0.1842\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1193 - val_loss: 0.1975\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1190 - val_loss: 0.1934\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1238 - val_loss: 0.1811\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1248 - val_loss: 0.1790\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1201 - val_loss: 0.2680\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1172 - val_loss: 0.1881\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1212 - val_loss: 0.1856\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1145 - val_loss: 0.1846\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1160 - val_loss: 0.2690\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1144 - val_loss: 0.2060\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1191 - val_loss: 0.1810\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1124 - val_loss: 0.1812\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1158 - val_loss: 0.1830\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1120 - val_loss: 0.2184\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1230 - val_loss: 0.1900\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1104 - val_loss: 0.1986\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0981 - val_loss: 0.1844\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1052 - val_loss: 0.2049\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1034 - val_loss: 0.1816\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0986 - val_loss: 0.2062\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1063 - val_loss: 0.1849\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1068 - val_loss: 0.2208\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1009 - val_loss: 0.1891\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0946 - val_loss: 0.1939\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0992 - val_loss: 0.1803\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0965 - val_loss: 0.2229\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1038 - val_loss: 0.1816\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0989 - val_loss: 0.2288\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1208 - val_loss: 0.2968\n",
      "Epoch 00163: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 5.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 131.9452 - val_loss: 8.0479\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 8.1449 - val_loss: 1.9124\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.4441 - val_loss: 1.5726\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.2905 - val_loss: 0.6477\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.3682 - val_loss: 1.4495\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9053 - val_loss: 0.7330\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1171 - val_loss: 0.9367\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9134 - val_loss: 0.7552\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9892 - val_loss: 1.6169\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.7302 - val_loss: 0.8981\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6777 - val_loss: 1.8722\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.4850 - val_loss: 1.1426\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.6311 - val_loss: 3.8836\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 5.2794 - val_loss: 4.5253\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 6.0400 - val_loss: 2.9869\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.7096 - val_loss: 2.1652\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.6871 - val_loss: 0.9111\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.2608 - val_loss: 1.2339\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.5640 - val_loss: 1.1375\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1296 - val_loss: 0.5425\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.3901 - val_loss: 2.4632\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.4116 - val_loss: 0.8240\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.2284 - val_loss: 1.6240\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.2024 - val_loss: 1.5736\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 5.7761 - val_loss: 2.7233\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 6.9533 - val_loss: 17.6119\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 18.4910 - val_loss: 3.1315\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 10.0930 - val_loss: 1.2877\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.5939 - val_loss: 0.6850\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.7550 - val_loss: 0.9222\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.4485 - val_loss: 0.5916\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1200 - val_loss: 0.3590\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.4599 - val_loss: 0.3426\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0628 - val_loss: 0.4065\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7315 - val_loss: 0.2929\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8510 - val_loss: 0.5675\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7671 - val_loss: 0.4865\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1374 - val_loss: 1.0106\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7430 - val_loss: 0.3176\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5723 - val_loss: 0.3512\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7271 - val_loss: 0.3079\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5522 - val_loss: 0.2390\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5325 - val_loss: 0.3325\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6008 - val_loss: 0.4418\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5085 - val_loss: 0.3073\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5251 - val_loss: 0.4316\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4910 - val_loss: 0.2845\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0037 - val_loss: 0.3169\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4373 - val_loss: 0.2691\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3623 - val_loss: 0.2190\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5295 - val_loss: 0.2548\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5493 - val_loss: 0.3432\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7544 - val_loss: 0.2530\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4488 - val_loss: 0.3372\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5091 - val_loss: 0.2231\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3047 - val_loss: 0.2157\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2611 - val_loss: 0.2143\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3764 - val_loss: 0.2022\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3064 - val_loss: 0.2047\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2973 - val_loss: 0.2984\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3663 - val_loss: 0.2204\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2635 - val_loss: 0.2125\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2752 - val_loss: 0.2043\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2538 - val_loss: 0.1989\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2795 - val_loss: 0.2283\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3165 - val_loss: 0.2400\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2429 - val_loss: 0.2005\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3853 - val_loss: 0.2155\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2789 - val_loss: 0.2017\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2506 - val_loss: 0.2004\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2253 - val_loss: 0.2077\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2260 - val_loss: 0.2092\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2275 - val_loss: 0.2190\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2179 - val_loss: 0.2953\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4022 - val_loss: 0.2116\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2564 - val_loss: 0.2076\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2234 - val_loss: 0.2018\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2419 - val_loss: 0.2111\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2187 - val_loss: 0.3450\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2477 - val_loss: 0.2129\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2478 - val_loss: 0.2095\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2235 - val_loss: 0.2061\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1862 - val_loss: 0.2039\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2090 - val_loss: 0.2453\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2076 - val_loss: 0.2019\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1978 - val_loss: 0.2199\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2164 - val_loss: 0.2433\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2152 - val_loss: 0.2119\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2291 - val_loss: 0.2074\n",
      "Epoch 00089: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 3.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 77.5689 - val_loss: 2.2622\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 5.0780 - val_loss: 1.2400\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.5001 - val_loss: 0.5261\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.7701 - val_loss: 0.5420\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.6155 - val_loss: 0.4454\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.2599 - val_loss: 0.4059\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0983 - val_loss: 0.9080\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.1827 - val_loss: 0.7329\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.3076 - val_loss: 0.3998\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.3814 - val_loss: 0.5890\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.2808 - val_loss: 0.5951\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.1756 - val_loss: 0.4063\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.4608 - val_loss: 0.6433\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.8525 - val_loss: 0.7918\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1200 - val_loss: 0.5359\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9316 - val_loss: 0.7029\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9894 - val_loss: 1.4003\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.4363 - val_loss: 2.4503\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.5044 - val_loss: 0.7378\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4630 - val_loss: 0.5558\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1051 - val_loss: 1.1514\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.8061 - val_loss: 1.9685\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.5197 - val_loss: 0.6503\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.5297 - val_loss: 0.5320\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.0010 - val_loss: 1.4159\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.6522 - val_loss: 2.0891\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.6242 - val_loss: 0.5418\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.3094 - val_loss: 0.5652\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9888 - val_loss: 0.3797\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9372 - val_loss: 0.2723\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7315 - val_loss: 0.3196\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7320 - val_loss: 0.2627\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9083 - val_loss: 0.2731\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7111 - val_loss: 0.2461\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5778 - val_loss: 0.2564\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5569 - val_loss: 0.2618\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5038 - val_loss: 0.2790\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5395 - val_loss: 0.2714\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6027 - val_loss: 0.2681\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4342 - val_loss: 0.2547\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3742 - val_loss: 0.3229\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4015 - val_loss: 0.3953\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3871 - val_loss: 0.2211\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3609 - val_loss: 0.3250\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3786 - val_loss: 0.2164\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4334 - val_loss: 0.2245\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3032 - val_loss: 0.2236\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3893 - val_loss: 0.3069\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3035 - val_loss: 0.2053\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3246 - val_loss: 0.1919\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3152 - val_loss: 0.2284\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2808 - val_loss: 0.2120\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2775 - val_loss: 0.1951\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2933 - val_loss: 0.2260\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2829 - val_loss: 0.2240\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2649 - val_loss: 0.2471\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2464 - val_loss: 0.2294\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2422 - val_loss: 0.2024\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2602 - val_loss: 0.1986\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2286 - val_loss: 0.1891\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2371 - val_loss: 0.2616\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2521 - val_loss: 0.2215\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2445 - val_loss: 0.2044\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2116 - val_loss: 0.1958\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2206 - val_loss: 0.1917\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2093 - val_loss: 0.2045\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2516 - val_loss: 0.3439\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2045 - val_loss: 0.1788\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1834 - val_loss: 0.1840\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1845 - val_loss: 0.1933\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1801 - val_loss: 0.2101\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1728 - val_loss: 0.1779\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1775 - val_loss: 0.2228\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1668 - val_loss: 0.1963\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1695 - val_loss: 0.1828\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1964 - val_loss: 0.2638\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1638 - val_loss: 0.1843\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1688 - val_loss: 0.1866\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1610 - val_loss: 0.2098\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1651 - val_loss: 0.1970\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1623 - val_loss: 0.1867\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1639 - val_loss: 0.1875\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1604 - val_loss: 0.1876\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1540 - val_loss: 0.1847\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1432 - val_loss: 0.1846\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1608 - val_loss: 0.1858\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1582 - val_loss: 0.1854\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1553 - val_loss: 0.1808\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1594 - val_loss: 0.1767\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1432 - val_loss: 0.1780\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1391 - val_loss: 0.1937\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1497 - val_loss: 0.1852\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1348 - val_loss: 0.2002\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1470 - val_loss: 0.1957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1359 - val_loss: 0.1801\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1397 - val_loss: 0.1779\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1503 - val_loss: 0.1916\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1383 - val_loss: 0.1783\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1345 - val_loss: 0.1763\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1264 - val_loss: 0.1756\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1331 - val_loss: 0.2100\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1341 - val_loss: 0.1822\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1239 - val_loss: 0.1777\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1316 - val_loss: 0.1704\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1268 - val_loss: 0.2006\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1246 - val_loss: 0.2331\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1303 - val_loss: 0.1748\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1199 - val_loss: 0.1768\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1288 - val_loss: 0.1933\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1268 - val_loss: 0.1979\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1265 - val_loss: 0.1788\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1436 - val_loss: 0.1924\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1230 - val_loss: 0.1763\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1244 - val_loss: 0.2071\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1273 - val_loss: 0.1769\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1202 - val_loss: 0.1861\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1289 - val_loss: 0.1806\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1242 - val_loss: 0.1719\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1171 - val_loss: 0.1728\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1312 - val_loss: 0.1904\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1211 - val_loss: 0.1698\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1285 - val_loss: 0.2111\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1221 - val_loss: 0.2067\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1163 - val_loss: 0.1848\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1221 - val_loss: 0.1798\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1186 - val_loss: 0.2205\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1305 - val_loss: 0.1749\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1126 - val_loss: 0.1760\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.0985 - val_loss: 0.1764\n",
      "Epoch 00129: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 127.0743 - val_loss: 7.2682\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 8.0802 - val_loss: 2.0947\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.3790 - val_loss: 1.4803\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.7731 - val_loss: 0.8966\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.2245 - val_loss: 0.8809\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1342 - val_loss: 1.0178\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.9933 - val_loss: 0.8171\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.7968 - val_loss: 2.0815\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.1855 - val_loss: 1.4149\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.9839 - val_loss: 2.2618\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.4412 - val_loss: 1.7488\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.8205 - val_loss: 3.7059\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 8.6512 - val_loss: 5.9452\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7266 - val_loss: 5.3171\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7742 - val_loss: 5.9220\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 9.5665 - val_loss: 3.3722\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.8580 - val_loss: 0.8892\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 3.6929 - val_loss: 0.7278\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.8525 - val_loss: 0.8922\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.8430 - val_loss: 0.8592\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 4.5683 - val_loss: 0.9059\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.6115 - val_loss: 0.9963\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.1197 - val_loss: 0.8619\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 2.3842 - val_loss: 1.1083\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.5967 - val_loss: 0.4050\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2686 - val_loss: 0.4531\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.1932 - val_loss: 0.4894\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.5164 - val_loss: 0.5270\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0350 - val_loss: 0.3932\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9177 - val_loss: 0.5021\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8731 - val_loss: 0.3831\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0850 - val_loss: 0.5209\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.0164 - val_loss: 0.5016\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9368 - val_loss: 0.6528\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7908 - val_loss: 0.4516\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7896 - val_loss: 0.3543\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8698 - val_loss: 0.5732\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.4337 - val_loss: 0.6602\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 1.1254 - val_loss: 1.2595\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8934 - val_loss: 0.5039\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7289 - val_loss: 0.4200\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7534 - val_loss: 0.5099\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8578 - val_loss: 0.5248\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7665 - val_loss: 0.8819\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.9075 - val_loss: 0.4412\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6889 - val_loss: 0.2614\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.8173 - val_loss: 0.5221\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5892 - val_loss: 0.4228\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4562 - val_loss: 0.4550\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4307 - val_loss: 0.4058\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4236 - val_loss: 0.2540\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4323 - val_loss: 0.3418\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4379 - val_loss: 0.2840\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4019 - val_loss: 0.2631\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4431 - val_loss: 0.3373\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3811 - val_loss: 0.2358\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3627 - val_loss: 0.2261\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3830 - val_loss: 0.2607\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3424 - val_loss: 0.2398\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3206 - val_loss: 0.2234\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3667 - val_loss: 0.3875\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3889 - val_loss: 0.3065\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2957 - val_loss: 0.2375\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2790 - val_loss: 0.2080\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2759 - val_loss: 0.2821\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2471 - val_loss: 0.2192\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3244 - val_loss: 0.2517\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2944 - val_loss: 0.2260\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2783 - val_loss: 0.2211\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2606 - val_loss: 0.2323\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2552 - val_loss: 0.2603\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3309 - val_loss: 0.2255\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2671 - val_loss: 0.2038\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2592 - val_loss: 0.2077\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2264 - val_loss: 0.1968\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2249 - val_loss: 0.1940\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2418 - val_loss: 0.1960\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2258 - val_loss: 0.2341\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2243 - val_loss: 0.2513\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2231 - val_loss: 0.2419\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2104 - val_loss: 0.1978\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2251 - val_loss: 0.1949\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2094 - val_loss: 0.2230\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2393 - val_loss: 0.1853\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.2007 - val_loss: 0.2038\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1992 - val_loss: 0.1972\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1997 - val_loss: 0.1892\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1774 - val_loss: 0.2240\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1947 - val_loss: 0.1934\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1837 - val_loss: 0.1958\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1678 - val_loss: 0.1914\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1763 - val_loss: 0.2194\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1737 - val_loss: 0.1921\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1551 - val_loss: 0.1917\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1691 - val_loss: 0.2170\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1927 - val_loss: 0.1946\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1667 - val_loss: 0.2121\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1604 - val_loss: 0.1946\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1581 - val_loss: 0.1887\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1597 - val_loss: 0.1915\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1783 - val_loss: 0.1940\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1560 - val_loss: 0.1968\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1526 - val_loss: 0.2095\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1528 - val_loss: 0.1895\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1386 - val_loss: 0.1975\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1344 - val_loss: 0.2128\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1417 - val_loss: 0.1929\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1499 - val_loss: 0.1921\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.1462 - val_loss: 0.2257\n",
      "Epoch 00109: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 3.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 41.2245 - val_loss: 0.7326\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 13.1471 - val_loss: 1.1837\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 11.6090 - val_loss: 1.3787\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 16.7822 - val_loss: 0.3739\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 12.6730 - val_loss: 0.3320\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 12.1518 - val_loss: 0.7236\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 10.4232 - val_loss: 0.4845\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 9.7720 - val_loss: 1.0343\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 2s 2ms/step - loss: 8.8642 - val_loss: 0.5132\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.1454 - val_loss: 0.2207\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.9945 - val_loss: 0.2357\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.7700 - val_loss: 0.3502\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.2612 - val_loss: 0.3110\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.4542 - val_loss: 0.7236\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.9854 - val_loss: 0.4764\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.7028 - val_loss: 0.2134\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.3084 - val_loss: 0.5907\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.1834 - val_loss: 0.2258\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.2112 - val_loss: 0.3482\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.8028 - val_loss: 0.3774\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.5237 - val_loss: 0.2021\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.5559 - val_loss: 0.3562\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.4409 - val_loss: 0.2062\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2951 - val_loss: 0.3907\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2045 - val_loss: 0.1961\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9967 - val_loss: 0.2465\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9871 - val_loss: 0.2149\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8762 - val_loss: 0.2717\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8543 - val_loss: 0.2699\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7936 - val_loss: 0.1872\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7577 - val_loss: 0.2284\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7101 - val_loss: 0.2020\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6826 - val_loss: 0.2134\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5916 - val_loss: 0.2007\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6052 - val_loss: 0.1863\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5442 - val_loss: 0.1966\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5234 - val_loss: 0.2208\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5847 - val_loss: 0.2332\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5132 - val_loss: 0.2271\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4792 - val_loss: 0.1950\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4766 - val_loss: 0.1788\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4858 - val_loss: 0.1793\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4394 - val_loss: 0.2015\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4043 - val_loss: 0.2086\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3995 - val_loss: 0.2029\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3786 - val_loss: 0.1846\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3936 - val_loss: 0.1922\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3760 - val_loss: 0.2111\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3725 - val_loss: 0.1896\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3749 - val_loss: 0.1959\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3770 - val_loss: 0.1816\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3578 - val_loss: 0.1888\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3389 - val_loss: 0.1860\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3213 - val_loss: 0.1810\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3092 - val_loss: 0.2219\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3092 - val_loss: 0.1836\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3198 - val_loss: 0.1832\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2864 - val_loss: 0.1800\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3120 - val_loss: 0.2088\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2866 - val_loss: 0.1900\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2915 - val_loss: 0.2199\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2891 - val_loss: 0.1842\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2763 - val_loss: 0.2132\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2562 - val_loss: 0.1906\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2630 - val_loss: 0.1838\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2571 - val_loss: 0.1803\n",
      "Epoch 00066: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.5min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 47.2936 - val_loss: 1.1799\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.2037 - val_loss: 0.4102\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.5257 - val_loss: 0.5700\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.7826 - val_loss: 0.4501\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.2478 - val_loss: 0.3910\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.0853 - val_loss: 0.2753\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.8060 - val_loss: 0.4737\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 17.1289 - val_loss: 2.7495\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7242 - val_loss: 0.3714\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.5961 - val_loss: 0.3402\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.5853 - val_loss: 0.2388\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.4643 - val_loss: 0.3107\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.9274 - val_loss: 0.3259\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5640 - val_loss: 0.6638\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4367 - val_loss: 0.2237\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2046 - val_loss: 0.3197\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6170 - val_loss: 0.3122\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1690 - val_loss: 0.3938\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0203 - val_loss: 0.2500\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9349 - val_loss: 0.2367\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6815 - val_loss: 0.2065\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5501 - val_loss: 0.2154\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5794 - val_loss: 0.2434\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4325 - val_loss: 0.2236\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2701 - val_loss: 0.2119\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1424 - val_loss: 0.2145\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2062 - val_loss: 0.2736\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0744 - val_loss: 0.2161\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9749 - val_loss: 0.1808\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9427 - val_loss: 0.1885\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9426 - val_loss: 0.1841\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8515 - val_loss: 0.2664\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7392 - val_loss: 0.2301\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7517 - val_loss: 0.3263\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7370 - val_loss: 0.1808\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6330 - val_loss: 0.2150\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6000 - val_loss: 0.1974\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6563 - val_loss: 0.2593\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5429 - val_loss: 0.3508\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5406 - val_loss: 0.2064\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5035 - val_loss: 0.1838\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4917 - val_loss: 0.1891\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4987 - val_loss: 0.2195\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4725 - val_loss: 0.2476\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4702 - val_loss: 0.1874\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4390 - val_loss: 0.2124\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4400 - val_loss: 0.2398\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4041 - val_loss: 0.1820\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4116 - val_loss: 0.1731\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4072 - val_loss: 0.1742\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3569 - val_loss: 0.1777\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3552 - val_loss: 0.1813\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4030 - val_loss: 0.2256\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3543 - val_loss: 0.1716\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3484 - val_loss: 0.1972\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3465 - val_loss: 0.1820\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3252 - val_loss: 0.1850\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3144 - val_loss: 0.2053\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3069 - val_loss: 0.1710\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2983 - val_loss: 0.2146\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2851 - val_loss: 0.1926\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2667 - val_loss: 0.1810\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2920 - val_loss: 0.1841\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3068 - val_loss: 0.1796\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2758 - val_loss: 0.1827\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2565 - val_loss: 0.2198\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2697 - val_loss: 0.1718\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2622 - val_loss: 0.1935\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2488 - val_loss: 0.1747\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2551 - val_loss: 0.1762\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2456 - val_loss: 0.1965\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2515 - val_loss: 0.1740\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2279 - val_loss: 0.1752\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2390 - val_loss: 0.2243\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2457 - val_loss: 0.1879\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2218 - val_loss: 0.1785\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2382 - val_loss: 0.1962\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2251 - val_loss: 0.2550\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2180 - val_loss: 0.1763\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 144.5795 - val_loss: 1.5548\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.2700 - val_loss: 0.4389\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7582 - val_loss: 0.6410\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.9299 - val_loss: 0.8009\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.4427 - val_loss: 0.7004\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.3408 - val_loss: 1.5233\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.9975 - val_loss: 0.9329\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.8460 - val_loss: 0.5821\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 14.7803 - val_loss: 0.8636\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.3440 - val_loss: 0.4144\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.2881 - val_loss: 0.5024\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.3385 - val_loss: 0.6450\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.1293 - val_loss: 0.8159\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.5338 - val_loss: 0.2997\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.1219 - val_loss: 0.5396\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.9868 - val_loss: 0.3962\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.1851 - val_loss: 0.3535\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.7243 - val_loss: 1.6483\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.7438 - val_loss: 0.8867\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.6760 - val_loss: 0.6558\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.7856 - val_loss: 0.2688\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.4861 - val_loss: 0.6279\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.1499 - val_loss: 0.2349\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.4243 - val_loss: 0.5861\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.3605 - val_loss: 0.5907\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.2132 - val_loss: 0.2811\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3937 - val_loss: 0.2323\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9117 - val_loss: 0.3577\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7259 - val_loss: 0.3730\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2649 - val_loss: 0.2590\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6939 - val_loss: 0.5552\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3209 - val_loss: 0.3583\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1273 - val_loss: 0.3183\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2962 - val_loss: 0.2801\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5762 - val_loss: 0.2936\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0988 - val_loss: 0.2559\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9050 - val_loss: 0.2731\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8598 - val_loss: 0.2461\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7335 - val_loss: 0.2606\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6980 - val_loss: 0.2166\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5908 - val_loss: 0.2093\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5275 - val_loss: 0.3057\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3678 - val_loss: 0.2093\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3286 - val_loss: 0.2043\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2688 - val_loss: 0.2361\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2589 - val_loss: 0.2388\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1397 - val_loss: 0.2308\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0176 - val_loss: 0.2282\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0120 - val_loss: 0.2019\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0316 - val_loss: 0.3298\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8991 - val_loss: 0.2151\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9107 - val_loss: 0.3848\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8678 - val_loss: 0.1933\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7421 - val_loss: 0.2076\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9360 - val_loss: 0.2748\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8433 - val_loss: 0.1900\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8021 - val_loss: 0.2694\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7014 - val_loss: 0.1889\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9430 - val_loss: 0.2776\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7096 - val_loss: 0.2893\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6550 - val_loss: 0.2901\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7251 - val_loss: 0.2294\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5938 - val_loss: 0.2243\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5613 - val_loss: 0.2348\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5874 - val_loss: 0.2005\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4917 - val_loss: 0.2095\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5288 - val_loss: 0.1857\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4825 - val_loss: 0.1998\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5473 - val_loss: 0.1878\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4769 - val_loss: 0.2305\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4254 - val_loss: 0.2258\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4258 - val_loss: 0.1907\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4496 - val_loss: 0.1871\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4382 - val_loss: 0.1883\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3983 - val_loss: 0.1903\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4014 - val_loss: 0.1853\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3424 - val_loss: 0.1869\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3822 - val_loss: 0.2304\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3839 - val_loss: 0.2045\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3403 - val_loss: 0.1804\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3565 - val_loss: 0.1791\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3362 - val_loss: 0.2213\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3291 - val_loss: 0.2544\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3541 - val_loss: 0.2079\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2894 - val_loss: 0.1833\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3162 - val_loss: 0.1890\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3092 - val_loss: 0.2124\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3124 - val_loss: 0.2578\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3012 - val_loss: 0.2218\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3063 - val_loss: 0.1895\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2929 - val_loss: 0.2129\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2860 - val_loss: 0.1865\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2890 - val_loss: 0.1927\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2705 - val_loss: 0.1847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2818 - val_loss: 0.1955\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2641 - val_loss: 0.2102\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2715 - val_loss: 0.2160\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2486 - val_loss: 0.1961\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2640 - val_loss: 0.1799\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2537 - val_loss: 0.2046\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2316 - val_loss: 0.1812\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2553 - val_loss: 0.1852\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2413 - val_loss: 0.1881\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2144 - val_loss: 0.1997\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2256 - val_loss: 0.1867\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2155 - val_loss: 0.1768\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2272 - val_loss: 0.2006\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2021 - val_loss: 0.1784\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1889 - val_loss: 0.1805\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1990 - val_loss: 0.1785\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1965 - val_loss: 0.1771\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2075 - val_loss: 0.1968\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1987 - val_loss: 0.1814\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1928 - val_loss: 0.1909\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1847 - val_loss: 0.1984\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1742 - val_loss: 0.1888\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1814 - val_loss: 0.1804\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1831 - val_loss: 0.1929\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1842 - val_loss: 0.1925\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1713 - val_loss: 0.1842\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1654 - val_loss: 0.1910\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1622 - val_loss: 0.1838\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1628 - val_loss: 0.1826\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1580 - val_loss: 0.1988\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1528 - val_loss: 0.1832\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1409 - val_loss: 0.2102\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1511 - val_loss: 0.2063\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1454 - val_loss: 0.1796\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1363 - val_loss: 0.1841\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1444 - val_loss: 0.1886\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1457 - val_loss: 0.1821\n",
      "Epoch 00131: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 4.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 81.3118 - val_loss: 0.5878\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.3956 - val_loss: 0.6070\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.9354 - val_loss: 1.9089\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.5143 - val_loss: 0.9986\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.4730 - val_loss: 0.8033\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.7080 - val_loss: 0.4185\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 14.1328 - val_loss: 0.6329\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.5832 - val_loss: 1.0653\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.2893 - val_loss: 1.1786\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.2793 - val_loss: 0.3358\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.9143 - val_loss: 0.4140\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.4704 - val_loss: 0.2907\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.2535 - val_loss: 0.4383\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7932 - val_loss: 0.2718\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.8209 - val_loss: 0.3142\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.6870 - val_loss: 0.2767\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.3936 - val_loss: 0.8881\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.3305 - val_loss: 0.2528\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.2599 - val_loss: 0.4321\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.8105 - val_loss: 0.4577\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3159 - val_loss: 0.2794\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1424 - val_loss: 0.2770\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9510 - val_loss: 0.2078\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8417 - val_loss: 0.4943\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4866 - val_loss: 0.2213\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3447 - val_loss: 0.3817\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1544 - val_loss: 0.2509\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6959 - val_loss: 0.2602\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7861 - val_loss: 0.2883\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7118 - val_loss: 0.2491\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8562 - val_loss: 0.2297\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6107 - val_loss: 0.2241\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3124 - val_loss: 0.3366\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3553 - val_loss: 0.2018\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4302 - val_loss: 0.3440\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1969 - val_loss: 0.2407\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2917 - val_loss: 0.2260\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0736 - val_loss: 0.3043\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1860 - val_loss: 0.1932\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1057 - val_loss: 0.2623\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0052 - val_loss: 0.2129\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8969 - val_loss: 0.3672\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8162 - val_loss: 0.2116\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7411 - val_loss: 0.2253\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7577 - val_loss: 0.1853\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7093 - val_loss: 0.1844\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6644 - val_loss: 0.2001\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6418 - val_loss: 0.2177\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6308 - val_loss: 0.2353\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6952 - val_loss: 0.1971\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5811 - val_loss: 0.2096\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5568 - val_loss: 0.2624\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5556 - val_loss: 0.3028\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5023 - val_loss: 0.2369\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5286 - val_loss: 0.1957\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4453 - val_loss: 0.2330\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4872 - val_loss: 0.2360\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4550 - val_loss: 0.1965\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4701 - val_loss: 0.1974\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4069 - val_loss: 0.2309\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4281 - val_loss: 0.1850\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4295 - val_loss: 0.1877\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4101 - val_loss: 0.1803\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3591 - val_loss: 0.2248\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3558 - val_loss: 0.2031\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4175 - val_loss: 0.1791\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3676 - val_loss: 0.2241\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3434 - val_loss: 0.1987\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3384 - val_loss: 0.1819\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3492 - val_loss: 0.2759\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3228 - val_loss: 0.2119\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3070 - val_loss: 0.2001\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2900 - val_loss: 0.1863\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2884 - val_loss: 0.1833\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2614 - val_loss: 0.2059\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2711 - val_loss: 0.1773\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2634 - val_loss: 0.1792\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2808 - val_loss: 0.1758\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2695 - val_loss: 0.1768\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2643 - val_loss: 0.2182\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2592 - val_loss: 0.1777\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2317 - val_loss: 0.1746\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2387 - val_loss: 0.1804\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2359 - val_loss: 0.2008\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2393 - val_loss: 0.1857\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2358 - val_loss: 0.1789\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2255 - val_loss: 0.1851\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2175 - val_loss: 0.2048\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2281 - val_loss: 0.1753\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2078 - val_loss: 0.1794\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2017 - val_loss: 0.1800\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2054 - val_loss: 0.2070\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2166 - val_loss: 0.2077\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1974 - val_loss: 0.1782\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1962 - val_loss: 0.2748\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2128 - val_loss: 0.1775\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1844 - val_loss: 0.1980\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1749 - val_loss: 0.1822\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1736 - val_loss: 0.1794\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1946 - val_loss: 0.1980\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1753 - val_loss: 0.1961\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1866 - val_loss: 0.1874\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1729 - val_loss: 0.2027\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1812 - val_loss: 0.1778\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1740 - val_loss: 0.1772\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1684 - val_loss: 0.1819\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1695 - val_loss: 0.1880\n",
      "Epoch 00107: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 3.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 95.6328 - val_loss: 0.7702\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.1164 - val_loss: 0.3900\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.8732 - val_loss: 0.5704\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.3754 - val_loss: 0.3556\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.3533 - val_loss: 0.7538\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7390 - val_loss: 1.1074\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.7058 - val_loss: 1.8672\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.9592 - val_loss: 0.6886\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 14.2304 - val_loss: 0.4566\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.9706 - val_loss: 0.4419\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.6377 - val_loss: 0.6534\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.2570 - val_loss: 1.4936\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.8875 - val_loss: 0.5201\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 15.7388 - val_loss: 7.7043\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.9564 - val_loss: 0.5469\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.0424 - val_loss: 0.4005\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.7502 - val_loss: 0.4628\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.3227 - val_loss: 0.4534\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.9466 - val_loss: 0.2827\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.6415 - val_loss: 0.3747\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.8382 - val_loss: 0.2932\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1388 - val_loss: 0.2716\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2287 - val_loss: 0.2426\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3202 - val_loss: 0.4170\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8000 - val_loss: 0.4341\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.0948 - val_loss: 0.2427\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5364 - val_loss: 0.2730\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.7581 - val_loss: 0.2238\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4374 - val_loss: 0.3834\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9668 - val_loss: 0.3033\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9659 - val_loss: 0.2892\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5916 - val_loss: 0.2115\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6867 - val_loss: 0.2550\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4474 - val_loss: 0.3282\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2723 - val_loss: 0.3490\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4760 - val_loss: 0.2707\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6247 - val_loss: 0.3369\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2629 - val_loss: 0.2329\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1459 - val_loss: 0.2441\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0551 - val_loss: 0.2128\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1204 - val_loss: 0.2076\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9843 - val_loss: 0.3847\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8954 - val_loss: 0.2009\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8915 - val_loss: 0.2206\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9115 - val_loss: 0.2006\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8107 - val_loss: 0.2287\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8908 - val_loss: 0.2150\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8222 - val_loss: 0.3805\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7761 - val_loss: 0.2483\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7832 - val_loss: 0.2241\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8344 - val_loss: 0.2129\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7498 - val_loss: 0.2208\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6824 - val_loss: 0.2926\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5935 - val_loss: 0.2293\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5403 - val_loss: 0.2084\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5570 - val_loss: 0.1880\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6160 - val_loss: 0.1922\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4774 - val_loss: 0.2147\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5135 - val_loss: 0.2194\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4656 - val_loss: 0.1782\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4470 - val_loss: 0.2024\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4438 - val_loss: 0.1836\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4328 - val_loss: 0.1852\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4677 - val_loss: 0.1892\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3830 - val_loss: 0.1845\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4675 - val_loss: 0.3580\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4188 - val_loss: 0.1797\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4039 - val_loss: 0.2598\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3871 - val_loss: 0.1903\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3586 - val_loss: 0.2228\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3682 - val_loss: 0.1792\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3383 - val_loss: 0.2399\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3329 - val_loss: 0.1764\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3282 - val_loss: 0.1812\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3268 - val_loss: 0.1834\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3456 - val_loss: 0.1819\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3083 - val_loss: 0.1823\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2803 - val_loss: 0.1753\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2935 - val_loss: 0.1839\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2651 - val_loss: 0.1806\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2814 - val_loss: 0.1997\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2776 - val_loss: 0.1796\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2862 - val_loss: 0.1782\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2516 - val_loss: 0.1789\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2513 - val_loss: 0.1755\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2473 - val_loss: 0.1896\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2414 - val_loss: 0.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2288 - val_loss: 0.1871\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2273 - val_loss: 0.2077\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2414 - val_loss: 0.1755\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2260 - val_loss: 0.2098\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2393 - val_loss: 0.1950\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2220 - val_loss: 0.1915\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2125 - val_loss: 0.1795\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2207 - val_loss: 0.1816\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2204 - val_loss: 0.2087\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1919 - val_loss: 0.1747\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2135 - val_loss: 0.1757\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2119 - val_loss: 0.1919\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1910 - val_loss: 0.2238\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2092 - val_loss: 0.1755\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2056 - val_loss: 0.1750\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1994 - val_loss: 0.2099\n",
      "Epoch 00103: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 3.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 97.2302 - val_loss: 1.6027\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 42.0707 - val_loss: 3.2347\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 28.6720 - val_loss: 0.5777\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 21.4271 - val_loss: 2.0985\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 18.2772 - val_loss: 0.8990\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 16.2444 - val_loss: 1.0800\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 13.0346 - val_loss: 0.9213\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 12.7077 - val_loss: 0.4549\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 9.5984 - val_loss: 0.6317\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 8.4410 - val_loss: 0.8747\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.9095 - val_loss: 0.4570\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.7673 - val_loss: 0.3435\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.9063 - val_loss: 0.2944\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.5538 - val_loss: 0.6039\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.8530 - val_loss: 0.3618\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.2231 - val_loss: 0.6728\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.6232 - val_loss: 0.4922\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.0880 - val_loss: 0.3167\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.7059 - val_loss: 0.3568\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.6870 - val_loss: 0.2342\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.4067 - val_loss: 0.2778\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.4867 - val_loss: 0.2982\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.0968 - val_loss: 0.2342\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.9622 - val_loss: 0.2245\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.7353 - val_loss: 0.2442\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.6666 - val_loss: 0.2013\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.6209 - val_loss: 0.1995\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.3695 - val_loss: 0.2175\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.3661 - val_loss: 0.3441\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2896 - val_loss: 0.2766\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2335 - val_loss: 0.3224\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2265 - val_loss: 0.2311\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.1601 - val_loss: 0.2834\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.1296 - val_loss: 0.3004\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9429 - val_loss: 0.1859\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9844 - val_loss: 0.2419\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9877 - val_loss: 0.3090\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9113 - val_loss: 0.3249\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8733 - val_loss: 0.2451\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8426 - val_loss: 0.1945\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7967 - val_loss: 0.2452\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6913 - val_loss: 0.2045\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7003 - val_loss: 0.2806\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6956 - val_loss: 0.1876\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7287 - val_loss: 0.2296\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5735 - val_loss: 0.1923\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5975 - val_loss: 0.2101\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6145 - val_loss: 0.3954\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5756 - val_loss: 0.2186\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5360 - val_loss: 0.2157\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5157 - val_loss: 0.2428\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5280 - val_loss: 0.2137\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5464 - val_loss: 0.2298\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4849 - val_loss: 0.1819\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4407 - val_loss: 0.2020\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4616 - val_loss: 0.2139\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4280 - val_loss: 0.1870\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4224 - val_loss: 0.2396\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3891 - val_loss: 0.1947\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4383 - val_loss: 0.2035\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3948 - val_loss: 0.2117\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3770 - val_loss: 0.1883\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3628 - val_loss: 0.1907\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3492 - val_loss: 0.2452\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3539 - val_loss: 0.1926\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3411 - val_loss: 0.1943\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3223 - val_loss: 0.2140\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3151 - val_loss: 0.2012\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3098 - val_loss: 0.1875\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3143 - val_loss: 0.1974\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3062 - val_loss: 0.2101\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2653 - val_loss: 0.1843\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2822 - val_loss: 0.1860\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2577 - val_loss: 0.2683\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2498 - val_loss: 0.2052\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2721 - val_loss: 0.1870\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2463 - val_loss: 0.2062\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2419 - val_loss: 0.2219\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2569 - val_loss: 0.2136\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 3.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 119.2404 - val_loss: 1.8165\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 40.1711 - val_loss: 1.8730\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 29.5021 - val_loss: 0.8417\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 25.4669 - val_loss: 3.2406\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 30.2480 - val_loss: 1.1583\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 21.2603 - val_loss: 0.6717\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 15.6086 - val_loss: 0.9404\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.9855 - val_loss: 0.3434\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 17.1692 - val_loss: 1.0905\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.8805 - val_loss: 0.3548\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.3155 - val_loss: 1.5319\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.1517 - val_loss: 1.3282\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.7691 - val_loss: 0.3883\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.5897 - val_loss: 0.6984\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.2667 - val_loss: 0.8918\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.8703 - val_loss: 0.7097\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.7167 - val_loss: 0.8914\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.6968 - val_loss: 0.2424\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.1992 - val_loss: 0.5523\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5273 - val_loss: 0.6680\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3079 - val_loss: 0.4148\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8350 - val_loss: 0.4156\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.2602 - val_loss: 0.2839\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9581 - val_loss: 0.2407\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4452 - val_loss: 0.2799\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2419 - val_loss: 0.2887\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9824 - val_loss: 0.2175\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0533 - val_loss: 0.3062\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8492 - val_loss: 0.3463\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7881 - val_loss: 0.2601\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6820 - val_loss: 0.3450\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5745 - val_loss: 0.3434\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4300 - val_loss: 0.3190\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5079 - val_loss: 0.3414\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3516 - val_loss: 0.2952\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2525 - val_loss: 0.3315\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2401 - val_loss: 0.3455\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1068 - val_loss: 0.3423\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0628 - val_loss: 0.2069\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0812 - val_loss: 0.2472\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0309 - val_loss: 0.1760\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9619 - val_loss: 0.2719\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9244 - val_loss: 0.1906\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9341 - val_loss: 0.1894\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8983 - val_loss: 0.2320\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8906 - val_loss: 0.2399\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7347 - val_loss: 0.2205\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6969 - val_loss: 0.3054\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8049 - val_loss: 0.2422\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7476 - val_loss: 0.2630\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7122 - val_loss: 0.3283\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6674 - val_loss: 0.2376\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6954 - val_loss: 0.1902\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6168 - val_loss: 0.2062\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5689 - val_loss: 0.2167\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5828 - val_loss: 0.2515\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5164 - val_loss: 0.1967\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5027 - val_loss: 0.2062\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5589 - val_loss: 0.2533\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4702 - val_loss: 0.2290\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4975 - val_loss: 0.2020\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5006 - val_loss: 0.2267\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4855 - val_loss: 0.2199\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4567 - val_loss: 0.2281\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4486 - val_loss: 0.1804\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4268 - val_loss: 0.1868\n",
      "Epoch 00066: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 2.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 123.3099 - val_loss: 3.1345\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 34.7105 - val_loss: 0.7726\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 17.5763 - val_loss: 1.6713\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 19.0364 - val_loss: 1.4141\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 18.9532 - val_loss: 1.4086\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 15.8080 - val_loss: 1.8252\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 15.3111 - val_loss: 1.8728\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.3977 - val_loss: 1.3454\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.7091 - val_loss: 2.7749\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.7570 - val_loss: 0.5956\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.6735 - val_loss: 1.1508\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.7896 - val_loss: 0.4653\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.3858 - val_loss: 0.5633\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.6846 - val_loss: 0.2151\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.4197 - val_loss: 0.6582\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.5386 - val_loss: 0.4846\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.5970 - val_loss: 0.5468\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.3071 - val_loss: 0.8155\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6675 - val_loss: 0.3337\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4915 - val_loss: 0.7382\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2964 - val_loss: 0.3284\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1972 - val_loss: 0.6711\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6582 - val_loss: 0.2726\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4997 - val_loss: 0.2628\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3998 - val_loss: 0.5309\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6001 - val_loss: 0.3691\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2023 - val_loss: 0.3739\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1639 - val_loss: 0.2898\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9255 - val_loss: 0.2143\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7434 - val_loss: 0.1913\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6914 - val_loss: 0.3138\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5750 - val_loss: 0.3809\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4659 - val_loss: 0.2973\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4797 - val_loss: 0.2548\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4638 - val_loss: 0.3428\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2267 - val_loss: 0.3072\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4569 - val_loss: 0.1997\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1896 - val_loss: 0.2139\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2467 - val_loss: 0.2990\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0248 - val_loss: 0.1981\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0693 - val_loss: 0.2048\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9126 - val_loss: 0.2062\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9022 - val_loss: 0.2728\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0222 - val_loss: 0.2358\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8720 - val_loss: 0.2516\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8339 - val_loss: 0.2018\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7467 - val_loss: 0.2269\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7275 - val_loss: 0.2854\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7129 - val_loss: 0.2746\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7260 - val_loss: 0.2175\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6340 - val_loss: 0.3212\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6882 - val_loss: 0.2053\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6806 - val_loss: 0.2206\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6612 - val_loss: 0.2720\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5885 - val_loss: 0.2782\n",
      "Epoch 00055: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 2.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 101.9840 - val_loss: 0.9117\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 45.2563 - val_loss: 2.3409\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 25.9257 - val_loss: 1.4690\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 19.4915 - val_loss: 1.5312\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 20.5322 - val_loss: 0.6744\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 15.1591 - val_loss: 2.5719\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.1736 - val_loss: 1.6508\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.2745 - val_loss: 2.0681\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.7278 - val_loss: 0.8090\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.4883 - val_loss: 0.8948\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.2754 - val_loss: 0.6747\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.8383 - val_loss: 0.4075\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.7161 - val_loss: 0.3123\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.1424 - val_loss: 0.5150\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.4091 - val_loss: 0.2708\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.3182 - val_loss: 0.4366\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7350 - val_loss: 0.2089\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5194 - val_loss: 0.2780\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8786 - val_loss: 0.2501\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8602 - val_loss: 0.4634\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8271 - val_loss: 0.3721\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.0034 - val_loss: 0.4453\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4942 - val_loss: 0.4286\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1172 - val_loss: 0.2706\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0030 - val_loss: 0.2200\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0840 - val_loss: 0.3092\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7217 - val_loss: 0.2278\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6350 - val_loss: 0.4999\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5142 - val_loss: 0.3899\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4417 - val_loss: 0.2759\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3818 - val_loss: 0.2091\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2900 - val_loss: 0.1902\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2010 - val_loss: 0.2688\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1581 - val_loss: 0.2612\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2146 - val_loss: 0.1824\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0477 - val_loss: 0.2074\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0325 - val_loss: 0.2995\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9639 - val_loss: 0.1889\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8952 - val_loss: 0.2080\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8380 - val_loss: 0.2288\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7757 - val_loss: 0.2015\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7564 - val_loss: 0.2091\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7080 - val_loss: 0.2589\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7289 - val_loss: 0.2225\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6688 - val_loss: 0.2625\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6612 - val_loss: 0.2312\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6148 - val_loss: 0.1919\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6082 - val_loss: 0.2560\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5727 - val_loss: 0.2048\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5399 - val_loss: 0.1961\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5744 - val_loss: 0.1777\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5445 - val_loss: 0.2364\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5089 - val_loss: 0.2101\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4637 - val_loss: 0.2076\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4692 - val_loss: 0.2005\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4510 - val_loss: 0.3652\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4826 - val_loss: 0.2185\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4656 - val_loss: 0.2087\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3931 - val_loss: 0.2326\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4065 - val_loss: 0.1892\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4086 - val_loss: 0.1962\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4196 - val_loss: 0.1836\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3923 - val_loss: 0.1858\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3627 - val_loss: 0.1898\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3287 - val_loss: 0.1934\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3636 - val_loss: 0.2249\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3651 - val_loss: 0.1792\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3332 - val_loss: 0.2042\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3112 - val_loss: 0.1937\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3119 - val_loss: 0.2038\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3017 - val_loss: 0.2126\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2864 - val_loss: 0.1819\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3047 - val_loss: 0.1861\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2990 - val_loss: 0.1867\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2539 - val_loss: 0.2064\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2643 - val_loss: 0.2012\n",
      "Epoch 00076: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 3.1min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 136.8883 - val_loss: 2.4569\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 26.5845 - val_loss: 6.5445\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 23.1745 - val_loss: 0.9566\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 22.7927 - val_loss: 0.4791\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 19.9411 - val_loss: 1.5203\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 28.8490 - val_loss: 1.2040\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 22.2341 - val_loss: 0.3939\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 20.6934 - val_loss: 0.5083\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 15.5886 - val_loss: 0.8086\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.4020 - val_loss: 1.6640\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.7223 - val_loss: 1.2947\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.7711 - val_loss: 0.9193\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.8533 - val_loss: 0.5124\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.4451 - val_loss: 0.8988\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.1308 - val_loss: 0.6556\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.3802 - val_loss: 0.5906\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.1959 - val_loss: 0.5389\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.4750 - val_loss: 0.2687\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.7400 - val_loss: 0.7288\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.0202 - val_loss: 0.2076\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.6078 - val_loss: 0.3496\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.3644 - val_loss: 0.4145\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6475 - val_loss: 0.4959\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4051 - val_loss: 0.2241\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2243 - val_loss: 0.2604\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9868 - val_loss: 0.3778\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9898 - val_loss: 0.3749\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6067 - val_loss: 0.2431\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6425 - val_loss: 0.7367\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3933 - val_loss: 0.3421\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9247 - val_loss: 0.7929\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2207 - val_loss: 0.5231\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9568 - val_loss: 0.3234\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8465 - val_loss: 0.3271\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8005 - val_loss: 0.2625\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6576 - val_loss: 0.3463\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6295 - val_loss: 0.3202\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5441 - val_loss: 0.3770\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9610 - val_loss: 0.3592\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4742 - val_loss: 0.2725\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4564 - val_loss: 0.3237\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2853 - val_loss: 0.1940\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3630 - val_loss: 0.2380\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0920 - val_loss: 0.2513\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1922 - val_loss: 0.3400\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2348 - val_loss: 0.3769\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0645 - val_loss: 0.2077\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9661 - val_loss: 0.2746\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9497 - val_loss: 0.1974\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8409 - val_loss: 0.2124\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8700 - val_loss: 0.2657\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8636 - val_loss: 0.2025\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9273 - val_loss: 0.2865\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8926 - val_loss: 0.2255\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8070 - val_loss: 0.2408\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7275 - val_loss: 0.2850\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6800 - val_loss: 0.1846\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7843 - val_loss: 0.1966\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6302 - val_loss: 0.2075\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6863 - val_loss: 0.1836\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6630 - val_loss: 0.2151\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6185 - val_loss: 0.1776\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5849 - val_loss: 0.2291\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5486 - val_loss: 0.2265\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5704 - val_loss: 0.2247\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5472 - val_loss: 0.1926\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4927 - val_loss: 0.1989\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4801 - val_loss: 0.2698\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4931 - val_loss: 0.1862\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4451 - val_loss: 0.2138\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4715 - val_loss: 0.1831\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4445 - val_loss: 0.2210\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4410 - val_loss: 0.2224\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4448 - val_loss: 0.1793\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4009 - val_loss: 0.1920\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3793 - val_loss: 0.1942\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3848 - val_loss: 0.2206\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4365 - val_loss: 0.2161\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3625 - val_loss: 0.1749\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3652 - val_loss: 0.1903\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3657 - val_loss: 0.2621\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3411 - val_loss: 0.1869\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3367 - val_loss: 0.2765\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3423 - val_loss: 0.1951\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3169 - val_loss: 0.1757\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3213 - val_loss: 0.1831\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2917 - val_loss: 0.1855\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3224 - val_loss: 0.1935\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3313 - val_loss: 0.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2870 - val_loss: 0.2256\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2654 - val_loss: 0.1728\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2781 - val_loss: 0.1893\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2583 - val_loss: 0.2002\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2585 - val_loss: 0.1963\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2419 - val_loss: 0.1821\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2563 - val_loss: 0.2227\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2297 - val_loss: 0.2109\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2221 - val_loss: 0.1834\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.1902\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.1879\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2351 - val_loss: 0.1834\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2070 - val_loss: 0.1766\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2259 - val_loss: 0.1861\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2154 - val_loss: 0.1793\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2047 - val_loss: 0.1768\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1999 - val_loss: 0.1886\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1978 - val_loss: 0.1868\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2018 - val_loss: 0.1868\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1855 - val_loss: 0.2307\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2041 - val_loss: 0.1709\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1839 - val_loss: 0.1859\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1757 - val_loss: 0.1737\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1608 - val_loss: 0.1758\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1743 - val_loss: 0.1805\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1573 - val_loss: 0.1754\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1591 - val_loss: 0.1750\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1529 - val_loss: 0.1736\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1544 - val_loss: 0.1744\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1573 - val_loss: 0.1784\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1419 - val_loss: 0.1870\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1457 - val_loss: 0.1789\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1550 - val_loss: 0.1732\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1330 - val_loss: 0.1826\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1403 - val_loss: 0.2027\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1221 - val_loss: 0.1868\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1299 - val_loss: 0.1805\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1305 - val_loss: 0.1790\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1223 - val_loss: 0.1828\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1166 - val_loss: 0.1769\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1160 - val_loss: 0.1779\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1156 - val_loss: 0.1890\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1212 - val_loss: 0.1784\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1027 - val_loss: 0.1813\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1177 - val_loss: 0.1745\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1169 - val_loss: 0.1790\n",
      "Epoch 00135: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 5.5min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 276.1213 - val_loss: 5.6688\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 15.1778 - val_loss: 2.6863\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 7.1963 - val_loss: 1.2919\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.5892 - val_loss: 0.8507\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7417 - val_loss: 1.0054\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2491 - val_loss: 1.3940\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0182 - val_loss: 0.8463\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.5613 - val_loss: 0.8658\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8190 - val_loss: 0.7124\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.1588 - val_loss: 0.8747\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6641 - val_loss: 0.6326\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6354 - val_loss: 1.6084\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.9247 - val_loss: 0.7378\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2118 - val_loss: 0.8451\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0666 - val_loss: 1.3546\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.4679 - val_loss: 1.2161\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6122 - val_loss: 0.9568\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.5943 - val_loss: 2.5494\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.4814 - val_loss: 1.4059\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.9309 - val_loss: 2.9206\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.6792 - val_loss: 1.1018\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.7536 - val_loss: 1.0677\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.5010 - val_loss: 0.9157\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.1785 - val_loss: 0.9442\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.5637 - val_loss: 0.8155\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.8483 - val_loss: 1.4016\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.2120 - val_loss: 1.1167\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.8708 - val_loss: 1.4268\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.4769 - val_loss: 0.7489\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6722 - val_loss: 0.9101\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2002 - val_loss: 2.4127\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.4208 - val_loss: 0.5291\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.3556 - val_loss: 0.8373\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0499 - val_loss: 0.5660\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8762 - val_loss: 2.6492\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8405 - val_loss: 1.4266\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3309 - val_loss: 0.6381\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.2659 - val_loss: 0.4250\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3569 - val_loss: 0.4893\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7338 - val_loss: 1.9448\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.5522 - val_loss: 0.4020\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1618 - val_loss: 0.5099\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3128 - val_loss: 0.4452\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0585 - val_loss: 0.4590\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9929 - val_loss: 0.3585\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8530 - val_loss: 0.4572\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9840 - val_loss: 0.7839\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8572 - val_loss: 1.0744\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9762 - val_loss: 0.3644\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7004 - val_loss: 0.3517\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6919 - val_loss: 0.4355\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5933 - val_loss: 0.3716\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5819 - val_loss: 0.4006\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6648 - val_loss: 0.3664\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6082 - val_loss: 0.3134\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5477 - val_loss: 0.4554\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5045 - val_loss: 0.2931\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4324 - val_loss: 0.3158\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4843 - val_loss: 0.2818\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4608 - val_loss: 0.3381\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4141 - val_loss: 0.2692\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4152 - val_loss: 0.2841\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3764 - val_loss: 0.3330\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3316 - val_loss: 0.2641\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3473 - val_loss: 0.2852\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3235 - val_loss: 0.3167\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3151 - val_loss: 0.3105\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3360 - val_loss: 0.3705\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3682 - val_loss: 0.6245\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3235 - val_loss: 0.2720\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2814 - val_loss: 0.2554\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2616 - val_loss: 0.3393\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2929 - val_loss: 0.2451\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2600 - val_loss: 0.2465\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2040 - val_loss: 0.2797\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2385 - val_loss: 0.2445\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2758 - val_loss: 0.2636\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2227 - val_loss: 0.2331\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1981 - val_loss: 0.2363\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1903 - val_loss: 0.2232\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1883 - val_loss: 0.2308\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1863 - val_loss: 0.2173\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1831 - val_loss: 0.2256\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1684 - val_loss: 0.2622\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1585 - val_loss: 0.2271\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1536 - val_loss: 0.3189\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1749 - val_loss: 0.2319\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1550 - val_loss: 0.2310\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1708 - val_loss: 0.2123\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1540 - val_loss: 0.2096\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1622 - val_loss: 0.3269\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1451 - val_loss: 0.2120\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1468 - val_loss: 0.2338\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1338 - val_loss: 0.2145\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1293 - val_loss: 0.2189\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1298 - val_loss: 0.2374\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1215 - val_loss: 0.2094\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1264 - val_loss: 0.2125\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1445 - val_loss: 0.2190\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1133 - val_loss: 0.2043\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1162 - val_loss: 0.2004\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1094 - val_loss: 0.2031\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1122 - val_loss: 0.2037\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1054 - val_loss: 0.1998\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1200 - val_loss: 0.2004\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1113 - val_loss: 0.2022\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1071 - val_loss: 0.2417\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1044 - val_loss: 0.2040\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1132 - val_loss: 0.2098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1072 - val_loss: 0.2250\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1042 - val_loss: 0.2001\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0946 - val_loss: 0.2033\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1025 - val_loss: 0.2007\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0941 - val_loss: 0.2183\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1164 - val_loss: 0.2042\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1042 - val_loss: 0.2310\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.1065 - val_loss: 0.1973\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0939 - val_loss: 0.1941\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0978 - val_loss: 0.2004\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0896 - val_loss: 0.1966\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0877 - val_loss: 0.1959\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0863 - val_loss: 0.2124\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0945 - val_loss: 0.1967\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0904 - val_loss: 0.1948\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0820 - val_loss: 0.2042\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0856 - val_loss: 0.1995\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0894 - val_loss: 0.1942\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0898 - val_loss: 0.2018\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0947 - val_loss: 0.2309\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0894 - val_loss: 0.2271\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0758 - val_loss: 0.1943\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0832 - val_loss: 0.1953\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0871 - val_loss: 0.2008\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0847 - val_loss: 0.2066\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0902 - val_loss: 0.1984\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0883 - val_loss: 0.1946\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0795 - val_loss: 0.1938\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0812 - val_loss: 0.1906\n",
      "Epoch 139/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0904 - val_loss: 0.1944\n",
      "Epoch 140/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0900 - val_loss: 0.1912\n",
      "Epoch 141/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0817 - val_loss: 0.1957\n",
      "Epoch 142/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0807 - val_loss: 0.1971\n",
      "Epoch 143/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0801 - val_loss: 0.1930\n",
      "Epoch 144/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0774 - val_loss: 0.1951\n",
      "Epoch 145/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0826 - val_loss: 0.2005\n",
      "Epoch 146/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0807 - val_loss: 0.1997\n",
      "Epoch 147/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0770 - val_loss: 0.1916\n",
      "Epoch 148/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0738 - val_loss: 0.1942\n",
      "Epoch 149/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0741 - val_loss: 0.2395\n",
      "Epoch 150/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0882 - val_loss: 0.1886\n",
      "Epoch 151/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0802 - val_loss: 0.1930\n",
      "Epoch 152/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0807 - val_loss: 0.2311\n",
      "Epoch 153/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0795 - val_loss: 0.1869\n",
      "Epoch 154/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0785 - val_loss: 0.1940\n",
      "Epoch 155/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0752 - val_loss: 0.2138\n",
      "Epoch 156/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0762 - val_loss: 0.1912\n",
      "Epoch 157/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0774 - val_loss: 0.2285\n",
      "Epoch 158/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0859 - val_loss: 0.2037\n",
      "Epoch 159/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0771 - val_loss: 0.1936\n",
      "Epoch 160/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0743 - val_loss: 0.1956\n",
      "Epoch 161/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0824 - val_loss: 0.2001\n",
      "Epoch 162/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0796 - val_loss: 0.1883\n",
      "Epoch 163/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0798 - val_loss: 0.1893\n",
      "Epoch 164/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0802 - val_loss: 0.1883\n",
      "Epoch 165/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0725 - val_loss: 0.2042\n",
      "Epoch 166/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0702 - val_loss: 0.1895\n",
      "Epoch 167/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0779 - val_loss: 0.2142\n",
      "Epoch 168/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0935 - val_loss: 0.2220\n",
      "Epoch 169/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0867 - val_loss: 0.1888\n",
      "Epoch 170/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0754 - val_loss: 0.1887\n",
      "Epoch 171/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0710 - val_loss: 0.2198\n",
      "Epoch 172/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0747 - val_loss: 0.1956\n",
      "Epoch 173/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0815 - val_loss: 0.1881\n",
      "Epoch 174/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0687 - val_loss: 0.1933\n",
      "Epoch 175/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0686 - val_loss: 0.1998\n",
      "Epoch 176/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0672 - val_loss: 0.1891\n",
      "Epoch 177/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0737 - val_loss: 0.2084\n",
      "Epoch 178/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.0752 - val_loss: 0.1925\n",
      "Epoch 00178: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total=11.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 264.7809 - val_loss: 5.4089\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.5297 - val_loss: 1.9582\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.4497 - val_loss: 5.1978\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.4870 - val_loss: 1.1698\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1206 - val_loss: 0.8114\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1337 - val_loss: 1.6129\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6660 - val_loss: 3.0671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5001 - val_loss: 1.2898\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3081 - val_loss: 1.2078\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9703 - val_loss: 1.1573\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8847 - val_loss: 1.2915\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7088 - val_loss: 0.8245\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4046 - val_loss: 0.6935\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9066 - val_loss: 4.8918\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7585 - val_loss: 5.5586\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1718 - val_loss: 1.0249\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0154 - val_loss: 1.2371\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.1726 - val_loss: 3.4997\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.5114 - val_loss: 2.2519\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.1138 - val_loss: 2.0483\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8226 - val_loss: 2.9517\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.3349 - val_loss: 3.6993\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9528 - val_loss: 2.9002\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8017 - val_loss: 5.0953\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.0294 - val_loss: 2.3330\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9209 - val_loss: 0.7205\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7969 - val_loss: 0.6137\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2461 - val_loss: 0.5251\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7216 - val_loss: 0.5782\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2537 - val_loss: 0.5645\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3156 - val_loss: 0.9964\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7105 - val_loss: 0.4317\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0719 - val_loss: 2.8044\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5879 - val_loss: 0.4857\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7114 - val_loss: 0.7552\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2349 - val_loss: 1.6572\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6176 - val_loss: 0.4221\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9779 - val_loss: 0.4779\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1515 - val_loss: 1.0594\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0698 - val_loss: 0.2865\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0137 - val_loss: 0.7731\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5214 - val_loss: 1.3820\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1860 - val_loss: 0.3533\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8593 - val_loss: 0.3883\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6540 - val_loss: 0.3077\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4803 - val_loss: 0.3462\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5729 - val_loss: 0.4417\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6892 - val_loss: 0.3858\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6644 - val_loss: 0.4316\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4900 - val_loss: 0.2862\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4331 - val_loss: 0.2607\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4544 - val_loss: 0.3022\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6482 - val_loss: 0.4515\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4743 - val_loss: 0.2487\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3485 - val_loss: 0.2550\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3460 - val_loss: 0.2566\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6250 - val_loss: 0.8203\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5467 - val_loss: 0.2530\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3213 - val_loss: 0.2696\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3798 - val_loss: 0.2387\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4213 - val_loss: 0.3144\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3473 - val_loss: 0.3456\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4592 - val_loss: 0.2310\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5657 - val_loss: 0.6931\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3622 - val_loss: 0.2349\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2919 - val_loss: 0.2340\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2305 - val_loss: 0.2462\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2370 - val_loss: 0.2710\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2433 - val_loss: 0.2748\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2386 - val_loss: 0.2351\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2016 - val_loss: 0.2212\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2196 - val_loss: 0.2449\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3190 - val_loss: 0.5350\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2775 - val_loss: 0.2797\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2850 - val_loss: 0.2584\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2243 - val_loss: 0.3017\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2187 - val_loss: 0.2285\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1752 - val_loss: 0.2256\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2274 - val_loss: 0.2269\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1943 - val_loss: 0.2109\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1741 - val_loss: 0.2123\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1537 - val_loss: 0.2213\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1514 - val_loss: 0.2108\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1463 - val_loss: 0.2192\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2185 - val_loss: 0.2396\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1822 - val_loss: 0.2146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1462 - val_loss: 0.2174\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1475 - val_loss: 0.2051\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1761 - val_loss: 0.2473\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1357 - val_loss: 0.1986\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1211 - val_loss: 0.2094\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1516 - val_loss: 0.2620\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1459 - val_loss: 0.2256\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1196 - val_loss: 0.2022\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1191 - val_loss: 0.2060\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1142 - val_loss: 0.2270\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1165 - val_loss: 0.2031\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1492 - val_loss: 0.2396\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1908 - val_loss: 0.2362\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1200 - val_loss: 0.1964\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1189 - val_loss: 0.1909\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1035 - val_loss: 0.1932\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1005 - val_loss: 0.1923\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1095 - val_loss: 0.2001\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0967 - val_loss: 0.2021\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1150 - val_loss: 0.2194\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1009 - val_loss: 0.2215\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1040 - val_loss: 0.1912\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1109 - val_loss: 0.1925\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1122 - val_loss: 0.1907\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1016 - val_loss: 0.1981\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0991 - val_loss: 0.1944\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0899 - val_loss: 0.1989\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1005 - val_loss: 0.2674\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1026 - val_loss: 0.1953\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0894 - val_loss: 0.1940\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1020 - val_loss: 0.1925\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0863 - val_loss: 0.1972\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0911 - val_loss: 0.1945\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0906 - val_loss: 0.1916\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0861 - val_loss: 0.1883\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0898 - val_loss: 0.1903\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0902 - val_loss: 0.1962\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0813 - val_loss: 0.2084\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0844 - val_loss: 0.1958\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0857 - val_loss: 0.1952\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0823 - val_loss: 0.1886\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0827 - val_loss: 0.1845\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0855 - val_loss: 0.1887\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0809 - val_loss: 0.1910\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0845 - val_loss: 0.1915\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0762 - val_loss: 0.1958\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0832 - val_loss: 0.1878\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0809 - val_loss: 0.1891\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0821 - val_loss: 0.1891\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0767 - val_loss: 0.1853\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0790 - val_loss: 0.2222\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0770 - val_loss: 0.1881\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0783 - val_loss: 0.1868\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0795 - val_loss: 0.1816\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0820 - val_loss: 0.1854\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0728 - val_loss: 0.1830\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0737 - val_loss: 0.2139\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0837 - val_loss: 0.1821\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0846 - val_loss: 0.2110\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0823 - val_loss: 0.1901\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0810 - val_loss: 0.1897\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0863 - val_loss: 0.1858\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0812 - val_loss: 0.1996\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0784 - val_loss: 0.1888\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0736 - val_loss: 0.1907\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0715 - val_loss: 0.1831\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0794 - val_loss: 0.1825\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0697 - val_loss: 0.1947\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0736 - val_loss: 0.1896\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0711 - val_loss: 0.1889\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0682 - val_loss: 0.1865\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0742 - val_loss: 0.2038\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0680 - val_loss: 0.1903\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0783 - val_loss: 0.1833\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0744 - val_loss: 0.1890\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0751 - val_loss: 0.1834\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0752 - val_loss: 0.1871\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0789 - val_loss: 0.1866\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0757 - val_loss: 0.1900\n",
      "Epoch 00165: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total=10.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 242.9049 - val_loss: 5.1938\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.9230 - val_loss: 2.4571\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.0133 - val_loss: 2.0893\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.4774 - val_loss: 1.3361\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2266 - val_loss: 0.6763\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9916 - val_loss: 0.7587\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6728 - val_loss: 0.7149\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5581 - val_loss: 1.2897\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7380 - val_loss: 1.6753\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1197 - val_loss: 1.5341\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3715 - val_loss: 0.7663\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4337 - val_loss: 0.8142\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0412 - val_loss: 0.9918\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.5625 - val_loss: 1.1159\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.4616 - val_loss: 3.1394\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9643 - val_loss: 2.6504\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.7199 - val_loss: 10.2824\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.1161 - val_loss: 3.7387\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.9061 - val_loss: 5.7379\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.8221 - val_loss: 1.9072\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1356 - val_loss: 3.1345\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.6185 - val_loss: 1.3509\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5697 - val_loss: 0.8003\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9480 - val_loss: 1.9440\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1490 - val_loss: 2.6650\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.2148 - val_loss: 0.6837\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2966 - val_loss: 0.4832\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6214 - val_loss: 0.6748\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6763 - val_loss: 1.6630\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8929 - val_loss: 0.4146\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1669 - val_loss: 0.6646\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1334 - val_loss: 0.3942\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1021 - val_loss: 0.5380\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0523 - val_loss: 0.4189\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7749 - val_loss: 0.3990\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1244 - val_loss: 0.9209\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0919 - val_loss: 0.3448\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1618 - val_loss: 0.4469\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7747 - val_loss: 0.3740\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8975 - val_loss: 0.2963\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7960 - val_loss: 0.4659\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2144 - val_loss: 0.6012\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6053 - val_loss: 0.6208\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9014 - val_loss: 0.3692\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6809 - val_loss: 0.2331\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5549 - val_loss: 0.3854\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5189 - val_loss: 0.2569\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2769 - val_loss: 1.2761\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8479 - val_loss: 0.2668\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4820 - val_loss: 0.3238\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5036 - val_loss: 0.3713\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4564 - val_loss: 0.2701\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3857 - val_loss: 0.3286\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2925 - val_loss: 0.2289\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3012 - val_loss: 0.2669\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3254 - val_loss: 0.2909\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4003 - val_loss: 0.2089\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4163 - val_loss: 0.3656\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4377 - val_loss: 0.4091\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3418 - val_loss: 0.2972\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2971 - val_loss: 0.2023\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3864 - val_loss: 0.2104\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2442 - val_loss: 0.2284\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2177 - val_loss: 0.2071\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2356 - val_loss: 0.2253\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2273 - val_loss: 0.2025\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2311 - val_loss: 0.2197\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2070 - val_loss: 0.2013\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2613 - val_loss: 0.3059\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2184 - val_loss: 0.2337\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1938 - val_loss: 0.2408\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2169 - val_loss: 0.2052\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1705 - val_loss: 0.2087\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1909 - val_loss: 0.2026\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2217 - val_loss: 0.2243\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2161 - val_loss: 0.2673\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1896 - val_loss: 0.2076\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1910 - val_loss: 0.2106\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1808 - val_loss: 0.2105\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2552 - val_loss: 0.3024\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1768 - val_loss: 0.2032\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1600 - val_loss: 0.1994\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1486 - val_loss: 0.2047\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2422 - val_loss: 0.2950\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2854 - val_loss: 0.2806\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1783 - val_loss: 0.1941\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1391 - val_loss: 0.1939\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1520 - val_loss: 0.2097\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1264 - val_loss: 0.1908\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1311 - val_loss: 0.1980\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1310 - val_loss: 0.2083\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1485 - val_loss: 0.1918\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1307 - val_loss: 0.1933\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1194 - val_loss: 0.1880\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1250 - val_loss: 0.1891\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1340 - val_loss: 0.2091\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1212 - val_loss: 0.2055\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1211 - val_loss: 0.2010\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1201 - val_loss: 0.2309\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1300 - val_loss: 0.2092\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1160 - val_loss: 0.2221\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1080 - val_loss: 0.2068\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1235 - val_loss: 0.2084\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1156 - val_loss: 0.2331\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1132 - val_loss: 0.1930\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0965 - val_loss: 0.1891\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1009 - val_loss: 0.1879\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1090 - val_loss: 0.1860\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0986 - val_loss: 0.1865\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1046 - val_loss: 0.1843\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1044 - val_loss: 0.1911\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0976 - val_loss: 0.1978\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1175 - val_loss: 0.1975\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1155 - val_loss: 0.2082\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1132 - val_loss: 0.2050\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1001 - val_loss: 0.2542\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0960 - val_loss: 0.2085\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0978 - val_loss: 0.1867\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0900 - val_loss: 0.1856\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1051 - val_loss: 0.2264\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1113 - val_loss: 0.1883\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0960 - val_loss: 0.2007\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0916 - val_loss: 0.1859\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1129 - val_loss: 0.2192\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1090 - val_loss: 0.1863\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0909 - val_loss: 0.1867\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0876 - val_loss: 0.1839\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0891 - val_loss: 0.1846\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0892 - val_loss: 0.1854\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0878 - val_loss: 0.1829\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0798 - val_loss: 0.1908\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0924 - val_loss: 0.2410\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0909 - val_loss: 0.1888\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0848 - val_loss: 0.1873\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0822 - val_loss: 0.1842\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0799 - val_loss: 0.1903\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0817 - val_loss: 0.1872\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0830 - val_loss: 0.1903\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0758 - val_loss: 0.2341\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0874 - val_loss: 0.1878\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0882 - val_loss: 0.1965\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0817 - val_loss: 0.2313\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0938 - val_loss: 0.1834\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0882 - val_loss: 0.1814\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0805 - val_loss: 0.2005\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0794 - val_loss: 0.1834\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0756 - val_loss: 0.1947\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0916 - val_loss: 0.1991\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1120 - val_loss: 0.1914\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0779 - val_loss: 0.1829\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0754 - val_loss: 0.1818\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0861 - val_loss: 0.1905\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0787 - val_loss: 0.1860\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0747 - val_loss: 0.1936\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0877 - val_loss: 0.2110\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0994 - val_loss: 0.1928\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0784 - val_loss: 0.2133\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0725 - val_loss: 0.1971\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0705 - val_loss: 0.1984\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0722 - val_loss: 0.1874\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0730 - val_loss: 0.1833\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0729 - val_loss: 0.2034\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0761 - val_loss: 0.1865\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0768 - val_loss: 0.1940\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0835 - val_loss: 0.1847\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0720 - val_loss: 0.1856\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0834 - val_loss: 0.2160\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0740 - val_loss: 0.1892\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0806 - val_loss: 0.1853\n",
      "Epoch 00169: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total=10.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 260.8419 - val_loss: 4.9073\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.5051 - val_loss: 2.4605\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.6026 - val_loss: 2.6286\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1842 - val_loss: 3.5227\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.6599 - val_loss: 1.3228\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7901 - val_loss: 1.0101\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1040 - val_loss: 0.9885\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8940 - val_loss: 1.1121\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4650 - val_loss: 0.9296\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2818 - val_loss: 1.8948\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8712 - val_loss: 0.6475\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9947 - val_loss: 2.4233\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7247 - val_loss: 0.7810\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9937 - val_loss: 0.6719\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8818 - val_loss: 1.1511\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7098 - val_loss: 1.1375\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.2757 - val_loss: 2.6015\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9784 - val_loss: 1.5780\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1065 - val_loss: 1.0708\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.4944 - val_loss: 2.0574\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0431 - val_loss: 0.8764\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4220 - val_loss: 1.2038\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7877 - val_loss: 0.8927\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9988 - val_loss: 2.4004\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7853 - val_loss: 1.1514\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1721 - val_loss: 0.6003\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1339 - val_loss: 1.7142\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0041 - val_loss: 0.8801\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.2449 - val_loss: 0.9843\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3635 - val_loss: 5.5935\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0901 - val_loss: 1.1340\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1061 - val_loss: 1.2671\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0516 - val_loss: 0.5468\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6698 - val_loss: 0.9014\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4739 - val_loss: 0.7838\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8511 - val_loss: 0.4832\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0321 - val_loss: 0.4374\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9431 - val_loss: 1.6867\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9023 - val_loss: 0.5926\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1750 - val_loss: 0.3429\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9300 - val_loss: 0.3242\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6930 - val_loss: 0.2760\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5699 - val_loss: 0.3581\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5989 - val_loss: 0.5218\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1759 - val_loss: 0.4671\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7977 - val_loss: 0.2905\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8607 - val_loss: 0.4970\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0276 - val_loss: 1.4042\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3786 - val_loss: 0.8956\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8588 - val_loss: 0.5073\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6094 - val_loss: 0.3360\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6689 - val_loss: 0.3022\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4356 - val_loss: 0.2595\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3815 - val_loss: 0.2597\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3188 - val_loss: 0.2576\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3360 - val_loss: 0.2761\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3018 - val_loss: 0.2194\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2687 - val_loss: 0.2178\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3516 - val_loss: 0.4855\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3449 - val_loss: 0.1981\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2376 - val_loss: 0.2319\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1966 - val_loss: 0.2271\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2244 - val_loss: 0.2810\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2896 - val_loss: 0.2816\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2366 - val_loss: 0.1994\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1944 - val_loss: 0.2519\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1621 - val_loss: 0.2162\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1751 - val_loss: 0.1966\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1910 - val_loss: 0.2074\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1702 - val_loss: 0.2062\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2369 - val_loss: 0.3578\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5150 - val_loss: 0.1914\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1685 - val_loss: 0.2056\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1493 - val_loss: 0.1852\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1648 - val_loss: 0.1999\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1539 - val_loss: 0.2054\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1747 - val_loss: 0.2139\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1543 - val_loss: 0.2162\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1443 - val_loss: 0.1854\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1665 - val_loss: 0.2005\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1585 - val_loss: 0.2070\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1262 - val_loss: 0.1973\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1262 - val_loss: 0.1823\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1308 - val_loss: 0.1895\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1210 - val_loss: 0.1925\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1226 - val_loss: 0.2084\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1165 - val_loss: 0.1831\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1141 - val_loss: 0.1836\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1372 - val_loss: 0.2094\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1144 - val_loss: 0.2377\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1225 - val_loss: 0.2221\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1495 - val_loss: 0.1814\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1091 - val_loss: 0.2194\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1080 - val_loss: 0.1911\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1490 - val_loss: 0.2205\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1164 - val_loss: 0.1869\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1130 - val_loss: 0.1983\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1118 - val_loss: 0.1959\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1536 - val_loss: 0.2133\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1084 - val_loss: 0.1941\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1054 - val_loss: 0.1782\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0943 - val_loss: 0.1846\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0962 - val_loss: 0.1796\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1002 - val_loss: 0.1877\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1115 - val_loss: 0.2118\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1112 - val_loss: 0.2137\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1056 - val_loss: 0.1849\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1128 - val_loss: 0.1932\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1009 - val_loss: 0.1875\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0913 - val_loss: 0.1819\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0925 - val_loss: 0.1797\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0889 - val_loss: 0.1876\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0922 - val_loss: 0.1852\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0892 - val_loss: 0.1819\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0947 - val_loss: 0.1880\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0973 - val_loss: 0.1972\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0937 - val_loss: 0.1772\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0847 - val_loss: 0.1793\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0881 - val_loss: 0.1838\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0900 - val_loss: 0.1763\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0824 - val_loss: 0.1818\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0836 - val_loss: 0.1867\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0999 - val_loss: 0.2118\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0931 - val_loss: 0.1871\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1008 - val_loss: 0.1804\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0793 - val_loss: 0.1824\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0830 - val_loss: 0.1887\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0819 - val_loss: 0.1925\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0812 - val_loss: 0.1823\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0891 - val_loss: 0.1928\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0774 - val_loss: 0.1820\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0795 - val_loss: 0.1939\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0806 - val_loss: 0.1997\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0747 - val_loss: 0.1797\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0745 - val_loss: 0.2303\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0794 - val_loss: 0.1888\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0721 - val_loss: 0.2094\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0847 - val_loss: 0.1776\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1080 - val_loss: 0.1790\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0830 - val_loss: 0.1764\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0858 - val_loss: 0.1948\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0778 - val_loss: 0.1781\n",
      "Epoch 00142: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 8.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 192.2383 - val_loss: 3.6684\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.4558 - val_loss: 1.2869\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.7333 - val_loss: 0.9210\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8909 - val_loss: 1.1639\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9645 - val_loss: 0.5236\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7714 - val_loss: 0.7195\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5271 - val_loss: 2.8492\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8261 - val_loss: 0.8404\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4816 - val_loss: 0.7251\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9222 - val_loss: 0.8055\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2959 - val_loss: 0.6348\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2163 - val_loss: 3.0334\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.1030 - val_loss: 1.1766\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.6848 - val_loss: 5.0183\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.9832 - val_loss: 1.9754\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.0910 - val_loss: 1.4889\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.1921 - val_loss: 4.1010\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.3248 - val_loss: 2.3371\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.2979 - val_loss: 1.0033\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5279 - val_loss: 1.2171\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.7119 - val_loss: 3.4977\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.2335 - val_loss: 1.7880\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.6455 - val_loss: 0.6932\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8831 - val_loss: 2.2569\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1070 - val_loss: 1.3446\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8574 - val_loss: 0.8627\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4589 - val_loss: 0.4979\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4312 - val_loss: 0.4011\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0074 - val_loss: 0.3170\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2967 - val_loss: 0.6338\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3078 - val_loss: 1.0108\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1477 - val_loss: 0.6556\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4454 - val_loss: 1.0528\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7872 - val_loss: 1.2366\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1376 - val_loss: 0.3724\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1341 - val_loss: 0.4668\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6107 - val_loss: 0.3805\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7515 - val_loss: 0.2757\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9785 - val_loss: 0.9142\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6546 - val_loss: 0.3044\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4857 - val_loss: 0.2739\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7447 - val_loss: 0.2756\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8106 - val_loss: 0.5550\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7816 - val_loss: 0.2723\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3953 - val_loss: 0.3242\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3764 - val_loss: 0.3742\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3297 - val_loss: 0.2520\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7197 - val_loss: 0.5126\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9323 - val_loss: 0.4314\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3617 - val_loss: 0.2611\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4052 - val_loss: 0.4990\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6826 - val_loss: 0.2380\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4306 - val_loss: 0.2298\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4648 - val_loss: 0.2796\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3966 - val_loss: 0.2395\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3859 - val_loss: 0.3356\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2367 - val_loss: 0.2796\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2333 - val_loss: 0.2312\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2065 - val_loss: 0.3049\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4190 - val_loss: 0.2926\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2436 - val_loss: 0.2461\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2110 - val_loss: 0.2013\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1831 - val_loss: 0.2344\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2266 - val_loss: 0.2198\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2498 - val_loss: 0.2058\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1658 - val_loss: 0.2196\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1733 - val_loss: 0.2095\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3560 - val_loss: 0.4135\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2708 - val_loss: 0.2177\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2706 - val_loss: 0.2317\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2041 - val_loss: 0.1967\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1660 - val_loss: 0.1969\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1718 - val_loss: 0.2018\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1678 - val_loss: 0.2531\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1510 - val_loss: 0.2135\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1543 - val_loss: 0.2116\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1640 - val_loss: 0.2136\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1468 - val_loss: 0.1989\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1366 - val_loss: 0.1993\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1328 - val_loss: 0.2338\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1329 - val_loss: 0.2319\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1471 - val_loss: 0.2317\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1815 - val_loss: 0.2547\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2420 - val_loss: 0.2125\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1637 - val_loss: 0.2164\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1681 - val_loss: 0.1911\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1232 - val_loss: 0.1990\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1373 - val_loss: 0.1863\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1180 - val_loss: 0.1970\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1217 - val_loss: 0.2064\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1201 - val_loss: 0.1800\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1285 - val_loss: 0.1894\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1945 - val_loss: 0.2641\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1405 - val_loss: 0.1790\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1341 - val_loss: 0.1822\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1078 - val_loss: 0.2133\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1187 - val_loss: 0.1791\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1195 - val_loss: 0.1871\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1034 - val_loss: 0.1856\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0991 - val_loss: 0.1847\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0954 - val_loss: 0.1757\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1059 - val_loss: 0.1817\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0948 - val_loss: 0.1883\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1040 - val_loss: 0.2171\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1005 - val_loss: 0.2280\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1024 - val_loss: 0.1807\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0941 - val_loss: 0.1794\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1030 - val_loss: 0.1772\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0961 - val_loss: 0.1857\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0963 - val_loss: 0.1804\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0973 - val_loss: 0.1798\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0982 - val_loss: 0.1843\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0920 - val_loss: 0.1825\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0955 - val_loss: 0.1752\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0947 - val_loss: 0.1919\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0869 - val_loss: 0.1828\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0931 - val_loss: 0.1850\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1079 - val_loss: 0.1842\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0819 - val_loss: 0.1911\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0898 - val_loss: 0.1918\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0941 - val_loss: 0.2206\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0956 - val_loss: 0.2131\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0879 - val_loss: 0.1960\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0939 - val_loss: 0.1798\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0832 - val_loss: 0.1797\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.0864 - val_loss: 0.1797\n",
      "Epoch 00127: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 8.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 174.3231 - val_loss: 5.0416\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 14.2570 - val_loss: 0.3736\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 8.5912 - val_loss: 0.2936\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 8.9772 - val_loss: 0.4026\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 8.9517 - val_loss: 0.6762\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 10.9948 - val_loss: 0.3583\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 11.6342 - val_loss: 0.3169\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 14.3133 - val_loss: 0.6187\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 14.1868 - val_loss: 0.4265\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 13.2268 - val_loss: 0.2948\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 13.9926 - val_loss: 0.3064\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 14.3683 - val_loss: 0.3402\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 16.0560 - val_loss: 0.6177\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 11.1567 - val_loss: 0.8620\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 10.3976 - val_loss: 0.8474\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 9.9937 - val_loss: 0.3767\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 9.9823 - val_loss: 1.7891\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 9.9976 - val_loss: 0.4323\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 8.3614 - val_loss: 0.4744\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 7.2360 - val_loss: 0.4121\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 5.9036 - val_loss: 0.4884\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 5.4826 - val_loss: 0.3160\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.5343 - val_loss: 0.2954\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.7224 - val_loss: 0.4049\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.1339 - val_loss: 0.2447\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.7369 - val_loss: 0.2574\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.2964 - val_loss: 0.2404\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.3732 - val_loss: 0.2275\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.9272 - val_loss: 0.2825\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6718 - val_loss: 0.2193\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.5129 - val_loss: 0.2053\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.1174 - val_loss: 0.2157\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2407 - val_loss: 0.2686\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0179 - val_loss: 0.6526\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7747 - val_loss: 0.2023\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7842 - val_loss: 0.2612\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6764 - val_loss: 0.2137\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.4911 - val_loss: 0.2681\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3583 - val_loss: 0.2598\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3581 - val_loss: 0.2738\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1837 - val_loss: 0.2201\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.2164 - val_loss: 0.2835\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1589 - val_loss: 0.3010\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0186 - val_loss: 0.2409\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0500 - val_loss: 0.2008\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0078 - val_loss: 0.1885\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8795 - val_loss: 0.2223\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8571 - val_loss: 0.2002\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7930 - val_loss: 0.2215\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7539 - val_loss: 0.2261\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7132 - val_loss: 0.1970\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7094 - val_loss: 0.2032\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6698 - val_loss: 0.2068\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6716 - val_loss: 0.1979\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5999 - val_loss: 0.2069\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5666 - val_loss: 0.2069\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5005 - val_loss: 0.2151\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5167 - val_loss: 0.1865\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5095 - val_loss: 0.1852\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4668 - val_loss: 0.2085\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4860 - val_loss: 0.1946\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4534 - val_loss: 0.1854\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4222 - val_loss: 0.2095\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4078 - val_loss: 0.2080\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3867 - val_loss: 0.1960\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3582 - val_loss: 0.1831\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3512 - val_loss: 0.1828\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3169 - val_loss: 0.1911\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3422 - val_loss: 0.2115\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3361 - val_loss: 0.1880\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3493 - val_loss: 0.1922\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3300 - val_loss: 0.2754\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2934 - val_loss: 0.2102\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2664 - val_loss: 0.1924\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2881 - val_loss: 0.1880\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2769 - val_loss: 0.1978\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2757 - val_loss: 0.1946\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2604 - val_loss: 0.1984\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2574 - val_loss: 0.1951\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2253 - val_loss: 0.1925\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2281 - val_loss: 0.1958\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2474 - val_loss: 0.1910\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2218 - val_loss: 0.2152\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2399 - val_loss: 0.1840\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2084 - val_loss: 0.1971\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2228 - val_loss: 0.1845\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2198 - val_loss: 0.2018\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2134 - val_loss: 0.1866\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2076 - val_loss: 0.1876\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2000 - val_loss: 0.2510\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2151 - val_loss: 0.1836\n",
      "Epoch 00091: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 6.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 245.4567 - val_loss: 0.5716\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.3728 - val_loss: 0.5366\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.0097 - val_loss: 0.3295\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.3406 - val_loss: 0.3698\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.3412 - val_loss: 2.2213\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.7300 - val_loss: 0.3193\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.6062 - val_loss: 0.6824\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.8384 - val_loss: 0.8077\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 16.4970 - val_loss: 0.3959\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.4780 - val_loss: 0.3692\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 20.0311 - val_loss: 1.7636\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 22.8970 - val_loss: 4.2240\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 24.9426 - val_loss: 1.9542\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 21.5778 - val_loss: 0.4429\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.3568 - val_loss: 1.3555\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.0176 - val_loss: 0.6473\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.0649 - val_loss: 0.8715\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 16.9280 - val_loss: 2.7699\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.9481 - val_loss: 1.8462\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.0902 - val_loss: 0.2724\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.9260 - val_loss: 0.2511\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.7076 - val_loss: 0.3570\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.1366 - val_loss: 0.5511\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.2054 - val_loss: 0.3638\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.2208 - val_loss: 0.3408\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.0540 - val_loss: 0.4810\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9869 - val_loss: 0.3305\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.6750 - val_loss: 1.1619\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.5185 - val_loss: 0.3370\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1183 - val_loss: 0.5647\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.4047 - val_loss: 0.2387\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0631 - val_loss: 0.4388\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.1335 - val_loss: 0.4962\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.4473 - val_loss: 0.3335\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1915 - val_loss: 0.2862\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.6644 - val_loss: 0.2606\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5983 - val_loss: 0.3243\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.2551 - val_loss: 0.5015\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 3.3827 - val_loss: 0.4364\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3360 - val_loss: 0.2222\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0586 - val_loss: 0.2635\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0242 - val_loss: 0.2132\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7205 - val_loss: 0.2310\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9098 - val_loss: 0.3467\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7892 - val_loss: 0.2531\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4168 - val_loss: 0.2123\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3544 - val_loss: 0.2417\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2594 - val_loss: 0.1910\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1669 - val_loss: 0.2086\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2430 - val_loss: 0.2065\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0703 - val_loss: 0.1945\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3090 - val_loss: 0.3794\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2445 - val_loss: 0.1990\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1055 - val_loss: 0.2380\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9152 - val_loss: 0.2083\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9373 - val_loss: 0.2003\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9473 - val_loss: 0.2805\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8012 - val_loss: 0.1927\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7716 - val_loss: 0.2091\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6926 - val_loss: 0.2099\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6416 - val_loss: 0.2056\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6546 - val_loss: 0.1924\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6426 - val_loss: 0.1874\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6088 - val_loss: 0.1853\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5802 - val_loss: 0.1836\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5534 - val_loss: 0.2141\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4952 - val_loss: 0.1846\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5284 - val_loss: 0.2247\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5553 - val_loss: 0.1931\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4454 - val_loss: 0.1842\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4166 - val_loss: 0.1854\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4464 - val_loss: 0.2027\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4406 - val_loss: 0.1796\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3743 - val_loss: 0.1809\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4545 - val_loss: 0.2120\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3887 - val_loss: 0.2160\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3606 - val_loss: 0.2190\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3586 - val_loss: 0.1840\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3789 - val_loss: 0.1831\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3145 - val_loss: 0.1965\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3169 - val_loss: 0.1790\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3132 - val_loss: 0.1833\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3118 - val_loss: 0.1959\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3499 - val_loss: 0.2107\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2791 - val_loss: 0.2377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3038 - val_loss: 0.1806\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2760 - val_loss: 0.1787\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2576 - val_loss: 0.1893\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3131 - val_loss: 0.1865\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2663 - val_loss: 0.2044\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2544 - val_loss: 0.1986\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2162 - val_loss: 0.1913\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2386 - val_loss: 0.1894\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2378 - val_loss: 0.2030\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2225 - val_loss: 0.1815\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2231 - val_loss: 0.1802\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2151 - val_loss: 0.1871\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2123 - val_loss: 0.1907\n",
      "Epoch 00098: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 6.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 130.7382 - val_loss: 0.5440\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.6041 - val_loss: 0.8988\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.5228 - val_loss: 0.3029\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.2461 - val_loss: 0.3974\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.3103 - val_loss: 0.8389\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.8769 - val_loss: 0.6913\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.5105 - val_loss: 0.6818\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 18.1818 - val_loss: 4.0832\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 25.7605 - val_loss: 2.7074\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 18.2840 - val_loss: 0.8796\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.1098 - val_loss: 0.4071\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.3214 - val_loss: 0.3617\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.2260 - val_loss: 0.7028\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.1009 - val_loss: 0.6819\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.6151 - val_loss: 0.5014\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.5400 - val_loss: 0.4137\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.7043 - val_loss: 0.7947\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.0892 - val_loss: 0.4172\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9316 - val_loss: 0.4599\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.3884 - val_loss: 0.2879\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7751 - val_loss: 0.6365\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5241 - val_loss: 0.5185\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0235 - val_loss: 0.3284\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6983 - val_loss: 0.2358\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8955 - val_loss: 0.7479\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0325 - val_loss: 0.3268\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3821 - val_loss: 0.2393\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7300 - val_loss: 0.6378\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1703 - val_loss: 0.2206\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9260 - val_loss: 0.2765\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0148 - val_loss: 0.2498\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6932 - val_loss: 0.2800\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2139 - val_loss: 0.3126\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3408 - val_loss: 0.2629\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5639 - val_loss: 0.4584\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1877 - val_loss: 0.1920\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2062 - val_loss: 0.2388\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0095 - val_loss: 0.2023\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9135 - val_loss: 0.1998\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9114 - val_loss: 0.1976\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8825 - val_loss: 0.1946\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7394 - val_loss: 0.1995\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7709 - val_loss: 0.2064\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7135 - val_loss: 0.1925\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6652 - val_loss: 0.2182\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5890 - val_loss: 0.2019\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6168 - val_loss: 0.1838\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5624 - val_loss: 0.2256\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5186 - val_loss: 0.1923\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5162 - val_loss: 0.1817\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5394 - val_loss: 0.1852\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4680 - val_loss: 0.1995\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4568 - val_loss: 0.1987\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4974 - val_loss: 0.1986\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4633 - val_loss: 0.1834\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4280 - val_loss: 0.1934\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3923 - val_loss: 0.2531\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4206 - val_loss: 0.1791\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3528 - val_loss: 0.1861\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4073 - val_loss: 0.1833\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3749 - val_loss: 0.2332\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3275 - val_loss: 0.2279\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3094 - val_loss: 0.2061\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2951 - val_loss: 0.1895\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2814 - val_loss: 0.1843\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3242 - val_loss: 0.2226\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2755 - val_loss: 0.1813\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2842 - val_loss: 0.1805\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2576 - val_loss: 0.1780\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2818 - val_loss: 0.1872\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2625 - val_loss: 0.1816\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2518 - val_loss: 0.1785\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2421 - val_loss: 0.1924\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2444 - val_loss: 0.2027\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2194 - val_loss: 0.1832\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2284 - val_loss: 0.1799\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2049 - val_loss: 0.2016\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2435 - val_loss: 0.1915\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2222 - val_loss: 0.1970\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2079 - val_loss: 0.1841\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2033 - val_loss: 0.1958\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2071 - val_loss: 0.1845\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2050 - val_loss: 0.1803\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1989 - val_loss: 0.1804\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2034 - val_loss: 0.1836\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2008 - val_loss: 0.1979\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2001 - val_loss: 0.1827\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1813 - val_loss: 0.1826\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2266 - val_loss: 0.1978\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2554 - val_loss: 0.1785\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2082 - val_loss: 0.1854\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1866 - val_loss: 0.1991\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2013 - val_loss: 0.1909\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1771 - val_loss: 0.2058\n",
      "Epoch 00094: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 6.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 143.4769 - val_loss: 1.2032\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.5589 - val_loss: 0.5734\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.3205 - val_loss: 0.3317\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.1331 - val_loss: 1.1013\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.1736 - val_loss: 0.5794\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.3590 - val_loss: 0.4365\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.2186 - val_loss: 0.6943\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.8679 - val_loss: 0.5226\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 19.8197 - val_loss: 0.7928\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.5619 - val_loss: 0.3074\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.8520 - val_loss: 0.4772\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.8915 - val_loss: 0.5939\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.4014 - val_loss: 0.5060\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.1438 - val_loss: 0.7054\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.8209 - val_loss: 0.7005\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.2426 - val_loss: 0.3322\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.9149 - val_loss: 0.2414\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.2170 - val_loss: 0.7396\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.3496 - val_loss: 0.5754\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.9928 - val_loss: 0.4571\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.1787 - val_loss: 0.5836\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.3822 - val_loss: 0.5736\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.3009 - val_loss: 0.4885\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8047 - val_loss: 0.2946\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.4255 - val_loss: 0.9052\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1148 - val_loss: 0.7060\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.2732 - val_loss: 0.3712\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8131 - val_loss: 0.3236\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6575 - val_loss: 0.4212\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5535 - val_loss: 0.3788\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2842 - val_loss: 0.2398\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8795 - val_loss: 0.2348\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3787 - val_loss: 0.1806\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4570 - val_loss: 0.3155\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3875 - val_loss: 0.1772\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3145 - val_loss: 0.1864\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2936 - val_loss: 0.2224\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0609 - val_loss: 0.2261\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0775 - val_loss: 0.2048\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9471 - val_loss: 0.2632\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9470 - val_loss: 0.1788\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8771 - val_loss: 0.1920\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8724 - val_loss: 0.1936\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8526 - val_loss: 0.2558\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8274 - val_loss: 0.1908\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7304 - val_loss: 0.2478\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7571 - val_loss: 0.1975\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6114 - val_loss: 0.1886\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5771 - val_loss: 0.2086\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5616 - val_loss: 0.2459\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5180 - val_loss: 0.1970\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5586 - val_loss: 0.1996\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5253 - val_loss: 0.1844\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4800 - val_loss: 0.2209\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5449 - val_loss: 0.2140\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4613 - val_loss: 0.1963\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4117 - val_loss: 0.1933\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3948 - val_loss: 0.2047\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3790 - val_loss: 0.1935\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4411 - val_loss: 0.1836\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 4.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 206.7620 - val_loss: 1.6991\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.2447 - val_loss: 0.5801\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.2174 - val_loss: 0.2365\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.3534 - val_loss: 0.3059\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.5213 - val_loss: 0.3416\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.0910 - val_loss: 1.3267\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.6129 - val_loss: 0.4415\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.9329 - val_loss: 0.3455\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.6168 - val_loss: 0.7300\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 19.8161 - val_loss: 1.3539\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.8439 - val_loss: 1.4091\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 16.2676 - val_loss: 0.5276\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.4079 - val_loss: 0.6035\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.6548 - val_loss: 0.9797\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.8312 - val_loss: 0.2731\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.9681 - val_loss: 0.8611\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.7102 - val_loss: 0.9003\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.9854 - val_loss: 1.3679\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.8951 - val_loss: 5.9135\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.2142 - val_loss: 0.9796\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.4086 - val_loss: 0.3080\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.0452 - val_loss: 0.8151\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.2136 - val_loss: 0.3887\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9890 - val_loss: 0.3555\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.3429 - val_loss: 0.2119\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1498 - val_loss: 0.5535\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8869 - val_loss: 0.3168\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1610 - val_loss: 0.3462\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7742 - val_loss: 0.2531\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0889 - val_loss: 0.2732\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7721 - val_loss: 0.4732\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1183 - val_loss: 0.2136\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6706 - val_loss: 0.6124\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3455 - val_loss: 0.2467\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5644 - val_loss: 0.2951\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0200 - val_loss: 0.3662\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9880 - val_loss: 0.2206\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7273 - val_loss: 0.3310\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6128 - val_loss: 0.3278\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3790 - val_loss: 0.2020\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2964 - val_loss: 0.2010\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2561 - val_loss: 0.1759\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3138 - val_loss: 0.1985\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0682 - val_loss: 0.1783\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2100 - val_loss: 0.3344\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3297 - val_loss: 0.2675\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9510 - val_loss: 0.2036\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9329 - val_loss: 0.1972\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8517 - val_loss: 0.2011\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8519 - val_loss: 0.1922\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8098 - val_loss: 0.1956\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7530 - val_loss: 0.2727\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7115 - val_loss: 0.2010\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7745 - val_loss: 0.1800\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6971 - val_loss: 0.2239\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5960 - val_loss: 0.1907\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6006 - val_loss: 0.1731\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5830 - val_loss: 0.1860\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6229 - val_loss: 0.2274\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6255 - val_loss: 0.1810\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5202 - val_loss: 0.1787\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5325 - val_loss: 0.1773\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4653 - val_loss: 0.1828\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4387 - val_loss: 0.1967\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4300 - val_loss: 0.2204\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4358 - val_loss: 0.2219\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4065 - val_loss: 0.1739\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3950 - val_loss: 0.2318\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4240 - val_loss: 0.2228\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3807 - val_loss: 0.1765\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3975 - val_loss: 0.1789\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3422 - val_loss: 0.1750\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3344 - val_loss: 0.1897\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3355 - val_loss: 0.1859\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3128 - val_loss: 0.2335\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3381 - val_loss: 0.2075\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3215 - val_loss: 0.1705\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3053 - val_loss: 0.1769\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2895 - val_loss: 0.1875\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2739 - val_loss: 0.1936\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3129 - val_loss: 0.1999\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3069 - val_loss: 0.1675\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2459 - val_loss: 0.1706\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2467 - val_loss: 0.1718\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2400 - val_loss: 0.1794\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2615 - val_loss: 0.1715\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2420 - val_loss: 0.1822\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2533 - val_loss: 0.1807\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2264 - val_loss: 0.1829\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2289 - val_loss: 0.1738\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2314 - val_loss: 0.1721\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2221 - val_loss: 0.1763\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2130 - val_loss: 0.1704\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2197 - val_loss: 0.1752\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2119 - val_loss: 0.1948\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2178 - val_loss: 0.1805\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2016 - val_loss: 0.1803\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1924 - val_loss: 0.1780\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1739 - val_loss: 0.2166\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2041 - val_loss: 0.1976\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1928 - val_loss: 0.1862\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1797 - val_loss: 0.1714\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1748 - val_loss: 0.1695\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1769 - val_loss: 0.1685\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1675 - val_loss: 0.1756\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1784 - val_loss: 0.1696\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1758 - val_loss: 0.1910\n",
      "Epoch 00107: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 7.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 211.2687 - val_loss: 2.6447\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 36.0252 - val_loss: 1.0986\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 25.9242 - val_loss: 1.3759\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 25.0504 - val_loss: 0.3499\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 25.4908 - val_loss: 0.3490\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 23.5448 - val_loss: 0.3800\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 20.6523 - val_loss: 0.4768\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 17.0693 - val_loss: 1.0008\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 16.4824 - val_loss: 0.7735\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 15.6290 - val_loss: 1.0308\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 15.1592 - val_loss: 1.1812\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 12.5833 - val_loss: 0.4422\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 10.1967 - val_loss: 1.2241\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 11.0008 - val_loss: 0.2822\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 10.2129 - val_loss: 0.4917\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 7.9805 - val_loss: 0.5065\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 7.4061 - val_loss: 0.2434\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 6.4214 - val_loss: 0.8217\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 5.3203 - val_loss: 0.5602\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 5.1920 - val_loss: 0.2114\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.8114 - val_loss: 0.4647\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.2813 - val_loss: 0.7210\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.7718 - val_loss: 0.4474\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.5909 - val_loss: 0.4954\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.7102 - val_loss: 0.5929\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.0401 - val_loss: 0.6940\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.8637 - val_loss: 0.5113\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7765 - val_loss: 0.2083\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7202 - val_loss: 0.2732\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.3129 - val_loss: 0.2028\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.1660 - val_loss: 0.2333\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2757 - val_loss: 0.2016\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.9448 - val_loss: 0.2869\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8026 - val_loss: 0.2716\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7351 - val_loss: 0.2328\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6984 - val_loss: 0.2815\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.5556 - val_loss: 0.7590\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.5668 - val_loss: 0.6140\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.4495 - val_loss: 0.4766\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3395 - val_loss: 0.2135\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1987 - val_loss: 0.2085\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1726 - val_loss: 0.2335\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.2281 - val_loss: 0.2299\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0308 - val_loss: 0.2200\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0023 - val_loss: 0.2123\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0107 - val_loss: 0.1941\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9014 - val_loss: 0.2228\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9385 - val_loss: 0.2001\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8748 - val_loss: 0.1851\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8745 - val_loss: 0.2225\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7519 - val_loss: 0.1872\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8208 - val_loss: 0.2471\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7206 - val_loss: 0.1911\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6818 - val_loss: 0.2503\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6531 - val_loss: 0.2198\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5986 - val_loss: 0.1840\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6146 - val_loss: 0.1989\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5651 - val_loss: 0.2265\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5715 - val_loss: 0.1916\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5589 - val_loss: 0.1983\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5123 - val_loss: 0.1966\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5053 - val_loss: 0.2665\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5323 - val_loss: 0.1913\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4883 - val_loss: 0.2381\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4638 - val_loss: 0.1965\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4452 - val_loss: 0.1889\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4007 - val_loss: 0.2421\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4247 - val_loss: 0.1990\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4130 - val_loss: 0.1868\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3778 - val_loss: 0.2004\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4018 - val_loss: 0.2411\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3712 - val_loss: 0.1962\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3644 - val_loss: 0.2082\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3444 - val_loss: 0.1963\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3441 - val_loss: 0.1885\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3304 - val_loss: 0.2251\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3042 - val_loss: 0.2161\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3213 - val_loss: 0.1931\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3051 - val_loss: 0.2007\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3171 - val_loss: 0.1885\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2899 - val_loss: 0.1909\n",
      "Epoch 00081: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 5.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 153.7505 - val_loss: 0.4748\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 48.9564 - val_loss: 4.6322\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 33.2015 - val_loss: 0.3440\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 26.6970 - val_loss: 0.3938\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 22.5752 - val_loss: 0.4950\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 21.5605 - val_loss: 0.9222\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 20.2531 - val_loss: 0.2882\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 16.9240 - val_loss: 3.0995\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.6488 - val_loss: 1.0310\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 16.0004 - val_loss: 0.8467\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.3425 - val_loss: 0.5742\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.0852 - val_loss: 0.7535\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.0312 - val_loss: 0.4156\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.9944 - val_loss: 0.2240\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.9153 - val_loss: 0.3076\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1766 - val_loss: 0.4358\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.4330 - val_loss: 0.2644\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0908 - val_loss: 0.1999\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7911 - val_loss: 0.3176\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.1619 - val_loss: 0.5820\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.2526 - val_loss: 0.2271\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0242 - val_loss: 0.2450\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6376 - val_loss: 0.2232\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4156 - val_loss: 0.1891\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1820 - val_loss: 0.2813\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2943 - val_loss: 0.3966\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8766 - val_loss: 0.2748\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9256 - val_loss: 0.2282\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6101 - val_loss: 0.3097\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5610 - val_loss: 0.3556\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5014 - val_loss: 0.2933\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4418 - val_loss: 0.3325\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2445 - val_loss: 0.2070\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1842 - val_loss: 0.1970\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0483 - val_loss: 0.1851\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0047 - val_loss: 0.2681\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9497 - val_loss: 0.2267\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8616 - val_loss: 0.2083\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8491 - val_loss: 0.1871\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8979 - val_loss: 0.2043\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7642 - val_loss: 0.1969\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7234 - val_loss: 0.2091\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6160 - val_loss: 0.2155\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6373 - val_loss: 0.1880\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6114 - val_loss: 0.1770\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5765 - val_loss: 0.1796\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5090 - val_loss: 0.1716\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5185 - val_loss: 0.1928\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5160 - val_loss: 0.1748\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4727 - val_loss: 0.2133\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4533 - val_loss: 0.1772\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4883 - val_loss: 0.1778\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4260 - val_loss: 0.1700\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4285 - val_loss: 0.1696\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4292 - val_loss: 0.2028\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3857 - val_loss: 0.2274\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4033 - val_loss: 0.1698\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3875 - val_loss: 0.1720\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3533 - val_loss: 0.1701\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3754 - val_loss: 0.1706\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3432 - val_loss: 0.2439\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3160 - val_loss: 0.1703\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3351 - val_loss: 0.1973\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3218 - val_loss: 0.1767\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3153 - val_loss: 0.1711\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3061 - val_loss: 0.2161\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2972 - val_loss: 0.1806\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3084 - val_loss: 0.1727\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2752 - val_loss: 0.2113\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2887 - val_loss: 0.1864\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3072 - val_loss: 0.1707\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2713 - val_loss: 0.1875\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2679 - val_loss: 0.1731\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2748 - val_loss: 0.2395\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2742 - val_loss: 0.1938\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2658 - val_loss: 0.1718\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2620 - val_loss: 0.1865\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2580 - val_loss: 0.2070\n",
      "Epoch 00078: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 5.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 168.1496 - val_loss: 1.5615\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 38.7132 - val_loss: 1.3408\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 27.0741 - val_loss: 0.8618\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 25.5912 - val_loss: 3.8723\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 31.1781 - val_loss: 1.2706\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 23.8928 - val_loss: 0.5779\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 24.3836 - val_loss: 0.4623\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 20.5460 - val_loss: 0.6680\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.8133 - val_loss: 0.2868\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.4436 - val_loss: 1.1973\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.1107 - val_loss: 2.5710\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.2023 - val_loss: 1.1798\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.3444 - val_loss: 2.0376\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.5739 - val_loss: 0.8858\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.0902 - val_loss: 0.4310\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.4677 - val_loss: 0.3916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.2576 - val_loss: 0.8356\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.2509 - val_loss: 0.4578\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.3464 - val_loss: 0.5555\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.6882 - val_loss: 0.3026\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1315 - val_loss: 0.2266\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8068 - val_loss: 0.6729\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0756 - val_loss: 0.2083\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.3698 - val_loss: 0.3643\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4871 - val_loss: 0.2169\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5058 - val_loss: 0.2805\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2168 - val_loss: 0.3463\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1614 - val_loss: 0.2551\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9844 - val_loss: 0.2475\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6306 - val_loss: 0.2633\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6704 - val_loss: 0.2193\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6652 - val_loss: 0.3302\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5256 - val_loss: 0.2609\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4091 - val_loss: 0.2837\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4161 - val_loss: 0.1841\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1152 - val_loss: 0.2064\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1452 - val_loss: 0.2383\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0505 - val_loss: 0.2124\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0232 - val_loss: 0.3417\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8932 - val_loss: 0.1935\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9451 - val_loss: 0.2255\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8131 - val_loss: 0.1982\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8286 - val_loss: 0.2316\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7430 - val_loss: 0.1826\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7342 - val_loss: 0.2324\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6610 - val_loss: 0.1822\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6477 - val_loss: 0.2073\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6504 - val_loss: 0.2642\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6184 - val_loss: 0.1846\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5851 - val_loss: 0.3084\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5326 - val_loss: 0.2129\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5169 - val_loss: 0.1807\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5251 - val_loss: 0.2287\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4928 - val_loss: 0.2197\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4793 - val_loss: 0.1745\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4639 - val_loss: 0.1811\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4543 - val_loss: 0.1789\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4387 - val_loss: 0.2023\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4086 - val_loss: 0.1856\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4155 - val_loss: 0.1914\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3744 - val_loss: 0.2525\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3596 - val_loss: 0.2176\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3470 - val_loss: 0.1801\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3560 - val_loss: 0.1866\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3494 - val_loss: 0.1896\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3285 - val_loss: 0.1991\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3163 - val_loss: 0.1964\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3132 - val_loss: 0.1792\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3094 - val_loss: 0.1907\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3158 - val_loss: 0.1894\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3142 - val_loss: 0.1880\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3057 - val_loss: 0.1800\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3156 - val_loss: 0.1747\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2862 - val_loss: 0.2366\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2871 - val_loss: 0.1838\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2828 - val_loss: 0.2061\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2809 - val_loss: 0.1821\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2682 - val_loss: 0.2240\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2737 - val_loss: 0.1776\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2727 - val_loss: 0.1757\n",
      "Epoch 00080: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 5.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 188.0296 - val_loss: 6.7870\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 33.5272 - val_loss: 2.9552\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 27.7458 - val_loss: 0.6187\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 26.4443 - val_loss: 0.8125\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 23.6803 - val_loss: 0.4797\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 22.8838 - val_loss: 1.9424\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 21.6002 - val_loss: 0.5846\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 20.8336 - val_loss: 0.3013\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 16.2238 - val_loss: 0.2531\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.1481 - val_loss: 0.5558\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.4309 - val_loss: 0.3470\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.1250 - val_loss: 0.9254\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.2892 - val_loss: 0.6987\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.4102 - val_loss: 0.3778\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.1008 - val_loss: 0.2485\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.1213 - val_loss: 0.7983\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.6701 - val_loss: 0.3987\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.2126 - val_loss: 0.5234\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.5011 - val_loss: 0.4245\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.6547 - val_loss: 0.2729\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.3315 - val_loss: 0.5088\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.1790 - val_loss: 0.4207\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9764 - val_loss: 0.5431\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8862 - val_loss: 0.3154\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0621 - val_loss: 0.2545\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0913 - val_loss: 0.4210\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5521 - val_loss: 0.2387\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2404 - val_loss: 0.4618\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0473 - val_loss: 0.2020\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0093 - val_loss: 0.1935\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0404 - val_loss: 0.2708\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7642 - val_loss: 0.2149\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8606 - val_loss: 0.2792\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5425 - val_loss: 0.1888\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5788 - val_loss: 0.4513\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4314 - val_loss: 0.2340\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3828 - val_loss: 0.2268\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2431 - val_loss: 0.2341\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2299 - val_loss: 0.3131\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2422 - val_loss: 0.3816\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1020 - val_loss: 0.1896\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1531 - val_loss: 0.2882\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9932 - val_loss: 0.2305\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8967 - val_loss: 0.3422\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8942 - val_loss: 0.3189\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9154 - val_loss: 0.2309\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7103 - val_loss: 0.1909\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8026 - val_loss: 0.2621\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8123 - val_loss: 0.1962\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6456 - val_loss: 0.2531\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6992 - val_loss: 0.1926\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8666 - val_loss: 0.1928\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6531 - val_loss: 0.1853\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6053 - val_loss: 0.1840\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5657 - val_loss: 0.1884\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5276 - val_loss: 0.2368\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5434 - val_loss: 0.2226\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4953 - val_loss: 0.1746\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4452 - val_loss: 0.1802\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4512 - val_loss: 0.1736\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4601 - val_loss: 0.2423\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4686 - val_loss: 0.2708\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4359 - val_loss: 0.1891\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4063 - val_loss: 0.1699\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3705 - val_loss: 0.1701\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3700 - val_loss: 0.1831\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3759 - val_loss: 0.1761\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3903 - val_loss: 0.1888\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3701 - val_loss: 0.1778\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3339 - val_loss: 0.1890\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3104 - val_loss: 0.1780\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3127 - val_loss: 0.1685\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3143 - val_loss: 0.1714\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3161 - val_loss: 0.2211\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3445 - val_loss: 0.1827\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3137 - val_loss: 0.1723\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2981 - val_loss: 0.2073\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2891 - val_loss: 0.1856\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2618 - val_loss: 0.1773\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2790 - val_loss: 0.1973\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2723 - val_loss: 0.1687\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2613 - val_loss: 0.1812\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2447 - val_loss: 0.1762\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2406 - val_loss: 0.1803\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2568 - val_loss: 0.1708\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2454 - val_loss: 0.2023\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2488 - val_loss: 0.1757\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2523 - val_loss: 0.2244\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2383 - val_loss: 0.2088\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2242 - val_loss: 0.1703\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2124 - val_loss: 0.1742\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2223 - val_loss: 0.1818\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2156 - val_loss: 0.1792\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2334 - val_loss: 0.1942\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2294 - val_loss: 0.2137\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2246 - val_loss: 0.1716\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2058 - val_loss: 0.1760\n",
      "Epoch 00097: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 6.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 117.1931 - val_loss: 2.8054\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 36.8575 - val_loss: 1.5752\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 24.9490 - val_loss: 1.5050\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 25.7133 - val_loss: 0.5974\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 23.9152 - val_loss: 0.3950\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.1649 - val_loss: 0.3328\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.5119 - val_loss: 0.5049\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 12.4058 - val_loss: 0.7995\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.3550 - val_loss: 0.7168\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.4459 - val_loss: 0.3280\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.4155 - val_loss: 0.3635\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.1240 - val_loss: 0.7895\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.1054 - val_loss: 0.2230\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.3478 - val_loss: 0.4691\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8734 - val_loss: 0.5969\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5025 - val_loss: 0.2619\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.2400 - val_loss: 0.1916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9174 - val_loss: 0.2111\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4700 - val_loss: 0.2334\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2193 - val_loss: 0.3078\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3408 - val_loss: 0.3437\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1138 - val_loss: 0.1963\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7274 - val_loss: 0.2466\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7181 - val_loss: 0.2665\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5157 - val_loss: 0.2783\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3529 - val_loss: 0.3517\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3121 - val_loss: 0.1894\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2831 - val_loss: 0.2258\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1707 - val_loss: 0.2846\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4930 - val_loss: 0.2687\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1425 - val_loss: 0.2850\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9238 - val_loss: 0.2020\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9329 - val_loss: 0.2021\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8398 - val_loss: 0.2001\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7721 - val_loss: 0.2265\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7355 - val_loss: 0.2214\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6416 - val_loss: 0.1838\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6211 - val_loss: 0.1746\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5826 - val_loss: 0.1811\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5945 - val_loss: 0.1802\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5544 - val_loss: 0.2081\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5066 - val_loss: 0.1674\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4835 - val_loss: 0.1704\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5460 - val_loss: 0.2034\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4861 - val_loss: 0.1759\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4267 - val_loss: 0.1977\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4757 - val_loss: 0.2639\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4381 - val_loss: 0.1754\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3946 - val_loss: 0.1773\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3444 - val_loss: 0.1815\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3488 - val_loss: 0.1773\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3477 - val_loss: 0.1671\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3725 - val_loss: 0.1700\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3473 - val_loss: 0.1665\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3540 - val_loss: 0.2450\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3350 - val_loss: 0.2195\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3354 - val_loss: 0.1957\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3299 - val_loss: 0.1677\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2865 - val_loss: 0.2490\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3184 - val_loss: 0.2201\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2995 - val_loss: 0.1681\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2926 - val_loss: 0.1716\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2888 - val_loss: 0.2047\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2910 - val_loss: 0.1670\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2886 - val_loss: 0.1657\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2809 - val_loss: 0.1752\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2627 - val_loss: 0.1964\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2478 - val_loss: 0.2174\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2531 - val_loss: 0.1695\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2703 - val_loss: 0.1841\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2419 - val_loss: 0.1879\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2251 - val_loss: 0.2232\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2458 - val_loss: 0.1703\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2287 - val_loss: 0.2075\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2490 - val_loss: 0.1811\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2267 - val_loss: 0.2470\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2293 - val_loss: 0.2218\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2345 - val_loss: 0.1778\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2169 - val_loss: 0.1902\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2331 - val_loss: 0.1729\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2118 - val_loss: 0.2014\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1990 - val_loss: 0.1722\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2109 - val_loss: 0.1781\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2053 - val_loss: 0.2017\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2182 - val_loss: 0.1806\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2016 - val_loss: 0.1894\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2080 - val_loss: 0.1933\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2007 - val_loss: 0.1939\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2223 - val_loss: 0.1812\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2381 - val_loss: 0.2193\n",
      "Epoch 00090: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 6.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 576.7394 - val_loss: 20.9101\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 26.8456 - val_loss: 5.6875\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 12.0043 - val_loss: 2.4290\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 6.1870 - val_loss: 1.9542\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.9580 - val_loss: 1.1784\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.4893 - val_loss: 0.8510\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.7273 - val_loss: 1.1756\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.5541 - val_loss: 0.9763\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.6865 - val_loss: 0.7960\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.4023 - val_loss: 1.9028\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.6548 - val_loss: 1.2702\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.6716 - val_loss: 0.6677\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.4700 - val_loss: 0.7681\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.2410 - val_loss: 0.6937\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.1685 - val_loss: 0.7371\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.2376 - val_loss: 2.0382\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.5799 - val_loss: 0.7416\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.1019 - val_loss: 1.3925\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.9360 - val_loss: 0.9815\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.0752 - val_loss: 1.2440\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.1511 - val_loss: 1.3122\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.4298 - val_loss: 1.9799\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.2226 - val_loss: 1.2470\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.9339 - val_loss: 1.2165\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.1325 - val_loss: 0.9505\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.2823 - val_loss: 2.5607\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.6990 - val_loss: 3.7421\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 6.8311 - val_loss: 3.4514\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 7.8191 - val_loss: 1.4348\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 6.1515 - val_loss: 2.2381\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 5.2855 - val_loss: 1.9343\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 4.0802 - val_loss: 4.0263\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.6878 - val_loss: 1.2288\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 3.0048 - val_loss: 0.8323\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.4936 - val_loss: 1.6907\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.8559 - val_loss: 1.0606\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.8736 - val_loss: 0.6850\n",
      "Epoch 00037: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 3.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 585.0978 - val_loss: 33.0925\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 27.8141 - val_loss: 3.5235\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.2198 - val_loss: 2.3503\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.0838 - val_loss: 1.2885\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.2126 - val_loss: 2.2194\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1558 - val_loss: 1.0478\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9157 - val_loss: 0.7734\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9895 - val_loss: 0.5540\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7624 - val_loss: 1.2129\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6735 - val_loss: 0.7707\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9927 - val_loss: 1.1185\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2610 - val_loss: 0.6935\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9811 - val_loss: 5.0578\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2951 - val_loss: 0.9738\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2476 - val_loss: 1.0431\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.9680 - val_loss: 2.1129\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.5185 - val_loss: 4.3087\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 8.2544 - val_loss: 2.0059\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.9030 - val_loss: 1.5426\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.5408 - val_loss: 2.0937\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.0105 - val_loss: 2.3960\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.8974 - val_loss: 2.4529\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.6961 - val_loss: 1.9348\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5807 - val_loss: 1.3467\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.4556 - val_loss: 2.3013\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.6014 - val_loss: 1.1172\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.9757 - val_loss: 1.1697\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.5536 - val_loss: 6.8502\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.5101 - val_loss: 1.8379\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.5598 - val_loss: 2.0108\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8771 - val_loss: 1.0484\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.8700 - val_loss: 1.5953\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.5519 - val_loss: 1.7339\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 567.7505 - val_loss: 14.6324\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 29.4738 - val_loss: 4.3384\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.7995 - val_loss: 3.2002\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.6987 - val_loss: 1.4918\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.1546 - val_loss: 1.0518\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.3364 - val_loss: 2.3653\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1654 - val_loss: 3.3361\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.3654 - val_loss: 0.8399\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5582 - val_loss: 1.2628\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.0870 - val_loss: 2.1546\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.6783 - val_loss: 1.7251\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.7076 - val_loss: 0.8359\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.9886 - val_loss: 1.6301\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.6485 - val_loss: 1.4534\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.2059 - val_loss: 1.7384\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.1299 - val_loss: 1.3122\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.3777 - val_loss: 7.5033\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.5741 - val_loss: 5.7228\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.6708 - val_loss: 1.5185\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.8445 - val_loss: 11.1994\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 13.5409 - val_loss: 16.6413\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.6707 - val_loss: 3.9084\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.0530 - val_loss: 1.8657\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.4270 - val_loss: 1.4197\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.7027 - val_loss: 2.0409\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.0571 - val_loss: 1.0083\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.3793 - val_loss: 0.8927\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.3625 - val_loss: 1.6766\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.9130 - val_loss: 0.7532\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8660 - val_loss: 2.7690\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.6750 - val_loss: 2.1878\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.2382 - val_loss: 2.7971\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.3829 - val_loss: 0.9736\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5091 - val_loss: 0.6304\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3771 - val_loss: 0.6739\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2350 - val_loss: 0.4589\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.1947 - val_loss: 0.9851\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.7080 - val_loss: 0.9850\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.8978 - val_loss: 1.2735\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5069 - val_loss: 0.4875\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2967 - val_loss: 0.3931\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3647 - val_loss: 0.7422\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.3955 - val_loss: 0.5132\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8768 - val_loss: 0.4104\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9597 - val_loss: 0.5943\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.0388 - val_loss: 0.2879\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6755 - val_loss: 0.5980\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8147 - val_loss: 0.5143\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6628 - val_loss: 0.6018\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5926 - val_loss: 0.9238\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5861 - val_loss: 0.4831\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7906 - val_loss: 0.4908\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5258 - val_loss: 0.3361\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4209 - val_loss: 0.2900\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3533 - val_loss: 0.2454\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6947 - val_loss: 0.5189\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4294 - val_loss: 0.2643\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3226 - val_loss: 0.3241\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2924 - val_loss: 0.2313\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3403 - val_loss: 0.2364\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2565 - val_loss: 0.2347\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2706 - val_loss: 0.2688\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3755 - val_loss: 0.5538\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3835 - val_loss: 0.2873\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6340 - val_loss: 0.9823\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8643 - val_loss: 0.4211\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4354 - val_loss: 0.3996\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7321 - val_loss: 0.4053\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3414 - val_loss: 0.2548\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2421 - val_loss: 0.2380\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4245 - val_loss: 0.3481\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4991 - val_loss: 0.2976\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2357 - val_loss: 0.2308\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2102 - val_loss: 0.2221\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2929 - val_loss: 0.2934\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1732 - val_loss: 0.2128\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4285 - val_loss: 0.3432\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1845 - val_loss: 0.2746\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3173 - val_loss: 0.2263\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2344 - val_loss: 0.2140\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1501 - val_loss: 0.2168\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3013 - val_loss: 0.2831\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1587 - val_loss: 0.2108\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1374 - val_loss: 0.2056\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1281 - val_loss: 0.2174\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1187 - val_loss: 0.2890\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1325 - val_loss: 0.2043\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1722 - val_loss: 0.2153\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1631 - val_loss: 0.2400\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1284 - val_loss: 0.2165\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1208 - val_loss: 0.2148\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1483 - val_loss: 0.2066\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1226 - val_loss: 0.2049\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1055 - val_loss: 0.1959\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1757 - val_loss: 0.2214\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1292 - val_loss: 0.2049\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0957 - val_loss: 0.2230\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1011 - val_loss: 0.2330\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1076 - val_loss: 0.2206\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1138 - val_loss: 0.1992\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1135 - val_loss: 0.2342\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.0947 - val_loss: 0.2069\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1407 - val_loss: 0.2569\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1177 - val_loss: 0.2202\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0917 - val_loss: 0.2190\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1030 - val_loss: 0.2229\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0965 - val_loss: 0.2075\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0940 - val_loss: 0.1876\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0741 - val_loss: 0.2021\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0743 - val_loss: 0.2009\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0888 - val_loss: 0.1903\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0841 - val_loss: 0.1863\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0785 - val_loss: 0.1944\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0695 - val_loss: 0.2005\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.0636 - val_loss: 0.2053\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0974 - val_loss: 0.1934\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0703 - val_loss: 0.2022\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0692 - val_loss: 0.1935\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0643 - val_loss: 0.1920\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0765 - val_loss: 0.1915\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0666 - val_loss: 0.1852\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0668 - val_loss: 0.1971\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0647 - val_loss: 0.1874\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0609 - val_loss: 0.1952\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0733 - val_loss: 0.1990\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0901 - val_loss: 0.1949\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0904 - val_loss: 0.2438\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0877 - val_loss: 0.1895\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1097 - val_loss: 0.1849\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0681 - val_loss: 0.2133\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0715 - val_loss: 0.2046\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0984 - val_loss: 0.1843\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0682 - val_loss: 0.1842\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0543 - val_loss: 0.1823\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0573 - val_loss: 0.1874\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0535 - val_loss: 0.1843\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0534 - val_loss: 0.1926\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0627 - val_loss: 0.1891\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0734 - val_loss: 0.1880\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0660 - val_loss: 0.1836\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0530 - val_loss: 0.1845\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0524 - val_loss: 0.1904\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0537 - val_loss: 0.1918\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0529 - val_loss: 0.1854\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0559 - val_loss: 0.1836\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0566 - val_loss: 0.1952\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0549 - val_loss: 0.1898\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0554 - val_loss: 0.1832\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0528 - val_loss: 0.1872\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0517 - val_loss: 0.1862\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0507 - val_loss: 0.1871\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0955 - val_loss: 0.1831\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0614 - val_loss: 0.1943\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0534 - val_loss: 0.1866\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0524 - val_loss: 0.1956\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0533 - val_loss: 0.1832\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0516 - val_loss: 0.1898\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0542 - val_loss: 0.1811\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0498 - val_loss: 0.2009\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0498 - val_loss: 0.2311\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0633 - val_loss: 0.1897\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0559 - val_loss: 0.1892\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0547 - val_loss: 0.1846\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0501 - val_loss: 0.1961\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0481 - val_loss: 0.1851\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0521 - val_loss: 0.2026\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0521 - val_loss: 0.1844\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0497 - val_loss: 0.2118\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0496 - val_loss: 0.1917\n",
      "Epoch 170/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0504 - val_loss: 0.1863\n",
      "Epoch 171/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0482 - val_loss: 0.1868\n",
      "Epoch 172/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0501 - val_loss: 0.2110\n",
      "Epoch 173/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0663 - val_loss: 0.1903\n",
      "Epoch 174/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0709 - val_loss: 0.2188\n",
      "Epoch 175/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0830 - val_loss: 0.2137\n",
      "Epoch 176/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0750 - val_loss: 0.2479\n",
      "Epoch 177/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0795 - val_loss: 0.1876\n",
      "Epoch 178/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0513 - val_loss: 0.1842\n",
      "Epoch 179/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0548 - val_loss: 0.2179\n",
      "Epoch 180/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0845 - val_loss: 0.2802\n",
      "Epoch 181/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0936 - val_loss: 0.2005\n",
      "Epoch 182/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0648 - val_loss: 0.2477\n",
      "Epoch 183/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.0617 - val_loss: 0.1846\n",
      "Epoch 00183: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total=17.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 533.4016 - val_loss: 11.3125\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 26.2385 - val_loss: 3.1247\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.6682 - val_loss: 2.0454\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.2992 - val_loss: 0.9704\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.7146 - val_loss: 1.2083\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.5536 - val_loss: 0.5286\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.1410 - val_loss: 1.4593\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0485 - val_loss: 0.9232\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9416 - val_loss: 2.3774\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.0688 - val_loss: 2.0238\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.3791 - val_loss: 4.2661\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.6330 - val_loss: 0.9713\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1813 - val_loss: 1.7007\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.3376 - val_loss: 1.5990\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2517 - val_loss: 1.1803\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1149 - val_loss: 0.6092\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8193 - val_loss: 0.6019\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.1930 - val_loss: 1.0902\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.1964 - val_loss: 3.1424\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.0273 - val_loss: 1.3165\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5519 - val_loss: 0.9541\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.2582 - val_loss: 3.2928\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.9751 - val_loss: 4.4388\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.7451 - val_loss: 3.5922\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.6847 - val_loss: 2.3387\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.4291 - val_loss: 1.0278\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.7619 - val_loss: 0.7579\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.0498 - val_loss: 1.4845\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.9710 - val_loss: 1.4946\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.7717 - val_loss: 2.8140\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.5795 - val_loss: 1.3519\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 3.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 459.6631 - val_loss: 11.5581\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 25.3842 - val_loss: 4.7408\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 9.5435 - val_loss: 1.5007\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.1033 - val_loss: 1.1650\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5526 - val_loss: 1.0076\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.4509 - val_loss: 1.4091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9246 - val_loss: 0.5784\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6644 - val_loss: 0.5164\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6697 - val_loss: 0.8578\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8687 - val_loss: 0.7306\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0838 - val_loss: 1.8490\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8510 - val_loss: 1.9050\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.0160 - val_loss: 1.8208\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5663 - val_loss: 4.9707\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.2591 - val_loss: 2.4723\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.1962 - val_loss: 0.8411\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1783 - val_loss: 1.2072\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.9727 - val_loss: 2.3987\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.9782 - val_loss: 0.9612\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.5111 - val_loss: 3.4273\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.5954 - val_loss: 1.4109\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.7360 - val_loss: 2.1498\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.6538 - val_loss: 1.7340\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.9431 - val_loss: 5.6992\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.4793 - val_loss: 2.0005\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.2731 - val_loss: 1.1127\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.4208 - val_loss: 1.6248\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8880 - val_loss: 1.5031\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.2835 - val_loss: 1.4707\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.1325 - val_loss: 0.7317\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9545 - val_loss: 0.6488\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.5683 - val_loss: 1.1569\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.3624 - val_loss: 0.8761\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 10s 7ms/step - loss: 324.4548 - val_loss: 5.0152\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 18.3846 - val_loss: 0.6240\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 10.1221 - val_loss: 0.3771\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 8.8345 - val_loss: 0.5446\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 9.3953 - val_loss: 0.4530\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 11.1228 - val_loss: 2.2421\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 14.3151 - val_loss: 0.5272\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 15.9530 - val_loss: 0.3375\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 17.1486 - val_loss: 0.3339\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 20.3339 - val_loss: 0.3525\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 23.7261 - val_loss: 0.6763\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 20.6982 - val_loss: 2.1394\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 19.8959 - val_loss: 0.9835\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 16.2873 - val_loss: 0.9215\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 18.1591 - val_loss: 2.6212\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 16.5815 - val_loss: 0.4524\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 15.1693 - val_loss: 0.5351\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 12.4208 - val_loss: 0.5584\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 11.2257 - val_loss: 0.3641\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 9.5362 - val_loss: 0.2935\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 8.0000 - val_loss: 1.4022\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 7.9360 - val_loss: 0.2907\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 6.9001 - val_loss: 0.2362\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 6.1706 - val_loss: 0.3095\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 5.6739 - val_loss: 0.3207\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 5.5535 - val_loss: 0.3386\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 4.9044 - val_loss: 0.2856\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 4.0014 - val_loss: 0.2335\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.9838 - val_loss: 0.2362\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.5742 - val_loss: 0.5057\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.3866 - val_loss: 0.2244\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 3.1218 - val_loss: 0.3812\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.8780 - val_loss: 0.2090\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.7113 - val_loss: 0.3063\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.5789 - val_loss: 0.3039\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.1691 - val_loss: 0.2000\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.0638 - val_loss: 0.2117\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.0596 - val_loss: 0.2206\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.7664 - val_loss: 0.2385\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.8125 - val_loss: 0.1962\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.6746 - val_loss: 0.2248\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.5827 - val_loss: 0.2151\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.5935 - val_loss: 0.2176\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.2392 - val_loss: 0.2049\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.2510 - val_loss: 0.1963\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.2323 - val_loss: 0.2021\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.0254 - val_loss: 0.2159\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.9850 - val_loss: 0.2334\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.8956 - val_loss: 0.2415\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8936 - val_loss: 0.2104\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8073 - val_loss: 0.2094\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7812 - val_loss: 0.1965\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7118 - val_loss: 0.2041\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7512 - val_loss: 0.2416\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6968 - val_loss: 0.1883\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6061 - val_loss: 0.2108\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5849 - val_loss: 0.2631\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5628 - val_loss: 0.1859\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5161 - val_loss: 0.1936\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5313 - val_loss: 0.2130\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4828 - val_loss: 0.2181\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5146 - val_loss: 0.1955\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4358 - val_loss: 0.1989\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4157 - val_loss: 0.1889\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3874 - val_loss: 0.1981\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3850 - val_loss: 0.2377\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3913 - val_loss: 0.2018\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3504 - val_loss: 0.2079\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3296 - val_loss: 0.1889\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3207 - val_loss: 0.2207\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2968 - val_loss: 0.1833\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2832 - val_loss: 0.1876\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2692 - val_loss: 0.1847\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2893 - val_loss: 0.1845\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2913 - val_loss: 0.1836\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2388 - val_loss: 0.1936\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2434 - val_loss: 0.1857\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2296 - val_loss: 0.2064\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2334 - val_loss: 0.1846\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2145 - val_loss: 0.1813\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2126 - val_loss: 0.1802\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2144 - val_loss: 0.1937\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2087 - val_loss: 0.1847\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2029 - val_loss: 0.1854\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1970 - val_loss: 0.1832\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2025 - val_loss: 0.1850\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1842 - val_loss: 0.1860\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1754 - val_loss: 0.1838\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1794 - val_loss: 0.1992\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1783 - val_loss: 0.1841\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1696 - val_loss: 0.1869\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1601 - val_loss: 0.2197\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1746 - val_loss: 0.1971\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1637 - val_loss: 0.1871\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1606 - val_loss: 0.1881\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1534 - val_loss: 0.1849\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1528 - val_loss: 0.1846\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1452 - val_loss: 0.1851\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1381 - val_loss: 0.2250\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1430 - val_loss: 0.1875\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1351 - val_loss: 0.1898\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1423 - val_loss: 0.1842\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1278 - val_loss: 0.1836\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1434 - val_loss: 0.1843\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1424 - val_loss: 0.1889\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1349 - val_loss: 0.2064\n",
      "Epoch 00106: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total=10.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 8ms/step - loss: 308.0086 - val_loss: 8.3172\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 17.5131 - val_loss: 0.3458\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 8.4643 - val_loss: 0.4866\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 8.4559 - val_loss: 0.3128\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 9.3436 - val_loss: 0.3829\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 9.7500 - val_loss: 0.5902\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 11.4709 - val_loss: 0.9250\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 14.7366 - val_loss: 1.6310\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 29.5485 - val_loss: 3.1503\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 24.7132 - val_loss: 0.8722\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 30.7090 - val_loss: 1.8240\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 20.4113 - val_loss: 1.3498\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 17.0195 - val_loss: 1.1668\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 15.2546 - val_loss: 0.5156\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 12.2715 - val_loss: 2.7488\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 16.1335 - val_loss: 7.4000\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 46.0854 - val_loss: 3.9277\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 24.3866 - val_loss: 3.0730\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.1585 - val_loss: 1.8401\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 9.3883 - val_loss: 1.2892\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.0585 - val_loss: 2.6486\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 12.0302 - val_loss: 0.9710\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 7.8830 - val_loss: 1.6451\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 13.5361 - val_loss: 0.5438\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.0446 - val_loss: 0.3829\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.8248 - val_loss: 1.1930\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.2532 - val_loss: 0.6851\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.8481 - val_loss: 1.0345\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.0056 - val_loss: 0.4186\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 3.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 8ms/step - loss: 263.2165 - val_loss: 13.2320\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 15.3915 - val_loss: 0.5980\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 9.2741 - val_loss: 0.5575\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 9.1055 - val_loss: 0.6622\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 9.9653 - val_loss: 0.2604\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.4492 - val_loss: 0.4269\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 14.8235 - val_loss: 1.0463\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 15.3635 - val_loss: 1.3036\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 17.7770 - val_loss: 0.6427\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 19.5123 - val_loss: 1.5631\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 20.4219 - val_loss: 2.3697\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 18.7105 - val_loss: 0.5099\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 17.9925 - val_loss: 2.3258\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 17.7664 - val_loss: 0.3904\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 18.3424 - val_loss: 4.9146\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 22.7629 - val_loss: 2.7982\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 16.2424 - val_loss: 0.7017\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 11.9824 - val_loss: 1.3528\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 14.6423 - val_loss: 1.2436\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.6723 - val_loss: 0.9341\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.9100 - val_loss: 0.4204\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.8655 - val_loss: 2.9854\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.0258 - val_loss: 1.3088\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.2105 - val_loss: 0.5580\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.7411 - val_loss: 0.4491\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.9783 - val_loss: 1.1709\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.2425 - val_loss: 0.7623\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.6042 - val_loss: 0.4178\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.4283 - val_loss: 1.0124\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.2888 - val_loss: 0.2473\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.3671 - val_loss: 0.8392\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.4805 - val_loss: 0.5136\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0093 - val_loss: 0.2225\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.6395 - val_loss: 0.3983\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.8241 - val_loss: 0.4965\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.7069 - val_loss: 0.5755\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.0733 - val_loss: 0.4883\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.2150 - val_loss: 0.7043\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2156 - val_loss: 0.7644\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.9911 - val_loss: 0.7031\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5723 - val_loss: 0.3885\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.0809 - val_loss: 0.3291\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6962 - val_loss: 0.2070\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7511 - val_loss: 0.2569\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.9402 - val_loss: 0.2171\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7217 - val_loss: 0.1834\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7107 - val_loss: 0.1806\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5345 - val_loss: 0.1804\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5431 - val_loss: 0.2118\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5103 - val_loss: 0.1780\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5398 - val_loss: 0.1827\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4586 - val_loss: 0.2054\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4616 - val_loss: 0.1766\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3939 - val_loss: 0.1988\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4101 - val_loss: 0.1868\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5262 - val_loss: 0.1961\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4486 - val_loss: 0.2176\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3822 - val_loss: 0.2110\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3576 - val_loss: 0.2025\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3421 - val_loss: 0.1756\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2946 - val_loss: 0.1808\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2959 - val_loss: 0.1800\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2693 - val_loss: 0.2085\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3379 - val_loss: 0.1974\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2713 - val_loss: 0.1900\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2640 - val_loss: 0.1797\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2352 - val_loss: 0.2029\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2827 - val_loss: 0.1822\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2405 - val_loss: 0.1798\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2322 - val_loss: 0.1826\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2162 - val_loss: 0.1765\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2329 - val_loss: 0.1851\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2143 - val_loss: 0.1849\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2090 - val_loss: 0.1785\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1888 - val_loss: 0.1784\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1818 - val_loss: 0.1867\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1826 - val_loss: 0.1828\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1681 - val_loss: 0.1836\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1748 - val_loss: 0.1808\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1721 - val_loss: 0.1779\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1680 - val_loss: 0.1775\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1800 - val_loss: 0.1805\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1826 - val_loss: 0.2204\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1634 - val_loss: 0.1818\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1739 - val_loss: 0.1776\n",
      "Epoch 00085: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 8.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 281.8414 - val_loss: 1.1349\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 23.0120 - val_loss: 0.3304\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 12.7368 - val_loss: 0.4846\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 12.8286 - val_loss: 0.4721\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 16.1738 - val_loss: 2.7831\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 18.7406 - val_loss: 0.3596\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 18.9531 - val_loss: 2.3392\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 24.1459 - val_loss: 3.2288\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 35.2441 - val_loss: 0.8796\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 31.2692 - val_loss: 1.5173\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 25.3561 - val_loss: 1.0114\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 22.9693 - val_loss: 0.6427\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 17.8288 - val_loss: 1.4788\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 15.5624 - val_loss: 0.3380\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 11.8483 - val_loss: 1.4111\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 13.6663 - val_loss: 0.5725\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.4484 - val_loss: 0.4456\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 9.7942 - val_loss: 0.7750\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 8.3631 - val_loss: 0.4449\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.2574 - val_loss: 0.2730\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.2028 - val_loss: 0.2410\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.3794 - val_loss: 0.2533\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.6125 - val_loss: 1.1510\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.8323 - val_loss: 0.2316\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.7599 - val_loss: 0.2089\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.1143 - val_loss: 1.2730\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.9126 - val_loss: 0.6655\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.6081 - val_loss: 0.3403\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.8284 - val_loss: 0.2837\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.6597 - val_loss: 0.2104\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1806 - val_loss: 0.3348\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.5371 - val_loss: 0.5185\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.7498 - val_loss: 0.2267\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.3782 - val_loss: 0.2679\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9757 - val_loss: 0.2876\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0220 - val_loss: 0.2821\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6793 - val_loss: 0.2296\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.9612 - val_loss: 0.4156\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.1330 - val_loss: 0.3131\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5227 - val_loss: 0.2628\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2870 - val_loss: 0.2724\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2544 - val_loss: 0.2352\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2064 - val_loss: 0.2099\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7675 - val_loss: 0.5211\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0441 - val_loss: 0.2046\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.9997 - val_loss: 0.1837\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8669 - val_loss: 0.1973\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8325 - val_loss: 0.1962\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8549 - val_loss: 0.1893\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.0707 - val_loss: 0.2059\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7003 - val_loss: 0.1711\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5915 - val_loss: 0.1810\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5580 - val_loss: 0.2316\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5406 - val_loss: 0.1690\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5178 - val_loss: 0.1715\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5399 - val_loss: 0.1906\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4671 - val_loss: 0.1797\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4658 - val_loss: 0.1937\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4268 - val_loss: 0.1928\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4918 - val_loss: 0.1688\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3615 - val_loss: 0.1723\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3600 - val_loss: 0.1894\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3320 - val_loss: 0.1767\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3313 - val_loss: 0.1823\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3053 - val_loss: 0.2065\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3955 - val_loss: 0.1836\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3084 - val_loss: 0.1693\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2778 - val_loss: 0.1681\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2716 - val_loss: 0.1738\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2696 - val_loss: 0.1696\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2461 - val_loss: 0.1692\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2485 - val_loss: 0.1999\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2297 - val_loss: 0.1731\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2376 - val_loss: 0.1760\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2304 - val_loss: 0.1684\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2001 - val_loss: 0.1698\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2195 - val_loss: 0.1943\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2089 - val_loss: 0.1757\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2185 - val_loss: 0.1710\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 8.1min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 8ms/step - loss: 322.8960 - val_loss: 7.4670\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 19.0661 - val_loss: 0.4672\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 10.6320 - val_loss: 0.3930\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 10.4256 - val_loss: 0.3401\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 12.3709 - val_loss: 0.9738\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 16.5697 - val_loss: 0.3580\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 15.6688 - val_loss: 1.4373\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 18.1135 - val_loss: 1.2034\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 23.3556 - val_loss: 1.3498\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 32.7739 - val_loss: 1.0656\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 32.3068 - val_loss: 2.3520\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 29.7050 - val_loss: 2.2358\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 30.0311 - val_loss: 6.6469\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 19.8118 - val_loss: 0.6081\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 15.2054 - val_loss: 1.8228\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 13.7213 - val_loss: 2.1051\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 11.3911 - val_loss: 0.6821\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.6989 - val_loss: 1.7290\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 11.3497 - val_loss: 1.5722\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 13.7615 - val_loss: 1.6445\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 16.7672 - val_loss: 3.0214\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 12.0718 - val_loss: 1.5758\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.6631 - val_loss: 0.3838\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 9.0996 - val_loss: 2.3729\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.3055 - val_loss: 0.8860\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 13.1651 - val_loss: 0.7415\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.7866 - val_loss: 1.2451\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.4217 - val_loss: 0.6327\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.2535 - val_loss: 0.2704\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8597 - val_loss: 0.2174\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.5627 - val_loss: 0.2036\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.4308 - val_loss: 0.5231\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.1291 - val_loss: 0.2924\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.7284 - val_loss: 0.5101\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.2310 - val_loss: 0.2860\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.4981 - val_loss: 1.3417\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.3839 - val_loss: 0.4589\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8602 - val_loss: 0.3241\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4966 - val_loss: 0.2239\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5007 - val_loss: 0.3352\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2141 - val_loss: 0.3498\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8367 - val_loss: 0.2976\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4185 - val_loss: 0.3313\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.6797 - val_loss: 0.7068\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3820 - val_loss: 0.1864\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.0662 - val_loss: 0.1923\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.9122 - val_loss: 0.2076\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8595 - val_loss: 0.1860\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.0123 - val_loss: 0.2157\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8237 - val_loss: 0.2006\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8485 - val_loss: 0.1786\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6955 - val_loss: 0.1841\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6395 - val_loss: 0.1962\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6037 - val_loss: 0.1756\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5501 - val_loss: 0.1792\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6346 - val_loss: 0.1754\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5308 - val_loss: 0.1739\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6501 - val_loss: 0.2036\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4828 - val_loss: 0.1757\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4855 - val_loss: 0.1732\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4432 - val_loss: 0.1841\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4105 - val_loss: 0.1703\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3783 - val_loss: 0.1862\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4196 - val_loss: 0.1693\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3811 - val_loss: 0.2023\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3541 - val_loss: 0.1749\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3450 - val_loss: 0.1772\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3489 - val_loss: 0.1781\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3191 - val_loss: 0.1735\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3587 - val_loss: 0.1743\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3282 - val_loss: 0.1896\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2862 - val_loss: 0.1827\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2628 - val_loss: 0.1756\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2638 - val_loss: 0.1772\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2711 - val_loss: 0.1699\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2446 - val_loss: 0.1902\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2798 - val_loss: 0.1791\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2416 - val_loss: 0.1833\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2518 - val_loss: 0.1721\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2233 - val_loss: 0.1692\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2051 - val_loss: 0.1692\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2053 - val_loss: 0.1859\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1815 - val_loss: 0.1714\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1961 - val_loss: 0.1797\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2040 - val_loss: 0.1734\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1845 - val_loss: 0.1799\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1789 - val_loss: 0.1875\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1770 - val_loss: 0.1824\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1691 - val_loss: 0.1793\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1936 - val_loss: 0.1711\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1764 - val_loss: 0.1770\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1717 - val_loss: 0.1704\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1701 - val_loss: 0.2041\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1521 - val_loss: 0.1767\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1456 - val_loss: 0.1692\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1521 - val_loss: 0.1792\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1496 - val_loss: 0.1707\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1599 - val_loss: 0.1958\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1421 - val_loss: 0.1731\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1446 - val_loss: 0.1770\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1443 - val_loss: 0.1711\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1663 - val_loss: 0.1775\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1637 - val_loss: 0.1785\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1393 - val_loss: 0.1899\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1427 - val_loss: 0.1901\n",
      "Epoch 00105: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total=10.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 11s 8ms/step - loss: 247.9227 - val_loss: 0.5428\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 53.0649 - val_loss: 2.6515\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 34.7486 - val_loss: 1.3393\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 32.5373 - val_loss: 0.8117\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 36.3911 - val_loss: 0.3700\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 32.8940 - val_loss: 0.4741\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 29.6974 - val_loss: 0.9845\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 24.1846 - val_loss: 0.7319\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 20.0914 - val_loss: 0.2971\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 16.5106 - val_loss: 0.4085\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 13.3372 - val_loss: 0.2403\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 12.8108 - val_loss: 0.4387\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 9.7818 - val_loss: 0.2656\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 8.5653 - val_loss: 0.5655\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 7.3441 - val_loss: 1.1316\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 6.5066 - val_loss: 0.9086\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 5.9467 - val_loss: 0.9011\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 4.9725 - val_loss: 0.2142\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 4.5299 - val_loss: 0.5132\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 3.6670 - val_loss: 0.3785\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 3.7612 - val_loss: 0.3410\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 3.4574 - val_loss: 0.4176\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.8654 - val_loss: 0.3296\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.7273 - val_loss: 0.2742\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.5379 - val_loss: 0.1956\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.2835 - val_loss: 0.4390\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.1352 - val_loss: 0.2814\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.9911 - val_loss: 0.5845\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.6351 - val_loss: 0.1785\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.7873 - val_loss: 0.2017\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.5379 - val_loss: 0.1827\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.3589 - val_loss: 0.1838\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.1909 - val_loss: 0.2058\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.1420 - val_loss: 0.2101\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.1516 - val_loss: 0.2099\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.0417 - val_loss: 0.1907\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.9987 - val_loss: 0.1922\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.8738 - val_loss: 0.2150\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8643 - val_loss: 0.1815\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7300 - val_loss: 0.2172\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7352 - val_loss: 0.1864\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6692 - val_loss: 0.2696\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6185 - val_loss: 0.2108\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6884 - val_loss: 0.2268\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5663 - val_loss: 0.2079\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5254 - val_loss: 0.1792\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4990 - val_loss: 0.1803\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4947 - val_loss: 0.2098\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4666 - val_loss: 0.1720\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4649 - val_loss: 0.2304\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4414 - val_loss: 0.2169\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4368 - val_loss: 0.2084\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3983 - val_loss: 0.1839\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3345 - val_loss: 0.1906\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3300 - val_loss: 0.1805\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3322 - val_loss: 0.1752\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3491 - val_loss: 0.1788\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2975 - val_loss: 0.1751\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3162 - val_loss: 0.1910\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3029 - val_loss: 0.1790\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2889 - val_loss: 0.1811\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2916 - val_loss: 0.1764\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2911 - val_loss: 0.1881\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2660 - val_loss: 0.1864\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2571 - val_loss: 0.2007\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2625 - val_loss: 0.2042\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2354 - val_loss: 0.1743\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2509 - val_loss: 0.1758\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2428 - val_loss: 0.1760\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2699 - val_loss: 0.1820\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2312 - val_loss: 0.1810\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2314 - val_loss: 0.1761\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2295 - val_loss: 0.2020\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2163 - val_loss: 0.1757\n",
      "Epoch 00074: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 8.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 263.9706 - val_loss: 21.7591\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 49.4561 - val_loss: 2.4136\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 28.3658 - val_loss: 1.0731\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 32.7930 - val_loss: 0.9489\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 38.1270 - val_loss: 1.5826\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 39.9102 - val_loss: 3.2138\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 31.8473 - val_loss: 0.6614\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 29.6209 - val_loss: 1.0189\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 22.1136 - val_loss: 2.9230\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 20.2372 - val_loss: 2.6036\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 34.4874 - val_loss: 3.0903\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 23.4680 - val_loss: 0.7370\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 12.2091 - val_loss: 0.3172\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.8634 - val_loss: 0.3500\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.3497 - val_loss: 0.4508\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.8155 - val_loss: 0.5781\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.5568 - val_loss: 0.2137\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.9361 - val_loss: 1.3888\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.7804 - val_loss: 0.3067\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.6041 - val_loss: 0.4798\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.3819 - val_loss: 0.6719\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.5209 - val_loss: 0.8774\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.1455 - val_loss: 0.7158\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.3578 - val_loss: 0.8116\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.5205 - val_loss: 0.2689\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.2305 - val_loss: 0.3181\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.5454 - val_loss: 0.4111\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.0455 - val_loss: 0.2416\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8891 - val_loss: 0.2092\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6158 - val_loss: 0.3639\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4755 - val_loss: 0.3230\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3251 - val_loss: 0.3211\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2422 - val_loss: 0.2102\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4501 - val_loss: 0.2869\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6697 - val_loss: 0.2270\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4034 - val_loss: 0.2843\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1933 - val_loss: 0.1812\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9407 - val_loss: 0.1799\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9660 - val_loss: 0.1944\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8210 - val_loss: 0.2185\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9053 - val_loss: 0.1786\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8538 - val_loss: 0.1777\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7123 - val_loss: 0.2045\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6983 - val_loss: 0.1790\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5885 - val_loss: 0.1767\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7284 - val_loss: 0.1884\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5639 - val_loss: 0.2090\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5327 - val_loss: 0.1770\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6297 - val_loss: 0.1774\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5054 - val_loss: 0.1754\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4730 - val_loss: 0.1674\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4477 - val_loss: 0.1709\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4527 - val_loss: 0.1851\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4156 - val_loss: 0.1803\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4060 - val_loss: 0.1795\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4141 - val_loss: 0.1849\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3699 - val_loss: 0.2069\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3676 - val_loss: 0.1691\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3512 - val_loss: 0.2265\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3345 - val_loss: 0.1736\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3168 - val_loss: 0.1676\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3189 - val_loss: 0.1901\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2843 - val_loss: 0.1677\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2780 - val_loss: 0.1720\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2837 - val_loss: 0.1797\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3070 - val_loss: 0.1713\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2888 - val_loss: 0.1728\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2768 - val_loss: 0.1735\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2611 - val_loss: 0.1825\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2931 - val_loss: 0.1683\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2903 - val_loss: 0.2008\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2827 - val_loss: 0.2036\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2562 - val_loss: 0.1761\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2570 - val_loss: 0.1828\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2551 - val_loss: 0.1700\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2504 - val_loss: 0.1915\n",
      "Epoch 00076: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 8.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 328.6733 - val_loss: 2.7858\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 55.0338 - val_loss: 2.2649\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 36.7641 - val_loss: 2.9770\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 37.3715 - val_loss: 2.1019\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 39.5000 - val_loss: 0.5765\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 35.3961 - val_loss: 2.6526\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 42.1678 - val_loss: 0.7429\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 40.0679 - val_loss: 0.7433\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 34.2714 - val_loss: 0.6686\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 24.8098 - val_loss: 1.3578\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 21.9494 - val_loss: 0.4151\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 18.2072 - val_loss: 2.0275\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 15.5730 - val_loss: 0.8515\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 12.3337 - val_loss: 0.5044\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 11.4973 - val_loss: 1.2596\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 10.6257 - val_loss: 0.9643\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 9.5457 - val_loss: 1.0533\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.9136 - val_loss: 0.3050\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 8.1093 - val_loss: 0.2635\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.9951 - val_loss: 0.2148\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.8765 - val_loss: 0.2699\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.7496 - val_loss: 0.5105\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.0320 - val_loss: 0.7373\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.0859 - val_loss: 0.3081\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.9932 - val_loss: 0.2514\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.2312 - val_loss: 0.2020\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.2873 - val_loss: 0.4938\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.1746 - val_loss: 0.2578\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.7479 - val_loss: 0.6623\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.8257 - val_loss: 0.3207\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.9937 - val_loss: 0.3414\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.6595 - val_loss: 0.2932\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.4236 - val_loss: 0.3125\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.1732 - val_loss: 0.4188\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.8884 - val_loss: 0.2742\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6690 - val_loss: 0.2119\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3787 - val_loss: 0.2187\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4541 - val_loss: 0.2164\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3073 - val_loss: 0.2832\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2505 - val_loss: 0.2466\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1115 - val_loss: 0.2546\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6871 - val_loss: 0.3225\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1313 - val_loss: 0.2584\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0237 - val_loss: 0.2465\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9397 - val_loss: 0.1854\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8354 - val_loss: 0.1844\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8943 - val_loss: 0.2140\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7682 - val_loss: 0.1753\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6735 - val_loss: 0.1901\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6870 - val_loss: 0.2095\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6606 - val_loss: 0.2638\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5457 - val_loss: 0.1735\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5398 - val_loss: 0.1890\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4881 - val_loss: 0.1836\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5282 - val_loss: 0.1760\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5104 - val_loss: 0.1744\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4559 - val_loss: 0.1877\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4165 - val_loss: 0.1810\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4061 - val_loss: 0.2092\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4059 - val_loss: 0.1749\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3888 - val_loss: 0.1703\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3727 - val_loss: 0.1738\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3272 - val_loss: 0.1921\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3366 - val_loss: 0.1747\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3376 - val_loss: 0.1728\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3369 - val_loss: 0.1708\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3120 - val_loss: 0.1731\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2977 - val_loss: 0.1726\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3027 - val_loss: 0.1701\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2888 - val_loss: 0.1801\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2984 - val_loss: 0.1850\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2991 - val_loss: 0.2335\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3107 - val_loss: 0.1750\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2896 - val_loss: 0.1982\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2720 - val_loss: 0.2009\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3401 - val_loss: 0.1867\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2935 - val_loss: 0.1781\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2484 - val_loss: 0.1862\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2450 - val_loss: 0.1774\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2595 - val_loss: 0.1790\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2486 - val_loss: 0.1755\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2586 - val_loss: 0.1840\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2343 - val_loss: 0.1770\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2333 - val_loss: 0.1962\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2168 - val_loss: 0.1824\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2257 - val_loss: 0.1796\n",
      "Epoch 00086: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 9.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 287.3156 - val_loss: 8.2669\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 69.2673 - val_loss: 3.9640\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 45.6392 - val_loss: 1.5478\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 40.6214 - val_loss: 1.9101\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 41.3704 - val_loss: 4.3492\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 39.2475 - val_loss: 2.8321\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 56.9541 - val_loss: 1.0353\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 38.0152 - val_loss: 5.5659\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 31.7363 - val_loss: 0.5473\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 19.1034 - val_loss: 0.9879\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 16.0947 - val_loss: 0.5824\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 13.1178 - val_loss: 2.2095\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 13.5404 - val_loss: 0.8154\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 10.6269 - val_loss: 0.3898\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 8.3429 - val_loss: 0.6041\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 7.2201 - val_loss: 0.4257\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.8396 - val_loss: 0.7062\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.1448 - val_loss: 0.4663\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.1243 - val_loss: 0.4231\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.1180 - val_loss: 0.2390\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.2004 - val_loss: 0.2620\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.1038 - val_loss: 0.4289\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.7283 - val_loss: 0.2675\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.3680 - val_loss: 0.5110\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.2700 - val_loss: 0.2529\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.9535 - val_loss: 0.3178\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.4928 - val_loss: 0.2029\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.5262 - val_loss: 0.2758\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.0739 - val_loss: 0.4491\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.0830 - val_loss: 0.4106\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0261 - val_loss: 0.3296\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1130 - val_loss: 0.6149\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.7505 - val_loss: 0.2367\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5843 - val_loss: 0.3885\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8973 - val_loss: 0.2369\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3837 - val_loss: 0.2352\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1917 - val_loss: 0.2303\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3939 - val_loss: 0.2174\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.0874 - val_loss: 0.1790\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2708 - val_loss: 0.2860\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9651 - val_loss: 0.2756\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9269 - val_loss: 0.3104\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8587 - val_loss: 0.2039\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7652 - val_loss: 0.2186\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7533 - val_loss: 0.1813\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6861 - val_loss: 0.1996\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6608 - val_loss: 0.1980\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6150 - val_loss: 0.2291\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7608 - val_loss: 0.1818\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6066 - val_loss: 0.1969\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5288 - val_loss: 0.2262\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4672 - val_loss: 0.2076\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5113 - val_loss: 0.1958\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4815 - val_loss: 0.1761\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4684 - val_loss: 0.1705\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4260 - val_loss: 0.1714\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4211 - val_loss: 0.1836\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3847 - val_loss: 0.1882\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4873 - val_loss: 0.1875\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3993 - val_loss: 0.2135\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4301 - val_loss: 0.1831\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3731 - val_loss: 0.1974\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3449 - val_loss: 0.1746\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3226 - val_loss: 0.1770\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3147 - val_loss: 0.1880\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3107 - val_loss: 0.1937\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2906 - val_loss: 0.1770\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3607 - val_loss: 0.1856\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3249 - val_loss: 0.1907\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2953 - val_loss: 0.1729\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2875 - val_loss: 0.1835\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2799 - val_loss: 0.1801\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2694 - val_loss: 0.1688\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2744 - val_loss: 0.1839\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2598 - val_loss: 0.1832\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2466 - val_loss: 0.1857\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2385 - val_loss: 0.1832\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2264 - val_loss: 0.1743\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2378 - val_loss: 0.1849\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2274 - val_loss: 0.1717\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2422 - val_loss: 0.1891\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2340 - val_loss: 0.1719\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2418 - val_loss: 0.2040\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2244 - val_loss: 0.1751\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2148 - val_loss: 0.1806\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2200 - val_loss: 0.2041\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2183 - val_loss: 0.1810\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2061 - val_loss: 0.1715\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2350 - val_loss: 0.1718\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2078 - val_loss: 0.1721\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2166 - val_loss: 0.1775\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2116 - val_loss: 0.1777\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2157 - val_loss: 0.1922\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2169 - val_loss: 0.2274\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2106 - val_loss: 0.1792\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1915 - val_loss: 0.1772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1910 - val_loss: 0.1813\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2000 - val_loss: 0.1794\n",
      "Epoch 00098: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total=10.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 302.3796 - val_loss: 2.1219\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 59.8027 - val_loss: 5.7998\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 33.9797 - val_loss: 0.6296\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 34.1943 - val_loss: 0.3952\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 37.2741 - val_loss: 0.9256\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 37.5831 - val_loss: 0.5563\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 36.5785 - val_loss: 0.3613\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 31.8419 - val_loss: 0.6502\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 27.0264 - val_loss: 2.1187\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 31.7831 - val_loss: 2.2726\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 21.5460 - val_loss: 1.1603\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 21.0040 - val_loss: 0.4723\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 15.7647 - val_loss: 2.4056\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 14.0187 - val_loss: 0.4041\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 10.8701 - val_loss: 0.5685\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 9.0505 - val_loss: 0.5436\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.7552 - val_loss: 0.6840\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.9339 - val_loss: 0.5426\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.6675 - val_loss: 0.5170\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.2594 - val_loss: 0.3454\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.1123 - val_loss: 0.2658\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.9421 - val_loss: 0.2472\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.4541 - val_loss: 0.4321\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.5167 - val_loss: 0.2280\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.2670 - val_loss: 0.2925\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.9089 - val_loss: 0.2777\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.6176 - val_loss: 0.2766\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1681 - val_loss: 0.2065\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.3719 - val_loss: 0.2885\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.4562 - val_loss: 0.2413\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.7633 - val_loss: 0.2138\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8651 - val_loss: 0.3124\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6244 - val_loss: 0.4013\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5253 - val_loss: 0.2398\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4538 - val_loss: 0.2894\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.6861 - val_loss: 0.3772\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.9541 - val_loss: 0.4713\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3815 - val_loss: 0.2685\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1422 - val_loss: 0.2535\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1313 - val_loss: 0.1846\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9211 - val_loss: 0.2395\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9366 - val_loss: 0.1834\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8566 - val_loss: 0.2003\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8314 - val_loss: 0.2030\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7605 - val_loss: 0.1726\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6875 - val_loss: 0.1799\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6222 - val_loss: 0.1675\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6616 - val_loss: 0.1859\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6393 - val_loss: 0.2110\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5526 - val_loss: 0.1944\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4937 - val_loss: 0.2002\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4915 - val_loss: 0.2146\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4835 - val_loss: 0.2110\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4902 - val_loss: 0.1778\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4528 - val_loss: 0.2061\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4635 - val_loss: 0.1853\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4151 - val_loss: 0.2064\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4087 - val_loss: 0.2024\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3553 - val_loss: 0.1675\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3321 - val_loss: 0.1671\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3457 - val_loss: 0.1887\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3218 - val_loss: 0.1711\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3458 - val_loss: 0.1859\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3743 - val_loss: 0.1724\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3688 - val_loss: 0.1691\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3116 - val_loss: 0.1683\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3002 - val_loss: 0.2051\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3011 - val_loss: 0.1806\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2768 - val_loss: 0.1702\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2822 - val_loss: 0.2090\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2945 - val_loss: 0.1804\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2666 - val_loss: 0.1711\n",
      "Epoch 00072: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 7.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.3997 - val_loss: 0.2195\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.7367 - val_loss: 0.2439\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.7333 - val_loss: 0.2336\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6701 - val_loss: 0.2304\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6444 - val_loss: 0.2319\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6178 - val_loss: 0.2451\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.6429 - val_loss: 0.2403\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5620 - val_loss: 0.2294\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5927 - val_loss: 0.2296\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5743 - val_loss: 0.2385\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5740 - val_loss: 0.2382\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5584 - val_loss: 0.2392\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5290 - val_loss: 0.2328\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5470 - val_loss: 0.2314\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5803 - val_loss: 0.2312\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5683 - val_loss: 0.2455\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5274 - val_loss: 0.2270\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5071 - val_loss: 0.2383\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5213 - val_loss: 0.2353\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5041 - val_loss: 0.2286\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5343 - val_loss: 0.2305\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5038 - val_loss: 0.2348\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5177 - val_loss: 0.2282\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 1ms/step - loss: 0.5017 - val_loss: 0.2256\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4790 - val_loss: 0.2391\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5007 - val_loss: 0.2332\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 1.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.3382 - val_loss: 0.4936\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7938 - val_loss: 0.2186\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.7010 - val_loss: 0.2335\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6318 - val_loss: 0.2231\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5822 - val_loss: 0.2220\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5956 - val_loss: 0.2257\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6039 - val_loss: 0.2291\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5460 - val_loss: 0.2236\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5298 - val_loss: 0.2300\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5232 - val_loss: 0.2239\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4912 - val_loss: 0.2260\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4962 - val_loss: 0.2218\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5240 - val_loss: 0.2253\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5063 - val_loss: 0.2296\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4850 - val_loss: 0.2306\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4591 - val_loss: 0.2259\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4904 - val_loss: 0.2285\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4581 - val_loss: 0.2304\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4523 - val_loss: 0.2317\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4783 - val_loss: 0.2320\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4661 - val_loss: 0.2263\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4461 - val_loss: 0.2297\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4338 - val_loss: 0.2216\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4459 - val_loss: 0.2271\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4301 - val_loss: 0.2246\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4597 - val_loss: 0.2350\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4207 - val_loss: 0.2223\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 1.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3183 - val_loss: 0.2218\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6405 - val_loss: 0.2273\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6546 - val_loss: 0.2233\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5885 - val_loss: 0.2301\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5934 - val_loss: 0.2228\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5758 - val_loss: 0.2325\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5323 - val_loss: 0.2256\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5347 - val_loss: 0.2542\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5033 - val_loss: 0.2217\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4867 - val_loss: 0.2308\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4842 - val_loss: 0.2310\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5258 - val_loss: 0.2342\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5038 - val_loss: 0.2304\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4740 - val_loss: 0.2219\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4609 - val_loss: 0.2282\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4671 - val_loss: 0.2326\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4713 - val_loss: 0.2229\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4907 - val_loss: 0.2319\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4532 - val_loss: 0.2199\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4582 - val_loss: 0.2273\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4474 - val_loss: 0.2282\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4667 - val_loss: 0.2225\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4476 - val_loss: 0.2220\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4655 - val_loss: 0.2302\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4531 - val_loss: 0.2301\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4399 - val_loss: 0.2216\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4449 - val_loss: 0.2283\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4298 - val_loss: 0.2293\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4512 - val_loss: 0.2266\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4148 - val_loss: 0.2299\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4227 - val_loss: 0.2333\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4245 - val_loss: 0.2234\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4384 - val_loss: 0.2241\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4178 - val_loss: 0.2296\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4121 - val_loss: 0.2232\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3966 - val_loss: 0.2423\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3986 - val_loss: 0.2197\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4150 - val_loss: 0.2189\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3998 - val_loss: 0.2232\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3974 - val_loss: 0.2354\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3942 - val_loss: 0.2206\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3930 - val_loss: 0.2301\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3776 - val_loss: 0.2302\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3734 - val_loss: 0.2266\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3820 - val_loss: 0.2376\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3794 - val_loss: 0.2272\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3774 - val_loss: 0.2215\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3667 - val_loss: 0.2264\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3850 - val_loss: 0.2244\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3455 - val_loss: 0.2269\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3606 - val_loss: 0.2199\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3579 - val_loss: 0.2234\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3489 - val_loss: 0.2220\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3809 - val_loss: 0.2239\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3502 - val_loss: 0.2251\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3366 - val_loss: 0.2203\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3658 - val_loss: 0.2238\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3517 - val_loss: 0.2228\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3517 - val_loss: 0.2196\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3347 - val_loss: 0.2186\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.3438 - val_loss: 0.2202\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3283 - val_loss: 0.2272\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3287 - val_loss: 0.2241\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.5242 - val_loss: 0.5519\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8501 - val_loss: 0.2186\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6930 - val_loss: 0.2255\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6811 - val_loss: 0.2267\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6305 - val_loss: 0.2261\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5890 - val_loss: 0.2239\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5739 - val_loss: 0.2246\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5452 - val_loss: 0.2360\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5953 - val_loss: 0.2227\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5457 - val_loss: 0.2378\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4854 - val_loss: 0.2260\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5341 - val_loss: 0.2296\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4855 - val_loss: 0.2220\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4888 - val_loss: 0.2235\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4923 - val_loss: 0.2312\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4686 - val_loss: 0.2336\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4630 - val_loss: 0.2224\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4598 - val_loss: 0.2306\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4517 - val_loss: 0.2269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4494 - val_loss: 0.2282\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4427 - val_loss: 0.2271\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4472 - val_loss: 0.2306\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4405 - val_loss: 0.2231\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4359 - val_loss: 0.2227\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4439 - val_loss: 0.2273\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4040 - val_loss: 0.2224\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4429 - val_loss: 0.2359\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 1.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5919 - val_loss: 0.2498\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7561 - val_loss: 0.2265\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6358 - val_loss: 0.2362\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6537 - val_loss: 0.2224\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6238 - val_loss: 0.2300\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.6058 - val_loss: 0.2239\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5462 - val_loss: 0.2266\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5272 - val_loss: 0.2358\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.5440 - val_loss: 0.2269\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4832 - val_loss: 0.2349\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4958 - val_loss: 0.2269\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4999 - val_loss: 0.2252\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4745 - val_loss: 0.2251\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4881 - val_loss: 0.2236\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4902 - val_loss: 0.2240\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4520 - val_loss: 0.2223\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4570 - val_loss: 0.2281\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4655 - val_loss: 0.2291\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4540 - val_loss: 0.2216\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4489 - val_loss: 0.2371\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4416 - val_loss: 0.2251\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4497 - val_loss: 0.2388\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4516 - val_loss: 0.2316\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4590 - val_loss: 0.2277\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4426 - val_loss: 0.2294\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4324 - val_loss: 0.2334\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 1ms/step - loss: 0.4569 - val_loss: 0.2262\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4092 - val_loss: 0.2253\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4357 - val_loss: 0.2257\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 1.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.2574 - val_loss: 0.2206\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9071 - val_loss: 0.2272\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7841 - val_loss: 0.2205\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6720 - val_loss: 0.2186\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6352 - val_loss: 0.2234\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5844 - val_loss: 0.2194\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5236 - val_loss: 0.2226\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5314 - val_loss: 0.2201\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4830 - val_loss: 0.2186\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4854 - val_loss: 0.2261\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4601 - val_loss: 0.2330\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4759 - val_loss: 0.2201\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4709 - val_loss: 0.2278\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4602 - val_loss: 0.2221\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4473 - val_loss: 0.2305\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4405 - val_loss: 0.2277\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4117 - val_loss: 0.2225\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4311 - val_loss: 0.2261\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4179 - val_loss: 0.2362\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3954 - val_loss: 0.2285\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4442 - val_loss: 0.2247\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3848 - val_loss: 0.2236\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3965 - val_loss: 0.2186\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4156 - val_loss: 0.2222\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3993 - val_loss: 0.2195\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3912 - val_loss: 0.2297\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3814 - val_loss: 0.2248\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3759 - val_loss: 0.2247\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3654 - val_loss: 0.2236\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.6731 - val_loss: 0.2464\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0410 - val_loss: 0.2249\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9526 - val_loss: 0.2226\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8910 - val_loss: 0.2198\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7343 - val_loss: 0.2236\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7944 - val_loss: 0.2201\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7089 - val_loss: 0.2200\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6204 - val_loss: 0.2186\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5790 - val_loss: 0.2191\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5884 - val_loss: 0.2186\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5198 - val_loss: 0.2221\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5115 - val_loss: 0.2201\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4960 - val_loss: 0.2190\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4674 - val_loss: 0.2186\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4719 - val_loss: 0.2188\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4594 - val_loss: 0.2189\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4223 - val_loss: 0.2259\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4361 - val_loss: 0.2200\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4290 - val_loss: 0.2225\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4209 - val_loss: 0.2193\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4334 - val_loss: 0.2229\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3816 - val_loss: 0.2215\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4356 - val_loss: 0.2214\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3959 - val_loss: 0.2209\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4034 - val_loss: 0.2202\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3912 - val_loss: 0.2190\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3893 - val_loss: 0.2190\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4011 - val_loss: 0.2220\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3748 - val_loss: 0.2246\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3952 - val_loss: 0.2215\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3799 - val_loss: 0.2186\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3781 - val_loss: 0.2229\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3835 - val_loss: 0.2195\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total= 1.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.0891 - val_loss: 0.2192\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0902 - val_loss: 0.2199\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1241 - val_loss: 0.2193\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9346 - val_loss: 0.2203\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9110 - val_loss: 0.2186\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8455 - val_loss: 0.2190\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7602 - val_loss: 0.2197\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7221 - val_loss: 0.2203\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6349 - val_loss: 0.2187\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6553 - val_loss: 0.2268\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6237 - val_loss: 0.2190\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5707 - val_loss: 0.2217\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5645 - val_loss: 0.2220\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5260 - val_loss: 0.2215\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5385 - val_loss: 0.2201\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5459 - val_loss: 0.2273\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4883 - val_loss: 0.2258\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5030 - val_loss: 0.2216\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4838 - val_loss: 0.2206\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4371 - val_loss: 0.2186\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4589 - val_loss: 0.2265\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4512 - val_loss: 0.2193\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4363 - val_loss: 0.2243\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4468 - val_loss: 0.2206\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4129 - val_loss: 0.2226\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4310 - val_loss: 0.2293\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total= 1.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6502 - val_loss: 0.2692\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9417 - val_loss: 0.2186\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8073 - val_loss: 0.2187\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7098 - val_loss: 0.2221\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6448 - val_loss: 0.2279\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5581 - val_loss: 0.2192\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5256 - val_loss: 0.2291\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5150 - val_loss: 0.2259\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5164 - val_loss: 0.2217\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4677 - val_loss: 0.2197\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4613 - val_loss: 0.2186\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4632 - val_loss: 0.2209\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4216 - val_loss: 0.2351\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4411 - val_loss: 0.2289\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4255 - val_loss: 0.2216\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3846 - val_loss: 0.2195\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4072 - val_loss: 0.2242\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4159 - val_loss: 0.2240\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4062 - val_loss: 0.2269\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4067 - val_loss: 0.2228\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3812 - val_loss: 0.2220\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3841 - val_loss: 0.2212\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3933 - val_loss: 0.2362\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3938 - val_loss: 0.2284\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3902 - val_loss: 0.2287\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3647 - val_loss: 0.2220\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3793 - val_loss: 0.2236\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2479 - val_loss: 0.2189\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9080 - val_loss: 0.2241\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7688 - val_loss: 0.2186\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6820 - val_loss: 0.2186\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5831 - val_loss: 0.2201\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5544 - val_loss: 0.2188\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5633 - val_loss: 0.2186\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5197 - val_loss: 0.2194\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4773 - val_loss: 0.2311\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4453 - val_loss: 0.2259\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4852 - val_loss: 0.2364\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4531 - val_loss: 0.2323\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4547 - val_loss: 0.2226\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4199 - val_loss: 0.2234\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4298 - val_loss: 0.2248\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4324 - val_loss: 0.2212\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4015 - val_loss: 0.2215\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4219 - val_loss: 0.2230\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3977 - val_loss: 0.2232\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3867 - val_loss: 0.2270\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3981 - val_loss: 0.2248\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3796 - val_loss: 0.2219\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3772 - val_loss: 0.2208\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3812 - val_loss: 0.2219\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4026 - val_loss: 0.2222\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3665 - val_loss: 0.2250\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total= 1.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 1.9043 - val_loss: 0.2933\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.8392 - val_loss: 0.2198\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6995 - val_loss: 0.2186\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6802 - val_loss: 0.2213\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5998 - val_loss: 0.2284\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5700 - val_loss: 0.2198\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5057 - val_loss: 0.2201\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4912 - val_loss: 0.2186\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4631 - val_loss: 0.2188\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4670 - val_loss: 0.2205\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4794 - val_loss: 0.2188\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4670 - val_loss: 0.2287\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4548 - val_loss: 0.2193\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4517 - val_loss: 0.2266\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4222 - val_loss: 0.2189\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4297 - val_loss: 0.2209\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4317 - val_loss: 0.2422\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4254 - val_loss: 0.2204\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4268 - val_loss: 0.2225\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3941 - val_loss: 0.2212\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4237 - val_loss: 0.2289\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3866 - val_loss: 0.2195\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4287 - val_loss: 0.2305\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4072 - val_loss: 0.2233\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3957 - val_loss: 0.2249\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3842 - val_loss: 0.2297\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4036 - val_loss: 0.2397\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4189 - val_loss: 0.2273\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 1.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 4.2487 - val_loss: 0.2338\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9776 - val_loss: 0.2374\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9232 - val_loss: 0.2363\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8345 - val_loss: 0.2227\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7812 - val_loss: 0.2236\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7431 - val_loss: 0.2258\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6411 - val_loss: 0.2210\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6192 - val_loss: 0.2204\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5788 - val_loss: 0.2196\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5482 - val_loss: 0.2266\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4941 - val_loss: 0.2253\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4867 - val_loss: 0.2192\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4756 - val_loss: 0.2244\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4999 - val_loss: 0.2198\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4864 - val_loss: 0.2214\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4879 - val_loss: 0.2222\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4663 - val_loss: 0.2247\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4737 - val_loss: 0.2219\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4078 - val_loss: 0.2411\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4344 - val_loss: 0.2235\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4544 - val_loss: 0.2186\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4514 - val_loss: 0.2240\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4318 - val_loss: 0.2362\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4235 - val_loss: 0.2278\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4202 - val_loss: 0.2187\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4135 - val_loss: 0.2389\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4212 - val_loss: 0.2214\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3965 - val_loss: 0.2217\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4189 - val_loss: 0.2229\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4110 - val_loss: 0.2328\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4289 - val_loss: 0.2190\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3939 - val_loss: 0.2260\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4124 - val_loss: 0.2202\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4270 - val_loss: 0.2200\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4005 - val_loss: 0.2243\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3908 - val_loss: 0.2337\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3835 - val_loss: 0.2295\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3965 - val_loss: 0.2193\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3981 - val_loss: 0.2231\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4006 - val_loss: 0.2211\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3568 - val_loss: 0.2251\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3829 - val_loss: 0.2203\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3895 - val_loss: 0.2333\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3974 - val_loss: 0.2233\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3863 - val_loss: 0.2330\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3581 - val_loss: 0.2266\n",
      "Epoch 00046: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 2.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 2.4579 - val_loss: 0.3300\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9332 - val_loss: 0.2216\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7852 - val_loss: 0.2237\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7234 - val_loss: 0.2204\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7096 - val_loss: 0.2188\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6339 - val_loss: 0.2230\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6161 - val_loss: 0.2207\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5496 - val_loss: 0.2198\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5356 - val_loss: 0.2188\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5049 - val_loss: 0.2200\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4754 - val_loss: 0.2236\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4883 - val_loss: 0.2192\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4591 - val_loss: 0.2350\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4523 - val_loss: 0.2334\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4648 - val_loss: 0.2300\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4470 - val_loss: 0.2186\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4303 - val_loss: 0.2240\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4609 - val_loss: 0.2217\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4204 - val_loss: 0.2218\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4501 - val_loss: 0.2254\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4371 - val_loss: 0.2303\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4215 - val_loss: 0.2276\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4395 - val_loss: 0.2212\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3791 - val_loss: 0.2236\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4231 - val_loss: 0.2204\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4058 - val_loss: 0.2223\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3952 - val_loss: 0.2234\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4364 - val_loss: 0.2186\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4104 - val_loss: 0.2323\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3764 - val_loss: 0.2305\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 1.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 1.6758 - val_loss: 0.2579\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8781 - val_loss: 0.2188\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7915 - val_loss: 0.2195\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6800 - val_loss: 0.2252\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6224 - val_loss: 0.2190\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5364 - val_loss: 0.2192\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5079 - val_loss: 0.2209\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4980 - val_loss: 0.2196\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5102 - val_loss: 0.2240\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4346 - val_loss: 0.2200\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4508 - val_loss: 0.2295\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4280 - val_loss: 0.2353\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4200 - val_loss: 0.2239\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4458 - val_loss: 0.2282\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4173 - val_loss: 0.2186\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4178 - val_loss: 0.2301\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4093 - val_loss: 0.2259\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4406 - val_loss: 0.2218\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4256 - val_loss: 0.2190\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4161 - val_loss: 0.2189\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3911 - val_loss: 0.2359\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3873 - val_loss: 0.2258\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3889 - val_loss: 0.2330\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4057 - val_loss: 0.2248\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3917 - val_loss: 0.2289\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3810 - val_loss: 0.2300\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3862 - val_loss: 0.2218\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 1.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 1.3752 - val_loss: 0.2206\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8940 - val_loss: 0.2190\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6832 - val_loss: 0.2189\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6167 - val_loss: 0.2188\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5465 - val_loss: 0.2186\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4978 - val_loss: 0.2277\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4998 - val_loss: 0.2219\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4914 - val_loss: 0.2187\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4317 - val_loss: 0.2191\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4453 - val_loss: 0.2377\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4072 - val_loss: 0.2341\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4527 - val_loss: 0.2330\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4114 - val_loss: 0.2236\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4171 - val_loss: 0.2273\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4107 - val_loss: 0.2211\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3934 - val_loss: 0.2244\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3908 - val_loss: 0.2314\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3888 - val_loss: 0.2321\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4047 - val_loss: 0.2383\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3925 - val_loss: 0.2212\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3705 - val_loss: 0.2295\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3854 - val_loss: 0.2320\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3778 - val_loss: 0.2355\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3909 - val_loss: 0.2190\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3610 - val_loss: 0.2302\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3592 - val_loss: 0.2208\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3736 - val_loss: 0.2207\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 1.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 8.5321 - val_loss: 1.2292\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1478 - val_loss: 0.2401\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7177 - val_loss: 0.2211\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7498 - val_loss: 0.2226\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6853 - val_loss: 0.2210\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6686 - val_loss: 0.2174\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6446 - val_loss: 0.2134\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5662 - val_loss: 0.2229\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5897 - val_loss: 0.2215\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5650 - val_loss: 0.2212\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5642 - val_loss: 0.2125\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4998 - val_loss: 0.2026\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4724 - val_loss: 0.2183\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4867 - val_loss: 0.2126\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4869 - val_loss: 0.2198\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4474 - val_loss: 0.2069\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4144 - val_loss: 0.2120\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4401 - val_loss: 0.2212\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4168 - val_loss: 0.2118\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4066 - val_loss: 0.2108\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4041 - val_loss: 0.2053\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3812 - val_loss: 0.2138\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3926 - val_loss: 0.2174\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3630 - val_loss: 0.2114\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3771 - val_loss: 0.2066\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3678 - val_loss: 0.2053\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3569 - val_loss: 0.2058\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3377 - val_loss: 0.2075\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3520 - val_loss: 0.1982\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3446 - val_loss: 0.2125\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3442 - val_loss: 0.1998\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3553 - val_loss: 0.2115\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3374 - val_loss: 0.2104\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3363 - val_loss: 0.2152\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3276 - val_loss: 0.2158\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3306 - val_loss: 0.1987\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3487 - val_loss: 0.2101\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3451 - val_loss: 0.2079\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3380 - val_loss: 0.2043\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3478 - val_loss: 0.2156\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3043 - val_loss: 0.2107\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3460 - val_loss: 0.2076\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3265 - val_loss: 0.2051\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3171 - val_loss: 0.2134\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3213 - val_loss: 0.1966\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3455 - val_loss: 0.2061\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3098 - val_loss: 0.1968\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3201 - val_loss: 0.2006\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3304 - val_loss: 0.2188\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3140 - val_loss: 0.2072\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3347 - val_loss: 0.2040\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3102 - val_loss: 0.2087\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3179 - val_loss: 0.1975\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3346 - val_loss: 0.2026\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3082 - val_loss: 0.2121\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3324 - val_loss: 0.2058\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3296 - val_loss: 0.1934\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3263 - val_loss: 0.2087\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3224 - val_loss: 0.2111\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3098 - val_loss: 0.2060\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3181 - val_loss: 0.1962\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2933 - val_loss: 0.2057\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2999 - val_loss: 0.2125\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3216 - val_loss: 0.2125\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3174 - val_loss: 0.2106\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3101 - val_loss: 0.2119\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3214 - val_loss: 0.2128\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2940 - val_loss: 0.1939\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2983 - val_loss: 0.2105\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2889 - val_loss: 0.2076\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3123 - val_loss: 0.1973\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3039 - val_loss: 0.2081\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2949 - val_loss: 0.2084\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2941 - val_loss: 0.2162\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3078 - val_loss: 0.2018\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3017 - val_loss: 0.1943\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2772 - val_loss: 0.2129\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3018 - val_loss: 0.2172\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2950 - val_loss: 0.2052\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2922 - val_loss: 0.1947\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2960 - val_loss: 0.2279\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2860 - val_loss: 0.1915\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2915 - val_loss: 0.2013\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2851 - val_loss: 0.2001\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2757 - val_loss: 0.2021\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2893 - val_loss: 0.2029\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2724 - val_loss: 0.2017\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2716 - val_loss: 0.2115\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2768 - val_loss: 0.1807\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2752 - val_loss: 0.1964\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2702 - val_loss: 0.2005\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2548 - val_loss: 0.1992\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2814 - val_loss: 0.1911\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2496 - val_loss: 0.1896\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2590 - val_loss: 0.1872\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2507 - val_loss: 0.1832\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2550 - val_loss: 0.1966\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2609 - val_loss: 0.1908\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2455 - val_loss: 0.1878\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2433 - val_loss: 0.1858\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2486 - val_loss: 0.1803\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2399 - val_loss: 0.2018\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2495 - val_loss: 0.1888\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2486 - val_loss: 0.1799\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2437 - val_loss: 0.1827\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2251 - val_loss: 0.1847\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2274 - val_loss: 0.1844\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2396 - val_loss: 0.1913\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2238 - val_loss: 0.1866\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2284 - val_loss: 0.1815\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2271 - val_loss: 0.1832\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2265 - val_loss: 0.1856\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2211 - val_loss: 0.1997\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2316 - val_loss: 0.1815\n",
      "Epoch 00114: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 7.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s 7ms/step - loss: 4.4841 - val_loss: 0.9261\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8032 - val_loss: 0.2191\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6100 - val_loss: 0.2254\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5431 - val_loss: 0.2220\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5408 - val_loss: 0.2197\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4799 - val_loss: 0.2226\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4975 - val_loss: 0.2201\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4938 - val_loss: 0.2241\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4886 - val_loss: 0.2226\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4441 - val_loss: 0.2186\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4426 - val_loss: 0.2221\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4456 - val_loss: 0.2299\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4243 - val_loss: 0.2200\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4074 - val_loss: 0.2269\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3950 - val_loss: 0.2210\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4063 - val_loss: 0.2195\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4140 - val_loss: 0.2233\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3999 - val_loss: 0.2220\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3674 - val_loss: 0.2185\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3499 - val_loss: 0.2252\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3841 - val_loss: 0.2195\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3615 - val_loss: 0.2236\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3834 - val_loss: 0.2189\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3566 - val_loss: 0.2214\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3705 - val_loss: 0.2246\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3762 - val_loss: 0.2226\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3570 - val_loss: 0.2200\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 1.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s 7ms/step - loss: 4.6416 - val_loss: 0.9566\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7414 - val_loss: 0.2188\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5530 - val_loss: 0.2201\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5351 - val_loss: 0.2221\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5083 - val_loss: 0.2219\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4825 - val_loss: 0.2226\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5105 - val_loss: 0.2224\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4733 - val_loss: 0.2187\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4679 - val_loss: 0.2201\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4843 - val_loss: 0.2197\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4653 - val_loss: 0.2196\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4048 - val_loss: 0.2214\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4181 - val_loss: 0.2199\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4271 - val_loss: 0.2201\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4363 - val_loss: 0.2200\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4077 - val_loss: 0.2266\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3905 - val_loss: 0.2193\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3844 - val_loss: 0.2232\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4019 - val_loss: 0.2231\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3955 - val_loss: 0.2186\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3802 - val_loss: 0.2216\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3757 - val_loss: 0.2230\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3769 - val_loss: 0.2316\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3595 - val_loss: 0.2258\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3783 - val_loss: 0.2199\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3662 - val_loss: 0.2201\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3605 - val_loss: 0.2187\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 1.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s 7ms/step - loss: 7.2267 - val_loss: 1.9492\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3063 - val_loss: 0.2355\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6566 - val_loss: 0.2302\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6403 - val_loss: 0.2210\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5468 - val_loss: 0.2217\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6224 - val_loss: 0.2202\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5798 - val_loss: 0.2264\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5122 - val_loss: 0.2064\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4818 - val_loss: 0.2050\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5029 - val_loss: 0.2067\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4769 - val_loss: 0.2060\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4593 - val_loss: 0.2097\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4405 - val_loss: 0.2077\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4538 - val_loss: 0.2030\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4177 - val_loss: 0.2043\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4069 - val_loss: 0.2050\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3977 - val_loss: 0.2038\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3991 - val_loss: 0.2083\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3865 - val_loss: 0.2116\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3663 - val_loss: 0.2009\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3449 - val_loss: 0.2006\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3361 - val_loss: 0.2060\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3732 - val_loss: 0.1982\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3385 - val_loss: 0.1963\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3441 - val_loss: 0.2001\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3435 - val_loss: 0.1972\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3231 - val_loss: 0.2004\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3276 - val_loss: 0.1976\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3262 - val_loss: 0.1971\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3471 - val_loss: 0.1944\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3318 - val_loss: 0.1927\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3163 - val_loss: 0.2028\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3201 - val_loss: 0.1911\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3094 - val_loss: 0.1927\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3020 - val_loss: 0.1916\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3215 - val_loss: 0.1994\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3029 - val_loss: 0.1937\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3054 - val_loss: 0.2012\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3019 - val_loss: 0.1989\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3018 - val_loss: 0.1967\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2982 - val_loss: 0.1904\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3007 - val_loss: 0.1890\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3123 - val_loss: 0.1959\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3102 - val_loss: 0.1926\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3066 - val_loss: 0.2001\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2865 - val_loss: 0.2016\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3013 - val_loss: 0.1930\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2970 - val_loss: 0.1978\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2881 - val_loss: 0.1920\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2847 - val_loss: 0.1860\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2847 - val_loss: 0.2049\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2810 - val_loss: 0.1923\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2909 - val_loss: 0.1919\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2732 - val_loss: 0.1915\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2889 - val_loss: 0.1991\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2639 - val_loss: 0.1891\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2845 - val_loss: 0.1898\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2966 - val_loss: 0.1840\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2758 - val_loss: 0.1863\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2639 - val_loss: 0.1944\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2856 - val_loss: 0.1824\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2759 - val_loss: 0.2115\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2739 - val_loss: 0.2079\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2793 - val_loss: 0.1833\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2981 - val_loss: 0.2120\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2613 - val_loss: 0.1830\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2726 - val_loss: 0.2089\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2671 - val_loss: 0.2012\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.1957\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2746 - val_loss: 0.1837\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2806 - val_loss: 0.1945\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2694 - val_loss: 0.1801\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2644 - val_loss: 0.2110\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2776 - val_loss: 0.1820\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2512 - val_loss: 0.2002\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2526 - val_loss: 0.1965\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2586 - val_loss: 0.2023\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2697 - val_loss: 0.1881\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2612 - val_loss: 0.1839\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2621 - val_loss: 0.1966\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2497 - val_loss: 0.1805\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2662 - val_loss: 0.1944\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2577 - val_loss: 0.1910\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2561 - val_loss: 0.1820\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2520 - val_loss: 0.2008\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2583 - val_loss: 0.1885\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2463 - val_loss: 0.1912\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2493 - val_loss: 0.2026\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2594 - val_loss: 0.1917\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2533 - val_loss: 0.2017\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2550 - val_loss: 0.1828\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2569 - val_loss: 0.1824\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2577 - val_loss: 0.2054\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2639 - val_loss: 0.1858\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2361 - val_loss: 0.1981\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2529 - val_loss: 0.1858\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2382 - val_loss: 0.1842\n",
      "Epoch 00097: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 6.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s 7ms/step - loss: 6.0304 - val_loss: 1.2271\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8100 - val_loss: 0.2187\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5422 - val_loss: 0.2236\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5206 - val_loss: 0.2229\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4702 - val_loss: 0.2215\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4852 - val_loss: 0.2242\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4787 - val_loss: 0.2234\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4399 - val_loss: 0.2194\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4340 - val_loss: 0.2241\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4511 - val_loss: 0.2211\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4207 - val_loss: 0.2196\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4442 - val_loss: 0.2233\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3782 - val_loss: 0.2190\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3940 - val_loss: 0.2189\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3874 - val_loss: 0.2210\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3989 - val_loss: 0.2199\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3527 - val_loss: 0.2190\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3637 - val_loss: 0.2204\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3577 - val_loss: 0.2249\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3609 - val_loss: 0.2208\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3715 - val_loss: 0.2197\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3818 - val_loss: 0.2209\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3518 - val_loss: 0.2184\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3621 - val_loss: 0.2246\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3500 - val_loss: 0.2212\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3547 - val_loss: 0.2302\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3440 - val_loss: 0.2188\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 1.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 10s 7ms/step - loss: 1.5280 - val_loss: 0.2189\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7970 - val_loss: 0.2290\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6996 - val_loss: 0.2316\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5792 - val_loss: 0.2314\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4925 - val_loss: 0.2223\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4885 - val_loss: 0.2206\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4501 - val_loss: 0.2187\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4400 - val_loss: 0.2256\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4236 - val_loss: 0.2193\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3990 - val_loss: 0.2187\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3951 - val_loss: 0.2313\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3940 - val_loss: 0.2192\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3835 - val_loss: 0.2223\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3563 - val_loss: 0.2354\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3507 - val_loss: 0.2221\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3705 - val_loss: 0.2223\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3722 - val_loss: 0.2289\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3642 - val_loss: 0.2200\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3429 - val_loss: 0.2221\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3464 - val_loss: 0.2238\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3558 - val_loss: 0.2401\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3580 - val_loss: 0.2252\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3440 - val_loss: 0.2241\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3411 - val_loss: 0.2385\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3467 - val_loss: 0.2252\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3402 - val_loss: 0.2201\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 1.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 1.0023 - val_loss: 0.2417\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6383 - val_loss: 0.2219\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5526 - val_loss: 0.2211\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4335 - val_loss: 0.2270\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4082 - val_loss: 0.2202\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4001 - val_loss: 0.2311\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3685 - val_loss: 0.2193\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3579 - val_loss: 0.2317\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3570 - val_loss: 0.2428\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3482 - val_loss: 0.2240\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3490 - val_loss: 0.2215\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3477 - val_loss: 0.2467\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3379 - val_loss: 0.2434\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3339 - val_loss: 0.2182\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3233 - val_loss: 0.2121\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3272 - val_loss: 0.2135\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3135 - val_loss: 0.2041\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3156 - val_loss: 0.2067\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3020 - val_loss: 0.2051\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3079 - val_loss: 0.1999\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3106 - val_loss: 0.2004\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2999 - val_loss: 0.1949\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3059 - val_loss: 0.2226\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2940 - val_loss: 0.2006\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3008 - val_loss: 0.1958\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2887 - val_loss: 0.1991\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2950 - val_loss: 0.2042\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2938 - val_loss: 0.1955\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2832 - val_loss: 0.2015\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2826 - val_loss: 0.1953\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2811 - val_loss: 0.2167\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2692 - val_loss: 0.1973\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2855 - val_loss: 0.2043\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2595 - val_loss: 0.2026\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2629 - val_loss: 0.2060\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2680 - val_loss: 0.1935\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2662 - val_loss: 0.2106\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2767 - val_loss: 0.1978\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2605 - val_loss: 0.1997\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2836 - val_loss: 0.1974\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2492 - val_loss: 0.1961\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2662 - val_loss: 0.2016\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2842 - val_loss: 0.2069\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2557 - val_loss: 0.1909\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2638 - val_loss: 0.1895\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2603 - val_loss: 0.1895\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2483 - val_loss: 0.1954\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2567 - val_loss: 0.1996\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2544 - val_loss: 0.1933\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2670 - val_loss: 0.1900\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2590 - val_loss: 0.1886\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2498 - val_loss: 0.2107\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2471 - val_loss: 0.1906\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2503 - val_loss: 0.1890\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2375 - val_loss: 0.1888\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2576 - val_loss: 0.1863\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2494 - val_loss: 0.1842\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2292 - val_loss: 0.1897\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2411 - val_loss: 0.2022\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2387 - val_loss: 0.1905\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2493 - val_loss: 0.1957\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2511 - val_loss: 0.1921\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2225 - val_loss: 0.1864\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2476 - val_loss: 0.1817\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2452 - val_loss: 0.1896\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2372 - val_loss: 0.1874\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2205 - val_loss: 0.1968\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2422 - val_loss: 0.1831\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2362 - val_loss: 0.1905\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2483 - val_loss: 0.2134\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2508 - val_loss: 0.1969\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2321 - val_loss: 0.1995\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2385 - val_loss: 0.1948\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2465 - val_loss: 0.1896\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2349 - val_loss: 0.2230\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2281 - val_loss: 0.1915\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2290 - val_loss: 0.2194\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2914 - val_loss: 0.2264\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2762 - val_loss: 0.2192\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2702 - val_loss: 0.2195\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.2191\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2732 - val_loss: 0.2196\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2883 - val_loss: 0.2238\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2727 - val_loss: 0.2186\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2626 - val_loss: 0.2191\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2748 - val_loss: 0.2199\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.2188\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2744 - val_loss: 0.2224\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2634 - val_loss: 0.2185\n",
      "Epoch 00089: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 6.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 1.0103 - val_loss: 0.2527\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6446 - val_loss: 0.2188\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5251 - val_loss: 0.2181\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4609 - val_loss: 0.2150\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4043 - val_loss: 0.2120\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3688 - val_loss: 0.2065\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3712 - val_loss: 0.2099\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3444 - val_loss: 0.2025\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3484 - val_loss: 0.2084\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3481 - val_loss: 0.2045\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3237 - val_loss: 0.1988\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3257 - val_loss: 0.2001\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3212 - val_loss: 0.2000\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3177 - val_loss: 0.1944\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3165 - val_loss: 0.2070\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2878 - val_loss: 0.1930\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2993 - val_loss: 0.1907\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3050 - val_loss: 0.1876\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2990 - val_loss: 0.1892\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2848 - val_loss: 0.1866\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2977 - val_loss: 0.1835\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2798 - val_loss: 0.1841\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2854 - val_loss: 0.2030\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2926 - val_loss: 0.1880\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2795 - val_loss: 0.1888\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2520 - val_loss: 0.1847\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2616 - val_loss: 0.1857\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2730 - val_loss: 0.1863\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2704 - val_loss: 0.1851\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2786 - val_loss: 0.2085\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2680 - val_loss: 0.1831\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2522 - val_loss: 0.1933\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2484 - val_loss: 0.1877\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2507 - val_loss: 0.1844\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2602 - val_loss: 0.1979\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2462 - val_loss: 0.1846\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2506 - val_loss: 0.1954\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2411 - val_loss: 0.1925\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2555 - val_loss: 0.1831\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2506 - val_loss: 0.2030\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2530 - val_loss: 0.1859\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2423 - val_loss: 0.1848\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2612 - val_loss: 0.1767\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2280 - val_loss: 0.1902\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2414 - val_loss: 0.1814\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2361 - val_loss: 0.1869\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2550 - val_loss: 0.1882\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2543 - val_loss: 0.1872\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2408 - val_loss: 0.1782\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2524 - val_loss: 0.1850\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2372 - val_loss: 0.1799\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2313 - val_loss: 0.1877\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2276 - val_loss: 0.1822\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2272 - val_loss: 0.2013\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2329 - val_loss: 0.1894\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2322 - val_loss: 0.1897\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2422 - val_loss: 0.1844\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2223 - val_loss: 0.1900\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2170 - val_loss: 0.1811\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2246 - val_loss: 0.1900\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2262 - val_loss: 0.1812\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2324 - val_loss: 0.1794\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2406 - val_loss: 0.1871\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2198 - val_loss: 0.1845\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2226 - val_loss: 0.1740\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2135 - val_loss: 0.1771\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2203 - val_loss: 0.1830\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2222 - val_loss: 0.1818\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2107 - val_loss: 0.1849\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2196 - val_loss: 0.1796\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2047 - val_loss: 0.1807\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2201 - val_loss: 0.1855\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2104 - val_loss: 0.1842\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2120 - val_loss: 0.1914\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2034 - val_loss: 0.1844\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2151 - val_loss: 0.1934\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2271 - val_loss: 0.1814\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2146 - val_loss: 0.2016\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2177 - val_loss: 0.1839\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2048 - val_loss: 0.1838\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2109 - val_loss: 0.1895\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2033 - val_loss: 0.1804\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2146 - val_loss: 0.1780\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2115 - val_loss: 0.1751\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2088 - val_loss: 0.1817\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2082 - val_loss: 0.1882\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2097 - val_loss: 0.1904\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2021 - val_loss: 0.1903\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2010 - val_loss: 0.1809\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2102 - val_loss: 0.1793\n",
      "Epoch 00090: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 6.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 10s 8ms/step - loss: 1.1121 - val_loss: 0.3013\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7237 - val_loss: 0.2393\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5740 - val_loss: 0.2198\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4754 - val_loss: 0.2243\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4041 - val_loss: 0.2189\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4337 - val_loss: 0.2186\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3813 - val_loss: 0.2186\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3717 - val_loss: 0.2188\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3702 - val_loss: 0.2375\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3568 - val_loss: 0.2246\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3685 - val_loss: 0.2186\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3667 - val_loss: 0.2188\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3435 - val_loss: 0.2186\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3389 - val_loss: 0.2281\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3224 - val_loss: 0.2263\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3438 - val_loss: 0.2144\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3529 - val_loss: 0.2243\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3356 - val_loss: 0.2222\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3519 - val_loss: 0.2397\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3404 - val_loss: 0.2212\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3444 - val_loss: 0.2209\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3332 - val_loss: 0.2275\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3323 - val_loss: 0.2189\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3333 - val_loss: 0.2197\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3264 - val_loss: 0.2258\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3261 - val_loss: 0.2479\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3216 - val_loss: 0.2222\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3057 - val_loss: 0.2376\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3099 - val_loss: 0.2186\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3242 - val_loss: 0.2190\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3186 - val_loss: 0.2211\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3103 - val_loss: 0.2228\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3135 - val_loss: 0.2186\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3238 - val_loss: 0.2206\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3158 - val_loss: 0.2353\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3062 - val_loss: 0.2213\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3143 - val_loss: 0.2199\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3207 - val_loss: 0.2242\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3190 - val_loss: 0.2215\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3208 - val_loss: 0.2207\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3135 - val_loss: 0.2262\n",
      "Epoch 00041: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 3.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 1.0932 - val_loss: 0.2312\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6842 - val_loss: 0.2187\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5417 - val_loss: 0.2219\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5015 - val_loss: 0.2199\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4668 - val_loss: 0.2196\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3896 - val_loss: 0.2212\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3764 - val_loss: 0.2272\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3802 - val_loss: 0.2247\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3663 - val_loss: 0.2190\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3915 - val_loss: 0.2373\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3506 - val_loss: 0.2274\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3722 - val_loss: 0.2204\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3462 - val_loss: 0.2268\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3446 - val_loss: 0.2205\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3536 - val_loss: 0.2200\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3415 - val_loss: 0.2288\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3396 - val_loss: 0.2207\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3442 - val_loss: 0.2268\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3370 - val_loss: 0.2311\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3402 - val_loss: 0.2331\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3415 - val_loss: 0.2194\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3342 - val_loss: 0.2276\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3355 - val_loss: 0.2250\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3345 - val_loss: 0.2327\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3183 - val_loss: 0.2186\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3218 - val_loss: 0.2197\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3262 - val_loss: 0.2186\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 2.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 10s 8ms/step - loss: 1.5636 - val_loss: 0.2223\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7390 - val_loss: 0.2187\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6552 - val_loss: 0.2272\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5188 - val_loss: 0.2191\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4794 - val_loss: 0.2236\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4674 - val_loss: 0.2186\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4177 - val_loss: 0.2223\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4150 - val_loss: 0.2234\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3896 - val_loss: 0.2228\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3896 - val_loss: 0.2291\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3892 - val_loss: 0.2237\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3556 - val_loss: 0.2190\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3839 - val_loss: 0.2187\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3501 - val_loss: 0.2265\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3421 - val_loss: 0.2187\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3680 - val_loss: 0.2189\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3660 - val_loss: 0.2189\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3376 - val_loss: 0.2402\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3340 - val_loss: 0.2181\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3688 - val_loss: 0.2253\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3586 - val_loss: 0.2302\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3484 - val_loss: 0.2181\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3434 - val_loss: 0.2177\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3457 - val_loss: 0.2251\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3529 - val_loss: 0.2195\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3499 - val_loss: 0.2498\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3432 - val_loss: 0.2203\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 2.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 1.5017 - val_loss: 0.2570\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6850 - val_loss: 0.2186\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6224 - val_loss: 0.2190\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5125 - val_loss: 0.2212\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4502 - val_loss: 0.2205\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4200 - val_loss: 0.2228\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3948 - val_loss: 0.2212\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3959 - val_loss: 0.2181\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3773 - val_loss: 0.2195\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3472 - val_loss: 0.2288\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3659 - val_loss: 0.2390\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3412 - val_loss: 0.2210\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3476 - val_loss: 0.2165\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3416 - val_loss: 0.2180\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3453 - val_loss: 0.2176\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3372 - val_loss: 0.2153\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3479 - val_loss: 0.2166\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3297 - val_loss: 0.2286\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3450 - val_loss: 0.2162\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3080 - val_loss: 0.2217\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3284 - val_loss: 0.2276\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3231 - val_loss: 0.2283\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3328 - val_loss: 0.2320\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3227 - val_loss: 0.2162\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3231 - val_loss: 0.2265\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3173 - val_loss: 0.2323\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3063 - val_loss: 0.2163\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3069 - val_loss: 0.2053\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3001 - val_loss: 0.2216\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3100 - val_loss: 0.2048\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3142 - val_loss: 0.2041\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2920 - val_loss: 0.1996\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2987 - val_loss: 0.2018\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2932 - val_loss: 0.1990\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2835 - val_loss: 0.2092\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3165 - val_loss: 0.1992\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2691 - val_loss: 0.2095\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2788 - val_loss: 0.1966\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2971 - val_loss: 0.2022\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2705 - val_loss: 0.2030\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2851 - val_loss: 0.2038\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2862 - val_loss: 0.2615\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2743 - val_loss: 0.2021\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2747 - val_loss: 0.2140\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2749 - val_loss: 0.2031\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2726 - val_loss: 0.2071\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2850 - val_loss: 0.2001\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2759 - val_loss: 0.2014\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2590 - val_loss: 0.2007\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2711 - val_loss: 0.2169\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2720 - val_loss: 0.2004\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2681 - val_loss: 0.1947\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2744 - val_loss: 0.2013\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2695 - val_loss: 0.1960\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2559 - val_loss: 0.1992\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2596 - val_loss: 0.2036\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2611 - val_loss: 0.2018\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2643 - val_loss: 0.1964\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2506 - val_loss: 0.1987\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2657 - val_loss: 0.1997\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2678 - val_loss: 0.2014\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2652 - val_loss: 0.1941\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2592 - val_loss: 0.1988\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2672 - val_loss: 0.1969\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2728 - val_loss: 0.1976\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2533 - val_loss: 0.1976\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2552 - val_loss: 0.2089\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2437 - val_loss: 0.2088\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2481 - val_loss: 0.1916\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2475 - val_loss: 0.1951\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2519 - val_loss: 0.2008\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2663 - val_loss: 0.2096\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2449 - val_loss: 0.1986\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2392 - val_loss: 0.1898\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2438 - val_loss: 0.2076\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2519 - val_loss: 0.1985\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2453 - val_loss: 0.1901\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2570 - val_loss: 0.1913\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2427 - val_loss: 0.1953\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2302 - val_loss: 0.1927\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2462 - val_loss: 0.1924\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2456 - val_loss: 0.1995\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2417 - val_loss: 0.1916\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2389 - val_loss: 0.1996\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2501 - val_loss: 0.1973\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2458 - val_loss: 0.1935\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2518 - val_loss: 0.1940\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2382 - val_loss: 0.2158\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2459 - val_loss: 0.1921\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2365 - val_loss: 0.2062\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2297 - val_loss: 0.1945\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2276 - val_loss: 0.1995\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2389 - val_loss: 0.2028\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2254 - val_loss: 0.1930\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2323 - val_loss: 0.1921\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2446 - val_loss: 0.2094\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2334 - val_loss: 0.1904\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2277 - val_loss: 0.2032\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2505 - val_loss: 0.1929\n",
      "Epoch 00099: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 7.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 1.5447 - val_loss: 0.2204\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7311 - val_loss: 0.2238\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6623 - val_loss: 0.2341\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5320 - val_loss: 0.2195\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4586 - val_loss: 0.2201\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4392 - val_loss: 0.2189\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4199 - val_loss: 0.2185\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3957 - val_loss: 0.2246\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3923 - val_loss: 0.2506\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3764 - val_loss: 0.2201\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3775 - val_loss: 0.2186\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3601 - val_loss: 0.2324\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3796 - val_loss: 0.2345\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3820 - val_loss: 0.2277\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3396 - val_loss: 0.2206\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3536 - val_loss: 0.2273\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3460 - val_loss: 0.2308\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3302 - val_loss: 0.2287\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3641 - val_loss: 0.2403\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3577 - val_loss: 0.2245\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3209 - val_loss: 0.2203\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3289 - val_loss: 0.2366\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3449 - val_loss: 0.2176\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3528 - val_loss: 0.2218\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3296 - val_loss: 0.2310\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3413 - val_loss: 0.2196\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3426 - val_loss: 0.2188\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3131 - val_loss: 0.2482\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3176 - val_loss: 0.2168\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3297 - val_loss: 0.2247\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3338 - val_loss: 0.2383\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3327 - val_loss: 0.2170\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3196 - val_loss: 0.2252\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3331 - val_loss: 0.2169\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3214 - val_loss: 0.2258\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3275 - val_loss: 0.2252\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3223 - val_loss: 0.2226\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3222 - val_loss: 0.2324\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3029 - val_loss: 0.2136\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3069 - val_loss: 0.2164\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3098 - val_loss: 0.2212\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3189 - val_loss: 0.2187\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3010 - val_loss: 0.2174\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3001 - val_loss: 0.2098\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3195 - val_loss: 0.2114\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3218 - val_loss: 0.2125\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3051 - val_loss: 0.2203\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3020 - val_loss: 0.2061\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2930 - val_loss: 0.2183\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2920 - val_loss: 0.2129\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3033 - val_loss: 0.2049\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2930 - val_loss: 0.2040\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2994 - val_loss: 0.2047\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2926 - val_loss: 0.2106\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2917 - val_loss: 0.2011\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2787 - val_loss: 0.1977\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2823 - val_loss: 0.1987\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2838 - val_loss: 0.2014\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2798 - val_loss: 0.2019\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2721 - val_loss: 0.2084\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2712 - val_loss: 0.2011\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2734 - val_loss: 0.1988\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2653 - val_loss: 0.2024\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2700 - val_loss: 0.1993\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2672 - val_loss: 0.1985\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2717 - val_loss: 0.1979\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2769 - val_loss: 0.2011\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2689 - val_loss: 0.2142\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2675 - val_loss: 0.2107\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2673 - val_loss: 0.2008\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2651 - val_loss: 0.2124\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2706 - val_loss: 0.1986\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2692 - val_loss: 0.1975\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2630 - val_loss: 0.1944\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2709 - val_loss: 0.2016\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2668 - val_loss: 0.1985\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2555 - val_loss: 0.2103\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2533 - val_loss: 0.2085\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2537 - val_loss: 0.2073\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2558 - val_loss: 0.1989\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2698 - val_loss: 0.2065\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2408 - val_loss: 0.2024\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2579 - val_loss: 0.2000\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2526 - val_loss: 0.2049\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2509 - val_loss: 0.1968\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2448 - val_loss: 0.2128\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2428 - val_loss: 0.2040\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2453 - val_loss: 0.2041\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2476 - val_loss: 0.1988\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2435 - val_loss: 0.2061\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2481 - val_loss: 0.1967\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2307 - val_loss: 0.2056\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2558 - val_loss: 0.1973\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2483 - val_loss: 0.2041\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2401 - val_loss: 0.2068\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2483 - val_loss: 0.2032\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2294 - val_loss: 0.1953\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2200 - val_loss: 0.2086\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2323 - val_loss: 0.2050\n",
      "Epoch 00099: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 7.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 1.0282 - val_loss: 0.2400\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6574 - val_loss: 0.2197\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5096 - val_loss: 0.2282\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4400 - val_loss: 0.2312\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4170 - val_loss: 0.2187\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4000 - val_loss: 0.2246\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3796 - val_loss: 0.2193\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3478 - val_loss: 0.2224\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3543 - val_loss: 0.2246\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3611 - val_loss: 0.2532\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3410 - val_loss: 0.2219\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3480 - val_loss: 0.2186\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3431 - val_loss: 0.2274\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3376 - val_loss: 0.2517\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3355 - val_loss: 0.2198\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3324 - val_loss: 0.2485\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3382 - val_loss: 0.2197\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3423 - val_loss: 0.2192\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3315 - val_loss: 0.2227\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3450 - val_loss: 0.2192\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3114 - val_loss: 0.2268\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3183 - val_loss: 0.2239\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3054 - val_loss: 0.2468\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3420 - val_loss: 0.2238\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3216 - val_loss: 0.2245\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3076 - val_loss: 0.2337\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3155 - val_loss: 0.2250\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3066 - val_loss: 0.2250\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3242 - val_loss: 0.2196\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3248 - val_loss: 0.2219\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 2.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 1.7140 - val_loss: 0.2697\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7530 - val_loss: 0.2198\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6469 - val_loss: 0.2332\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5286 - val_loss: 0.2227\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4973 - val_loss: 0.2172\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4270 - val_loss: 0.2300\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4326 - val_loss: 0.2287\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3961 - val_loss: 0.2344\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3727 - val_loss: 0.2178\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3738 - val_loss: 0.2202\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3735 - val_loss: 0.2322\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3719 - val_loss: 0.2285\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3551 - val_loss: 0.2301\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3353 - val_loss: 0.2196\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3488 - val_loss: 0.2205\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3491 - val_loss: 0.2166\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3469 - val_loss: 0.2353\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3454 - val_loss: 0.2170\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3466 - val_loss: 0.2211\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3248 - val_loss: 0.2160\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3410 - val_loss: 0.2319\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3249 - val_loss: 0.2163\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3443 - val_loss: 0.2532\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3451 - val_loss: 0.2153\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3134 - val_loss: 0.2158\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3206 - val_loss: 0.2274\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3159 - val_loss: 0.2405\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3131 - val_loss: 0.2185\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3150 - val_loss: 0.2132\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3304 - val_loss: 0.2178\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2909 - val_loss: 0.2158\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3369 - val_loss: 0.2206\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3131 - val_loss: 0.2126\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3155 - val_loss: 0.2151\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3070 - val_loss: 0.2141\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3103 - val_loss: 0.2084\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2989 - val_loss: 0.2203\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2947 - val_loss: 0.2138\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3073 - val_loss: 0.2309\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3000 - val_loss: 0.2059\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2947 - val_loss: 0.2250\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2896 - val_loss: 0.2040\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2910 - val_loss: 0.2047\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2858 - val_loss: 0.2035\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2945 - val_loss: 0.2060\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2776 - val_loss: 0.2022\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2936 - val_loss: 0.2047\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2872 - val_loss: 0.2171\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2893 - val_loss: 0.2059\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2828 - val_loss: 0.2001\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2746 - val_loss: 0.2053\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2822 - val_loss: 0.2037\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2760 - val_loss: 0.1975\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2848 - val_loss: 0.1995\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2803 - val_loss: 0.2055\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2729 - val_loss: 0.2221\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2780 - val_loss: 0.2066\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2660 - val_loss: 0.1979\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2744 - val_loss: 0.2026\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2752 - val_loss: 0.1993\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2756 - val_loss: 0.2043\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2723 - val_loss: 0.2015\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2678 - val_loss: 0.2006\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2592 - val_loss: 0.1991\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2586 - val_loss: 0.1976\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2698 - val_loss: 0.1993\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2651 - val_loss: 0.1918\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2628 - val_loss: 0.2105\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2553 - val_loss: 0.1955\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2518 - val_loss: 0.1924\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2595 - val_loss: 0.1972\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2661 - val_loss: 0.1986\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2481 - val_loss: 0.2064\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2671 - val_loss: 0.1948\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2553 - val_loss: 0.1949\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2446 - val_loss: 0.1890\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2628 - val_loss: 0.2022\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2560 - val_loss: 0.2035\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2571 - val_loss: 0.1981\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2589 - val_loss: 0.2012\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2510 - val_loss: 0.2066\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2503 - val_loss: 0.2076\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2418 - val_loss: 0.2080\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2555 - val_loss: 0.1976\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2524 - val_loss: 0.2013\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2458 - val_loss: 0.2018\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2462 - val_loss: 0.1961\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2521 - val_loss: 0.1925\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2334 - val_loss: 0.2041\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2441 - val_loss: 0.1900\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2499 - val_loss: 0.2052\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2364 - val_loss: 0.1988\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2419 - val_loss: 0.2057\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2260 - val_loss: 0.1893\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2423 - val_loss: 0.1951\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2430 - val_loss: 0.1958\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2360 - val_loss: 0.1985\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2370 - val_loss: 0.1888\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2460 - val_loss: 0.2031\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2368 - val_loss: 0.1979\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2332 - val_loss: 0.2101\n",
      "Epoch 00101: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 7.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 13s 9ms/step - loss: 13.0945 - val_loss: 0.5634\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.9283 - val_loss: 0.2257\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8753 - val_loss: 0.2180\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8877 - val_loss: 0.2154\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8346 - val_loss: 0.2017\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7433 - val_loss: 0.2002\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6519 - val_loss: 0.2008\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7016 - val_loss: 0.2156\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6571 - val_loss: 0.1957\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5928 - val_loss: 0.2037\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5878 - val_loss: 0.2028\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5533 - val_loss: 0.1926\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4956 - val_loss: 0.1969\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4783 - val_loss: 0.1880\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4500 - val_loss: 0.1948\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4375 - val_loss: 0.1941\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3714 - val_loss: 0.1860\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3506 - val_loss: 0.1870\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3414 - val_loss: 0.1956\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3401 - val_loss: 0.1872\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3137 - val_loss: 0.1862\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3017 - val_loss: 0.1826\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2798 - val_loss: 0.1828\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2694 - val_loss: 0.1861\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2700 - val_loss: 0.1869\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2501 - val_loss: 0.1848\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2475 - val_loss: 0.1843\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2398 - val_loss: 0.1801\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2310 - val_loss: 0.1796\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2197 - val_loss: 0.1794\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2051 - val_loss: 0.1834\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2105 - val_loss: 0.1800\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2116 - val_loss: 0.1857\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1951 - val_loss: 0.1848\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2138 - val_loss: 0.1837\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1946 - val_loss: 0.1887\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1936 - val_loss: 0.1799\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1816 - val_loss: 0.1772\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1787 - val_loss: 0.1803\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1816 - val_loss: 0.1844\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1801 - val_loss: 0.1772\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1938 - val_loss: 0.1775\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1916 - val_loss: 0.1978\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1821 - val_loss: 0.1768\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1800 - val_loss: 0.1802\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1716 - val_loss: 0.1738\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1738 - val_loss: 0.1788\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1740 - val_loss: 0.1772\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1676 - val_loss: 0.1891\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1727 - val_loss: 0.1835\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1701 - val_loss: 0.1785\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1565 - val_loss: 0.1783\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1722 - val_loss: 0.1782\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1652 - val_loss: 0.1752\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1623 - val_loss: 0.1822\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1707 - val_loss: 0.1847\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1712 - val_loss: 0.1805\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1619 - val_loss: 0.1767\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1661 - val_loss: 0.1819\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1595 - val_loss: 0.1792\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1538 - val_loss: 0.1817\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1485 - val_loss: 0.1792\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1683 - val_loss: 0.1798\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1674 - val_loss: 0.1805\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1754 - val_loss: 0.1796\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1606 - val_loss: 0.1844\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1492 - val_loss: 0.1843\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1597 - val_loss: 0.1796\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1604 - val_loss: 0.1835\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1534 - val_loss: 0.1842\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1552 - val_loss: 0.1794\n",
      "Epoch 00071: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 7.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 10.9871 - val_loss: 0.2228\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8291 - val_loss: 0.2117\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8383 - val_loss: 0.2043\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7133 - val_loss: 0.1948\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7081 - val_loss: 0.1979\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6872 - val_loss: 0.1967\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6012 - val_loss: 0.1890\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6085 - val_loss: 0.1868\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5573 - val_loss: 0.1836\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5355 - val_loss: 0.1949\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4753 - val_loss: 0.1846\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4269 - val_loss: 0.1804\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4099 - val_loss: 0.1767\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4068 - val_loss: 0.1861\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3682 - val_loss: 0.1769\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3429 - val_loss: 0.1796\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3204 - val_loss: 0.1794\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2954 - val_loss: 0.1787\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2876 - val_loss: 0.1706\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2741 - val_loss: 0.1753\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2632 - val_loss: 0.1771\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2360 - val_loss: 0.1827\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2454 - val_loss: 0.1794\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2178 - val_loss: 0.1761\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2095 - val_loss: 0.1777\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1979 - val_loss: 0.1726\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1863 - val_loss: 0.1770\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1748 - val_loss: 0.1768\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1766 - val_loss: 0.1732\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1626 - val_loss: 0.1834\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1762 - val_loss: 0.1745\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1586 - val_loss: 0.1699\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1602 - val_loss: 0.1758\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1650 - val_loss: 0.1721\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1440 - val_loss: 0.1809\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1486 - val_loss: 0.1743\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1529 - val_loss: 0.1703\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1497 - val_loss: 0.1693\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1427 - val_loss: 0.1832\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1455 - val_loss: 0.1689\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1435 - val_loss: 0.1685\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1463 - val_loss: 0.1706\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1400 - val_loss: 0.1838\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1443 - val_loss: 0.1688\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1453 - val_loss: 0.1757\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1462 - val_loss: 0.1721\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1364 - val_loss: 0.1841\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1241 - val_loss: 0.1748\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1388 - val_loss: 0.1764\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1357 - val_loss: 0.1778\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1377 - val_loss: 0.1844\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1444 - val_loss: 0.1771\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1291 - val_loss: 0.1795\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1331 - val_loss: 0.1698\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1420 - val_loss: 0.1702\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1342 - val_loss: 0.1806\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1302 - val_loss: 0.1742\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1384 - val_loss: 0.1715\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1406 - val_loss: 0.1747\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1334 - val_loss: 0.1724\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1210 - val_loss: 0.1792\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1316 - val_loss: 0.1759\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1236 - val_loss: 0.1797\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 6.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 7.4063 - val_loss: 0.2371\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8233 - val_loss: 0.2063\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7411 - val_loss: 0.1913\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6700 - val_loss: 0.1845\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5984 - val_loss: 0.1823\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5608 - val_loss: 0.1775\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4933 - val_loss: 0.1824\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5082 - val_loss: 0.1776\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4332 - val_loss: 0.1866\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3986 - val_loss: 0.1787\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3899 - val_loss: 0.1955\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3773 - val_loss: 0.1778\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3131 - val_loss: 0.1740\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3071 - val_loss: 0.1784\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2748 - val_loss: 0.1799\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2687 - val_loss: 0.1771\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2495 - val_loss: 0.1740\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2401 - val_loss: 0.1764\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2476 - val_loss: 0.1696\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2145 - val_loss: 0.1726\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2114 - val_loss: 0.1756\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2082 - val_loss: 0.1731\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1905 - val_loss: 0.1825\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1796 - val_loss: 0.1748\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1889 - val_loss: 0.1781\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1705 - val_loss: 0.1875\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1671 - val_loss: 0.1876\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1660 - val_loss: 0.1761\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1530 - val_loss: 0.1774\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1438 - val_loss: 0.1756\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1516 - val_loss: 0.1888\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1467 - val_loss: 0.1907\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1549 - val_loss: 0.1810\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1368 - val_loss: 0.1793\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1382 - val_loss: 0.1811\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1469 - val_loss: 0.1875\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1491 - val_loss: 0.1981\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1456 - val_loss: 0.1782\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1424 - val_loss: 0.1824\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1311 - val_loss: 0.1978\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1386 - val_loss: 0.1720\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1315 - val_loss: 0.1789\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1382 - val_loss: 0.1781\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1340 - val_loss: 0.1743\n",
      "Epoch 00044: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 15.6487 - val_loss: 0.5581\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.9694 - val_loss: 0.2229\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8704 - val_loss: 0.2185\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8655 - val_loss: 0.2159\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7953 - val_loss: 0.2178\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7568 - val_loss: 0.2113\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7713 - val_loss: 0.2067\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6849 - val_loss: 0.2049\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6513 - val_loss: 0.2031\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6076 - val_loss: 0.2039\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5594 - val_loss: 0.2090\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5095 - val_loss: 0.2001\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4998 - val_loss: 0.1937\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4650 - val_loss: 0.1907\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4286 - val_loss: 0.1990\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4077 - val_loss: 0.1924\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4123 - val_loss: 0.1928\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3641 - val_loss: 0.1881\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3411 - val_loss: 0.1938\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3241 - val_loss: 0.1875\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3128 - val_loss: 0.1810\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2817 - val_loss: 0.1883\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2835 - val_loss: 0.1805\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2647 - val_loss: 0.1806\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2617 - val_loss: 0.1816\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2323 - val_loss: 0.1872\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2402 - val_loss: 0.1746\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2202 - val_loss: 0.1909\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2367 - val_loss: 0.1774\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2174 - val_loss: 0.1791\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2155 - val_loss: 0.1777\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1984 - val_loss: 0.1785\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2062 - val_loss: 0.1720\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1993 - val_loss: 0.1797\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1911 - val_loss: 0.1789\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1905 - val_loss: 0.1706\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1831 - val_loss: 0.1783\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1886 - val_loss: 0.1727\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1755 - val_loss: 0.1730\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1720 - val_loss: 0.1785\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1713 - val_loss: 0.1790\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1711 - val_loss: 0.1684\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1708 - val_loss: 0.1874\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1871 - val_loss: 0.1917\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1669 - val_loss: 0.1846\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1679 - val_loss: 0.1828\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1698 - val_loss: 0.1775\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1631 - val_loss: 0.1980\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1682 - val_loss: 0.1745\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1676 - val_loss: 0.1699\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1593 - val_loss: 0.1826\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1584 - val_loss: 0.1743\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1427 - val_loss: 0.1813\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1588 - val_loss: 0.1739\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1558 - val_loss: 0.1884\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1587 - val_loss: 0.1724\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1545 - val_loss: 0.1812\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1483 - val_loss: 0.1821\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1577 - val_loss: 0.1729\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1560 - val_loss: 0.1843\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1693 - val_loss: 0.1790\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1574 - val_loss: 0.1691\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1724 - val_loss: 0.1718\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1516 - val_loss: 0.1765\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1644 - val_loss: 0.1748\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1669 - val_loss: 0.1704\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1742 - val_loss: 0.1716\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 6.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 8.1391 - val_loss: 0.2196\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.0224 - val_loss: 0.2016\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8185 - val_loss: 0.1921\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7364 - val_loss: 0.1773\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6490 - val_loss: 0.1850\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6178 - val_loss: 0.1785\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6092 - val_loss: 0.1858\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5293 - val_loss: 0.1791\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4736 - val_loss: 0.1698\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4437 - val_loss: 0.1859\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4170 - val_loss: 0.1774\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3618 - val_loss: 0.1747\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3259 - val_loss: 0.1704\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3175 - val_loss: 0.1742\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2989 - val_loss: 0.1715\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2735 - val_loss: 0.1696\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2652 - val_loss: 0.1659\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2282 - val_loss: 0.1913\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2399 - val_loss: 0.1731\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2222 - val_loss: 0.1696\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2016 - val_loss: 0.1691\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2047 - val_loss: 0.1865\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1777 - val_loss: 0.1743\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1851 - val_loss: 0.1764\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1633 - val_loss: 0.1707\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1638 - val_loss: 0.1863\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1500 - val_loss: 0.1746\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1437 - val_loss: 0.1756\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1522 - val_loss: 0.1754\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1429 - val_loss: 0.1776\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1447 - val_loss: 0.1747\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1462 - val_loss: 0.2201\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1668 - val_loss: 0.1768\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1425 - val_loss: 0.1708\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1414 - val_loss: 0.1740\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1382 - val_loss: 0.1744\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1373 - val_loss: 0.1800\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1343 - val_loss: 0.1684\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1424 - val_loss: 0.1728\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1363 - val_loss: 0.1739\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1336 - val_loss: 0.1725\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1289 - val_loss: 0.1977\n",
      "Epoch 00042: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1.1469 - val_loss: 0.3506\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6396 - val_loss: 0.2239\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5102 - val_loss: 0.2342\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4264 - val_loss: 0.2196\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3973 - val_loss: 0.2254\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3428 - val_loss: 0.2222\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3350 - val_loss: 0.2197\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3378 - val_loss: 0.2214\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3235 - val_loss: 0.2253\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3279 - val_loss: 0.2288\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3437 - val_loss: 0.2427\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3274 - val_loss: 0.2180\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2997 - val_loss: 0.2339\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3159 - val_loss: 0.2097\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2971 - val_loss: 0.1977\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2931 - val_loss: 0.2083\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2863 - val_loss: 0.1963\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2682 - val_loss: 0.1958\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2723 - val_loss: 0.2007\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2794 - val_loss: 0.1946\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2742 - val_loss: 0.2405\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2800 - val_loss: 0.1927\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2666 - val_loss: 0.1927\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2649 - val_loss: 0.1895\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2654 - val_loss: 0.1875\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2729 - val_loss: 0.1979\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2589 - val_loss: 0.1959\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2494 - val_loss: 0.1981\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2573 - val_loss: 0.1816\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2731 - val_loss: 0.1844\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2528 - val_loss: 0.2010\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2593 - val_loss: 0.1892\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2529 - val_loss: 0.1862\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2502 - val_loss: 0.1884\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2424 - val_loss: 0.2054\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2401 - val_loss: 0.1796\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2540 - val_loss: 0.1873\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2525 - val_loss: 0.1863\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2365 - val_loss: 0.1786\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2379 - val_loss: 0.1787\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2532 - val_loss: 0.1806\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2430 - val_loss: 0.1886\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2397 - val_loss: 0.1806\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2442 - val_loss: 0.1813\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2380 - val_loss: 0.1844\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2294 - val_loss: 0.1775\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2412 - val_loss: 0.1853\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2233 - val_loss: 0.1747\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2387 - val_loss: 0.2082\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2401 - val_loss: 0.1729\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2169 - val_loss: 0.1770\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2269 - val_loss: 0.1766\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2249 - val_loss: 0.1750\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2279 - val_loss: 0.1913\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2211 - val_loss: 0.1827\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2374 - val_loss: 0.1885\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2327 - val_loss: 0.1807\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2148 - val_loss: 0.1765\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2269 - val_loss: 0.1906\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2247 - val_loss: 0.1808\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2244 - val_loss: 0.1813\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2065 - val_loss: 0.1834\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2124 - val_loss: 0.1748\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2256 - val_loss: 0.1771\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2052 - val_loss: 0.1813\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2169 - val_loss: 0.2475\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2120 - val_loss: 0.1847\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2071 - val_loss: 0.1775\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2118 - val_loss: 0.1727\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1935 - val_loss: 0.1751\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2055 - val_loss: 0.1767\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2049 - val_loss: 0.1781\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2116 - val_loss: 0.1876\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2044 - val_loss: 0.1765\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2079 - val_loss: 0.1873\n",
      "Epoch 00075: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 8.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 15s 11ms/step - loss: 1.1466 - val_loss: 0.2747\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.6306 - val_loss: 0.2154\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.4978 - val_loss: 0.2233\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.3980 - val_loss: 0.2186\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3780 - val_loss: 0.2188\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3595 - val_loss: 0.2498\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3387 - val_loss: 0.2202\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3278 - val_loss: 0.2338\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3071 - val_loss: 0.2207\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3040 - val_loss: 0.2308\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3026 - val_loss: 0.2221\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2987 - val_loss: 0.2226\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3104 - val_loss: 0.2206\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2955 - val_loss: 0.2190\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3005 - val_loss: 0.2447\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2911 - val_loss: 0.2296\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2972 - val_loss: 0.2226\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2864 - val_loss: 0.2361\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3198 - val_loss: 0.2215\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2985 - val_loss: 0.2415\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2849 - val_loss: 0.2206\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2972 - val_loss: 0.2205\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2881 - val_loss: 0.2661\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2899 - val_loss: 0.2167\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3042 - val_loss: 0.2228\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2890 - val_loss: 0.2207\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2950 - val_loss: 0.2189\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 3.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 10ms/step - loss: 1.1348 - val_loss: 0.2371\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6223 - val_loss: 0.2223\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4474 - val_loss: 0.2161\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4150 - val_loss: 0.2242\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3606 - val_loss: 0.2149\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3330 - val_loss: 0.2052\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3260 - val_loss: 0.2128\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3129 - val_loss: 0.2014\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3038 - val_loss: 0.2071\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2879 - val_loss: 0.2201\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2918 - val_loss: 0.2168\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2855 - val_loss: 0.2060\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2852 - val_loss: 0.2016\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2818 - val_loss: 0.1996\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2790 - val_loss: 0.2089\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2763 - val_loss: 0.1940\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2959 - val_loss: 0.2023\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2724 - val_loss: 0.2048\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2744 - val_loss: 0.2267\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2782 - val_loss: 0.2068\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2694 - val_loss: 0.1941\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2602 - val_loss: 0.2058\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2635 - val_loss: 0.1905\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2568 - val_loss: 0.2233\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2564 - val_loss: 0.1985\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2763 - val_loss: 0.2039\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2656 - val_loss: 0.2057\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2418 - val_loss: 0.1953\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2684 - val_loss: 0.2154\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2504 - val_loss: 0.1875\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2551 - val_loss: 0.1901\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2606 - val_loss: 0.1862\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2502 - val_loss: 0.2044\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2429 - val_loss: 0.1920\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2254 - val_loss: 0.1898\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2439 - val_loss: 0.1847\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2482 - val_loss: 0.2133\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2280 - val_loss: 0.1858\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2342 - val_loss: 0.1831\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2380 - val_loss: 0.2090\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2384 - val_loss: 0.2064\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2360 - val_loss: 0.1808\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2343 - val_loss: 0.1791\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2374 - val_loss: 0.1852\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2295 - val_loss: 0.1917\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2230 - val_loss: 0.1810\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2357 - val_loss: 0.1772\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2356 - val_loss: 0.1761\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2103 - val_loss: 0.1778\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2234 - val_loss: 0.1881\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2218 - val_loss: 0.1849\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2202 - val_loss: 0.1853\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2200 - val_loss: 0.2025\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2123 - val_loss: 0.1792\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2114 - val_loss: 0.1845\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2137 - val_loss: 0.1842\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2009 - val_loss: 0.1731\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2194 - val_loss: 0.1849\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1990 - val_loss: 0.1845\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2079 - val_loss: 0.1862\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2060 - val_loss: 0.1894\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2110 - val_loss: 0.1848\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2040 - val_loss: 0.1787\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1923 - val_loss: 0.1855\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2002 - val_loss: 0.1891\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2015 - val_loss: 0.1872\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2006 - val_loss: 0.1783\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1891 - val_loss: 0.1888\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1952 - val_loss: 0.1939\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1876 - val_loss: 0.2078\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1813 - val_loss: 0.1782\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1926 - val_loss: 0.1831\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2001 - val_loss: 0.1780\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2039 - val_loss: 0.1870\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1944 - val_loss: 0.1852\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1975 - val_loss: 0.1969\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1950 - val_loss: 0.1868\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1883 - val_loss: 0.1879\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1912 - val_loss: 0.1821\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1951 - val_loss: 0.2034\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1901 - val_loss: 0.1836\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1727 - val_loss: 0.1948\n",
      "Epoch 00082: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 8.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 1.2646 - val_loss: 0.2345\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6470 - val_loss: 0.2187\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5041 - val_loss: 0.2264\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4211 - val_loss: 0.2170\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3949 - val_loss: 0.2440\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3745 - val_loss: 0.2167\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3458 - val_loss: 0.2135\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3117 - val_loss: 0.2036\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3053 - val_loss: 0.1981\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2998 - val_loss: 0.2095\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2991 - val_loss: 0.2131\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2952 - val_loss: 0.2003\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2724 - val_loss: 0.1941\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2791 - val_loss: 0.1969\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2848 - val_loss: 0.2013\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2684 - val_loss: 0.1897\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2819 - val_loss: 0.1905\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2748 - val_loss: 0.1894\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2699 - val_loss: 0.1896\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2662 - val_loss: 0.1949\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2625 - val_loss: 0.1854\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2450 - val_loss: 0.1827\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2648 - val_loss: 0.2016\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2664 - val_loss: 0.1903\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2714 - val_loss: 0.1891\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2731 - val_loss: 0.1950\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2604 - val_loss: 0.2205\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2583 - val_loss: 0.2296\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2559 - val_loss: 0.1873\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2610 - val_loss: 0.1889\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2611 - val_loss: 0.2080\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2383 - val_loss: 0.1863\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2578 - val_loss: 0.1842\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2403 - val_loss: 0.1938\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2550 - val_loss: 0.1935\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2359 - val_loss: 0.1999\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2286 - val_loss: 0.1818\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2316 - val_loss: 0.2013\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2238 - val_loss: 0.1892\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2301 - val_loss: 0.1930\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2321 - val_loss: 0.1905\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2302 - val_loss: 0.1904\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2250 - val_loss: 0.1864\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2173 - val_loss: 0.2072\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2234 - val_loss: 0.1864\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2267 - val_loss: 0.1871\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2270 - val_loss: 0.1819\n",
      "Epoch 00047: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 5.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 1.0640 - val_loss: 0.2346\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5931 - val_loss: 0.2858\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4504 - val_loss: 0.2270\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4096 - val_loss: 0.2216\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3683 - val_loss: 0.2426\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3544 - val_loss: 0.2217\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3255 - val_loss: 0.2327\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3200 - val_loss: 0.2357\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3063 - val_loss: 0.2443\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3137 - val_loss: 0.2328\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3126 - val_loss: 0.2414\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3158 - val_loss: 0.2214\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3133 - val_loss: 0.2218\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3010 - val_loss: 0.2434\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2964 - val_loss: 0.2853\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3187 - val_loss: 0.2422\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2968 - val_loss: 0.2201\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2947 - val_loss: 0.2249\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2834 - val_loss: 0.2288\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2902 - val_loss: 0.2507\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2898 - val_loss: 0.2223\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3000 - val_loss: 0.2385\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2834 - val_loss: 0.2547\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2845 - val_loss: 0.2223\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2876 - val_loss: 0.2369\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3001 - val_loss: 0.2150\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2930 - val_loss: 0.2577\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2761 - val_loss: 0.2244\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2880 - val_loss: 0.2129\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2784 - val_loss: 0.2157\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2749 - val_loss: 0.2171\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2667 - val_loss: 0.2375\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2763 - val_loss: 0.2149\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2680 - val_loss: 0.2143\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2830 - val_loss: 0.2078\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2654 - val_loss: 0.2119\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2736 - val_loss: 0.2158\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2672 - val_loss: 0.2087\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2734 - val_loss: 0.2109\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2653 - val_loss: 0.2036\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2657 - val_loss: 0.2092\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2613 - val_loss: 0.2039\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2620 - val_loss: 0.2096\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2705 - val_loss: 0.2159\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2618 - val_loss: 0.2101\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2500 - val_loss: 0.2005\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2558 - val_loss: 0.2169\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2610 - val_loss: 0.2024\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2481 - val_loss: 0.2027\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2474 - val_loss: 0.2014\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2668 - val_loss: 0.2077\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2535 - val_loss: 0.2181\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2596 - val_loss: 0.1978\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2576 - val_loss: 0.2151\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2396 - val_loss: 0.2045\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2563 - val_loss: 0.2026\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2536 - val_loss: 0.1999\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2418 - val_loss: 0.2013\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2436 - val_loss: 0.1970\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2510 - val_loss: 0.2155\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2422 - val_loss: 0.1986\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2425 - val_loss: 0.2048\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2411 - val_loss: 0.2015\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2381 - val_loss: 0.2138\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2455 - val_loss: 0.2034\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2334 - val_loss: 0.2140\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2316 - val_loss: 0.1946\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2449 - val_loss: 0.1960\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2301 - val_loss: 0.2061\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2366 - val_loss: 0.2125\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2396 - val_loss: 0.2033\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2383 - val_loss: 0.2118\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2399 - val_loss: 0.2163\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2319 - val_loss: 0.2141\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2315 - val_loss: 0.2128\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2427 - val_loss: 0.2003\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2303 - val_loss: 0.2036\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2318 - val_loss: 0.2011\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2397 - val_loss: 0.2020\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2271 - val_loss: 0.2004\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2238 - val_loss: 0.2113\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2284 - val_loss: 0.2022\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2311 - val_loss: 0.1994\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2223 - val_loss: 0.2003\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2350 - val_loss: 0.2015\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2261 - val_loss: 0.2023\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2279 - val_loss: 0.2060\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2177 - val_loss: 0.1993\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2269 - val_loss: 0.1968\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2146 - val_loss: 0.2090\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2169 - val_loss: 0.2072\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2201 - val_loss: 0.2017\n",
      "Epoch 00092: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 9.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 1.3063 - val_loss: 0.2197\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6620 - val_loss: 0.2187\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4970 - val_loss: 0.2247\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4271 - val_loss: 0.2238\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3902 - val_loss: 0.2179\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3740 - val_loss: 0.2523\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3380 - val_loss: 0.2422\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3299 - val_loss: 0.2160\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3229 - val_loss: 0.2205\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3181 - val_loss: 0.2252\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3212 - val_loss: 0.2120\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3048 - val_loss: 0.2145\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2888 - val_loss: 0.2309\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2883 - val_loss: 0.2183\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2821 - val_loss: 0.2031\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2779 - val_loss: 0.1847\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2808 - val_loss: 0.1852\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2666 - val_loss: 0.1896\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2669 - val_loss: 0.1801\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2691 - val_loss: 0.1812\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2668 - val_loss: 0.1798\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2557 - val_loss: 0.1809\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2406 - val_loss: 0.1788\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2508 - val_loss: 0.1762\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2485 - val_loss: 0.1908\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2473 - val_loss: 0.1824\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2357 - val_loss: 0.1787\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2286 - val_loss: 0.1893\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2343 - val_loss: 0.1715\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2208 - val_loss: 0.1881\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2266 - val_loss: 0.1901\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2377 - val_loss: 0.1921\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2260 - val_loss: 0.1824\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2229 - val_loss: 0.2063\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2096 - val_loss: 0.1808\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2115 - val_loss: 0.1935\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2080 - val_loss: 0.1808\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2043 - val_loss: 0.2020\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2112 - val_loss: 0.1798\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2037 - val_loss: 0.1891\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1984 - val_loss: 0.1748\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2026 - val_loss: 0.1937\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1830 - val_loss: 0.1786\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1983 - val_loss: 0.1748\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2067 - val_loss: 0.1832\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2012 - val_loss: 0.1861\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1785 - val_loss: 0.1919\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1822 - val_loss: 0.1740\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1705 - val_loss: 0.1749\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1809 - val_loss: 0.1900\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1732 - val_loss: 0.1714\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1872 - val_loss: 0.1708\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1651 - val_loss: 0.1731\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1633 - val_loss: 0.2139\n",
      "Epoch 00054: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 6.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 15s 11ms/step - loss: 1.0010 - val_loss: 0.3104\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6082 - val_loss: 0.2339\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4472 - val_loss: 0.2173\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3786 - val_loss: 0.2188\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3642 - val_loss: 0.2227\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3266 - val_loss: 0.2168\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3169 - val_loss: 0.2165\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3114 - val_loss: 0.2349\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3214 - val_loss: 0.2286\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3085 - val_loss: 0.2292\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3016 - val_loss: 0.2451\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2925 - val_loss: 0.2298\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2898 - val_loss: 0.2136\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2873 - val_loss: 0.2094\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2828 - val_loss: 0.2111\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2768 - val_loss: 0.2131\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2740 - val_loss: 0.2105\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2740 - val_loss: 0.2140\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2826 - val_loss: 0.2026\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2607 - val_loss: 0.1951\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2776 - val_loss: 0.1978\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2727 - val_loss: 0.1978\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2776 - val_loss: 0.1960\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2586 - val_loss: 0.1940\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2542 - val_loss: 0.1952\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2608 - val_loss: 0.1900\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2495 - val_loss: 0.1984\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2476 - val_loss: 0.1844\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2516 - val_loss: 0.1983\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2412 - val_loss: 0.1893\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2339 - val_loss: 0.1848\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2476 - val_loss: 0.1890\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2420 - val_loss: 0.1896\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2483 - val_loss: 0.1920\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2262 - val_loss: 0.1856\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2288 - val_loss: 0.2176\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2254 - val_loss: 0.1806\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2299 - val_loss: 0.2172\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2122 - val_loss: 0.1850\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2186 - val_loss: 0.1827\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2139 - val_loss: 0.1743\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2232 - val_loss: 0.1751\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2223 - val_loss: 0.1919\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2107 - val_loss: 0.1819\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1905 - val_loss: 0.1954\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2155 - val_loss: 0.1779\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2118 - val_loss: 0.1760\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2087 - val_loss: 0.1852\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2079 - val_loss: 0.1833\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2196 - val_loss: 0.1852\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1939 - val_loss: 0.1839\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2028 - val_loss: 0.1737\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2074 - val_loss: 0.1714\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1942 - val_loss: 0.1748\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1987 - val_loss: 0.1694\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1961 - val_loss: 0.1761\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1903 - val_loss: 0.1720\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2040 - val_loss: 0.1780\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1937 - val_loss: 0.1688\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1838 - val_loss: 0.1705\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1999 - val_loss: 0.1765\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1874 - val_loss: 0.1704\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1753 - val_loss: 0.1711\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1835 - val_loss: 0.1732\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1875 - val_loss: 0.1683\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1910 - val_loss: 0.1760\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1768 - val_loss: 0.1738\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1703 - val_loss: 0.1965\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1890 - val_loss: 0.1717\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1692 - val_loss: 0.1976\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1791 - val_loss: 0.1743\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1734 - val_loss: 0.1912\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1702 - val_loss: 0.1759\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1789 - val_loss: 0.1707\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1661 - val_loss: 0.1701\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1786 - val_loss: 0.1690\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1812 - val_loss: 0.1937\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1703 - val_loss: 0.1685\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1678 - val_loss: 0.1675\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1685 - val_loss: 0.1669\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1768 - val_loss: 0.1791\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1685 - val_loss: 0.1716\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1572 - val_loss: 0.1738\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1688 - val_loss: 0.1820\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1603 - val_loss: 0.1950\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1615 - val_loss: 0.1817\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1690 - val_loss: 0.1854\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1534 - val_loss: 0.1784\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1636 - val_loss: 0.1750\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1662 - val_loss: 0.1711\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1520 - val_loss: 0.1883\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1636 - val_loss: 0.1726\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1470 - val_loss: 0.1784\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1455 - val_loss: 0.1753\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1561 - val_loss: 0.1796\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1596 - val_loss: 0.1766\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1603 - val_loss: 0.1728\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1511 - val_loss: 0.1786\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1456 - val_loss: 0.1712\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1528 - val_loss: 0.1690\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1512 - val_loss: 0.1751\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1483 - val_loss: 0.1682\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1461 - val_loss: 0.1695\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1621 - val_loss: 0.2272\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1577 - val_loss: 0.1697\n",
      "Epoch 00105: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total=11.7min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 15s 11ms/step - loss: 1.6987 - val_loss: 0.3992\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7236 - val_loss: 0.2570\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5684 - val_loss: 0.2278\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4716 - val_loss: 0.2187\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3893 - val_loss: 0.2191\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3812 - val_loss: 0.2213\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3372 - val_loss: 0.2263\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3408 - val_loss: 0.2216\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3332 - val_loss: 0.2242\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3087 - val_loss: 0.2309\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3212 - val_loss: 0.2446\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3226 - val_loss: 0.2306\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3122 - val_loss: 0.2396\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3194 - val_loss: 0.2279\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3075 - val_loss: 0.2469\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3031 - val_loss: 0.2235\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3064 - val_loss: 0.2233\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3156 - val_loss: 0.2333\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3155 - val_loss: 0.2380\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3143 - val_loss: 0.2397\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2999 - val_loss: 0.2386\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3032 - val_loss: 0.2297\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2990 - val_loss: 0.2236\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3101 - val_loss: 0.2292\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2887 - val_loss: 0.2230\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3028 - val_loss: 0.2318\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3007 - val_loss: 0.2198\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2851 - val_loss: 0.2544\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2944 - val_loss: 0.2240\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 3.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 11ms/step - loss: 2.5434 - val_loss: 0.3095\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7066 - val_loss: 0.2257\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5894 - val_loss: 0.2180\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5536 - val_loss: 0.2566\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4725 - val_loss: 0.2202\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4033 - val_loss: 0.2198\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3828 - val_loss: 0.2145\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3546 - val_loss: 0.2136\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3386 - val_loss: 0.2273\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3193 - val_loss: 0.2158\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3088 - val_loss: 0.2096\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3101 - val_loss: 0.2164\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3196 - val_loss: 0.2090\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3096 - val_loss: 0.2111\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3014 - val_loss: 0.2081\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2974 - val_loss: 0.2055\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3023 - val_loss: 0.2100\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2921 - val_loss: 0.2156\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2915 - val_loss: 0.2216\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2975 - val_loss: 0.2003\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2701 - val_loss: 0.1876\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2832 - val_loss: 0.1939\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2907 - val_loss: 0.1934\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2791 - val_loss: 0.1912\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2684 - val_loss: 0.2132\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2665 - val_loss: 0.1993\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2683 - val_loss: 0.2202\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2787 - val_loss: 0.1814\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2515 - val_loss: 0.1920\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2471 - val_loss: 0.1859\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2563 - val_loss: 0.1913\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2536 - val_loss: 0.1792\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2460 - val_loss: 0.1848\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2508 - val_loss: 0.1790\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2523 - val_loss: 0.1912\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2631 - val_loss: 0.1837\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2571 - val_loss: 0.1782\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2347 - val_loss: 0.1774\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2436 - val_loss: 0.1872\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2382 - val_loss: 0.1721\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2451 - val_loss: 0.1831\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2262 - val_loss: 0.1740\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2228 - val_loss: 0.1829\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2234 - val_loss: 0.1777\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2266 - val_loss: 0.1848\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2211 - val_loss: 0.1990\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2175 - val_loss: 0.1845\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2155 - val_loss: 0.1708\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2147 - val_loss: 0.1815\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2113 - val_loss: 0.1740\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2188 - val_loss: 0.1786\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2223 - val_loss: 0.1835\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2080 - val_loss: 0.1727\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2200 - val_loss: 0.1718\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2127 - val_loss: 0.1821\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1979 - val_loss: 0.1705\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2020 - val_loss: 0.1681\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2026 - val_loss: 0.1754\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2010 - val_loss: 0.1910\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2044 - val_loss: 0.1850\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1915 - val_loss: 0.1735\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1855 - val_loss: 0.1741\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1989 - val_loss: 0.1844\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1832 - val_loss: 0.1728\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1948 - val_loss: 0.1695\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1835 - val_loss: 0.1732\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1871 - val_loss: 0.1681\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1824 - val_loss: 0.1749\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1971 - val_loss: 0.1735\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1874 - val_loss: 0.1692\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1851 - val_loss: 0.1744\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1703 - val_loss: 0.1763\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1759 - val_loss: 0.1740\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1824 - val_loss: 0.1977\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1818 - val_loss: 0.1802\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1809 - val_loss: 0.1749\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1709 - val_loss: 0.1854\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1641 - val_loss: 0.1681\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1848 - val_loss: 0.1703\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1835 - val_loss: 0.1777\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1694 - val_loss: 0.1826\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1813 - val_loss: 0.1950\n",
      "Epoch 00082: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 9.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 15s 11ms/step - loss: 1.2427 - val_loss: 0.2275\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6630 - val_loss: 0.2301\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4861 - val_loss: 0.2190\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3944 - val_loss: 0.2385\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3747 - val_loss: 0.2536\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3465 - val_loss: 0.2215\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3161 - val_loss: 0.2260\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3275 - val_loss: 0.2210\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3094 - val_loss: 0.2177\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3097 - val_loss: 0.2157\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2996 - val_loss: 0.2345\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3098 - val_loss: 0.2190\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2970 - val_loss: 0.2275\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3016 - val_loss: 0.2283\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2848 - val_loss: 0.2134\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2984 - val_loss: 0.2217\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2899 - val_loss: 0.2304\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2816 - val_loss: 0.2121\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2739 - val_loss: 0.2205\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2846 - val_loss: 0.2075\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2851 - val_loss: 0.2036\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2822 - val_loss: 0.2063\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2637 - val_loss: 0.2029\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2807 - val_loss: 0.1991\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2781 - val_loss: 0.2034\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2690 - val_loss: 0.2147\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2744 - val_loss: 0.1935\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2671 - val_loss: 0.2004\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2523 - val_loss: 0.1910\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2554 - val_loss: 0.2337\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2446 - val_loss: 0.1925\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2360 - val_loss: 0.1853\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2482 - val_loss: 0.2021\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2376 - val_loss: 0.1900\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2449 - val_loss: 0.2101\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2537 - val_loss: 0.1958\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2311 - val_loss: 0.1936\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2439 - val_loss: 0.1878\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2371 - val_loss: 0.1888\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2320 - val_loss: 0.1841\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2434 - val_loss: 0.1902\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2410 - val_loss: 0.1810\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2341 - val_loss: 0.1998\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2437 - val_loss: 0.1974\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2330 - val_loss: 0.1835\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2341 - val_loss: 0.1858\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2310 - val_loss: 0.1904\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2390 - val_loss: 0.1993\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2275 - val_loss: 0.1924\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2180 - val_loss: 0.1954\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2338 - val_loss: 0.1787\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2100 - val_loss: 0.1835\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2302 - val_loss: 0.1826\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2234 - val_loss: 0.1822\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.1926\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2091 - val_loss: 0.1755\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2182 - val_loss: 0.1839\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2276 - val_loss: 0.1786\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2370 - val_loss: 0.2483\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2204 - val_loss: 0.1817\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2045 - val_loss: 0.1745\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2001 - val_loss: 0.1799\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2133 - val_loss: 0.1849\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2001 - val_loss: 0.1812\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2088 - val_loss: 0.1802\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2073 - val_loss: 0.2000\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2031 - val_loss: 0.1902\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2078 - val_loss: 0.1854\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1972 - val_loss: 0.1736\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2014 - val_loss: 0.1790\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1884 - val_loss: 0.1860\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2052 - val_loss: 0.1831\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1998 - val_loss: 0.1786\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1891 - val_loss: 0.1826\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1907 - val_loss: 0.1803\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1883 - val_loss: 0.1806\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1855 - val_loss: 0.1733\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1776 - val_loss: 0.2288\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1913 - val_loss: 0.1794\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1997 - val_loss: 0.1793\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1990 - val_loss: 0.1789\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2042 - val_loss: 0.1803\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2106 - val_loss: 0.1786\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2146 - val_loss: 0.1817\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2065 - val_loss: 0.1816\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1973 - val_loss: 0.1935\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1959 - val_loss: 0.1865\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1949 - val_loss: 0.1848\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2032 - val_loss: 0.1859\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2016 - val_loss: 0.1818\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1885 - val_loss: 0.1784\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2084 - val_loss: 0.1786\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2044 - val_loss: 0.1776\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2022 - val_loss: 0.1796\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1900 - val_loss: 0.1773\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2010 - val_loss: 0.1814\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1869 - val_loss: 0.1898\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1926 - val_loss: 0.1753\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2042 - val_loss: 0.1798\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1918 - val_loss: 0.1845\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1812 - val_loss: 0.1863\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1862 - val_loss: 0.1777\n",
      "Epoch 00102: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total=11.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 14.6642 - val_loss: 7.9061\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.8092 - val_loss: 7.7153\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.6116 - val_loss: 7.5129\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.4076 - val_loss: 7.3075\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.2024 - val_loss: 7.1023\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.9981 - val_loss: 6.8987\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.7963 - val_loss: 6.6978\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.5974 - val_loss: 6.5006\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.4019 - val_loss: 6.3070\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.2101 - val_loss: 6.1170\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.0222 - val_loss: 5.9303\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.8380 - val_loss: 5.7474\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.6574 - val_loss: 5.5696\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.4811 - val_loss: 5.3947\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.3086 - val_loss: 5.2236\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.1398 - val_loss: 5.0569\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.9751 - val_loss: 4.8935\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.8140 - val_loss: 4.7343\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.6567 - val_loss: 4.5788\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.5034 - val_loss: 4.4272\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.3539 - val_loss: 4.2793\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.2080 - val_loss: 4.1352\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.0657 - val_loss: 3.9946\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.9271 - val_loss: 3.8571\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.7919 - val_loss: 3.7242\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.6604 - val_loss: 3.5939\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.5324 - val_loss: 3.4676\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.4078 - val_loss: 3.3445\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.2866 - val_loss: 3.2248\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.1689 - val_loss: 3.1082\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.0543 - val_loss: 2.9952\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.9431 - val_loss: 2.8848\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.8347 - val_loss: 2.7790\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.7299 - val_loss: 2.6744\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.6275 - val_loss: 2.5739\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.5286 - val_loss: 2.4761\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.4323 - val_loss: 2.3812\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.3391 - val_loss: 2.2891\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.2486 - val_loss: 2.2000\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.1610 - val_loss: 2.1137\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.0762 - val_loss: 2.0301\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.9943 - val_loss: 1.9489\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.9148 - val_loss: 1.8709\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.8379 - val_loss: 1.7950\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.7637 - val_loss: 1.7218\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.6918 - val_loss: 1.6511\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.6225 - val_loss: 1.5829\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.5555 - val_loss: 1.5170\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.4910 - val_loss: 1.4534\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.4288 - val_loss: 1.3924\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.3687 - val_loss: 1.3334\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.3109 - val_loss: 1.2763\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2553 - val_loss: 1.2216\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2017 - val_loss: 1.1691\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.1503 - val_loss: 1.1179\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.1007 - val_loss: 1.0699\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.0535 - val_loss: 1.0234\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.0079 - val_loss: 0.9784\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9641 - val_loss: 0.9353\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9222 - val_loss: 0.8942\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8822 - val_loss: 0.8548\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8438 - val_loss: 0.8173\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8070 - val_loss: 0.7810\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7719 - val_loss: 0.7471\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7385 - val_loss: 0.7141\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7067 - val_loss: 0.6826\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6763 - val_loss: 0.6528\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6473 - val_loss: 0.6247\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6199 - val_loss: 0.5977\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5937 - val_loss: 0.5721\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5691 - val_loss: 0.5481\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5456 - val_loss: 0.5250\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5234 - val_loss: 0.5036\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5026 - val_loss: 0.4831\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4828 - val_loss: 0.4637\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4640 - val_loss: 0.4456\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4464 - val_loss: 0.4283\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4299 - val_loss: 0.4121\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4143 - val_loss: 0.3971\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3998 - val_loss: 0.3827\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3860 - val_loss: 0.3693\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3732 - val_loss: 0.3569\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3612 - val_loss: 0.3453\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3500 - val_loss: 0.3343\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3396 - val_loss: 0.3241\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3300 - val_loss: 0.3147\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3210 - val_loss: 0.3061\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3127 - val_loss: 0.2981\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3051 - val_loss: 0.2906\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2980 - val_loss: 0.2836\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2914 - val_loss: 0.2774\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2855 - val_loss: 0.2715\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2800 - val_loss: 0.2662\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2749 - val_loss: 0.2614\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2704 - val_loss: 0.2568\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2662 - val_loss: 0.2527\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2624 - val_loss: 0.2492\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2589 - val_loss: 0.2457\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2557 - val_loss: 0.2425\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2528 - val_loss: 0.2398\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2503 - val_loss: 0.2374\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2480 - val_loss: 0.2351\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2460 - val_loss: 0.2331\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2441 - val_loss: 0.2314\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2425 - val_loss: 0.2298\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2410 - val_loss: 0.2283\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2397 - val_loss: 0.2270\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2385 - val_loss: 0.2259\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2375 - val_loss: 0.2249\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2366 - val_loss: 0.2240\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2358 - val_loss: 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2351 - val_loss: 0.2226\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2345 - val_loss: 0.2220\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2341 - val_loss: 0.2215\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2336 - val_loss: 0.2211\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2332 - val_loss: 0.2207\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2329 - val_loss: 0.2203\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2326 - val_loss: 0.2201\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2324 - val_loss: 0.2198\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2322 - val_loss: 0.2196\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2320 - val_loss: 0.2195\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2319 - val_loss: 0.2193\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2318 - val_loss: 0.2192\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2317 - val_loss: 0.2191\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2316 - val_loss: 0.2190\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2315 - val_loss: 0.2190\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2315 - val_loss: 0.2189\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2188\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2188\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2188\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2188\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 139/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 140/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 141/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 142/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 143/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 144/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 145/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 146/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 147/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2186\n",
      "Epoch 00147: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s 7ms/step - loss: 13.2610 - val_loss: 7.8547\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.8399 - val_loss: 1.2845\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9813 - val_loss: 1.9576\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9363 - val_loss: 1.7213\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7216 - val_loss: 1.9338\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6501 - val_loss: 2.0164\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7282 - val_loss: 2.0273\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5485 - val_loss: 2.0013\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2977 - val_loss: 1.7162\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3722 - val_loss: 0.9566\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2665 - val_loss: 0.6954\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3686 - val_loss: 0.7143\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3131 - val_loss: 0.9950\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2257 - val_loss: 0.5631\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0847 - val_loss: 0.5399\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2119 - val_loss: 0.7632\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0285 - val_loss: 0.8003\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9814 - val_loss: 0.3989\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0041 - val_loss: 0.5379\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8642 - val_loss: 0.4498\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9129 - val_loss: 0.7364\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9266 - val_loss: 0.7965\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7690 - val_loss: 0.4607\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7460 - val_loss: 0.7082\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6770 - val_loss: 0.9546\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7099 - val_loss: 0.5742\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6046 - val_loss: 0.8312\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5199 - val_loss: 0.5822\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5393 - val_loss: 0.5887\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3918 - val_loss: 0.5652\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4308 - val_loss: 0.7053\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4553 - val_loss: 0.5952\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2998 - val_loss: 0.5720\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3491 - val_loss: 0.6907\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2988 - val_loss: 0.4411\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2393 - val_loss: 0.5880\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1368 - val_loss: 0.6524\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1721 - val_loss: 0.4148\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1731 - val_loss: 0.5218\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1090 - val_loss: 0.4560\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1095 - val_loss: 0.5757\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0243 - val_loss: 0.3869\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9553 - val_loss: 0.5021\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9511 - val_loss: 0.3662\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9660 - val_loss: 0.4238\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9797 - val_loss: 0.3942\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8901 - val_loss: 0.4124\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8979 - val_loss: 0.5212\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8074 - val_loss: 0.3676\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8201 - val_loss: 0.4072\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8108 - val_loss: 0.4043\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7716 - val_loss: 0.3494\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7365 - val_loss: 0.3620\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7247 - val_loss: 0.3461\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7113 - val_loss: 0.3141\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6633 - val_loss: 0.3721\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5763 - val_loss: 0.4815\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6088 - val_loss: 0.3122\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5922 - val_loss: 0.3679\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5990 - val_loss: 0.3041\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5564 - val_loss: 0.3804\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5582 - val_loss: 0.3097\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5063 - val_loss: 0.2758\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4866 - val_loss: 0.3796\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4265 - val_loss: 0.3182\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4657 - val_loss: 0.3478\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4218 - val_loss: 0.2906\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4181 - val_loss: 0.2423\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4094 - val_loss: 0.2779\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3888 - val_loss: 0.2369\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3838 - val_loss: 0.2493\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3899 - val_loss: 0.2630\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3241 - val_loss: 0.2618\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3329 - val_loss: 0.2489\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3263 - val_loss: 0.2268\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3105 - val_loss: 0.2470\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2895 - val_loss: 0.2331\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3164 - val_loss: 0.2509\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2603 - val_loss: 0.2631\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2683 - val_loss: 0.2287\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2759 - val_loss: 0.2236\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2517 - val_loss: 0.2340\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2438 - val_loss: 0.2182\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2323 - val_loss: 0.2350\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2152 - val_loss: 0.2147\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2114 - val_loss: 0.2400\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1984 - val_loss: 0.2037\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2135 - val_loss: 0.2367\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2114 - val_loss: 0.2479\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1943 - val_loss: 0.1993\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1764 - val_loss: 0.2117\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1649 - val_loss: 0.1945\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1709 - val_loss: 0.2009\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1693 - val_loss: 0.2068\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1558 - val_loss: 0.2002\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1696 - val_loss: 0.2126\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1565 - val_loss: 0.2036\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1545 - val_loss: 0.2069\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1476 - val_loss: 0.1843\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1405 - val_loss: 0.1877\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1481 - val_loss: 0.1802\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1458 - val_loss: 0.1818\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1373 - val_loss: 0.1903\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1544 - val_loss: 0.1879\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1323 - val_loss: 0.1791\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1326 - val_loss: 0.2043\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1311 - val_loss: 0.1770\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1257 - val_loss: 0.1864\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1253 - val_loss: 0.1983\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1277 - val_loss: 0.1791\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1244 - val_loss: 0.1757\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1338 - val_loss: 0.1792\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1206 - val_loss: 0.1773\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1241 - val_loss: 0.1812\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.1819\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1290 - val_loss: 0.1793\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1289 - val_loss: 0.1817\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1240 - val_loss: 0.1748\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1207 - val_loss: 0.1822\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1318 - val_loss: 0.1754\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1208 - val_loss: 0.1842\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1185 - val_loss: 0.1718\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1219 - val_loss: 0.1778\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1146 - val_loss: 0.1828\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1220 - val_loss: 0.1759\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1203 - val_loss: 0.1710\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1190 - val_loss: 0.1787\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1191 - val_loss: 0.1818\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1224 - val_loss: 0.1786\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1211 - val_loss: 0.1749\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1221 - val_loss: 0.1796\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1185 - val_loss: 0.1738\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1284 - val_loss: 0.1771\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1193 - val_loss: 0.1744\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1253 - val_loss: 0.1829\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1240 - val_loss: 0.1767\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.1776\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1209 - val_loss: 0.1794\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1146 - val_loss: 0.1725\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1262 - val_loss: 0.1796\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1259 - val_loss: 0.1793\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1233 - val_loss: 0.1721\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1179 - val_loss: 0.1927\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1231 - val_loss: 0.1733\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1352 - val_loss: 0.1740\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1293 - val_loss: 0.1763\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1147 - val_loss: 0.1729\n",
      "Epoch 00147: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 8.9634 - val_loss: 2.5161\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.1013 - val_loss: 2.1388\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9525 - val_loss: 2.0485\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2185 - val_loss: 0.8011\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.5795 - val_loss: 0.6902\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4876 - val_loss: 0.9183\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4036 - val_loss: 0.6311\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4127 - val_loss: 1.0545\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3037 - val_loss: 1.0700\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4042 - val_loss: 0.9349\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2822 - val_loss: 0.9814\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1758 - val_loss: 0.8360\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2271 - val_loss: 0.8060\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0162 - val_loss: 1.0149\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1402 - val_loss: 0.6049\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1037 - val_loss: 0.8924\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8666 - val_loss: 1.1728\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9161 - val_loss: 0.8709\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7977 - val_loss: 0.6326\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8876 - val_loss: 0.7455\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7369 - val_loss: 0.6524\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6764 - val_loss: 0.8479\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6750 - val_loss: 0.8355\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6643 - val_loss: 0.7605\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6651 - val_loss: 0.7469\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3908 - val_loss: 0.6475\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4518 - val_loss: 0.6775\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5144 - val_loss: 0.6119\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3682 - val_loss: 0.5011\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3368 - val_loss: 0.6098\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3009 - val_loss: 0.5785\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2854 - val_loss: 0.5410\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2176 - val_loss: 0.6249\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2954 - val_loss: 0.5111\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2021 - val_loss: 0.4264\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1037 - val_loss: 0.5866\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0897 - val_loss: 0.5301\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0722 - val_loss: 0.5175\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9857 - val_loss: 0.4298\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0580 - val_loss: 0.4881\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9906 - val_loss: 0.4926\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8796 - val_loss: 0.4422\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9141 - val_loss: 0.4414\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8530 - val_loss: 0.3966\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8076 - val_loss: 0.3409\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8029 - val_loss: 0.4708\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7588 - val_loss: 0.3932\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7532 - val_loss: 0.4040\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6828 - val_loss: 0.3714\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6994 - val_loss: 0.4770\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7086 - val_loss: 0.3746\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6553 - val_loss: 0.3148\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6439 - val_loss: 0.3782\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5890 - val_loss: 0.4292\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5652 - val_loss: 0.2631\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5979 - val_loss: 0.3357\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5457 - val_loss: 0.4326\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5143 - val_loss: 0.3114\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4590 - val_loss: 0.3649\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4618 - val_loss: 0.2714\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4438 - val_loss: 0.3126\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4364 - val_loss: 0.2600\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4023 - val_loss: 0.3705\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3861 - val_loss: 0.3187\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3663 - val_loss: 0.2827\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3983 - val_loss: 0.3301\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3551 - val_loss: 0.2955\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3658 - val_loss: 0.2538\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3169 - val_loss: 0.2258\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3207 - val_loss: 0.2529\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2921 - val_loss: 0.2612\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2887 - val_loss: 0.2709\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2687 - val_loss: 0.2582\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2651 - val_loss: 0.2145\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2622 - val_loss: 0.2476\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2559 - val_loss: 0.2372\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2538 - val_loss: 0.2162\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2181 - val_loss: 0.2283\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2605 - val_loss: 0.2550\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2172 - val_loss: 0.2090\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2059 - val_loss: 0.1953\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1954 - val_loss: 0.2286\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1990 - val_loss: 0.1994\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1840 - val_loss: 0.1876\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1794 - val_loss: 0.2185\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1763 - val_loss: 0.1959\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1707 - val_loss: 0.2136\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1674 - val_loss: 0.2052\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1619 - val_loss: 0.1926\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1599 - val_loss: 0.1964\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1451 - val_loss: 0.2042\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1547 - val_loss: 0.1818\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1578 - val_loss: 0.2147\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1461 - val_loss: 0.2013\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1416 - val_loss: 0.1874\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1339 - val_loss: 0.1896\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1291 - val_loss: 0.1919\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1420 - val_loss: 0.1988\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1375 - val_loss: 0.1832\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1380 - val_loss: 0.1833\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1278 - val_loss: 0.1890\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1425 - val_loss: 0.1844\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1245 - val_loss: 0.1848\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1308 - val_loss: 0.1875\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1246 - val_loss: 0.1859\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1307 - val_loss: 0.1828\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1218 - val_loss: 0.1826\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1272 - val_loss: 0.1768\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1191 - val_loss: 0.1768\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1202 - val_loss: 0.1791\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1252 - val_loss: 0.1790\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1204 - val_loss: 0.1784\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1285 - val_loss: 0.1805\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1302 - val_loss: 0.1750\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1268 - val_loss: 0.1848\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.1764\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1301 - val_loss: 0.1795\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1163 - val_loss: 0.1805\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1296 - val_loss: 0.1779\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1219 - val_loss: 0.1860\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1304 - val_loss: 0.1874\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1216 - val_loss: 0.1821\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1220 - val_loss: 0.1842\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1276 - val_loss: 0.1798\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1230 - val_loss: 0.1805\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1248 - val_loss: 0.1794\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1274 - val_loss: 0.1831\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1358 - val_loss: 0.1838\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1222 - val_loss: 0.1795\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1248 - val_loss: 0.1786\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1348 - val_loss: 0.1825\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1249 - val_loss: 0.1760\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1284 - val_loss: 0.1795\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1264 - val_loss: 0.1784\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1319 - val_loss: 0.1801\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1260 - val_loss: 0.1811\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1229 - val_loss: 0.1783\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1202 - val_loss: 0.1811\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1244 - val_loss: 0.1841\n",
      "Epoch 00139: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 13.8887 - val_loss: 7.8906\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.7460 - val_loss: 7.6962\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.5425 - val_loss: 7.4923\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.3408 - val_loss: 7.2819\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.1209 - val_loss: 7.0740\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.2360 - val_loss: 1.3049\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6228 - val_loss: 1.8377\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3056 - val_loss: 1.7546\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3732 - val_loss: 1.7366\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4230 - val_loss: 1.8078\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1966 - val_loss: 1.6166\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2263 - val_loss: 1.7126\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1094 - val_loss: 1.6374\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1323 - val_loss: 1.6296\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.0383 - val_loss: 1.5646\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.7886 - val_loss: 1.6743\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6979 - val_loss: 1.5191\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8049 - val_loss: 1.5521\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6245 - val_loss: 1.5236\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6842 - val_loss: 1.4378\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5194 - val_loss: 1.3812\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4985 - val_loss: 1.3727\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3879 - val_loss: 1.3724\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4101 - val_loss: 1.3011\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3040 - val_loss: 1.2414\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2253 - val_loss: 1.2601\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1968 - val_loss: 1.2580\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1561 - val_loss: 1.1995\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9211 - val_loss: 1.1554\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9805 - val_loss: 1.0987\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9966 - val_loss: 1.0989\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9493 - val_loss: 1.0828\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8441 - val_loss: 1.0643\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8645 - val_loss: 1.0140\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6324 - val_loss: 0.9933\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6326 - val_loss: 0.9977\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6192 - val_loss: 0.9685\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5528 - val_loss: 0.9104\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4854 - val_loss: 0.8995\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4147 - val_loss: 0.8673\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4237 - val_loss: 0.8597\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3856 - val_loss: 0.8267\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3602 - val_loss: 0.8178\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3017 - val_loss: 0.7860\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2329 - val_loss: 0.7639\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2174 - val_loss: 0.7424\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1444 - val_loss: 0.7207\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1153 - val_loss: 0.7033\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1152 - val_loss: 0.6783\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0210 - val_loss: 0.6572\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0262 - val_loss: 0.6409\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9466 - val_loss: 0.6202\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9249 - val_loss: 0.6082\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8830 - val_loss: 0.5881\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8317 - val_loss: 0.5727\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8780 - val_loss: 0.5548\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8036 - val_loss: 0.5387\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7775 - val_loss: 0.5257\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7592 - val_loss: 0.5101\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7051 - val_loss: 0.4946\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6673 - val_loss: 0.4811\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6811 - val_loss: 0.4675\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5907 - val_loss: 0.4542\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6161 - val_loss: 0.4417\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6046 - val_loss: 0.4292\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5430 - val_loss: 0.4167\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5431 - val_loss: 0.4065\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5093 - val_loss: 0.3966\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4956 - val_loss: 0.3859\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5003 - val_loss: 0.3753\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4682 - val_loss: 0.3645\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4182 - val_loss: 0.3558\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4267 - val_loss: 0.3455\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3758 - val_loss: 0.3382\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3923 - val_loss: 0.3281\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3549 - val_loss: 0.3242\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3817 - val_loss: 0.3077\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3634 - val_loss: 0.3064\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3332 - val_loss: 0.2941\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3390 - val_loss: 0.2941\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3071 - val_loss: 0.2924\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3013 - val_loss: 0.2798\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3011 - val_loss: 0.2775\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2836 - val_loss: 0.2650\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2720 - val_loss: 0.2732\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2672 - val_loss: 0.2632\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2475 - val_loss: 0.2409\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2372 - val_loss: 0.2501\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2430 - val_loss: 0.2223\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2207 - val_loss: 0.2543\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2110 - val_loss: 0.2293\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2141 - val_loss: 0.2473\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2069 - val_loss: 0.2477\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1970 - val_loss: 0.2188\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2012 - val_loss: 0.2073\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1927 - val_loss: 0.2185\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1980 - val_loss: 0.2203\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1740 - val_loss: 0.2225\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1784 - val_loss: 0.2116\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1781 - val_loss: 0.2072\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1727 - val_loss: 0.2090\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1771 - val_loss: 0.1988\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1687 - val_loss: 0.2025\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1793 - val_loss: 0.1965\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1735 - val_loss: 0.1994\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1813 - val_loss: 0.1933\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1748 - val_loss: 0.1976\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1624 - val_loss: 0.1945\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1505 - val_loss: 0.1951\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1561 - val_loss: 0.1917\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1502 - val_loss: 0.1914\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1641 - val_loss: 0.1908\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1526 - val_loss: 0.1903\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1542 - val_loss: 0.1911\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1610 - val_loss: 0.1885\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1498 - val_loss: 0.1899\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1597 - val_loss: 0.1933\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1453 - val_loss: 0.1841\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1563 - val_loss: 0.1913\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1608 - val_loss: 0.1886\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1594 - val_loss: 0.1936\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1571 - val_loss: 0.1892\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1459 - val_loss: 0.1856\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1612 - val_loss: 0.1835\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1581 - val_loss: 0.1923\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1522 - val_loss: 0.1815\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1598 - val_loss: 0.1813\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1567 - val_loss: 0.1982\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1609 - val_loss: 0.1934\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1646 - val_loss: 0.1852\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1485 - val_loss: 0.1954\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1473 - val_loss: 0.1826\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1592 - val_loss: 0.1899\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1551 - val_loss: 0.1850\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1502 - val_loss: 0.1878\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1505 - val_loss: 0.1971\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1615 - val_loss: 0.1861\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1544 - val_loss: 0.1872\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1551 - val_loss: 0.1871\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1459 - val_loss: 0.1847\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1485 - val_loss: 0.1850\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1582 - val_loss: 0.1855\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1639 - val_loss: 0.1866\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1588 - val_loss: 0.1853\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1504 - val_loss: 0.1853\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1614 - val_loss: 0.1862\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1499 - val_loss: 0.1857\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1514 - val_loss: 0.1854\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1388 - val_loss: 0.1860\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1547 - val_loss: 0.1855\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1553 - val_loss: 0.1856\n",
      "Epoch 00151: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.8min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 7ms/step - loss: 17.8874 - val_loss: 1.6358\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.0604 - val_loss: 2.1275\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9118 - val_loss: 2.0926\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.0712 - val_loss: 2.1355\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9936 - val_loss: 2.1681\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.8801 - val_loss: 1.9029\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6157 - val_loss: 1.9052\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5094 - val_loss: 1.8581\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5305 - val_loss: 1.9549\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3601 - val_loss: 1.8883\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3538 - val_loss: 1.6996\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1872 - val_loss: 1.7583\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.0837 - val_loss: 1.8028\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1280 - val_loss: 1.6191\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9461 - val_loss: 1.4589\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8736 - val_loss: 1.4810\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6272 - val_loss: 1.6338\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.7685 - val_loss: 1.5530\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6901 - val_loss: 1.4802\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5311 - val_loss: 1.4274\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4877 - val_loss: 1.3562\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3823 - val_loss: 1.3777\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3188 - val_loss: 1.3077\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2819 - val_loss: 1.2813\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3129 - val_loss: 1.2430\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2070 - val_loss: 1.2199\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1017 - val_loss: 1.1647\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9356 - val_loss: 1.1184\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8926 - val_loss: 1.1533\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8568 - val_loss: 1.0960\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8147 - val_loss: 1.0398\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7605 - val_loss: 1.0056\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6406 - val_loss: 0.9838\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7282 - val_loss: 0.9600\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6016 - val_loss: 0.9434\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6002 - val_loss: 0.9184\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4553 - val_loss: 0.8789\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4680 - val_loss: 0.8601\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3315 - val_loss: 0.8231\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3852 - val_loss: 0.8037\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3154 - val_loss: 0.7894\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2015 - val_loss: 0.7550\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1742 - val_loss: 0.7379\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1763 - val_loss: 0.7111\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1901 - val_loss: 0.7079\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0847 - val_loss: 0.6265\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0280 - val_loss: 0.6589\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0415 - val_loss: 0.6259\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8913 - val_loss: 0.6114\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9263 - val_loss: 0.5902\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8932 - val_loss: 0.5596\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8223 - val_loss: 0.5561\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7848 - val_loss: 0.5337\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7513 - val_loss: 0.5219\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7438 - val_loss: 0.5226\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7223 - val_loss: 0.4755\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6872 - val_loss: 0.5103\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6788 - val_loss: 0.4469\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6802 - val_loss: 0.4496\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5958 - val_loss: 0.4709\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5902 - val_loss: 0.4225\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5556 - val_loss: 0.4091\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5215 - val_loss: 0.4053\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5540 - val_loss: 0.3738\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5028 - val_loss: 0.3765\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5028 - val_loss: 0.3906\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4339 - val_loss: 0.3409\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4654 - val_loss: 0.3182\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4374 - val_loss: 0.3482\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3958 - val_loss: 0.3329\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4246 - val_loss: 0.2921\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3910 - val_loss: 0.2894\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3666 - val_loss: 0.3215\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3642 - val_loss: 0.3170\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3331 - val_loss: 0.2804\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3266 - val_loss: 0.2840\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2975 - val_loss: 0.2756\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2837 - val_loss: 0.2721\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2972 - val_loss: 0.2562\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2516 - val_loss: 0.2505\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2754 - val_loss: 0.2531\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2492 - val_loss: 0.2447\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2471 - val_loss: 0.2443\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2436 - val_loss: 0.2424\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2287 - val_loss: 0.2277\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2331 - val_loss: 0.2349\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2269 - val_loss: 0.2292\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2099 - val_loss: 0.2131\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2022 - val_loss: 0.2168\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1851 - val_loss: 0.2122\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1981 - val_loss: 0.2104\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1934 - val_loss: 0.2138\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1880 - val_loss: 0.2117\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1745 - val_loss: 0.2034\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1711 - val_loss: 0.2043\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1633 - val_loss: 0.2037\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1654 - val_loss: 0.1999\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1627 - val_loss: 0.1958\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1568 - val_loss: 0.1954\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1716 - val_loss: 0.1972\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1768 - val_loss: 0.1936\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1588 - val_loss: 0.1908\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1599 - val_loss: 0.1910\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1552 - val_loss: 0.1887\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1588 - val_loss: 0.1941\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1482 - val_loss: 0.1889\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1621 - val_loss: 0.1894\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1589 - val_loss: 0.1842\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1577 - val_loss: 0.1884\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1527 - val_loss: 0.1858\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1560 - val_loss: 0.1823\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1540 - val_loss: 0.1903\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1550 - val_loss: 0.1902\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1460 - val_loss: 0.1849\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1539 - val_loss: 0.1822\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1478 - val_loss: 0.1848\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1547 - val_loss: 0.1848\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1415 - val_loss: 0.1873\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1638 - val_loss: 0.1847\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1495 - val_loss: 0.1871\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1662 - val_loss: 0.1854\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1615 - val_loss: 0.1840\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1497 - val_loss: 0.1818\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1511 - val_loss: 0.1882\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1567 - val_loss: 0.1876\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1380 - val_loss: 0.1881\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1437 - val_loss: 0.1829\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1547 - val_loss: 0.1842\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1449 - val_loss: 0.1829\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1533 - val_loss: 0.1835\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1507 - val_loss: 0.1860\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1429 - val_loss: 0.1820\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1451 - val_loss: 0.1840\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1485 - val_loss: 0.1842\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1423 - val_loss: 0.1824\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1479 - val_loss: 0.1814\n",
      "Epoch 00136: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 10s 8ms/step - loss: 6.3428 - val_loss: 0.7544\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.7849 - val_loss: 2.3981\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.1435 - val_loss: 2.0677\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.9721 - val_loss: 1.6073\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.6941 - val_loss: 1.6683\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.5886 - val_loss: 2.5044\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.2249 - val_loss: 2.0804\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.0471 - val_loss: 1.6738\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.9144 - val_loss: 1.2892\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.8241 - val_loss: 1.1334\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7388 - val_loss: 0.6550\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.6017 - val_loss: 0.3327\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4558 - val_loss: 0.1973\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4822 - val_loss: 0.2338\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4126 - val_loss: 0.2242\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4402 - val_loss: 0.2270\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4644 - val_loss: 0.2281\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4219 - val_loss: 0.2235\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4128 - val_loss: 0.2239\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4024 - val_loss: 0.2229\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4085 - val_loss: 0.2270\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3869 - val_loss: 0.2220\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3820 - val_loss: 0.2250\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4070 - val_loss: 0.2257\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4006 - val_loss: 0.2268\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3889 - val_loss: 0.2253\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3830 - val_loss: 0.2239\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3784 - val_loss: 0.2242\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3976 - val_loss: 0.2265\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3894 - val_loss: 0.2250\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3909 - val_loss: 0.2249\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3734 - val_loss: 0.2236\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3827 - val_loss: 0.2216\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3838 - val_loss: 0.2218\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3575 - val_loss: 0.2218\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3800 - val_loss: 0.2229\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3680 - val_loss: 0.2219\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3629 - val_loss: 0.2220\n",
      "Epoch 00038: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 1.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s 8ms/step - loss: 4.3802 - val_loss: 2.5925\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.6278 - val_loss: 1.0645\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.2527 - val_loss: 1.3153\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0492 - val_loss: 2.0420\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.5813 - val_loss: 2.1176\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.3581 - val_loss: 1.1934\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1976 - val_loss: 1.4294\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1571 - val_loss: 1.8971\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0783 - val_loss: 1.5518\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0597 - val_loss: 1.4977\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8653 - val_loss: 1.1957\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7518 - val_loss: 1.3421\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7470 - val_loss: 1.0270\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5740 - val_loss: 0.7107\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4785 - val_loss: 0.4623\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4206 - val_loss: 0.3191\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4261 - val_loss: 0.2340\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4260 - val_loss: 0.2254\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4238 - val_loss: 0.2271\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3839 - val_loss: 0.2264\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4065 - val_loss: 0.2259\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3886 - val_loss: 0.2233\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3991 - val_loss: 0.2227\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3990 - val_loss: 0.2275\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3764 - val_loss: 0.2225\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3646 - val_loss: 0.2284\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3727 - val_loss: 0.2233\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3601 - val_loss: 0.2214\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3817 - val_loss: 0.2246\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3755 - val_loss: 0.2273\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3727 - val_loss: 0.2210\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3793 - val_loss: 0.2239\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3547 - val_loss: 0.2229\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3760 - val_loss: 0.2246\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3526 - val_loss: 0.2195\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3729 - val_loss: 0.2248\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3730 - val_loss: 0.2248\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3695 - val_loss: 0.2232\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3362 - val_loss: 0.2211\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3434 - val_loss: 0.2211\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3454 - val_loss: 0.2237\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3670 - val_loss: 0.2242\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3621 - val_loss: 0.2218\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3460 - val_loss: 0.2224\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3478 - val_loss: 0.2266\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3448 - val_loss: 0.2234\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3524 - val_loss: 0.2208\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3370 - val_loss: 0.2234\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3467 - val_loss: 0.2256\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3379 - val_loss: 0.2219\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3491 - val_loss: 0.2216\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3515 - val_loss: 0.2229\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3437 - val_loss: 0.2225\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3458 - val_loss: 0.2201\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3418 - val_loss: 0.2250\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3359 - val_loss: 0.2211\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3320 - val_loss: 0.2223\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3445 - val_loss: 0.2240\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3161 - val_loss: 0.2236\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3474 - val_loss: 0.2219\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 2.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 4.7085 - val_loss: 1.3640\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.1154 - val_loss: 0.9444\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.6587 - val_loss: 1.9262\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.8151 - val_loss: 1.4251\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.5323 - val_loss: 2.3235\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2938 - val_loss: 2.4524\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1645 - val_loss: 1.7710\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1378 - val_loss: 1.4470\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9657 - val_loss: 1.5464\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9168 - val_loss: 1.4353\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8349 - val_loss: 0.9455\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6329 - val_loss: 0.9622\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5131 - val_loss: 0.5251\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4352 - val_loss: 0.3374\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4203 - val_loss: 0.2303\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4130 - val_loss: 0.2255\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4038 - val_loss: 0.2205\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4092 - val_loss: 0.2221\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3996 - val_loss: 0.2224\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3948 - val_loss: 0.2241\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3743 - val_loss: 0.2213\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3941 - val_loss: 0.2222\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4003 - val_loss: 0.2217\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3841 - val_loss: 0.2231\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3879 - val_loss: 0.2216\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3865 - val_loss: 0.2212\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3558 - val_loss: 0.2221\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3949 - val_loss: 0.2225\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3877 - val_loss: 0.2209\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3549 - val_loss: 0.2213\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3640 - val_loss: 0.2203\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3721 - val_loss: 0.2235\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3662 - val_loss: 0.2230\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3628 - val_loss: 0.2202\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3692 - val_loss: 0.2220\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3638 - val_loss: 0.2222\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3736 - val_loss: 0.2235\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3449 - val_loss: 0.2230\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3566 - val_loss: 0.2197\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3526 - val_loss: 0.2213\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3625 - val_loss: 0.2218\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3442 - val_loss: 0.2193\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3614 - val_loss: 0.2230\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3559 - val_loss: 0.2212\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3588 - val_loss: 0.2251\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3458 - val_loss: 0.2193\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3353 - val_loss: 0.2205\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3534 - val_loss: 0.2205\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3339 - val_loss: 0.2273\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3433 - val_loss: 0.2194\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3302 - val_loss: 0.2213\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3576 - val_loss: 0.2199\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3426 - val_loss: 0.2229\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3321 - val_loss: 0.2194\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3414 - val_loss: 0.2266\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3487 - val_loss: 0.2185\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3451 - val_loss: 0.2212\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3294 - val_loss: 0.2193\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3411 - val_loss: 0.2216\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3359 - val_loss: 0.2203\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3336 - val_loss: 0.2206\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3250 - val_loss: 0.2195\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3178 - val_loss: 0.2206\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3217 - val_loss: 0.2207\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3239 - val_loss: 0.2224\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3110 - val_loss: 0.2187\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3273 - val_loss: 0.2200\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 3.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 5.0454 - val_loss: 0.6979\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.8174 - val_loss: 0.6791\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.3642 - val_loss: 1.3790\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.1602 - val_loss: 1.3852\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.8516 - val_loss: 1.6384\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.3629 - val_loss: 1.1719\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0208 - val_loss: 0.6360\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8444 - val_loss: 0.7306\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5863 - val_loss: 0.3095\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4342 - val_loss: 0.2213\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3952 - val_loss: 0.2395\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4098 - val_loss: 0.2356\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4062 - val_loss: 0.2187\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3984 - val_loss: 0.2266\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3993 - val_loss: 0.2066\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3763 - val_loss: 0.2220\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3676 - val_loss: 0.2148\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3837 - val_loss: 0.2164\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3431 - val_loss: 0.2144\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3882 - val_loss: 0.2271\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3963 - val_loss: 0.2298\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3881 - val_loss: 0.2288\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3743 - val_loss: 0.2241\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3943 - val_loss: 0.2284\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3845 - val_loss: 0.2092\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3641 - val_loss: 0.1949\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3498 - val_loss: 0.2380\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3734 - val_loss: 0.2238\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3676 - val_loss: 0.1959\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3585 - val_loss: 0.2258\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3613 - val_loss: 0.2317\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3440 - val_loss: 0.2181\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3714 - val_loss: 0.2227\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3613 - val_loss: 0.2243\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3479 - val_loss: 0.2283\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3664 - val_loss: 0.2243\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3584 - val_loss: 0.2228\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3548 - val_loss: 0.2216\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3645 - val_loss: 0.2231\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3646 - val_loss: 0.2223\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3544 - val_loss: 0.2258\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3515 - val_loss: 0.2230\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3627 - val_loss: 0.2232\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3630 - val_loss: 0.2220\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3644 - val_loss: 0.2231\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3392 - val_loss: 0.2248\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3584 - val_loss: 0.2209\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3445 - val_loss: 0.2238\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3656 - val_loss: 0.2235\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3587 - val_loss: 0.2262\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3532 - val_loss: 0.2202\n",
      "Epoch 00051: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 2.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s 8ms/step - loss: 6.0526 - val_loss: 1.9818\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.4605 - val_loss: 1.1468\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.0993 - val_loss: 2.2989\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.5825 - val_loss: 2.3302\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0081 - val_loss: 1.3385\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.9370 - val_loss: 1.4232\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.5963 - val_loss: 1.4458\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1651 - val_loss: 0.9244\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0281 - val_loss: 0.7412\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7537 - val_loss: 0.6424\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5871 - val_loss: 0.4675\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5237 - val_loss: 0.2413\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5184 - val_loss: 0.2897\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4872 - val_loss: 0.2313\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4664 - val_loss: 0.2406\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4875 - val_loss: 0.2432\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4466 - val_loss: 0.2332\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4639 - val_loss: 0.2338\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4542 - val_loss: 0.2321\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4749 - val_loss: 0.2163\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4137 - val_loss: 0.2243\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4362 - val_loss: 0.2370\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4207 - val_loss: 0.2349\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4108 - val_loss: 0.2281\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4313 - val_loss: 0.2307\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4218 - val_loss: 0.2253\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4226 - val_loss: 0.2276\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4341 - val_loss: 0.2263\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4191 - val_loss: 0.2296\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4208 - val_loss: 0.2283\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4081 - val_loss: 0.2239\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4184 - val_loss: 0.2279\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3928 - val_loss: 0.2283\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4061 - val_loss: 0.2266\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4046 - val_loss: 0.2285\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3892 - val_loss: 0.2262\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4184 - val_loss: 0.2270\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4055 - val_loss: 0.2271\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3957 - val_loss: 0.2286\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3996 - val_loss: 0.2243\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3933 - val_loss: 0.2306\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3849 - val_loss: 0.2279\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3878 - val_loss: 0.2293\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3827 - val_loss: 0.2243\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4023 - val_loss: 0.2230\n",
      "Epoch 00045: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 2.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 11s 8ms/step - loss: 5.5540 - val_loss: 0.8505\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 3.0633 - val_loss: 1.3884\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.6706 - val_loss: 3.3968\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.0932 - val_loss: 2.1411\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.2970 - val_loss: 1.3257\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.8774 - val_loss: 0.3114\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.6357 - val_loss: 0.2408\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.6235 - val_loss: 0.2478\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5865 - val_loss: 0.2446\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5504 - val_loss: 0.2283\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5297 - val_loss: 0.2285\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5353 - val_loss: 0.2338\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4999 - val_loss: 0.2267\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5238 - val_loss: 0.2350\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4711 - val_loss: 0.2299\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4874 - val_loss: 0.2337\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4974 - val_loss: 0.2309\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4902 - val_loss: 0.2291\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4825 - val_loss: 0.2332\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4780 - val_loss: 0.2307\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4584 - val_loss: 0.2282\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4512 - val_loss: 0.2288\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4516 - val_loss: 0.2237\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4339 - val_loss: 0.2293\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4490 - val_loss: 0.2340\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4174 - val_loss: 0.2250\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4324 - val_loss: 0.2296\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4353 - val_loss: 0.2235\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4183 - val_loss: 0.2251\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4535 - val_loss: 0.2265\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4412 - val_loss: 0.2330\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4194 - val_loss: 0.2301\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4325 - val_loss: 0.2255\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4167 - val_loss: 0.2277\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4294 - val_loss: 0.2295\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3959 - val_loss: 0.2220\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4179 - val_loss: 0.2283\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4020 - val_loss: 0.2219\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4031 - val_loss: 0.2231\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3864 - val_loss: 0.2251\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3977 - val_loss: 0.2208\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4050 - val_loss: 0.2278\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4086 - val_loss: 0.2246\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4081 - val_loss: 0.2207\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3928 - val_loss: 0.2263\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3789 - val_loss: 0.2265\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4017 - val_loss: 0.2292\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3815 - val_loss: 0.2255\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3812 - val_loss: 0.2236\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3917 - val_loss: 0.2202\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3810 - val_loss: 0.2214\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3797 - val_loss: 0.2307\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3828 - val_loss: 0.2236\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3704 - val_loss: 0.2254\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3921 - val_loss: 0.2233\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3745 - val_loss: 0.2250\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3457 - val_loss: 0.2236\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3479 - val_loss: 0.2247\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3666 - val_loss: 0.2275\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3565 - val_loss: 0.2241\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3658 - val_loss: 0.2264\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3761 - val_loss: 0.2230\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3712 - val_loss: 0.2253\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3654 - val_loss: 0.2234\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3639 - val_loss: 0.2223\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3750 - val_loss: 0.2211\n",
      "Epoch 00066: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 3.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 5.3177 - val_loss: 2.0568\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.0323 - val_loss: 2.7920\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.1243 - val_loss: 2.5248\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.7444 - val_loss: 1.2845\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9332 - val_loss: 0.2650\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5882 - val_loss: 0.2515\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5818 - val_loss: 0.2382\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5040 - val_loss: 0.2361\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5085 - val_loss: 0.2307\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4829 - val_loss: 0.2295\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4839 - val_loss: 0.2466\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4801 - val_loss: 0.2300\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4355 - val_loss: 0.2313\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4479 - val_loss: 0.2317\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4460 - val_loss: 0.2354\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4329 - val_loss: 0.2303\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4498 - val_loss: 0.2232\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4242 - val_loss: 0.2317\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3666 - val_loss: 0.2254\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4117 - val_loss: 0.2290\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4198 - val_loss: 0.2199\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4083 - val_loss: 0.2213\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4072 - val_loss: 0.2258\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3916 - val_loss: 0.2257\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4068 - val_loss: 0.2279\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4138 - val_loss: 0.2295\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4170 - val_loss: 0.2276\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3799 - val_loss: 0.2253\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3583 - val_loss: 0.2240\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3814 - val_loss: 0.2341\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3783 - val_loss: 0.2232\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3607 - val_loss: 0.2252\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3800 - val_loss: 0.2235\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3742 - val_loss: 0.2250\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3604 - val_loss: 0.2224\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3660 - val_loss: 0.2281\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3543 - val_loss: 0.2235\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3718 - val_loss: 0.2256\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3704 - val_loss: 0.2278\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3447 - val_loss: 0.2222\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3635 - val_loss: 0.2261\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3576 - val_loss: 0.2227\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3507 - val_loss: 0.2237\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3734 - val_loss: 0.2216\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3503 - val_loss: 0.2238\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3404 - val_loss: 0.2191\n",
      "Epoch 00046: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 2.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 6.1635 - val_loss: 2.1332\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.6478 - val_loss: 2.2649\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.1436 - val_loss: 2.0199\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0115 - val_loss: 2.2859\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.5346 - val_loss: 1.8433\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1449 - val_loss: 1.4757\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8323 - val_loss: 0.2577\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5718 - val_loss: 0.2347\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5860 - val_loss: 0.2386\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5356 - val_loss: 0.2399\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4841 - val_loss: 0.2267\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5047 - val_loss: 0.2320\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4504 - val_loss: 0.2203\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4721 - val_loss: 0.2297\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4788 - val_loss: 0.2228\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4801 - val_loss: 0.2267\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4571 - val_loss: 0.2253\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4325 - val_loss: 0.2249\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4515 - val_loss: 0.2236\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4169 - val_loss: 0.2264\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4324 - val_loss: 0.2205\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4295 - val_loss: 0.2294\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4412 - val_loss: 0.2253\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4246 - val_loss: 0.2287\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4186 - val_loss: 0.2214\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4229 - val_loss: 0.2334\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4361 - val_loss: 0.2257\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4098 - val_loss: 0.2244\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4077 - val_loss: 0.2195\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4248 - val_loss: 0.2281\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4020 - val_loss: 0.2309\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3981 - val_loss: 0.2237\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4010 - val_loss: 0.2248\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3930 - val_loss: 0.2202\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3800 - val_loss: 0.2268\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3940 - val_loss: 0.2274\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3903 - val_loss: 0.2210\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3978 - val_loss: 0.2238\n",
      "Epoch 00038: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 2.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 4.7530 - val_loss: 2.2054\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.3464 - val_loss: 1.6307\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.9228 - val_loss: 3.1002\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.8200 - val_loss: 2.6027\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0087 - val_loss: 1.5730\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4167 - val_loss: 1.7278\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0417 - val_loss: 0.7789\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6903 - val_loss: 0.2568\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5563 - val_loss: 0.2376\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5173 - val_loss: 0.2388\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5058 - val_loss: 0.2469\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4673 - val_loss: 0.2425\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4618 - val_loss: 0.2303\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4402 - val_loss: 0.2320\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4722 - val_loss: 0.2406\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4556 - val_loss: 0.2360\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4543 - val_loss: 0.2393\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4368 - val_loss: 0.2297\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4121 - val_loss: 0.2279\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4210 - val_loss: 0.2362\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4382 - val_loss: 0.2364\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4081 - val_loss: 0.2317\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4197 - val_loss: 0.2300\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4315 - val_loss: 0.2416\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4121 - val_loss: 0.2239\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3954 - val_loss: 0.2398\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3986 - val_loss: 0.2387\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3994 - val_loss: 0.2265\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4198 - val_loss: 0.2281\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3971 - val_loss: 0.2263\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4027 - val_loss: 0.2338\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3769 - val_loss: 0.2318\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3732 - val_loss: 0.2294\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3798 - val_loss: 0.2269\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3838 - val_loss: 0.2315\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3796 - val_loss: 0.2260\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3797 - val_loss: 0.2297\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3958 - val_loss: 0.2274\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3773 - val_loss: 0.2317\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3760 - val_loss: 0.2260\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3699 - val_loss: 0.2306\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3817 - val_loss: 0.2241\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3729 - val_loss: 0.2290\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3677 - val_loss: 0.2306\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3424 - val_loss: 0.2261\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3504 - val_loss: 0.2231\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3660 - val_loss: 0.2286\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3444 - val_loss: 0.2256\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3473 - val_loss: 0.2234\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3523 - val_loss: 0.2262\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 2.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 5.6214 - val_loss: 2.4308\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.8633 - val_loss: 1.8872\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.5059 - val_loss: 2.6917\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.9243 - val_loss: 1.9837\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.5145 - val_loss: 0.8155\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8415 - val_loss: 0.4478\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6039 - val_loss: 0.2573\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5663 - val_loss: 0.2500\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5525 - val_loss: 0.2366\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5315 - val_loss: 0.2402\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4975 - val_loss: 0.2452\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4944 - val_loss: 0.2471\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5077 - val_loss: 0.2382\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4937 - val_loss: 0.2371\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4731 - val_loss: 0.2365\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4823 - val_loss: 0.2378\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4675 - val_loss: 0.2446\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4612 - val_loss: 0.2304\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4537 - val_loss: 0.2438\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4377 - val_loss: 0.2357\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4926 - val_loss: 0.2373\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4468 - val_loss: 0.2307\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4482 - val_loss: 0.2427\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4411 - val_loss: 0.2332\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4138 - val_loss: 0.2353\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4216 - val_loss: 0.2385\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4540 - val_loss: 0.2365\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4288 - val_loss: 0.2381\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4107 - val_loss: 0.2342\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3981 - val_loss: 0.2359\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4142 - val_loss: 0.2362\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4278 - val_loss: 0.2376\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4046 - val_loss: 0.2307\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4091 - val_loss: 0.2348\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3989 - val_loss: 0.2366\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4039 - val_loss: 0.2379\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3963 - val_loss: 0.2324\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4077 - val_loss: 0.2395\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4081 - val_loss: 0.2307\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3891 - val_loss: 0.2350\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3820 - val_loss: 0.2286\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3900 - val_loss: 0.2336\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3742 - val_loss: 0.2301\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3676 - val_loss: 0.2320\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3532 - val_loss: 0.2310\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3614 - val_loss: 0.2297\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3649 - val_loss: 0.2352\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3652 - val_loss: 0.2347\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3642 - val_loss: 0.2294\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3642 - val_loss: 0.2366\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3612 - val_loss: 0.2331\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3749 - val_loss: 0.2310\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3542 - val_loss: 0.2291\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3438 - val_loss: 0.2308\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3499 - val_loss: 0.2319\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3554 - val_loss: 0.2304\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3682 - val_loss: 0.2350\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3457 - val_loss: 0.2361\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3346 - val_loss: 0.2289\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3599 - val_loss: 0.2309\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3494 - val_loss: 0.2282\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3407 - val_loss: 0.2309\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3497 - val_loss: 0.2329\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3356 - val_loss: 0.2274\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3396 - val_loss: 0.2278\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3364 - val_loss: 0.2289\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3378 - val_loss: 0.2315\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3275 - val_loss: 0.2293\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3309 - val_loss: 0.2272\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3312 - val_loss: 0.2293\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3291 - val_loss: 0.2297\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3337 - val_loss: 0.2257\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3195 - val_loss: 0.2310\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3407 - val_loss: 0.2308\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3176 - val_loss: 0.2292\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3365 - val_loss: 0.2280\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3185 - val_loss: 0.2257\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3215 - val_loss: 0.2288\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3128 - val_loss: 0.2268\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3185 - val_loss: 0.2283\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3071 - val_loss: 0.2300\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3098 - val_loss: 0.2281\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3113 - val_loss: 0.2268\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3039 - val_loss: 0.2260\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3052 - val_loss: 0.2279\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3099 - val_loss: 0.2252\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2988 - val_loss: 0.2267\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3049 - val_loss: 0.2261\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2966 - val_loss: 0.2259\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3040 - val_loss: 0.2272\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3014 - val_loss: 0.2255\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2977 - val_loss: 0.2307\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2864 - val_loss: 0.2257\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2897 - val_loss: 0.2278\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2951 - val_loss: 0.2250\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2955 - val_loss: 0.2268\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3060 - val_loss: 0.2261\n",
      "Epoch 00097: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 5.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 12s 9ms/step - loss: 18.0189 - val_loss: 0.9817\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7818 - val_loss: 1.5604\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7215 - val_loss: 0.9391\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6665 - val_loss: 1.3357\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7351 - val_loss: 1.6965\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.8877 - val_loss: 0.5693\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.3459 - val_loss: 0.7314\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6656 - val_loss: 1.3336\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6808 - val_loss: 1.1935\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.4469 - val_loss: 0.6806\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.3309 - val_loss: 0.9379\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.3566 - val_loss: 0.6621\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2678 - val_loss: 0.8487\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.2682 - val_loss: 0.6153\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.3009 - val_loss: 1.1908\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.1449 - val_loss: 0.9222\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.1789 - val_loss: 0.8291\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0793 - val_loss: 0.7431\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.9602 - val_loss: 0.8080\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0897 - val_loss: 0.8749\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8647 - val_loss: 1.2025\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8548 - val_loss: 0.7306\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.9152 - val_loss: 0.6314\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7517 - val_loss: 0.7451\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7242 - val_loss: 0.6748\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.7276 - val_loss: 0.8604\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.5209 - val_loss: 0.6029\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6839 - val_loss: 0.6259\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.4795 - val_loss: 0.6083\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.5374 - val_loss: 0.6147\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.4337 - val_loss: 0.6950\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 13.6290 - val_loss: 1.1947\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6331 - val_loss: 0.9602\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6335 - val_loss: 0.8489\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6791 - val_loss: 0.8948\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7331 - val_loss: 1.1873\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5738 - val_loss: 1.1936\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7483 - val_loss: 0.6488\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3824 - val_loss: 0.8189\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4901 - val_loss: 0.6564\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4686 - val_loss: 1.1835\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4220 - val_loss: 0.7270\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1948 - val_loss: 0.7854\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1386 - val_loss: 0.6380\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0835 - val_loss: 1.2852\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1904 - val_loss: 0.6202\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1300 - val_loss: 0.8213\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1057 - val_loss: 0.7390\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0042 - val_loss: 0.5853\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9464 - val_loss: 0.9626\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8267 - val_loss: 0.7018\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8563 - val_loss: 0.8017\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8348 - val_loss: 0.7671\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6923 - val_loss: 0.8411\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7963 - val_loss: 0.5795\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6514 - val_loss: 0.6553\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5787 - val_loss: 0.6984\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5826 - val_loss: 0.6015\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5978 - val_loss: 0.5831\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3897 - val_loss: 0.5528\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3408 - val_loss: 0.6321\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3647 - val_loss: 0.6357\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3591 - val_loss: 0.6412\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2985 - val_loss: 0.6355\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2383 - val_loss: 0.7861\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2164 - val_loss: 0.6128\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1373 - val_loss: 0.5580\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1673 - val_loss: 0.5939\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0151 - val_loss: 0.5779\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1049 - val_loss: 0.4852\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0847 - val_loss: 0.4559\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0426 - val_loss: 0.4085\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9774 - val_loss: 0.4417\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9902 - val_loss: 0.4498\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9634 - val_loss: 0.4362\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8627 - val_loss: 0.3243\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8525 - val_loss: 0.6018\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8581 - val_loss: 0.4162\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8112 - val_loss: 0.5427\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8023 - val_loss: 0.3984\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6942 - val_loss: 0.4395\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6717 - val_loss: 0.4466\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6935 - val_loss: 0.4567\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6556 - val_loss: 0.3224\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6633 - val_loss: 0.3222\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5989 - val_loss: 0.2613\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6153 - val_loss: 0.3162\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5591 - val_loss: 0.3184\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5607 - val_loss: 0.2920\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5287 - val_loss: 0.2840\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4818 - val_loss: 0.3365\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4788 - val_loss: 0.4111\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4366 - val_loss: 0.2798\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4414 - val_loss: 0.3187\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4296 - val_loss: 0.2514\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4278 - val_loss: 0.2983\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3899 - val_loss: 0.2533\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4230 - val_loss: 0.2663\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3893 - val_loss: 0.2405\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3436 - val_loss: 0.2399\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3372 - val_loss: 0.2908\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3283 - val_loss: 0.2602\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2960 - val_loss: 0.2412\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2972 - val_loss: 0.1950\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2765 - val_loss: 0.2404\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2751 - val_loss: 0.2888\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2653 - val_loss: 0.2514\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2630 - val_loss: 0.2192\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2602 - val_loss: 0.2173\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2075 - val_loss: 0.1964\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2416 - val_loss: 0.2244\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2324 - val_loss: 0.2690\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2078 - val_loss: 0.2252\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2033 - val_loss: 0.1882\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1907 - val_loss: 0.1904\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2042 - val_loss: 0.2129\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1764 - val_loss: 0.1946\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1726 - val_loss: 0.2339\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1858 - val_loss: 0.2074\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1778 - val_loss: 0.1868\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1760 - val_loss: 0.1954\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1562 - val_loss: 0.1891\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1672 - val_loss: 0.1814\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1649 - val_loss: 0.1845\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1510 - val_loss: 0.1922\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1451 - val_loss: 0.1943\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1288 - val_loss: 0.1853\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1258 - val_loss: 0.1864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1486 - val_loss: 0.1942\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1299 - val_loss: 0.1821\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1307 - val_loss: 0.1919\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1368 - val_loss: 0.1839\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1370 - val_loss: 0.1886\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1366 - val_loss: 0.1807\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1294 - val_loss: 0.1824\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1415 - val_loss: 0.1832\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1283 - val_loss: 0.1767\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1265 - val_loss: 0.1873\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1322 - val_loss: 0.1867\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1256 - val_loss: 0.1737\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1268 - val_loss: 0.1818\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1203 - val_loss: 0.1721\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1264 - val_loss: 0.1743\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1154 - val_loss: 0.1769\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1146 - val_loss: 0.1756\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1226 - val_loss: 0.1742\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1233 - val_loss: 0.1768\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1256 - val_loss: 0.1970\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1212 - val_loss: 0.1896\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1350 - val_loss: 0.1740\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1225 - val_loss: 0.1826\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1274 - val_loss: 0.1794\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1180 - val_loss: 0.1764\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1190 - val_loss: 0.1824\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1132 - val_loss: 0.1831\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1166 - val_loss: 0.1751\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1149 - val_loss: 0.1765\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1114 - val_loss: 0.1774\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1145 - val_loss: 0.1751\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1309 - val_loss: 0.1766\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1195 - val_loss: 0.1775\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1181 - val_loss: 0.1754\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1240 - val_loss: 0.1864\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1313 - val_loss: 0.1719\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1252 - val_loss: 0.1729\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1203 - val_loss: 0.1787\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1249 - val_loss: 0.1793\n",
      "Epoch 00136: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 9.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 12.9761 - val_loss: 1.2102\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8386 - val_loss: 1.1675\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9149 - val_loss: 1.2416\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8296 - val_loss: 0.5325\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8712 - val_loss: 0.6189\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7120 - val_loss: 0.5627\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7714 - val_loss: 0.9256\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4294 - val_loss: 0.9022\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6297 - val_loss: 1.0358\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3690 - val_loss: 1.0230\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3879 - val_loss: 0.9634\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3505 - val_loss: 1.0860\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2563 - val_loss: 0.7538\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1749 - val_loss: 0.6803\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1511 - val_loss: 0.7533\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0421 - val_loss: 0.7945\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0405 - val_loss: 0.5993\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9720 - val_loss: 0.5620\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9429 - val_loss: 0.7653\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8565 - val_loss: 0.6181\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8870 - val_loss: 1.1413\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8390 - val_loss: 0.6210\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6907 - val_loss: 0.5039\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6623 - val_loss: 0.7354\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6595 - val_loss: 0.7548\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5185 - val_loss: 0.7534\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6041 - val_loss: 0.5879\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4886 - val_loss: 0.6166\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5807 - val_loss: 0.7982\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4053 - val_loss: 0.6991\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4167 - val_loss: 0.7646\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3183 - val_loss: 0.5983\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2384 - val_loss: 0.7581\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2431 - val_loss: 0.6080\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1437 - val_loss: 0.5022\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2849 - val_loss: 0.5648\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1488 - val_loss: 0.4400\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0534 - val_loss: 0.3945\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0656 - val_loss: 0.3950\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0287 - val_loss: 0.3899\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0934 - val_loss: 0.4765\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9639 - val_loss: 0.5317\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9009 - val_loss: 0.4392\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9748 - val_loss: 0.5077\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9337 - val_loss: 0.4126\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8419 - val_loss: 0.4386\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7757 - val_loss: 0.4425\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7778 - val_loss: 0.3233\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7956 - val_loss: 0.3949\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7450 - val_loss: 0.2574\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6903 - val_loss: 0.4044\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7654 - val_loss: 0.4140\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6268 - val_loss: 0.4529\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6274 - val_loss: 0.4571\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5708 - val_loss: 0.3678\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5759 - val_loss: 0.3219\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5599 - val_loss: 0.3369\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5648 - val_loss: 0.2841\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.5133 - val_loss: 0.3117\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4804 - val_loss: 0.2979\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4964 - val_loss: 0.2961\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4350 - val_loss: 0.3367\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4570 - val_loss: 0.3043\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4259 - val_loss: 0.2467\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4077 - val_loss: 0.2508\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4009 - val_loss: 0.2522\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3840 - val_loss: 0.2328\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3705 - val_loss: 0.2847\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3348 - val_loss: 0.2651\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3312 - val_loss: 0.2565\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3180 - val_loss: 0.2934\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3178 - val_loss: 0.2340\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3221 - val_loss: 0.2638\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3033 - val_loss: 0.2204\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.2511\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2688 - val_loss: 0.2609\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2486 - val_loss: 0.2011\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2478 - val_loss: 0.2188\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2453 - val_loss: 0.2534\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2346 - val_loss: 0.2145\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2398 - val_loss: 0.2647\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2136 - val_loss: 0.2441\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2073 - val_loss: 0.1909\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1804 - val_loss: 0.2295\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1992 - val_loss: 0.2074\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1848 - val_loss: 0.2102\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1860 - val_loss: 0.2003\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1820 - val_loss: 0.1980\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1746 - val_loss: 0.2168\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1778 - val_loss: 0.1963\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1952 - val_loss: 0.1984\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1610 - val_loss: 0.2004\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1490 - val_loss: 0.1963\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1504 - val_loss: 0.1910\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1415 - val_loss: 0.1989\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1547 - val_loss: 0.1866\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1506 - val_loss: 0.1936\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1369 - val_loss: 0.1973\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1458 - val_loss: 0.1861\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1375 - val_loss: 0.1917\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1369 - val_loss: 0.1874\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1373 - val_loss: 0.1773\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1426 - val_loss: 0.1836\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1264 - val_loss: 0.1840\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1333 - val_loss: 0.1811\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1237 - val_loss: 0.1837\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1234 - val_loss: 0.1864\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1200 - val_loss: 0.1807\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1239 - val_loss: 0.1924\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1228 - val_loss: 0.1878\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1390 - val_loss: 0.1789\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1200 - val_loss: 0.1834\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1325 - val_loss: 0.1886\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1302 - val_loss: 0.1833\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1213 - val_loss: 0.1843\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1244 - val_loss: 0.1822\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1258 - val_loss: 0.1814\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1189 - val_loss: 0.1768\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1148 - val_loss: 0.1864\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1275 - val_loss: 0.1758\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1216 - val_loss: 0.1799\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1184 - val_loss: 0.1798\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1172 - val_loss: 0.1789\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1136 - val_loss: 0.1829\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1242 - val_loss: 0.1814\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1275 - val_loss: 0.1823\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1226 - val_loss: 0.1806\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1129 - val_loss: 0.1820\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1156 - val_loss: 0.1800\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1382 - val_loss: 0.1790\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1205 - val_loss: 0.1801\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1280 - val_loss: 0.1851\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1201 - val_loss: 0.1803\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1246 - val_loss: 0.1888\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1300 - val_loss: 0.1768\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1308 - val_loss: 0.1790\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1265 - val_loss: 0.1800\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1260 - val_loss: 0.1829\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1291 - val_loss: 0.1786\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1215 - val_loss: 0.1800\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1200 - val_loss: 0.1815\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1311 - val_loss: 0.1779\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1281 - val_loss: 0.1800\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1324 - val_loss: 0.1821\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1296 - val_loss: 0.1797\n",
      "Epoch 00145: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 9.8min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 10.8279 - val_loss: 1.0367\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7897 - val_loss: 1.1329\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6446 - val_loss: 1.2578\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6862 - val_loss: 0.8772\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5796 - val_loss: 1.1305\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4790 - val_loss: 1.0413\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5124 - val_loss: 0.8398\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4813 - val_loss: 1.1136\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4308 - val_loss: 1.0948\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3767 - val_loss: 0.9644\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3187 - val_loss: 1.1204\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1219 - val_loss: 0.5300\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1798 - val_loss: 0.5267\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1481 - val_loss: 0.7739\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1264 - val_loss: 0.7660\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1621 - val_loss: 0.7858\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9627 - val_loss: 0.6644\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9002 - val_loss: 0.7976\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8986 - val_loss: 0.7101\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9239 - val_loss: 0.5536\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7615 - val_loss: 0.7611\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7429 - val_loss: 0.7141\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7448 - val_loss: 0.5162\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7536 - val_loss: 0.8099\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5721 - val_loss: 0.6387\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5458 - val_loss: 1.2701\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5592 - val_loss: 0.5263\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5200 - val_loss: 0.6073\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4139 - val_loss: 0.8108\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3422 - val_loss: 0.5743\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3150 - val_loss: 0.5528\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2245 - val_loss: 0.4626\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2022 - val_loss: 0.7055\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1712 - val_loss: 0.7436\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1087 - val_loss: 0.5413\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1011 - val_loss: 0.3926\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1136 - val_loss: 0.5096\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0526 - val_loss: 0.5348\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9879 - val_loss: 0.4120\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9547 - val_loss: 0.4390\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8853 - val_loss: 0.6084\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9124 - val_loss: 0.4847\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9229 - val_loss: 0.4287\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8876 - val_loss: 0.4387\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8607 - val_loss: 0.4732\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8251 - val_loss: 0.4644\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7742 - val_loss: 0.3797\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7048 - val_loss: 0.3488\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7195 - val_loss: 0.3454\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7116 - val_loss: 0.4063\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6749 - val_loss: 0.3713\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6597 - val_loss: 0.3333\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6392 - val_loss: 0.3767\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6103 - val_loss: 0.2704\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5657 - val_loss: 0.2763\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5869 - val_loss: 0.2774\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5270 - val_loss: 0.4046\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5379 - val_loss: 0.3171\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4961 - val_loss: 0.3644\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4866 - val_loss: 0.2796\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4497 - val_loss: 0.2353\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4021 - val_loss: 0.2882\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4073 - val_loss: 0.2990\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4289 - val_loss: 0.2656\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3971 - val_loss: 0.2811\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3807 - val_loss: 0.3109\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3488 - val_loss: 0.2730\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3601 - val_loss: 0.3060\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3078 - val_loss: 0.2201\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3062 - val_loss: 0.2633\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2958 - val_loss: 0.2672\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2755 - val_loss: 0.2471\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2657 - val_loss: 0.2891\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2752 - val_loss: 0.2718\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2437 - val_loss: 0.2189\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2406 - val_loss: 0.2477\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2437 - val_loss: 0.2465\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2327 - val_loss: 0.2113\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2213 - val_loss: 0.1986\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2169 - val_loss: 0.2296\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.2136 - val_loss: 0.2053\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2093 - val_loss: 0.1947\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1842 - val_loss: 0.2353\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1839 - val_loss: 0.2127\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1907 - val_loss: 0.2140\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1806 - val_loss: 0.2003\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1890 - val_loss: 0.2031\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1716 - val_loss: 0.1881\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1524 - val_loss: 0.2045\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1665 - val_loss: 0.2036\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1493 - val_loss: 0.2045\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1524 - val_loss: 0.1769\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1441 - val_loss: 0.1801\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1456 - val_loss: 0.1888\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1424 - val_loss: 0.1830\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1449 - val_loss: 0.1989\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1434 - val_loss: 0.1750\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1457 - val_loss: 0.1915\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1352 - val_loss: 0.1935\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1349 - val_loss: 0.1864\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1311 - val_loss: 0.1683\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1313 - val_loss: 0.1786\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1318 - val_loss: 0.1744\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1306 - val_loss: 0.1772\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1300 - val_loss: 0.1772\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1274 - val_loss: 0.1789\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1355 - val_loss: 0.1796\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1218 - val_loss: 0.1729\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1268 - val_loss: 0.1778\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1173 - val_loss: 0.1758\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1304 - val_loss: 0.1723\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1305 - val_loss: 0.1748\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1242 - val_loss: 0.1731\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1278 - val_loss: 0.1747\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1255 - val_loss: 0.1800\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1218 - val_loss: 0.1732\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1304 - val_loss: 0.1733\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1225 - val_loss: 0.1823\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1284 - val_loss: 0.1737\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1254 - val_loss: 0.1731\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1210 - val_loss: 0.1719\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1247 - val_loss: 0.1802\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1183 - val_loss: 0.1726\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1275 - val_loss: 0.1814\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1316 - val_loss: 0.1761\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.1266 - val_loss: 0.1740\n",
      "Epoch 00126: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 8.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 12s 9ms/step - loss: 10.2501 - val_loss: 1.4056\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9106 - val_loss: 1.0120\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8472 - val_loss: 1.3709\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7764 - val_loss: 0.8072\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6563 - val_loss: 0.9684\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4815 - val_loss: 0.9910\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5190 - val_loss: 1.2576\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5075 - val_loss: 0.7928\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4026 - val_loss: 0.9455\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3239 - val_loss: 1.1592\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1631 - val_loss: 1.0452\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3263 - val_loss: 0.6522\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1940 - val_loss: 1.2235\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1621 - val_loss: 0.9400\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0973 - val_loss: 1.1361\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9234 - val_loss: 0.9518\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0095 - val_loss: 0.8898\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8601 - val_loss: 0.9571\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8073 - val_loss: 0.6582\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8503 - val_loss: 0.9370\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7074 - val_loss: 0.7853\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6531 - val_loss: 0.6163\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7290 - val_loss: 0.6739\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6186 - val_loss: 0.7020\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6565 - val_loss: 0.5381\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4894 - val_loss: 0.5807\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5028 - val_loss: 0.7696\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4703 - val_loss: 0.4396\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3251 - val_loss: 0.8435\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3143 - val_loss: 0.8389\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2748 - val_loss: 0.6050\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2788 - val_loss: 0.6288\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2202 - val_loss: 0.4921\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2320 - val_loss: 0.4712\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1383 - val_loss: 0.2849\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1167 - val_loss: 0.6785\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0813 - val_loss: 0.4154\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0886 - val_loss: 0.4971\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0491 - val_loss: 0.4590\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0132 - val_loss: 0.5753\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9774 - val_loss: 0.4634\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9717 - val_loss: 0.4390\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9172 - val_loss: 0.4915\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8658 - val_loss: 0.4591\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8619 - val_loss: 0.3926\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7295 - val_loss: 0.4117\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7855 - val_loss: 0.3322\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7857 - val_loss: 0.4082\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7363 - val_loss: 0.3864\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6727 - val_loss: 0.3559\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6407 - val_loss: 0.5108\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6819 - val_loss: 0.4537\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5653 - val_loss: 0.3955\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5842 - val_loss: 0.3452\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5483 - val_loss: 0.3604\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5359 - val_loss: 0.3114\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4884 - val_loss: 0.2850\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5207 - val_loss: 0.3613\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5005 - val_loss: 0.3395\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4324 - val_loss: 0.2857\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 13s 10ms/step - loss: 5.4960 - val_loss: 0.4904\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6357 - val_loss: 0.6038\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.4705 - val_loss: 1.5776\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3629 - val_loss: 1.8518\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.0669 - val_loss: 1.8368\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9463 - val_loss: 2.1063\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9314 - val_loss: 2.2011\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8992 - val_loss: 2.2566\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7436 - val_loss: 1.7091\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7790 - val_loss: 1.8098\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6767 - val_loss: 1.2892\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5626 - val_loss: 1.5340\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5628 - val_loss: 0.9316\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4623 - val_loss: 0.7392\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4216 - val_loss: 0.2196\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3570 - val_loss: 0.2202\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3509 - val_loss: 0.2209\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3509 - val_loss: 0.2241\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3336 - val_loss: 0.2188\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3357 - val_loss: 0.2208\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3350 - val_loss: 0.2217\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3325 - val_loss: 0.2222\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3292 - val_loss: 0.2203\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3344 - val_loss: 0.2194\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3355 - val_loss: 0.2205\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3305 - val_loss: 0.2196\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3379 - val_loss: 0.2189\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3409 - val_loss: 0.2194\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3290 - val_loss: 0.2208\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3159 - val_loss: 0.2199\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3136 - val_loss: 0.2213\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3316 - val_loss: 0.2199\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3246 - val_loss: 0.2211\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3048 - val_loss: 0.2186\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3201 - val_loss: 0.2209\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3215 - val_loss: 0.2195\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3263 - val_loss: 0.2186\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3199 - val_loss: 0.2195\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3190 - val_loss: 0.2207\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3143 - val_loss: 0.2204\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 3.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 4.8950 - val_loss: 1.2977\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9587 - val_loss: 1.1758\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0336 - val_loss: 1.4240\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6222 - val_loss: 1.4203\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3229 - val_loss: 1.5933\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1393 - val_loss: 1.3321\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9456 - val_loss: 1.5294\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7227 - val_loss: 1.0565\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6775 - val_loss: 1.2005\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5734 - val_loss: 0.6501\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4509 - val_loss: 0.4623\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3487 - val_loss: 0.2236\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3315 - val_loss: 0.2035\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3228 - val_loss: 0.2203\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3308 - val_loss: 0.2133\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3408 - val_loss: 0.2227\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3031 - val_loss: 0.2253\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3155 - val_loss: 0.2218\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3214 - val_loss: 0.2215\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3366 - val_loss: 0.2205\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3243 - val_loss: 0.2213\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3166 - val_loss: 0.2205\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3228 - val_loss: 0.2204\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3242 - val_loss: 0.2195\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3261 - val_loss: 0.2196\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3254 - val_loss: 0.2200\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3221 - val_loss: 0.2212\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3232 - val_loss: 0.2210\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3276 - val_loss: 0.2193\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3040 - val_loss: 0.2208\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3186 - val_loss: 0.2217\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3111 - val_loss: 0.2187\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3099 - val_loss: 0.2200\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3086 - val_loss: 0.2197\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3091 - val_loss: 0.2187\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2955 - val_loss: 0.2197\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3093 - val_loss: 0.2195\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3183 - val_loss: 0.2206\n",
      "Epoch 00038: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 3.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 5.3767 - val_loss: 0.4147\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.7551 - val_loss: 1.1310\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4532 - val_loss: 1.7830\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3715 - val_loss: 1.5877\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2251 - val_loss: 1.6981\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1468 - val_loss: 1.9548\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9808 - val_loss: 2.0349\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8138 - val_loss: 1.7602\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8614 - val_loss: 1.5355\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7042 - val_loss: 1.5533\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6714 - val_loss: 1.3665\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5105 - val_loss: 1.2440\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4790 - val_loss: 1.3909\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4663 - val_loss: 1.0947\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4237 - val_loss: 0.7881\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3915 - val_loss: 0.3445\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3430 - val_loss: 0.3059\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3224 - val_loss: 0.2442\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2943 - val_loss: 0.2285\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3202 - val_loss: 0.2190\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3348 - val_loss: 0.2199\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3397 - val_loss: 0.2203\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3068 - val_loss: 0.2202\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3199 - val_loss: 0.2196\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3262 - val_loss: 0.2199\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3048 - val_loss: 0.2190\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3304 - val_loss: 0.2199\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3247 - val_loss: 0.2187\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3165 - val_loss: 0.2189\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3132 - val_loss: 0.2189\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3263 - val_loss: 0.2214\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3003 - val_loss: 0.2188\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3223 - val_loss: 0.2188\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3154 - val_loss: 0.2220\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3137 - val_loss: 0.2196\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3155 - val_loss: 0.2188\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2978 - val_loss: 0.2191\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3038 - val_loss: 0.2193\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2955 - val_loss: 0.2195\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3059 - val_loss: 0.2190\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3128 - val_loss: 0.2195\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3176 - val_loss: 0.2186\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3044 - val_loss: 0.2201\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3031 - val_loss: 0.2196\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3011 - val_loss: 0.2199\n",
      "Epoch 00045: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 3.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 6.9657 - val_loss: 0.8569\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0945 - val_loss: 1.2628\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8246 - val_loss: 0.9215\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5368 - val_loss: 1.3593\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3732 - val_loss: 1.1496\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1367 - val_loss: 1.9170\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9685 - val_loss: 1.7146\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9762 - val_loss: 1.4351\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8264 - val_loss: 1.3612\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7385 - val_loss: 0.8951\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6421 - val_loss: 0.7973\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5283 - val_loss: 0.4432\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4620 - val_loss: 0.3386\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3836 - val_loss: 0.2546\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3779 - val_loss: 0.2147\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3552 - val_loss: 0.2309\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3442 - val_loss: 0.2356\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3392 - val_loss: 0.2396\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3196 - val_loss: 0.2251\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3521 - val_loss: 0.2229\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3270 - val_loss: 0.2327\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3230 - val_loss: 0.2027\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3107 - val_loss: 0.2147\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2974 - val_loss: 0.2162\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2964 - val_loss: 0.1882\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3082 - val_loss: 0.2164\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3124 - val_loss: 0.1995\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3088 - val_loss: 0.2050\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3100 - val_loss: 0.2091\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3034 - val_loss: 0.1987\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3058 - val_loss: 0.2270\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2954 - val_loss: 0.2088\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2894 - val_loss: 0.2131\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3007 - val_loss: 0.2041\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2920 - val_loss: 0.2295\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2857 - val_loss: 0.2029\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3011 - val_loss: 0.2111\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2905 - val_loss: 0.1972\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2706 - val_loss: 0.2176\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2891 - val_loss: 0.2182\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3006 - val_loss: 0.2210\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2834 - val_loss: 0.2259\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2806 - val_loss: 0.1892\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2776 - val_loss: 0.2111\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2915 - val_loss: 0.2130\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2777 - val_loss: 0.2310\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2794 - val_loss: 0.2184\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2617 - val_loss: 0.2025\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2642 - val_loss: 0.2051\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2852 - val_loss: 0.2126\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 3.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 4.9147 - val_loss: 1.0104\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6505 - val_loss: 1.7755\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.3307 - val_loss: 1.5690\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1380 - val_loss: 2.5431\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0189 - val_loss: 2.4907\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0320 - val_loss: 1.2781\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9293 - val_loss: 1.7562\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7907 - val_loss: 1.5733\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6485 - val_loss: 1.4995\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6511 - val_loss: 1.2870\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5798 - val_loss: 1.4124\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4665 - val_loss: 1.2881\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4499 - val_loss: 0.4427\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3980 - val_loss: 0.2617\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3435 - val_loss: 0.2243\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3261 - val_loss: 0.2120\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3166 - val_loss: 0.2013\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3031 - val_loss: 0.2259\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3116 - val_loss: 0.2274\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3062 - val_loss: 0.1956\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3085 - val_loss: 0.2117\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3009 - val_loss: 0.2251\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3086 - val_loss: 0.2135\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2933 - val_loss: 0.2163\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3147 - val_loss: 0.2231\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2946 - val_loss: 0.2257\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3178 - val_loss: 0.2203\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3000 - val_loss: 0.2237\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3097 - val_loss: 0.2270\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3037 - val_loss: 0.2209\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2891 - val_loss: 0.1927\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2936 - val_loss: 0.2196\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2802 - val_loss: 0.2064\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2948 - val_loss: 0.2125\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2778 - val_loss: 0.2118\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2637 - val_loss: 0.2296\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2819 - val_loss: 0.1765\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2854 - val_loss: 0.1822\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2742 - val_loss: 0.2053\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3048 - val_loss: 0.2195\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2969 - val_loss: 0.2205\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2993 - val_loss: 0.2192\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3003 - val_loss: 0.2189\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2868 - val_loss: 0.2202\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2903 - val_loss: 0.2203\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2742 - val_loss: 0.2151\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2695 - val_loss: 0.2241\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2714 - val_loss: 0.2168\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2665 - val_loss: 0.2087\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2509 - val_loss: 0.1827\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2623 - val_loss: 0.1801\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2564 - val_loss: 0.2062\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2641 - val_loss: 0.1964\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2461 - val_loss: 0.1716\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2896 - val_loss: 0.2190\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2965 - val_loss: 0.2211\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2816 - val_loss: 0.1894\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2479 - val_loss: 0.1814\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2524 - val_loss: 0.1879\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2501 - val_loss: 0.1813\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2514 - val_loss: 0.2178\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2591 - val_loss: 0.1951\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2263 - val_loss: 0.2017\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2516 - val_loss: 0.1881\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2364 - val_loss: 0.1843\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2447 - val_loss: 0.2019\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2424 - val_loss: 0.2153\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2343 - val_loss: 0.1847\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2461 - val_loss: 0.1772\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2420 - val_loss: 0.1895\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2242 - val_loss: 0.1968\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2437 - val_loss: 0.1939\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2312 - val_loss: 0.2116\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2193 - val_loss: 0.1906\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2151 - val_loss: 0.1817\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2336 - val_loss: 0.1868\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2348 - val_loss: 0.1941\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2256 - val_loss: 0.1892\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2193 - val_loss: 0.1976\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 6.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 14s 10ms/step - loss: 4.9391 - val_loss: 2.3509\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 1.6366 - val_loss: 1.9587\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 1.5308 - val_loss: 2.4490\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 1.2583 - val_loss: 2.6837\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 1.1763 - val_loss: 2.9072\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.8708 - val_loss: 2.5964\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.7882 - val_loss: 1.9844\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.6392 - val_loss: 0.8485\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.4587 - val_loss: 0.5193\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.4024 - val_loss: 0.4588\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.4101 - val_loss: 0.5232\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3814 - val_loss: 0.3382\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3561 - val_loss: 0.4063\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3384 - val_loss: 0.3812\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3424 - val_loss: 0.2816\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3464 - val_loss: 0.2869\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3229 - val_loss: 0.3000\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3032 - val_loss: 0.2532\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3701 - val_loss: 0.2231\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3541 - val_loss: 0.2290\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3516 - val_loss: 0.2293\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3508 - val_loss: 0.2228\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3368 - val_loss: 0.2227\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3438 - val_loss: 0.2224\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3454 - val_loss: 0.2249\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3179 - val_loss: 0.2210\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3320 - val_loss: 0.2218\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3493 - val_loss: 0.2239\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3350 - val_loss: 0.2211\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3284 - val_loss: 0.2239\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3440 - val_loss: 0.2231\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3267 - val_loss: 0.2208\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3439 - val_loss: 0.2236\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3445 - val_loss: 0.2259\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3248 - val_loss: 0.2209\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3373 - val_loss: 0.2283\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3348 - val_loss: 0.2209\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3240 - val_loss: 0.2224\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3259 - val_loss: 0.2222\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3240 - val_loss: 0.2213\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3245 - val_loss: 0.2206\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3227 - val_loss: 0.2219\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3427 - val_loss: 0.2214\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3242 - val_loss: 0.2220\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3212 - val_loss: 0.2210\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3095 - val_loss: 0.2211\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3090 - val_loss: 0.2209\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3127 - val_loss: 0.2231\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2997 - val_loss: 0.2256\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3142 - val_loss: 0.2275\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.3176 - val_loss: 0.2293\n",
      "Epoch 00051: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 4.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 15s 11ms/step - loss: 3.9406 - val_loss: 0.8755\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.7606 - val_loss: 3.7782\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.3178 - val_loss: 2.8834\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.1341 - val_loss: 2.9131\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.2210 - val_loss: 2.7535\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.8524 - val_loss: 2.6889\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.7056 - val_loss: 1.7833\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.5216 - val_loss: 0.9352\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.4744 - val_loss: 0.2359\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.4404 - val_loss: 0.2356\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.4006 - val_loss: 0.2239\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3667 - val_loss: 0.2273\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3669 - val_loss: 0.2283\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3493 - val_loss: 0.2263\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3482 - val_loss: 0.2288\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3740 - val_loss: 0.2231\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3355 - val_loss: 0.2238\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3385 - val_loss: 0.2236\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3449 - val_loss: 0.2256\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3296 - val_loss: 0.2299\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3317 - val_loss: 0.2243\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3196 - val_loss: 0.2241\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3269 - val_loss: 0.2252\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3108 - val_loss: 0.2286\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3130 - val_loss: 0.2252\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3229 - val_loss: 0.2261\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3460 - val_loss: 0.2228\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3143 - val_loss: 0.2248\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3161 - val_loss: 0.2258\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3117 - val_loss: 0.2240\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3195 - val_loss: 0.2223\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3137 - val_loss: 0.2231\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3157 - val_loss: 0.2242\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3091 - val_loss: 0.2227\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3131 - val_loss: 0.2222\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3106 - val_loss: 0.2224\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3025 - val_loss: 0.2244\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3054 - val_loss: 0.2246\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3177 - val_loss: 0.2223\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3198 - val_loss: 0.2229\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3054 - val_loss: 0.2239\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3190 - val_loss: 0.2217\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3127 - val_loss: 0.2230\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3170 - val_loss: 0.2296\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3221 - val_loss: 0.2234\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2991 - val_loss: 0.2215\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2968 - val_loss: 0.2214\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2981 - val_loss: 0.2221\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.2945 - val_loss: 0.2269\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.2964 - val_loss: 0.2214\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2983 - val_loss: 0.2277\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2988 - val_loss: 0.2231\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2913 - val_loss: 0.2253\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3079 - val_loss: 0.2225\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2882 - val_loss: 0.2277\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2969 - val_loss: 0.2295\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3026 - val_loss: 0.2223\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2932 - val_loss: 0.2239\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.2867 - val_loss: 0.2215\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.2805 - val_loss: 0.2259\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3044 - val_loss: 0.2222\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2933 - val_loss: 0.2212\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2884 - val_loss: 0.2265\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2845 - val_loss: 0.2228\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2903 - val_loss: 0.2212\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2855 - val_loss: 0.2250\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2850 - val_loss: 0.2225\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 5.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 11ms/step - loss: 4.1357 - val_loss: 1.9785\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.8057 - val_loss: 2.6507\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.6275 - val_loss: 2.6528\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.1310 - val_loss: 2.4421\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.0688 - val_loss: 2.8030\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.8871 - val_loss: 2.3005\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.7552 - val_loss: 2.0563\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.6360 - val_loss: 0.3249\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.4301 - val_loss: 0.2281\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3916 - val_loss: 0.2218\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3860 - val_loss: 0.2238\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3637 - val_loss: 0.2278\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3571 - val_loss: 0.2224\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3667 - val_loss: 0.2232\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3596 - val_loss: 0.2226\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3426 - val_loss: 0.2192\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3600 - val_loss: 0.2201\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3306 - val_loss: 0.2192\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3442 - val_loss: 0.2228\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3299 - val_loss: 0.2242\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3354 - val_loss: 0.2244\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3127 - val_loss: 0.2272\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3273 - val_loss: 0.2271\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3279 - val_loss: 0.2244\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3222 - val_loss: 0.2188\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3225 - val_loss: 0.2256\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3233 - val_loss: 0.2217\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3270 - val_loss: 0.2192\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3110 - val_loss: 0.2188\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3231 - val_loss: 0.2212\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3336 - val_loss: 0.2189\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3170 - val_loss: 0.2188\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3123 - val_loss: 0.2192\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3050 - val_loss: 0.2231\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3082 - val_loss: 0.2238\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3030 - val_loss: 0.2191\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3169 - val_loss: 0.2211\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3004 - val_loss: 0.2214\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3084 - val_loss: 0.2190\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.2955 - val_loss: 0.2193\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3182 - val_loss: 0.2206\n",
      "Epoch 00041: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 3.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 11ms/step - loss: 3.9806 - val_loss: 1.4834\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.7788 - val_loss: 2.7389\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.6437 - val_loss: 3.3757\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.3236 - val_loss: 3.1843\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.2070 - val_loss: 2.8431\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.9531 - val_loss: 1.9246\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.5110 - val_loss: 0.2398\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4216 - val_loss: 0.2262\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3840 - val_loss: 0.2215\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4375 - val_loss: 0.2294\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.4012 - val_loss: 0.2222\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3865 - val_loss: 0.2277\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3782 - val_loss: 0.2251\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3669 - val_loss: 0.2218\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3590 - val_loss: 0.2250\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3416 - val_loss: 0.2256\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3309 - val_loss: 0.2307\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3450 - val_loss: 0.2235\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3417 - val_loss: 0.2213\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3243 - val_loss: 0.2210\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3429 - val_loss: 0.2237\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3472 - val_loss: 0.2294\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3435 - val_loss: 0.2289\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3416 - val_loss: 0.2222\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3300 - val_loss: 0.2203\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3316 - val_loss: 0.2279\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3200 - val_loss: 0.2205\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3340 - val_loss: 0.2221\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3147 - val_loss: 0.2272\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3241 - val_loss: 0.2205\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3311 - val_loss: 0.2203\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3300 - val_loss: 0.2243\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3088 - val_loss: 0.2222\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3060 - val_loss: 0.2285\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3210 - val_loss: 0.2232\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3268 - val_loss: 0.2213\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3220 - val_loss: 0.2202\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3158 - val_loss: 0.2279\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3123 - val_loss: 0.2273\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3239 - val_loss: 0.2215\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3212 - val_loss: 0.2231\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3164 - val_loss: 0.2235\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3151 - val_loss: 0.2249\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3188 - val_loss: 0.2268\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3046 - val_loss: 0.2288\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2974 - val_loss: 0.2234\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2999 - val_loss: 0.2203\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2983 - val_loss: 0.2207\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2997 - val_loss: 0.2253\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3208 - val_loss: 0.2208\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 4.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 15s 11ms/step - loss: 4.6828 - val_loss: 1.4947\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.7511 - val_loss: 1.8338\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.6628 - val_loss: 2.0748\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.3866 - val_loss: 2.3551\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.0958 - val_loss: 2.1473\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.9363 - val_loss: 2.4580\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.9262 - val_loss: 1.9965\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.6752 - val_loss: 0.7105\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4949 - val_loss: 0.2476\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4261 - val_loss: 0.2240\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4001 - val_loss: 0.2340\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3568 - val_loss: 0.2270\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3833 - val_loss: 0.2246\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3755 - val_loss: 0.2391\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3580 - val_loss: 0.2203\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3806 - val_loss: 0.2264\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3615 - val_loss: 0.2239\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3566 - val_loss: 0.2254\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 0.3398 - val_loss: 0.2211\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3542 - val_loss: 0.2272\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3510 - val_loss: 0.2252\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3456 - val_loss: 0.2249\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3524 - val_loss: 0.2269\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3450 - val_loss: 0.2303\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3326 - val_loss: 0.2214\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3272 - val_loss: 0.2246\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3383 - val_loss: 0.2201\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3466 - val_loss: 0.2313\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3240 - val_loss: 0.2213\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3220 - val_loss: 0.2203\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3158 - val_loss: 0.2221\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3268 - val_loss: 0.2254\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3271 - val_loss: 0.2245\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3267 - val_loss: 0.2232\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3190 - val_loss: 0.2227\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3163 - val_loss: 0.2239\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3121 - val_loss: 0.2203\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3274 - val_loss: 0.2290\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3189 - val_loss: 0.2255\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3219 - val_loss: 0.2232\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 3.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 16s 12ms/step - loss: 39.7492 - val_loss: 1.7561\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.8447 - val_loss: 1.4641\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.7696 - val_loss: 1.1522\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.7302 - val_loss: 0.9164\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.7602 - val_loss: 0.7848\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.7845 - val_loss: 1.1051\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.6336 - val_loss: 1.2738\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.4914 - val_loss: 1.3279\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.7111 - val_loss: 1.2514\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.5221 - val_loss: 0.7814\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.6526 - val_loss: 0.9541\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.4858 - val_loss: 0.9365\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.4297 - val_loss: 1.0812\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.5658 - val_loss: 0.8561\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.3763 - val_loss: 1.1371\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.2241 - val_loss: 0.7616\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.2233 - val_loss: 0.7107\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.1463 - val_loss: 1.1483\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.1817 - val_loss: 0.9291\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.9746 - val_loss: 0.6437\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.1231 - val_loss: 0.6652\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 2.1228 - val_loss: 1.1271\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.9360 - val_loss: 0.8386\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.9301 - val_loss: 0.8553\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.8896 - val_loss: 0.8604\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.9277 - val_loss: 1.0107\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.8725 - val_loss: 0.7204\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.6898 - val_loss: 0.8498\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.8260 - val_loss: 0.8002\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.7532 - val_loss: 0.5846\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.7718 - val_loss: 0.6616\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.5854 - val_loss: 0.6523\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.5198 - val_loss: 0.7790\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.5320 - val_loss: 0.6435\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.4839 - val_loss: 0.6855\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.4845 - val_loss: 0.5130\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.4538 - val_loss: 0.6132\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.3693 - val_loss: 0.4694\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.3748 - val_loss: 0.6656\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.2690 - val_loss: 0.6536\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.3343 - val_loss: 0.5989\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.2786 - val_loss: 0.7160\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.2871 - val_loss: 0.5454\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.1610 - val_loss: 0.5228\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.2250 - val_loss: 0.4564\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.0818 - val_loss: 0.4300\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.1421 - val_loss: 0.5822\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 1.0354 - val_loss: 0.5189\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.1017 - val_loss: 0.5944\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.9637 - val_loss: 0.4510\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.9610 - val_loss: 0.3914\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.0009 - val_loss: 0.4136\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8593 - val_loss: 0.3638\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.8855 - val_loss: 0.4995\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8849 - val_loss: 0.4703\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7781 - val_loss: 0.3703\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.8080 - val_loss: 0.3939\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7858 - val_loss: 0.3977\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7321 - val_loss: 0.4828\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7733 - val_loss: 0.3331\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6744 - val_loss: 0.4336\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6627 - val_loss: 0.3943\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6635 - val_loss: 0.3268\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6276 - val_loss: 0.3411\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6064 - val_loss: 0.3101\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5826 - val_loss: 0.3295\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5489 - val_loss: 0.3288\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5470 - val_loss: 0.3887\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5503 - val_loss: 0.2866\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4998 - val_loss: 0.3539\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4846 - val_loss: 0.3356\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4805 - val_loss: 0.3187\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4536 - val_loss: 0.2153\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.4321 - val_loss: 0.3142\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4155 - val_loss: 0.2522\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3895 - val_loss: 0.2848\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4036 - val_loss: 0.3490\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3784 - val_loss: 0.2601\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3510 - val_loss: 0.2404\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3388 - val_loss: 0.2620\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3323 - val_loss: 0.2843\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3057 - val_loss: 0.2772\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.3220 - val_loss: 0.2792\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3228 - val_loss: 0.2811\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2778 - val_loss: 0.2424\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3014 - val_loss: 0.2220\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2762 - val_loss: 0.2176\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2910 - val_loss: 0.2441\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2447 - val_loss: 0.2593\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2379 - val_loss: 0.2704\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2562 - val_loss: 0.2506\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2348 - val_loss: 0.2209\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2294 - val_loss: 0.2536\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2259 - val_loss: 0.2131\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.2075 - val_loss: 0.2307\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1819 - val_loss: 0.2135\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1889 - val_loss: 0.2402\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1811 - val_loss: 0.2152\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1825 - val_loss: 0.2227\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1825 - val_loss: 0.2275\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1711 - val_loss: 0.2124\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1517 - val_loss: 0.2143\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1705 - val_loss: 0.1884\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1509 - val_loss: 0.1865\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1653 - val_loss: 0.2054\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1422 - val_loss: 0.1989\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1395 - val_loss: 0.2179\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1391 - val_loss: 0.2010\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1525 - val_loss: 0.2036\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1464 - val_loss: 0.2031\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1442 - val_loss: 0.1954\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1279 - val_loss: 0.1980\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1349 - val_loss: 0.1878\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1225 - val_loss: 0.2010\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1258 - val_loss: 0.1859\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1376 - val_loss: 0.1892\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1363 - val_loss: 0.1904\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1298 - val_loss: 0.1846\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1328 - val_loss: 0.1809\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1301 - val_loss: 0.1893\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1317 - val_loss: 0.1836\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1297 - val_loss: 0.1819\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1247 - val_loss: 0.1908\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1190 - val_loss: 0.1834\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1248 - val_loss: 0.1771\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1266 - val_loss: 0.1811\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1225 - val_loss: 0.1865\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1187 - val_loss: 0.1800\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1330 - val_loss: 0.1833\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1277 - val_loss: 0.1825\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1213 - val_loss: 0.1828\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1384 - val_loss: 0.1846\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1221 - val_loss: 0.1863\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1169 - val_loss: 0.1802\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1281 - val_loss: 0.1859\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1146 - val_loss: 0.1830\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1214 - val_loss: 0.1829\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1310 - val_loss: 0.1862\n",
      "Epoch 139/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1302 - val_loss: 0.1783\n",
      "Epoch 140/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1321 - val_loss: 0.1893\n",
      "Epoch 141/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1323 - val_loss: 0.1798\n",
      "Epoch 142/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1198 - val_loss: 0.1798\n",
      "Epoch 143/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1284 - val_loss: 0.1779\n",
      "Epoch 144/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1191 - val_loss: 0.1788\n",
      "Epoch 145/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1343 - val_loss: 0.1786\n",
      "Epoch 146/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1284 - val_loss: 0.1811\n",
      "Epoch 147/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1277 - val_loss: 0.1802\n",
      "Epoch 148/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1232 - val_loss: 0.1785\n",
      "Epoch 149/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1323 - val_loss: 0.1787\n",
      "Epoch 150/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.1212 - val_loss: 0.1832\n",
      "Epoch 00150: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total=15.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 28.8630 - val_loss: 1.5423\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.2106 - val_loss: 0.7989\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1603 - val_loss: 0.7390\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2236 - val_loss: 0.8250\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1021 - val_loss: 0.4400\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0907 - val_loss: 1.1250\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0515 - val_loss: 0.6497\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0735 - val_loss: 0.5046\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0004 - val_loss: 0.8167\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0242 - val_loss: 0.4077\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9745 - val_loss: 1.0355\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8086 - val_loss: 1.0350\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8657 - val_loss: 0.3343\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8453 - val_loss: 0.3579\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8634 - val_loss: 0.9182\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8966 - val_loss: 0.3453\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6997 - val_loss: 0.6960\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6520 - val_loss: 0.4607\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6624 - val_loss: 0.7363\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7075 - val_loss: 0.5834\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.6314 - val_loss: 0.5130\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5517 - val_loss: 0.7071\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.6388 - val_loss: 0.5951\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5726 - val_loss: 0.5048\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5245 - val_loss: 0.3448\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4781 - val_loss: 0.5111\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4251 - val_loss: 0.6607\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3499 - val_loss: 0.6727\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3178 - val_loss: 0.5019\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2917 - val_loss: 0.5864\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3551 - val_loss: 0.6237\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2483 - val_loss: 0.4444\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3029 - val_loss: 0.6380\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2325 - val_loss: 0.3447\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2459 - val_loss: 0.3725\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.1955 - val_loss: 0.5927\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.0772 - val_loss: 0.3974\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.1189 - val_loss: 0.5272\n",
      "Epoch 00038: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total= 4.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 32.0383 - val_loss: 0.8092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.2079 - val_loss: 0.7735\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.9390 - val_loss: 0.6982\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1207 - val_loss: 0.9651\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0852 - val_loss: 0.6305\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0261 - val_loss: 0.8350\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0675 - val_loss: 0.5885\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.9295 - val_loss: 0.6834\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0430 - val_loss: 0.4278\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0194 - val_loss: 0.6321\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9286 - val_loss: 0.6763\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9620 - val_loss: 0.3082\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8779 - val_loss: 0.7324\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.9066 - val_loss: 0.6293\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9147 - val_loss: 0.6762\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7992 - val_loss: 0.9813\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7730 - val_loss: 0.5868\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7725 - val_loss: 0.5512\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.7165 - val_loss: 0.7211\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.7774 - val_loss: 0.3451\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6921 - val_loss: 0.7834\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6493 - val_loss: 0.6925\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5640 - val_loss: 1.0215\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6311 - val_loss: 0.3253\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6598 - val_loss: 0.4788\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6398 - val_loss: 0.6522\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5204 - val_loss: 0.5320\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4398 - val_loss: 0.6710\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4517 - val_loss: 0.5500\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4024 - val_loss: 0.7413\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.3425 - val_loss: 0.6118\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2956 - val_loss: 0.4988\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2092 - val_loss: 0.3791\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.1707 - val_loss: 0.6281\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.2368 - val_loss: 0.3532\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.1502 - val_loss: 0.5452\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1699 - val_loss: 0.5678\n",
      "Epoch 00037: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total= 4.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 12ms/step - loss: 30.1072 - val_loss: 0.5828\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1882 - val_loss: 0.3648\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1637 - val_loss: 0.5759\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.1147 - val_loss: 0.8137\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1375 - val_loss: 0.3246\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1538 - val_loss: 0.8242\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0106 - val_loss: 0.5329\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.1331 - val_loss: 0.6526\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9845 - val_loss: 0.8325\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.0613 - val_loss: 0.7371\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8792 - val_loss: 0.3768\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.8687 - val_loss: 0.4763\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9037 - val_loss: 0.6669\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.9006 - val_loss: 0.7927\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.8363 - val_loss: 0.8267\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6916 - val_loss: 0.6038\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.7508 - val_loss: 0.4489\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.7654 - val_loss: 0.4593\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6571 - val_loss: 0.8049\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5280 - val_loss: 0.4825\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6677 - val_loss: 0.6550\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5982 - val_loss: 0.5763\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6021 - val_loss: 0.4104\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4524 - val_loss: 0.5733\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5417 - val_loss: 0.5345\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5058 - val_loss: 0.5870\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4846 - val_loss: 0.6198\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4495 - val_loss: 0.4019\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4735 - val_loss: 0.3449\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4058 - val_loss: 0.3363\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 29.0623 - val_loss: 7.9432\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.8139 - val_loss: 7.8003\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 7.6602 - val_loss: 7.6362\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 7.4911 - val_loss: 7.4614\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 7.3140 - val_loss: 7.2811\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 7.1329 - val_loss: 7.0976\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.9496 - val_loss: 6.9137\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.7661 - val_loss: 6.7292\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.5832 - val_loss: 6.5460\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 6.4017 - val_loss: 6.3650\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.2222 - val_loss: 6.1852\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 6.0448 - val_loss: 6.0080\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.8701 - val_loss: 5.8346\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.6983 - val_loss: 5.6632\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.5294 - val_loss: 5.4946\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.3634 - val_loss: 5.3294\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 5.2006 - val_loss: 5.1674\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 5.0408 - val_loss: 5.0087\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.8844 - val_loss: 4.8528\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.7311 - val_loss: 4.7005\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.5811 - val_loss: 4.5512\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.4344 - val_loss: 4.4056\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.2908 - val_loss: 4.2633\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 4.1506 - val_loss: 4.1240\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 4.0140 - val_loss: 3.9875\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.8800 - val_loss: 3.8548\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.7496 - val_loss: 3.7250\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.6222 - val_loss: 3.5983\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.4982 - val_loss: 3.4755\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.3773 - val_loss: 3.3554\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 3.2593 - val_loss: 3.2383\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.1445 - val_loss: 3.1244\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.0328 - val_loss: 3.0131\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.9241 - val_loss: 2.9052\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.8183 - val_loss: 2.8001\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.7154 - val_loss: 2.6982\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.6154 - val_loss: 2.5991\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.5184 - val_loss: 2.5023\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.4240 - val_loss: 2.4089\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.3322 - val_loss: 2.3179\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.2434 - val_loss: 2.2298\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 2.1571 - val_loss: 2.1445\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.0736 - val_loss: 2.0613\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.9926 - val_loss: 1.9806\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.9140 - val_loss: 1.9030\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8380 - val_loss: 1.8275\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.7644 - val_loss: 1.7543\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6931 - val_loss: 1.6837\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6243 - val_loss: 1.6152\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.5577 - val_loss: 1.5493\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4936 - val_loss: 1.4858\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.4317 - val_loss: 1.4241\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3717 - val_loss: 1.3650\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3142 - val_loss: 1.3076\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2587 - val_loss: 1.2529\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2053 - val_loss: 1.1999\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1539 - val_loss: 1.1484\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1043 - val_loss: 1.0995\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.0568 - val_loss: 1.0525\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.0112 - val_loss: 1.0071\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9674 - val_loss: 0.9636\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.9252 - val_loss: 0.9223\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8851 - val_loss: 0.8821\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8465 - val_loss: 0.8438\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8094 - val_loss: 0.8075\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7743 - val_loss: 0.7721\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7406 - val_loss: 0.7384\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7083 - val_loss: 0.7068\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6778 - val_loss: 0.6761\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6484 - val_loss: 0.6475\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6209 - val_loss: 0.6198\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5944 - val_loss: 0.5938\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5694 - val_loss: 0.5690\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5456 - val_loss: 0.5452\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5231 - val_loss: 0.5229\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5016 - val_loss: 0.5018\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4815 - val_loss: 0.4815\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4624 - val_loss: 0.4627\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4443 - val_loss: 0.4449\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4274 - val_loss: 0.4279\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4113 - val_loss: 0.4120\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3963 - val_loss: 0.3969\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3821 - val_loss: 0.3830\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3690 - val_loss: 0.3699\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3568 - val_loss: 0.3575\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3451 - val_loss: 0.3463\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3345 - val_loss: 0.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3244 - val_loss: 0.3255\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3152 - val_loss: 0.3161\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3065 - val_loss: 0.3075\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2985 - val_loss: 0.2995\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2911 - val_loss: 0.2922\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2844 - val_loss: 0.2854\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2782 - val_loss: 0.2791\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2724 - val_loss: 0.2732\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2671 - val_loss: 0.2679\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2621 - val_loss: 0.2630\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2577 - val_loss: 0.2586\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2537 - val_loss: 0.2544\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2500 - val_loss: 0.2506\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2466 - val_loss: 0.2472\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2437 - val_loss: 0.2442\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2409 - val_loss: 0.2414\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2385 - val_loss: 0.2389\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2363 - val_loss: 0.2366\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2343 - val_loss: 0.2345\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2325 - val_loss: 0.2327\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2309 - val_loss: 0.2311\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2295 - val_loss: 0.2296\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2283 - val_loss: 0.2281\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2271 - val_loss: 0.2270\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2262 - val_loss: 0.2260\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2254 - val_loss: 0.2250\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2246 - val_loss: 0.2242\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2239 - val_loss: 0.2235\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2234 - val_loss: 0.2229\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2229 - val_loss: 0.2223\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2225 - val_loss: 0.2218\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2221 - val_loss: 0.2214\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2218 - val_loss: 0.2211\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2215 - val_loss: 0.2207\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2213 - val_loss: 0.2204\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2211 - val_loss: 0.2202\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2210 - val_loss: 0.2200\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2208 - val_loss: 0.2198\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2207 - val_loss: 0.2197\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2206 - val_loss: 0.2195\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2205 - val_loss: 0.2194\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2205 - val_loss: 0.2193\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2204 - val_loss: 0.2193\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2204 - val_loss: 0.2192\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2191\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2189\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2189\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2203 - val_loss: 0.2189\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2189\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 00151: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total=15.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 17s 12ms/step - loss: 6.8299 - val_loss: 0.7028\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.4108 - val_loss: 0.6075\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.3382 - val_loss: 1.5465\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.0775 - val_loss: 2.0382\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.0910 - val_loss: 2.1078\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8385 - val_loss: 1.2712\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9433 - val_loss: 2.1318\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.6965 - val_loss: 1.6494\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6172 - val_loss: 2.0035\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4991 - val_loss: 1.4490\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5257 - val_loss: 1.5087\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4943 - val_loss: 1.1641\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4487 - val_loss: 1.0444\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3368 - val_loss: 1.0982\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3257 - val_loss: 0.8735\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2527 - val_loss: 0.5989\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2196 - val_loss: 0.5306\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2599 - val_loss: 0.5454\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2331 - val_loss: 0.5441\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2379 - val_loss: 0.3850\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2307 - val_loss: 0.4604\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2228 - val_loss: 0.4490\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2354 - val_loss: 0.5268\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2312 - val_loss: 0.4860\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2481 - val_loss: 0.3939\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2010 - val_loss: 0.6105\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2182 - val_loss: 0.4261\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2112 - val_loss: 0.4311\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2180 - val_loss: 0.3626\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2100 - val_loss: 0.3948\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2279 - val_loss: 0.4593\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2040 - val_loss: 0.4245\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2125 - val_loss: 0.4496\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2039 - val_loss: 0.4447\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2048 - val_loss: 0.4470\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2117 - val_loss: 0.3870\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2143 - val_loss: 0.3101\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2212 - val_loss: 0.4808\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2036 - val_loss: 0.3943\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2081 - val_loss: 0.4374\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2000 - val_loss: 0.4436\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2120 - val_loss: 0.4846\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1964 - val_loss: 0.3618\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1842 - val_loss: 0.4473\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1981 - val_loss: 0.4516\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1964 - val_loss: 0.5659\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1965 - val_loss: 0.4484\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1948 - val_loss: 0.4832\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2045 - val_loss: 0.4819\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1928 - val_loss: 0.5531\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1957 - val_loss: 0.5084\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2004 - val_loss: 0.4092\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1701 - val_loss: 0.4190\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1839 - val_loss: 0.4140\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1857 - val_loss: 0.4118\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1975 - val_loss: 0.4801\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1925 - val_loss: 0.4972\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1905 - val_loss: 0.5226\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1794 - val_loss: 0.5354\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1809 - val_loss: 0.4441\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2008 - val_loss: 0.5355\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.1835 - val_loss: 0.5408\n",
      "Epoch 00062: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 7.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 12ms/step - loss: 10.4384 - val_loss: 0.5462\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.5614 - val_loss: 0.2144\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4615 - val_loss: 1.2819\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1713 - val_loss: 1.2480\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9320 - val_loss: 1.0727\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8376 - val_loss: 1.7757\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7362 - val_loss: 1.9858\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6749 - val_loss: 2.3879\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6813 - val_loss: 2.1632\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5945 - val_loss: 2.4875\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5632 - val_loss: 1.9957\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5505 - val_loss: 1.6573\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5271 - val_loss: 1.8237\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4316 - val_loss: 1.8108\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4768 - val_loss: 1.3850\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4883 - val_loss: 1.3905\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4068 - val_loss: 1.0304\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3589 - val_loss: 0.8515\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3413 - val_loss: 0.3456\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2733 - val_loss: 0.3088\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2775 - val_loss: 0.2839\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2565 - val_loss: 0.2925\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2431 - val_loss: 0.3515\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2446 - val_loss: 0.3152\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2425 - val_loss: 0.3886\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2442 - val_loss: 0.3175\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2160 - val_loss: 0.3630\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 3.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 12ms/step - loss: 8.9017 - val_loss: 0.4695\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5394 - val_loss: 0.7933\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2680 - val_loss: 0.3868\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0782 - val_loss: 1.0438\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7754 - val_loss: 1.5156\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8335 - val_loss: 1.7107\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8025 - val_loss: 3.0743\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6360 - val_loss: 2.1228\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6364 - val_loss: 2.5508\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6183 - val_loss: 2.2181\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4895 - val_loss: 2.1110\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4733 - val_loss: 2.0802\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4510 - val_loss: 1.8866\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4235 - val_loss: 1.6944\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4127 - val_loss: 1.8537\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3611 - val_loss: 1.7351\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3698 - val_loss: 1.5893\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3281 - val_loss: 1.2423\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2995 - val_loss: 1.0861\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3050 - val_loss: 1.5616\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2606 - val_loss: 1.2898\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2692 - val_loss: 1.1643\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2516 - val_loss: 1.3828\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2427 - val_loss: 1.0113\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2130 - val_loss: 0.9519\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1966 - val_loss: 1.0117\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1977 - val_loss: 0.9503\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1901 - val_loss: 0.7299\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 3.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 13ms/step - loss: 12.5648 - val_loss: 0.6288\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4115 - val_loss: 0.6376\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3333 - val_loss: 0.9638\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1608 - val_loss: 1.0973\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9976 - val_loss: 1.5482\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9031 - val_loss: 0.9099\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8385 - val_loss: 1.4169\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7507 - val_loss: 2.2386\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6613 - val_loss: 1.7685\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6398 - val_loss: 2.0509\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5318 - val_loss: 2.1060\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5721 - val_loss: 1.7292\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5713 - val_loss: 1.8605\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5038 - val_loss: 2.2642\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4546 - val_loss: 1.8930\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3899 - val_loss: 1.6770\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3428 - val_loss: 1.6760\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4186 - val_loss: 1.5264\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4609 - val_loss: 1.5103\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3812 - val_loss: 1.3524\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3014 - val_loss: 1.1586\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2767 - val_loss: 0.9925\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2478 - val_loss: 0.8892\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2560 - val_loss: 0.8434\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2519 - val_loss: 0.4948\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2392 - val_loss: 0.6537\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2324 - val_loss: 0.4394\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2349 - val_loss: 0.4289\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2007 - val_loss: 0.5003\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2175 - val_loss: 0.3661\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2254 - val_loss: 0.3942\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1964 - val_loss: 0.4083\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1980 - val_loss: 0.4379\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1970 - val_loss: 0.5403\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1800 - val_loss: 0.4959\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1831 - val_loss: 0.4694\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1687 - val_loss: 0.5119\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1816 - val_loss: 0.4738\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1871 - val_loss: 0.5851\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1960 - val_loss: 0.5274\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1738 - val_loss: 0.5179\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1779 - val_loss: 0.4793\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1749 - val_loss: 0.4380\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1748 - val_loss: 0.6008\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1737 - val_loss: 0.4654\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1742 - val_loss: 0.5790\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1689 - val_loss: 0.5077\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1713 - val_loss: 0.5796\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1655 - val_loss: 0.4943\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1737 - val_loss: 0.6615\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1786 - val_loss: 0.4980\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1668 - val_loss: 0.5227\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1691 - val_loss: 0.4340\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1644 - val_loss: 0.6411\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1619 - val_loss: 0.4638\n",
      "Epoch 00055: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 6.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 13ms/step - loss: 10.5938 - val_loss: 0.4135\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2866 - val_loss: 0.4224\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2119 - val_loss: 0.8550\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0174 - val_loss: 1.5330\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0357 - val_loss: 1.6135\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7969 - val_loss: 1.5714\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7744 - val_loss: 1.1815\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6855 - val_loss: 2.2154\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6095 - val_loss: 1.8548\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6338 - val_loss: 1.9076\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5956 - val_loss: 2.5852\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5211 - val_loss: 2.5973\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5050 - val_loss: 2.2347\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4034 - val_loss: 1.7649\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3908 - val_loss: 1.7704\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3814 - val_loss: 1.9425\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4086 - val_loss: 1.8228\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3908 - val_loss: 1.8549\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3491 - val_loss: 1.6664\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3102 - val_loss: 1.8836\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3557 - val_loss: 1.6287\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3706 - val_loss: 1.2121\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2998 - val_loss: 0.8297\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2717 - val_loss: 0.5153\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2653 - val_loss: 0.7330\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2070 - val_loss: 0.7307\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 3.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 18s 13ms/step - loss: 5.1207 - val_loss: 1.9524\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.1575 - val_loss: 2.1154\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.0971 - val_loss: 3.0291\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9185 - val_loss: 2.6420\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9087 - val_loss: 3.4473\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8359 - val_loss: 2.6519\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.7679 - val_loss: 2.2850\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5485 - val_loss: 2.0187\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3887 - val_loss: 1.4050\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3695 - val_loss: 0.7125\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3339 - val_loss: 0.6682\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3041 - val_loss: 0.4783\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2861 - val_loss: 0.3824\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3147 - val_loss: 0.2506\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3245 - val_loss: 0.2229\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3230 - val_loss: 0.2243\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3114 - val_loss: 0.2242\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3035 - val_loss: 0.2241\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2955 - val_loss: 0.2241\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3012 - val_loss: 0.2247\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3130 - val_loss: 0.2308\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3038 - val_loss: 0.2243\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3042 - val_loss: 0.2244\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2864 - val_loss: 0.2250\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3174 - val_loss: 0.2281\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2974 - val_loss: 0.2309\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2817 - val_loss: 0.2254\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3080 - val_loss: 0.2315\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2783 - val_loss: 0.2256\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2946 - val_loss: 0.2372\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2970 - val_loss: 0.2269\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2916 - val_loss: 0.2257\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2774 - val_loss: 0.2262\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2887 - val_loss: 0.2266\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2908 - val_loss: 0.2294\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2937 - val_loss: 0.2265\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2846 - val_loss: 0.2303\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2817 - val_loss: 0.2297\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2960 - val_loss: 0.2264\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2761 - val_loss: 0.2264\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 5.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 13ms/step - loss: 5.1280 - val_loss: 2.2851\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4639 - val_loss: 2.8921\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1651 - val_loss: 2.9608\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9413 - val_loss: 3.5545\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8055 - val_loss: 2.7486\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7403 - val_loss: 2.4840\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6321 - val_loss: 2.5580\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4742 - val_loss: 1.6159\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3948 - val_loss: 1.0216\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3455 - val_loss: 0.7515\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3296 - val_loss: 0.3831\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2879 - val_loss: 0.3229\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2769 - val_loss: 0.4027\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2820 - val_loss: 0.3997\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2659 - val_loss: 0.3741\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2658 - val_loss: 0.3643\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2670 - val_loss: 0.3521\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2593 - val_loss: 0.3188\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 6ms/step - loss: 0.2380 - val_loss: 0.3647\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2329 - val_loss: 0.2991\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2438 - val_loss: 0.3498\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2359 - val_loss: 0.4346\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2418 - val_loss: 0.3249\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2287 - val_loss: 0.3187\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2383 - val_loss: 0.4098\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2299 - val_loss: 0.3167\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2253 - val_loss: 0.3235\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2306 - val_loss: 0.3304\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2162 - val_loss: 0.2833\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2116 - val_loss: 0.3170\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2032 - val_loss: 0.3435\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2069 - val_loss: 0.3264\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2116 - val_loss: 0.2925\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2128 - val_loss: 0.3206\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2106 - val_loss: 0.3029\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2056 - val_loss: 0.3002\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2063 - val_loss: 0.2918\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2157 - val_loss: 0.3486\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2072 - val_loss: 0.3329\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2064 - val_loss: 0.3006\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2027 - val_loss: 0.3667\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2055 - val_loss: 0.3709\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1945 - val_loss: 0.2911\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2202 - val_loss: 0.3485\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2115 - val_loss: 0.3243\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2812 - val_loss: 0.2254\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2718 - val_loss: 0.2209\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2744 - val_loss: 0.2210\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2680 - val_loss: 0.2207\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2643 - val_loss: 0.2243\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2729 - val_loss: 0.2213\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2653 - val_loss: 0.2209\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2697 - val_loss: 0.2235\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2752 - val_loss: 0.2251\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2700 - val_loss: 0.2206\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2589 - val_loss: 0.2213\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2690 - val_loss: 0.2235\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2622 - val_loss: 0.2279\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2584 - val_loss: 0.2208\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2702 - val_loss: 0.2214\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2608 - val_loss: 0.2218\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2731 - val_loss: 0.2220\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2599 - val_loss: 0.2215\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2597 - val_loss: 0.2205\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2690 - val_loss: 0.2232\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2747 - val_loss: 0.2211\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2676 - val_loss: 0.2204\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2685 - val_loss: 0.2226\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2613 - val_loss: 0.2234\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2615 - val_loss: 0.2225\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2567 - val_loss: 0.2204\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2634 - val_loss: 0.2208\n",
      "Epoch 00072: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 9.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 18s 14ms/step - loss: 4.8372 - val_loss: 0.8908\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3360 - val_loss: 2.6988\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2284 - val_loss: 2.6730\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0035 - val_loss: 3.2085\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7655 - val_loss: 3.1023\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6978 - val_loss: 3.0344\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6747 - val_loss: 2.4987\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5417 - val_loss: 2.4087\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5401 - val_loss: 2.1744\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4064 - val_loss: 1.7383\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3313 - val_loss: 1.4432\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3361 - val_loss: 1.5204\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3324 - val_loss: 0.9875\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3607 - val_loss: 0.3545\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3311 - val_loss: 0.2323\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3186 - val_loss: 0.2251\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2937 - val_loss: 0.2210\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3051 - val_loss: 0.2218\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2911 - val_loss: 0.2212\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2925 - val_loss: 0.2206\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2937 - val_loss: 0.2247\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2914 - val_loss: 0.2219\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 6ms/step - loss: 0.3024 - val_loss: 0.2230\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2927 - val_loss: 0.2234\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2766 - val_loss: 0.2211\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2788 - val_loss: 0.2216\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2940 - val_loss: 0.2210\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2890 - val_loss: 0.2214\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2781 - val_loss: 0.2210\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2851 - val_loss: 0.2233\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2837 - val_loss: 0.2221\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2805 - val_loss: 0.2235\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2742 - val_loss: 0.2208\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2761 - val_loss: 0.2230\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2610 - val_loss: 0.2209\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2643 - val_loss: 0.2216\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2792 - val_loss: 0.2235\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.2821 - val_loss: 0.2218\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2719 - val_loss: 0.2213\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2695 - val_loss: 0.2219\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2739 - val_loss: 0.2232\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2780 - val_loss: 0.2222\n",
      "Epoch 00042: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 5.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 14ms/step - loss: 4.3447 - val_loss: 1.8183\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2941 - val_loss: 2.2859\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0344 - val_loss: 2.7424\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8739 - val_loss: 3.0958\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7475 - val_loss: 2.9938\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6664 - val_loss: 2.8093\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5888 - val_loss: 2.4085\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5825 - val_loss: 3.0243\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5214 - val_loss: 1.4516\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3622 - val_loss: 1.1913\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3773 - val_loss: 0.5762\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3339 - val_loss: 0.3692\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3122 - val_loss: 0.4049\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2566 - val_loss: 0.3304\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2484 - val_loss: 0.3829\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2243 - val_loss: 0.3848\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2535 - val_loss: 0.3905\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2465 - val_loss: 0.3995\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2442 - val_loss: 0.3410\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2346 - val_loss: 0.3322\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2318 - val_loss: 0.2580\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2378 - val_loss: 0.3120\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 6ms/step - loss: 0.2161 - val_loss: 0.3483\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2336 - val_loss: 0.2911\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2294 - val_loss: 0.4264\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2261 - val_loss: 0.3590\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2235 - val_loss: 0.3191\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2184 - val_loss: 0.3285\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2083 - val_loss: 0.3408\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2000 - val_loss: 0.3481\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2061 - val_loss: 0.3620\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2029 - val_loss: 0.3203\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2139 - val_loss: 0.3494\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2004 - val_loss: 0.3408\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2007 - val_loss: 0.3355\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2105 - val_loss: 0.4190\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1969 - val_loss: 0.3074\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2193 - val_loss: 0.3098\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2055 - val_loss: 0.2967\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2069 - val_loss: 0.2910\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2097 - val_loss: 0.2906\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2186 - val_loss: 0.3092\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2048 - val_loss: 0.3094\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2054 - val_loss: 0.3463\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2120 - val_loss: 0.2775\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2118 - val_loss: 0.2940\n",
      "Epoch 00046: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 5.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 14ms/step - loss: 5.9807 - val_loss: 2.1415\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2611 - val_loss: 2.1325\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3044 - val_loss: 3.4916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2315 - val_loss: 2.3301\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9771 - val_loss: 2.2479\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7451 - val_loss: 2.4383\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7655 - val_loss: 2.4776\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6212 - val_loss: 1.4009\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4281 - val_loss: 1.1904\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3440 - val_loss: 1.3294\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2905 - val_loss: 1.1818\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3108 - val_loss: 0.9980\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2805 - val_loss: 0.8481\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3145 - val_loss: 0.9120\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2849 - val_loss: 0.6225\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3237 - val_loss: 0.4513\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2501 - val_loss: 0.4561\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2629 - val_loss: 0.3993\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2761 - val_loss: 0.3876\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2462 - val_loss: 0.3324\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2412 - val_loss: 0.3303\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2221 - val_loss: 0.3077\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2165 - val_loss: 0.3239\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2192 - val_loss: 0.3857\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2198 - val_loss: 0.3322\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2002 - val_loss: 0.3099\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1953 - val_loss: 0.2811\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1917 - val_loss: 0.2710\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2016 - val_loss: 0.3165\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2014 - val_loss: 0.2897\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1997 - val_loss: 0.3466\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2091 - val_loss: 0.2217\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2131 - val_loss: 0.2746\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1885 - val_loss: 0.2639\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2078 - val_loss: 0.2534\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1977 - val_loss: 0.2924\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1978 - val_loss: 0.2583\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1914 - val_loss: 0.2452\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1916 - val_loss: 0.2666\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1762 - val_loss: 0.2651\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1751 - val_loss: 0.2830\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1965 - val_loss: 0.2637\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1891 - val_loss: 0.3036\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1813 - val_loss: 0.2413\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1710 - val_loss: 0.2447\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1751 - val_loss: 0.2606\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1504 - val_loss: 0.2385\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1781 - val_loss: 0.2583\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1678 - val_loss: 0.2431\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1661 - val_loss: 0.2497\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1709 - val_loss: 0.2623\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1632 - val_loss: 0.2831\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1824 - val_loss: 0.2094\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1846 - val_loss: 0.2725\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1652 - val_loss: 0.2517\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1633 - val_loss: 0.2481\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.1752 - val_loss: 0.3167\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.1742 - val_loss: 0.2912\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1656 - val_loss: 0.2571\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1663 - val_loss: 0.2574\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1612 - val_loss: 0.2280\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1612 - val_loss: 0.2701\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1602 - val_loss: 0.2509\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1765 - val_loss: 0.2648\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1809 - val_loss: 0.2887\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1544 - val_loss: 0.2343\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1605 - val_loss: 0.2715\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1657 - val_loss: 0.2662\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.1636 - val_loss: 0.2679\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1641 - val_loss: 0.2531\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1562 - val_loss: 0.2852\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1675 - val_loss: 0.2436\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1583 - val_loss: 0.3047\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1776 - val_loss: 0.2462\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1633 - val_loss: 0.2518\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1633 - val_loss: 0.2907\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1563 - val_loss: 0.2565\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1646 - val_loss: 0.2931\n",
      "Epoch 00078: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 9.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 13s 9ms/step - loss: 42.1233 - val_loss: 25.6407\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 17.2053 - val_loss: 8.8843\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.3634 - val_loss: 2.4291\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.1315 - val_loss: 0.6194\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.0313 - val_loss: 0.2767\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8656 - val_loss: 0.2215\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8491 - val_loss: 0.2189\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8325 - val_loss: 0.2192\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7809 - val_loss: 0.2233\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8147 - val_loss: 0.2239\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7725 - val_loss: 0.2204\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6917 - val_loss: 0.2228\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7422 - val_loss: 0.2203\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7335 - val_loss: 0.2199\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7134 - val_loss: 0.2223\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6905 - val_loss: 0.2223\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7035 - val_loss: 0.2203\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6680 - val_loss: 0.2246\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6255 - val_loss: 0.2222\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6154 - val_loss: 0.2199\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6567 - val_loss: 0.2231\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5878 - val_loss: 0.2237\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5855 - val_loss: 0.2202\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5667 - val_loss: 0.2209\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5813 - val_loss: 0.2217\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5662 - val_loss: 0.2195\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5137 - val_loss: 0.2201\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5102 - val_loss: 0.2213\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4671 - val_loss: 0.2201\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4922 - val_loss: 0.2239\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4870 - val_loss: 0.2190\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4642 - val_loss: 0.2217\n",
      "Epoch 00032: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total= 1.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 34.0074 - val_loss: 19.5528\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.6411 - val_loss: 5.9003\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.2773 - val_loss: 1.3088\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5159 - val_loss: 0.3535\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9761 - val_loss: 0.2254\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9048 - val_loss: 0.2199\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9096 - val_loss: 0.2256\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8449 - val_loss: 0.2258\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8524 - val_loss: 0.2224\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8779 - val_loss: 0.2201\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8176 - val_loss: 0.2211\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7883 - val_loss: 0.2224\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8328 - val_loss: 0.2213\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7777 - val_loss: 0.2205\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6837 - val_loss: 0.2205\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6817 - val_loss: 0.2220\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6636 - val_loss: 0.2262\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6569 - val_loss: 0.2228\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6575 - val_loss: 0.2245\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6437 - val_loss: 0.2215\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6322 - val_loss: 0.2208\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6176 - val_loss: 0.2260\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6345 - val_loss: 0.2235\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5711 - val_loss: 0.2207\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5586 - val_loss: 0.2191\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5488 - val_loss: 0.2232\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5226 - val_loss: 0.2211\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5145 - val_loss: 0.2211\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5112 - val_loss: 0.2220\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5023 - val_loss: 0.2198\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4743 - val_loss: 0.2239\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 51.1028 - val_loss: 33.6519\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 23.7401 - val_loss: 13.0157\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.9343 - val_loss: 4.2070\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1570 - val_loss: 1.1677\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2071 - val_loss: 0.3984\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8184 - val_loss: 0.2397\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6836 - val_loss: 0.2187\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6460 - val_loss: 0.2194\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6456 - val_loss: 0.2191\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6471 - val_loss: 0.2197\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6221 - val_loss: 0.2220\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6067 - val_loss: 0.2205\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6210 - val_loss: 0.2198\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6168 - val_loss: 0.2203\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5858 - val_loss: 0.2197\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5977 - val_loss: 0.2208\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5644 - val_loss: 0.2204\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5421 - val_loss: 0.2217\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5518 - val_loss: 0.2209\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4983 - val_loss: 0.2199\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5606 - val_loss: 0.2198\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5231 - val_loss: 0.2211\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4878 - val_loss: 0.2194\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5153 - val_loss: 0.2212\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5025 - val_loss: 0.2233\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5078 - val_loss: 0.2209\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4896 - val_loss: 0.2192\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4796 - val_loss: 0.2188\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4609 - val_loss: 0.2211\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4556 - val_loss: 0.2187\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4756 - val_loss: 0.2234\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4387 - val_loss: 0.2193\n",
      "Epoch 00032: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total= 1.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 30.2967 - val_loss: 16.3409\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.6798 - val_loss: 4.4268\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1612 - val_loss: 0.9454\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2500 - val_loss: 0.2968\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8879 - val_loss: 0.2194\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8168 - val_loss: 0.2204\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8287 - val_loss: 0.2209\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8195 - val_loss: 0.2216\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7970 - val_loss: 0.2199\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7701 - val_loss: 0.2204\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7414 - val_loss: 0.2189\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6913 - val_loss: 0.2229\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6877 - val_loss: 0.2253\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7163 - val_loss: 0.2253\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6711 - val_loss: 0.2212\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6375 - val_loss: 0.2239\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6032 - val_loss: 0.2229\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6258 - val_loss: 0.2226\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5962 - val_loss: 0.2214\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5813 - val_loss: 0.2214\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5512 - val_loss: 0.2192\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5630 - val_loss: 0.2236\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5251 - val_loss: 0.2225\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5424 - val_loss: 0.2206\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5258 - val_loss: 0.2199\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4793 - val_loss: 0.2196\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5031 - val_loss: 0.2274\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4771 - val_loss: 0.2240\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4660 - val_loss: 0.2201\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4186 - val_loss: 0.2232\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 9ms/step - loss: 35.4273 - val_loss: 20.6362\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.7205 - val_loss: 6.2892\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.3226 - val_loss: 1.5198\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5125 - val_loss: 0.4145\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9759 - val_loss: 0.2298\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8800 - val_loss: 0.2186\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8461 - val_loss: 0.2197\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8124 - val_loss: 0.2208\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7459 - val_loss: 0.2196\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7334 - val_loss: 0.2192\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7435 - val_loss: 0.2203\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7093 - val_loss: 0.2199\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7395 - val_loss: 0.2215\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7095 - val_loss: 0.2190\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7115 - val_loss: 0.2222\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6883 - val_loss: 0.2220\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6638 - val_loss: 0.2206\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6683 - val_loss: 0.2213\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6047 - val_loss: 0.2242\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5465 - val_loss: 0.2206\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5976 - val_loss: 0.2243\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5685 - val_loss: 0.2209\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5374 - val_loss: 0.2192\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5380 - val_loss: 0.2206\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5136 - val_loss: 0.2239\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5336 - val_loss: 0.2227\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4949 - val_loss: 0.2209\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4467 - val_loss: 0.2206\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4616 - val_loss: 0.2214\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4709 - val_loss: 0.2211\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4515 - val_loss: 0.2251\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total= 1.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 13s 10ms/step - loss: 1.5784 - val_loss: 0.3119\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2328 - val_loss: 0.4877\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.0001 - val_loss: 0.5464\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8235 - val_loss: 0.6208\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7400 - val_loss: 0.4497\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6776 - val_loss: 0.6137\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6453 - val_loss: 0.4943\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5739 - val_loss: 0.5361\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5622 - val_loss: 0.5401\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5245 - val_loss: 0.3419\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4995 - val_loss: 0.3400\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4557 - val_loss: 0.3488\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4178 - val_loss: 0.3090\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4202 - val_loss: 0.3700\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3991 - val_loss: 0.2666\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3982 - val_loss: 0.3200\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3772 - val_loss: 0.2700\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3908 - val_loss: 0.2656\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3538 - val_loss: 0.2499\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3646 - val_loss: 0.2475\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3747 - val_loss: 0.2328\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3651 - val_loss: 0.2311\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3532 - val_loss: 0.2354\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3599 - val_loss: 0.2272\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3439 - val_loss: 0.2222\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3648 - val_loss: 0.2298\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3443 - val_loss: 0.2248\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3360 - val_loss: 0.2224\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3347 - val_loss: 0.2214\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3487 - val_loss: 0.2269\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3489 - val_loss: 0.2244\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3249 - val_loss: 0.2223\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3460 - val_loss: 0.2186\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3299 - val_loss: 0.2203\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3391 - val_loss: 0.2326\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3150 - val_loss: 0.2186\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3343 - val_loss: 0.2201\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3285 - val_loss: 0.2188\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3331 - val_loss: 0.2254\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3400 - val_loss: 0.2186\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3225 - val_loss: 0.2187\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3185 - val_loss: 0.2241\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3255 - val_loss: 0.2212\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3150 - val_loss: 0.2237\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3244 - val_loss: 0.2196\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3073 - val_loss: 0.2206\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3117 - val_loss: 0.2257\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3214 - val_loss: 0.2215\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3204 - val_loss: 0.2195\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3041 - val_loss: 0.2188\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3124 - val_loss: 0.2236\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3152 - val_loss: 0.2212\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3212 - val_loss: 0.2186\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3174 - val_loss: 0.2255\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3221 - val_loss: 0.2217\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2973 - val_loss: 0.2186\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3068 - val_loss: 0.2196\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3088 - val_loss: 0.2219\n",
      "Epoch 00058: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 2.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 10ms/step - loss: 1.8662 - val_loss: 0.4923\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2883 - val_loss: 0.4389\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1149 - val_loss: 0.4823\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9980 - val_loss: 0.5881\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7826 - val_loss: 0.7844\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7398 - val_loss: 0.7708\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6437 - val_loss: 0.5646\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5887 - val_loss: 0.5530\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5645 - val_loss: 0.6790\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5619 - val_loss: 0.4882\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5146 - val_loss: 0.6351\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4785 - val_loss: 0.3941\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4374 - val_loss: 0.4047\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4280 - val_loss: 0.3836\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4108 - val_loss: 0.3034\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4023 - val_loss: 0.3701\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3813 - val_loss: 0.3415\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4114 - val_loss: 0.3123\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3839 - val_loss: 0.2951\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3572 - val_loss: 0.2671\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3577 - val_loss: 0.2633\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3636 - val_loss: 0.2487\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3570 - val_loss: 0.2676\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3671 - val_loss: 0.2544\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3543 - val_loss: 0.2384\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3426 - val_loss: 0.2243\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3398 - val_loss: 0.2312\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3478 - val_loss: 0.2246\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3372 - val_loss: 0.2360\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3412 - val_loss: 0.2396\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3283 - val_loss: 0.2206\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3169 - val_loss: 0.2305\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3226 - val_loss: 0.2442\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3436 - val_loss: 0.2230\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3254 - val_loss: 0.2241\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3360 - val_loss: 0.2196\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3216 - val_loss: 0.2398\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3429 - val_loss: 0.2187\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3142 - val_loss: 0.2202\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3169 - val_loss: 0.2191\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3139 - val_loss: 0.2246\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3270 - val_loss: 0.2191\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3064 - val_loss: 0.2199\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3045 - val_loss: 0.2238\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3178 - val_loss: 0.2212\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3037 - val_loss: 0.2186\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3068 - val_loss: 0.2202\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2996 - val_loss: 0.2205\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2994 - val_loss: 0.2187\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2968 - val_loss: 0.2210\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3096 - val_loss: 0.2239\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3137 - val_loss: 0.2187\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3063 - val_loss: 0.2249\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3099 - val_loss: 0.2201\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3062 - val_loss: 0.2197\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3011 - val_loss: 0.2241\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2932 - val_loss: 0.2223\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2984 - val_loss: 0.2195\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3016 - val_loss: 0.2236\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3038 - val_loss: 0.2201\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3002 - val_loss: 0.2222\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2965 - val_loss: 0.2205\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2905 - val_loss: 0.2212\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 2.8min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 13s 10ms/step - loss: 1.7806 - val_loss: 0.5121\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1943 - val_loss: 0.3949\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0939 - val_loss: 0.7216\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8563 - val_loss: 0.6344\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8326 - val_loss: 0.5697\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8109 - val_loss: 0.7808\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6858 - val_loss: 0.7254\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6087 - val_loss: 0.4860\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5749 - val_loss: 0.5154\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5332 - val_loss: 0.5325\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5110 - val_loss: 0.4650\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4553 - val_loss: 0.4422\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4681 - val_loss: 0.5023\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4599 - val_loss: 0.4129\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4104 - val_loss: 0.3609\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4293 - val_loss: 0.3333\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3939 - val_loss: 0.3202\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3898 - val_loss: 0.2769\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3898 - val_loss: 0.2914\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3698 - val_loss: 0.2657\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3464 - val_loss: 0.2601\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3450 - val_loss: 0.2493\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3505 - val_loss: 0.2478\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3596 - val_loss: 0.2585\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3491 - val_loss: 0.2536\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3560 - val_loss: 0.2689\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3442 - val_loss: 0.2293\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3351 - val_loss: 0.2363\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3273 - val_loss: 0.2261\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3266 - val_loss: 0.2323\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3312 - val_loss: 0.2196\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3421 - val_loss: 0.2569\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3303 - val_loss: 0.2207\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3173 - val_loss: 0.2310\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3377 - val_loss: 0.2251\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3205 - val_loss: 0.2194\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3093 - val_loss: 0.2193\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3341 - val_loss: 0.2255\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3275 - val_loss: 0.2299\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3326 - val_loss: 0.2187\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3243 - val_loss: 0.2195\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3162 - val_loss: 0.2201\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3131 - val_loss: 0.2205\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3193 - val_loss: 0.2196\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3221 - val_loss: 0.2234\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3133 - val_loss: 0.2187\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3168 - val_loss: 0.2183\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2980 - val_loss: 0.2221\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3225 - val_loss: 0.2224\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3118 - val_loss: 0.2176\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3068 - val_loss: 0.2208\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2999 - val_loss: 0.2198\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3052 - val_loss: 0.2217\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3053 - val_loss: 0.2179\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3120 - val_loss: 0.2194\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2881 - val_loss: 0.2217\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3069 - val_loss: 0.2175\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2815 - val_loss: 0.2169\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2874 - val_loss: 0.2302\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3006 - val_loss: 0.2216\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2998 - val_loss: 0.2284\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2867 - val_loss: 0.2178\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2830 - val_loss: 0.2141\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2963 - val_loss: 0.2215\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2976 - val_loss: 0.2130\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2748 - val_loss: 0.2183\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2909 - val_loss: 0.2195\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2930 - val_loss: 0.2119\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2829 - val_loss: 0.2178\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2669 - val_loss: 0.2122\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2762 - val_loss: 0.2096\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2738 - val_loss: 0.2036\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2755 - val_loss: 0.2096\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2691 - val_loss: 0.2088\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2693 - val_loss: 0.2130\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2788 - val_loss: 0.2058\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2548 - val_loss: 0.2008\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2697 - val_loss: 0.2055\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2670 - val_loss: 0.2008\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2565 - val_loss: 0.2000\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2815 - val_loss: 0.2021\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2543 - val_loss: 0.1952\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2474 - val_loss: 0.2034\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2476 - val_loss: 0.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2713 - val_loss: 0.2132\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2655 - val_loss: 0.1992\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2615 - val_loss: 0.1974\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2497 - val_loss: 0.2124\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2649 - val_loss: 0.1992\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2476 - val_loss: 0.2011\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2693 - val_loss: 0.1985\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2533 - val_loss: 0.2028\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2483 - val_loss: 0.1979\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2486 - val_loss: 0.1937\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2610 - val_loss: 0.2021\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2581 - val_loss: 0.2041\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2422 - val_loss: 0.1986\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2415 - val_loss: 0.1987\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2455 - val_loss: 0.2043\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2450 - val_loss: 0.2012\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2495 - val_loss: 0.2043\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2411 - val_loss: 0.1989\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2347 - val_loss: 0.1957\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2297 - val_loss: 0.2004\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2483 - val_loss: 0.1940\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2351 - val_loss: 0.2030\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2414 - val_loss: 0.1988\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2344 - val_loss: 0.1966\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2230 - val_loss: 0.1944\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2309 - val_loss: 0.2127\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2428 - val_loss: 0.1955\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2281 - val_loss: 0.1926\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2356 - val_loss: 0.1957\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2199 - val_loss: 0.1933\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2374 - val_loss: 0.1939\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2216 - val_loss: 0.1943\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2198 - val_loss: 0.1985\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2248 - val_loss: 0.1997\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2247 - val_loss: 0.2044\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2225 - val_loss: 0.1945\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2170 - val_loss: 0.1913\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2184 - val_loss: 0.1908\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2156 - val_loss: 0.2029\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2154 - val_loss: 0.1980\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.1970\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2253 - val_loss: 0.2104\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2197 - val_loss: 0.2453\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2340 - val_loss: 0.1916\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2230 - val_loss: 0.2019\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2194 - val_loss: 0.2024\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2173 - val_loss: 0.1980\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2198 - val_loss: 0.2012\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2195 - val_loss: 0.1973\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2155 - val_loss: 0.2012\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2123 - val_loss: 0.1971\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2169 - val_loss: 0.1901\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2163 - val_loss: 0.1924\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2143 - val_loss: 0.2079\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2148 - val_loss: 0.1855\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2315 - val_loss: 0.2211\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2156 - val_loss: 0.2180\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2077 - val_loss: 0.2052\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2453 - val_loss: 0.2208\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2579 - val_loss: 0.2211\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2551 - val_loss: 0.2277\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2492 - val_loss: 0.2190\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2526 - val_loss: 0.2186\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2574 - val_loss: 0.2186\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2501 - val_loss: 0.2295\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2452 - val_loss: 0.2188\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2562 - val_loss: 0.2196\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2497 - val_loss: 0.2190\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2605 - val_loss: 0.2186\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2475 - val_loss: 0.2196\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2565 - val_loss: 0.2186\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2566 - val_loss: 0.2208\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2483 - val_loss: 0.2216\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2460 - val_loss: 0.2151\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2185 - val_loss: 0.1969\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2066 - val_loss: 0.1971\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1988 - val_loss: 0.2004\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2063 - val_loss: 0.2165\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1952 - val_loss: 0.1968\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1995 - val_loss: 0.1972\n",
      "Epoch 00164: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 7.0min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 1.7715 - val_loss: 0.3079\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2072 - val_loss: 0.7495\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0530 - val_loss: 0.5425\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9078 - val_loss: 0.6264\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8465 - val_loss: 0.5544\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6839 - val_loss: 0.7096\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6411 - val_loss: 0.6954\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6022 - val_loss: 0.7053\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5276 - val_loss: 0.5902\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5420 - val_loss: 0.5421\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4783 - val_loss: 0.4698\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4524 - val_loss: 0.5322\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4307 - val_loss: 0.4525\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4427 - val_loss: 0.3976\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4039 - val_loss: 0.3366\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4147 - val_loss: 0.3000\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3859 - val_loss: 0.2982\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3656 - val_loss: 0.3015\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3852 - val_loss: 0.2670\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3621 - val_loss: 0.2475\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3598 - val_loss: 0.2376\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3555 - val_loss: 0.2435\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3762 - val_loss: 0.2369\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3804 - val_loss: 0.2417\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3547 - val_loss: 0.2237\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3382 - val_loss: 0.2317\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3527 - val_loss: 0.2368\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3503 - val_loss: 0.2286\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3367 - val_loss: 0.2186\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3365 - val_loss: 0.2350\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3307 - val_loss: 0.2251\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3381 - val_loss: 0.2214\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3395 - val_loss: 0.2218\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3285 - val_loss: 0.2194\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3094 - val_loss: 0.2242\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3189 - val_loss: 0.2193\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3202 - val_loss: 0.2187\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3243 - val_loss: 0.2215\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3352 - val_loss: 0.2188\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3213 - val_loss: 0.2195\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3178 - val_loss: 0.2187\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3390 - val_loss: 0.2187\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3179 - val_loss: 0.2189\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3273 - val_loss: 0.2187\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3316 - val_loss: 0.2212\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2965 - val_loss: 0.2192\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3138 - val_loss: 0.2222\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2928 - val_loss: 0.2275\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3090 - val_loss: 0.2222\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3086 - val_loss: 0.2210\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3095 - val_loss: 0.2186\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3040 - val_loss: 0.2251\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3127 - val_loss: 0.2266\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3000 - val_loss: 0.2191\n",
      "Epoch 00054: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 2.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 1.6376 - val_loss: 0.2507\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3531 - val_loss: 0.4436\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0775 - val_loss: 0.4385\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9917 - val_loss: 0.6563\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8344 - val_loss: 0.2964\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7035 - val_loss: 0.5815\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6914 - val_loss: 0.4895\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6174 - val_loss: 0.5078\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5546 - val_loss: 0.5821\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4906 - val_loss: 0.5463\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4994 - val_loss: 0.3817\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4787 - val_loss: 0.3952\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4372 - val_loss: 0.3510\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4316 - val_loss: 0.3667\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3882 - val_loss: 0.2951\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3773 - val_loss: 0.2835\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3849 - val_loss: 0.3025\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3922 - val_loss: 0.2829\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3577 - val_loss: 0.2604\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3475 - val_loss: 0.2355\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3489 - val_loss: 0.2473\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3570 - val_loss: 0.2324\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3486 - val_loss: 0.2352\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3477 - val_loss: 0.2410\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3569 - val_loss: 0.2197\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3221 - val_loss: 0.2390\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3494 - val_loss: 0.2201\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3207 - val_loss: 0.2204\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3274 - val_loss: 0.2276\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3274 - val_loss: 0.2199\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3280 - val_loss: 0.2215\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3371 - val_loss: 0.2221\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3227 - val_loss: 0.2237\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3388 - val_loss: 0.2191\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3292 - val_loss: 0.2188\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3228 - val_loss: 0.2231\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2985 - val_loss: 0.2186\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3202 - val_loss: 0.2225\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3152 - val_loss: 0.2198\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3328 - val_loss: 0.2193\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3170 - val_loss: 0.2186\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3149 - val_loss: 0.2196\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3140 - val_loss: 0.2202\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3008 - val_loss: 0.2187\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3172 - val_loss: 0.2197\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3075 - val_loss: 0.2187\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2904 - val_loss: 0.2186\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3003 - val_loss: 0.2206\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3123 - val_loss: 0.2192\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3055 - val_loss: 0.2186\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2975 - val_loss: 0.2191\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3042 - val_loss: 0.2191\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3036 - val_loss: 0.2186\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2977 - val_loss: 0.2199\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2921 - val_loss: 0.2189\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3053 - val_loss: 0.2320\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3070 - val_loss: 0.2189\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2990 - val_loss: 0.2190\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2968 - val_loss: 0.2225\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2929 - val_loss: 0.2189\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2941 - val_loss: 0.2187\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3016 - val_loss: 0.2243\n",
      "Epoch 00062: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 2.9min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 14s 11ms/step - loss: 1.8529 - val_loss: 1.2600\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.1768 - val_loss: 0.8557\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.9960 - val_loss: 0.9685\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.9148 - val_loss: 1.0421\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7442 - val_loss: 0.8103\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7815 - val_loss: 0.8962\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.6476 - val_loss: 0.8424\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.6327 - val_loss: 0.7995\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5396 - val_loss: 0.6684\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5641 - val_loss: 0.5899\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5154 - val_loss: 0.4821\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4960 - val_loss: 0.4690\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4682 - val_loss: 0.3917\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4250 - val_loss: 0.3252\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4178 - val_loss: 0.3602\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4385 - val_loss: 0.3456\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3888 - val_loss: 0.3016\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3850 - val_loss: 0.2974\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3859 - val_loss: 0.2882\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3784 - val_loss: 0.2534\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3589 - val_loss: 0.2694\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3500 - val_loss: 0.2395\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3568 - val_loss: 0.2385\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3654 - val_loss: 0.2417\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3514 - val_loss: 0.2574\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3389 - val_loss: 0.2433\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3583 - val_loss: 0.2368\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3458 - val_loss: 0.2368\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3594 - val_loss: 0.2340\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3480 - val_loss: 0.2386\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3471 - val_loss: 0.2200\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3540 - val_loss: 0.2222\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3468 - val_loss: 0.2220\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3434 - val_loss: 0.2312\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3220 - val_loss: 0.2242\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3395 - val_loss: 0.2247\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3350 - val_loss: 0.2277\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3401 - val_loss: 0.2206\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3157 - val_loss: 0.2194\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3218 - val_loss: 0.2253\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3147 - val_loss: 0.2259\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3274 - val_loss: 0.2188\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3188 - val_loss: 0.2197\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3394 - val_loss: 0.2189\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3290 - val_loss: 0.2315\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3078 - val_loss: 0.2196\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3254 - val_loss: 0.2265\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3224 - val_loss: 0.2190\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3119 - val_loss: 0.2225\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3268 - val_loss: 0.2191\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3187 - val_loss: 0.2188\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3338 - val_loss: 0.2206\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3219 - val_loss: 0.2257\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3311 - val_loss: 0.2189\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3033 - val_loss: 0.2192\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3170 - val_loss: 0.2188\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3163 - val_loss: 0.2186\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3032 - val_loss: 0.2191\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3217 - val_loss: 0.2193\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3127 - val_loss: 0.2196\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3170 - val_loss: 0.2187\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3050 - val_loss: 0.2241\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3105 - val_loss: 0.2202\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3044 - val_loss: 0.2234\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3136 - val_loss: 0.2189\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.2976 - val_loss: 0.2189\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.3128 - val_loss: 0.2187\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 3.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 10ms/step - loss: 1.8780 - val_loss: 0.9716\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1734 - val_loss: 1.3547\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0457 - val_loss: 1.1324\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9536 - val_loss: 0.9528\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8818 - val_loss: 0.9238\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7497 - val_loss: 0.9910\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6856 - val_loss: 0.9383\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6410 - val_loss: 0.8676\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5787 - val_loss: 0.5424\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5457 - val_loss: 0.6594\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4971 - val_loss: 0.5544\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4787 - val_loss: 0.5059\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4461 - val_loss: 0.4213\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4230 - val_loss: 0.4332\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4070 - val_loss: 0.3966\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4227 - val_loss: 0.3922\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3952 - val_loss: 0.3944\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3739 - val_loss: 0.2857\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3644 - val_loss: 0.3007\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3698 - val_loss: 0.2865\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3562 - val_loss: 0.2683\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3539 - val_loss: 0.2915\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3562 - val_loss: 0.2605\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3418 - val_loss: 0.2378\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3615 - val_loss: 0.2420\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3303 - val_loss: 0.2457\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3340 - val_loss: 0.2411\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3376 - val_loss: 0.2482\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3319 - val_loss: 0.2202\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3402 - val_loss: 0.2360\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3171 - val_loss: 0.2193\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3162 - val_loss: 0.2277\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3278 - val_loss: 0.2227\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3146 - val_loss: 0.2235\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3286 - val_loss: 0.2209\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3231 - val_loss: 0.2199\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3251 - val_loss: 0.2253\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3140 - val_loss: 0.2285\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3282 - val_loss: 0.2264\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3111 - val_loss: 0.2298\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3112 - val_loss: 0.2186\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3074 - val_loss: 0.2314\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3092 - val_loss: 0.2229\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3056 - val_loss: 0.2188\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3044 - val_loss: 0.2197\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3094 - val_loss: 0.2186\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2962 - val_loss: 0.2192\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3209 - val_loss: 0.2201\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2954 - val_loss: 0.2259\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3222 - val_loss: 0.2229\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3028 - val_loss: 0.2200\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2970 - val_loss: 0.2243\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2981 - val_loss: 0.2186\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3011 - val_loss: 0.2198\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2984 - val_loss: 0.2195\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3037 - val_loss: 0.2198\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2994 - val_loss: 0.2187\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2970 - val_loss: 0.2186\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3089 - val_loss: 0.2267\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2988 - val_loss: 0.2267\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2966 - val_loss: 0.2195\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2807 - val_loss: 0.2188\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3044 - val_loss: 0.2226\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2994 - val_loss: 0.2187\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2938 - val_loss: 0.2189\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2910 - val_loss: 0.2224\n",
      "Epoch 00066: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 3.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 11ms/step - loss: 1.9789 - val_loss: 1.7410\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4768 - val_loss: 1.2832\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1540 - val_loss: 1.2429\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0501 - val_loss: 1.0680\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9447 - val_loss: 0.9723\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8425 - val_loss: 1.1180\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7682 - val_loss: 0.7106\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6995 - val_loss: 0.6461\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5973 - val_loss: 0.8693\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5752 - val_loss: 0.6298\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5898 - val_loss: 0.6725\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4863 - val_loss: 0.5823\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5123 - val_loss: 0.4480\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4541 - val_loss: 0.4143\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4151 - val_loss: 0.3685\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4270 - val_loss: 0.4184\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4013 - val_loss: 0.4185\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4019 - val_loss: 0.3446\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3924 - val_loss: 0.3189\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3764 - val_loss: 0.3088\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4014 - val_loss: 0.2815\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3796 - val_loss: 0.2773\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3831 - val_loss: 0.2781\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3533 - val_loss: 0.2546\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3561 - val_loss: 0.2390\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3541 - val_loss: 0.2594\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3517 - val_loss: 0.2239\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3639 - val_loss: 0.2335\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3468 - val_loss: 0.2262\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3310 - val_loss: 0.2534\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3355 - val_loss: 0.2357\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3573 - val_loss: 0.2516\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3263 - val_loss: 0.2439\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3265 - val_loss: 0.2203\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3309 - val_loss: 0.2221\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3169 - val_loss: 0.2254\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3228 - val_loss: 0.2388\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3321 - val_loss: 0.2188\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3273 - val_loss: 0.2200\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3229 - val_loss: 0.2219\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3195 - val_loss: 0.2304\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3057 - val_loss: 0.2251\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3089 - val_loss: 0.2216\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3072 - val_loss: 0.2324\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3214 - val_loss: 0.2188\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3202 - val_loss: 0.2274\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3197 - val_loss: 0.2201\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3096 - val_loss: 0.2195\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3029 - val_loss: 0.2328\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3194 - val_loss: 0.2204\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3132 - val_loss: 0.2208\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3040 - val_loss: 0.2326\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3127 - val_loss: 0.2308\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3078 - val_loss: 0.2195\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3050 - val_loss: 0.2191\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3162 - val_loss: 0.2263\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3084 - val_loss: 0.2228\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2996 - val_loss: 0.2235\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3035 - val_loss: 0.2218\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3029 - val_loss: 0.2199\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3087 - val_loss: 0.2196\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3020 - val_loss: 0.2235\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3161 - val_loss: 0.2186\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 3.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 11ms/step - loss: 1.6785 - val_loss: 1.2426\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2180 - val_loss: 1.8832\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0283 - val_loss: 1.4420\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9009 - val_loss: 0.7824\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7866 - val_loss: 1.0065\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7192 - val_loss: 0.9862\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6094 - val_loss: 0.8328\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5785 - val_loss: 0.6962\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5570 - val_loss: 0.6893\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5473 - val_loss: 0.5236\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5103 - val_loss: 0.5260\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4600 - val_loss: 0.4941\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4301 - val_loss: 0.5388\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4059 - val_loss: 0.3422\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4121 - val_loss: 0.3437\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3893 - val_loss: 0.3197\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3730 - val_loss: 0.2587\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3913 - val_loss: 0.2751\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3738 - val_loss: 0.2565\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3550 - val_loss: 0.2914\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3669 - val_loss: 0.2904\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3549 - val_loss: 0.2520\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3510 - val_loss: 0.2366\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3621 - val_loss: 0.2458\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3347 - val_loss: 0.2552\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3583 - val_loss: 0.2485\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3321 - val_loss: 0.2386\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3227 - val_loss: 0.2231\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3495 - val_loss: 0.2343\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3410 - val_loss: 0.2201\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3289 - val_loss: 0.2364\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3287 - val_loss: 0.2190\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3425 - val_loss: 0.2408\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3255 - val_loss: 0.2206\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3168 - val_loss: 0.2211\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3169 - val_loss: 0.2213\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3205 - val_loss: 0.2186\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3123 - val_loss: 0.2190\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3245 - val_loss: 0.2187\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3054 - val_loss: 0.2272\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3072 - val_loss: 0.2277\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3131 - val_loss: 0.2190\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2963 - val_loss: 0.2191\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2988 - val_loss: 0.2187\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3042 - val_loss: 0.2194\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3213 - val_loss: 0.2249\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2912 - val_loss: 0.2194\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3066 - val_loss: 0.2186\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3034 - val_loss: 0.2228\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3121 - val_loss: 0.2248\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2898 - val_loss: 0.2189\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2927 - val_loss: 0.2186\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3147 - val_loss: 0.2186\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3087 - val_loss: 0.2219\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3051 - val_loss: 0.2186\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3012 - val_loss: 0.2189\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3193 - val_loss: 0.2191\n",
      "Epoch 00057: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 2.8min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 14s 11ms/step - loss: 2.0673 - val_loss: 1.1795\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.3289 - val_loss: 1.6641\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2295 - val_loss: 1.4388\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1375 - val_loss: 1.1211\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9847 - val_loss: 0.8976\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7958 - val_loss: 0.8945\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8071 - val_loss: 0.7757\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6757 - val_loss: 0.6237\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6279 - val_loss: 0.7840\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6471 - val_loss: 0.6691\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5525 - val_loss: 0.7211\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5206 - val_loss: 0.5542\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4918 - val_loss: 0.5138\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4590 - val_loss: 0.4967\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4514 - val_loss: 0.4727\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4438 - val_loss: 0.4420\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4473 - val_loss: 0.4410\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4208 - val_loss: 0.3860\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3822 - val_loss: 0.3340\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3696 - val_loss: 0.2979\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.4143 - val_loss: 0.2867\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3830 - val_loss: 0.2776\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3651 - val_loss: 0.3032\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3539 - val_loss: 0.2652\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3661 - val_loss: 0.2630\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3348 - val_loss: 0.2444\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3422 - val_loss: 0.2314\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3479 - val_loss: 0.2510\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3356 - val_loss: 0.2446\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3378 - val_loss: 0.2579\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3168 - val_loss: 0.2441\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3318 - val_loss: 0.2347\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3334 - val_loss: 0.2204\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3136 - val_loss: 0.2260\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3253 - val_loss: 0.2312\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3282 - val_loss: 0.2189\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3132 - val_loss: 0.2270\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3207 - val_loss: 0.2314\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3202 - val_loss: 0.2224\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3152 - val_loss: 0.2324\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3147 - val_loss: 0.2207\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3212 - val_loss: 0.2220\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3123 - val_loss: 0.2233\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2983 - val_loss: 0.2187\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3051 - val_loss: 0.2381\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3252 - val_loss: 0.2221\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3080 - val_loss: 0.2192\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2903 - val_loss: 0.2201\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3068 - val_loss: 0.2187\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3027 - val_loss: 0.2187\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3053 - val_loss: 0.2187\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3264 - val_loss: 0.2186\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2935 - val_loss: 0.2186\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2974 - val_loss: 0.2191\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3078 - val_loss: 0.2190\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3040 - val_loss: 0.2240\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2984 - val_loss: 0.2196\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2957 - val_loss: 0.2215\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2925 - val_loss: 0.2223\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2966 - val_loss: 0.2255\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3075 - val_loss: 0.2294\n",
      "Epoch 00061: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 3.0min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 15s 11ms/step - loss: 84.6356 - val_loss: 44.0774\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 24.6262 - val_loss: 8.7144\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.5531 - val_loss: 1.1513\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1490 - val_loss: 0.2643\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8330 - val_loss: 0.2186\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7425 - val_loss: 0.2192\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7383 - val_loss: 0.2189\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7069 - val_loss: 0.2188\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7235 - val_loss: 0.2191\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7482 - val_loss: 0.2202\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7362 - val_loss: 0.2207\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7194 - val_loss: 0.2193\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7166 - val_loss: 0.2199\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6902 - val_loss: 0.2202\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6558 - val_loss: 0.2190\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6740 - val_loss: 0.2187\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6460 - val_loss: 0.2196\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6113 - val_loss: 0.2186\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5995 - val_loss: 0.2198\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6066 - val_loss: 0.2223\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5773 - val_loss: 0.2198\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5932 - val_loss: 0.2197\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5334 - val_loss: 0.2190\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5886 - val_loss: 0.2236\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5469 - val_loss: 0.2204\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5405 - val_loss: 0.2198\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4922 - val_loss: 0.2195\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4904 - val_loss: 0.2233\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4662 - val_loss: 0.2196\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4844 - val_loss: 0.2188\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 11ms/step - loss: 98.7950 - val_loss: 52.1423\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 30.0616 - val_loss: 12.0760\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.5604 - val_loss: 1.9045\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5741 - val_loss: 0.3421\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8765 - val_loss: 0.2216\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8397 - val_loss: 0.2190\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7683 - val_loss: 0.2187\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8408 - val_loss: 0.2189\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7456 - val_loss: 0.2195\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7932 - val_loss: 0.2189\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7624 - val_loss: 0.2205\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7420 - val_loss: 0.2203\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7537 - val_loss: 0.2189\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6984 - val_loss: 0.2197\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6707 - val_loss: 0.2188\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7657 - val_loss: 0.2195\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7029 - val_loss: 0.2190\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6427 - val_loss: 0.2201\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7056 - val_loss: 0.2193\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6380 - val_loss: 0.2188\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6440 - val_loss: 0.2194\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6343 - val_loss: 0.2187\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6146 - val_loss: 0.2209\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5700 - val_loss: 0.2201\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5590 - val_loss: 0.2207\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6050 - val_loss: 0.2201\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5556 - val_loss: 0.2210\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5004 - val_loss: 0.2188\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5014 - val_loss: 0.2225\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4941 - val_loss: 0.2186\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4843 - val_loss: 0.2187\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 73.4387 - val_loss: 33.9145\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.7929 - val_loss: 5.7527\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1394 - val_loss: 0.6716\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9977 - val_loss: 0.2278\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8396 - val_loss: 0.2187\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7988 - val_loss: 0.2189\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7693 - val_loss: 0.2186\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7491 - val_loss: 0.2204\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7846 - val_loss: 0.2186\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7680 - val_loss: 0.2188\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7652 - val_loss: 0.2196\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6515 - val_loss: 0.2205\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6769 - val_loss: 0.2196\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6819 - val_loss: 0.2193\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6624 - val_loss: 0.2187\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6664 - val_loss: 0.2186\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7000 - val_loss: 0.2194\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6012 - val_loss: 0.2185\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5947 - val_loss: 0.2197\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5944 - val_loss: 0.2187\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5766 - val_loss: 0.2189\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5489 - val_loss: 0.2187\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5364 - val_loss: 0.2188\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5371 - val_loss: 0.2188\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5237 - val_loss: 0.2216\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4907 - val_loss: 0.2212\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5297 - val_loss: 0.2186\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4738 - val_loss: 0.2198\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4736 - val_loss: 0.2193\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4600 - val_loss: 0.2195\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 84.8433 - val_loss: 43.1081\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 23.7340 - val_loss: 8.4004\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.5914 - val_loss: 1.0863\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2546 - val_loss: 0.2565\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8677 - val_loss: 0.2190\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7738 - val_loss: 0.2197\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8116 - val_loss: 0.2187\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7897 - val_loss: 0.2189\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8293 - val_loss: 0.2186\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7851 - val_loss: 0.2205\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8000 - val_loss: 0.2193\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7285 - val_loss: 0.2202\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7363 - val_loss: 0.2210\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6952 - val_loss: 0.2186\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7329 - val_loss: 0.2212\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6855 - val_loss: 0.2216\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6759 - val_loss: 0.2219\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6632 - val_loss: 0.2205\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7027 - val_loss: 0.2232\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6241 - val_loss: 0.2193\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6331 - val_loss: 0.2201\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5747 - val_loss: 0.2218\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5936 - val_loss: 0.2211\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5795 - val_loss: 0.2194\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5932 - val_loss: 0.2206\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5697 - val_loss: 0.2188\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5322 - val_loss: 0.2204\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5308 - val_loss: 0.2226\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4955 - val_loss: 0.2195\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5073 - val_loss: 0.2190\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 71.2638 - val_loss: 33.9585\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.9677 - val_loss: 5.4738\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.9454 - val_loss: 0.6047\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8771 - val_loss: 0.2287\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7104 - val_loss: 0.2190\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6857 - val_loss: 0.2187\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6909 - val_loss: 0.2187\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7472 - val_loss: 0.2187\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7281 - val_loss: 0.2224\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6703 - val_loss: 0.2211\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6607 - val_loss: 0.2188\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6627 - val_loss: 0.2194\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6370 - val_loss: 0.2204\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5966 - val_loss: 0.2225\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6063 - val_loss: 0.2186\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6089 - val_loss: 0.2186\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5717 - val_loss: 0.2186\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5636 - val_loss: 0.2186\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6349 - val_loss: 0.2239\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5754 - val_loss: 0.2201\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5365 - val_loss: 0.2232\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5634 - val_loss: 0.2189\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5359 - val_loss: 0.2206\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5026 - val_loss: 0.2186\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4968 - val_loss: 0.2197\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5095 - val_loss: 0.2187\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4631 - val_loss: 0.2197\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4694 - val_loss: 0.2191\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4706 - val_loss: 0.2199\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4453 - val_loss: 0.2200\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 16s 12ms/step - loss: 2.4763 - val_loss: 0.8671\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.3711 - val_loss: 0.6705\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.1402 - val_loss: 0.7640\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.9989 - val_loss: 0.3993\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.8283 - val_loss: 0.5388\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7841 - val_loss: 0.6228\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.7525 - val_loss: 1.0533\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.6689 - val_loss: 0.6541\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5909 - val_loss: 0.7441\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5594 - val_loss: 0.5715\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.5009 - val_loss: 0.6956\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4837 - val_loss: 0.7230\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.4310 - val_loss: 0.5808\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3940 - val_loss: 0.5666\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3808 - val_loss: 0.5530\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3855 - val_loss: 0.3822\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3829 - val_loss: 0.5500\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3449 - val_loss: 0.3713\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3541 - val_loss: 0.3992\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3480 - val_loss: 0.3890\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3229 - val_loss: 0.3615\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3280 - val_loss: 0.2936\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3368 - val_loss: 0.3626\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3165 - val_loss: 0.2783\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3190 - val_loss: 0.2690\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2999 - val_loss: 0.2792\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3077 - val_loss: 0.2919\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3219 - val_loss: 0.2637\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3047 - val_loss: 0.2472\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2989 - val_loss: 0.2549\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3033 - val_loss: 0.2642\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3178 - val_loss: 0.2329\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3201 - val_loss: 0.2282\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3072 - val_loss: 0.2640\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3109 - val_loss: 0.2328\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3004 - val_loss: 0.2377\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3127 - val_loss: 0.2193\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3006 - val_loss: 0.2586\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3074 - val_loss: 0.2257\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3076 - val_loss: 0.2243\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2932 - val_loss: 0.3007\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2985 - val_loss: 0.2678\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2899 - val_loss: 0.2329\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2964 - val_loss: 0.2248\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2838 - val_loss: 0.2371\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2938 - val_loss: 0.2191\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3042 - val_loss: 0.2204\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3068 - val_loss: 0.2289\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2880 - val_loss: 0.2216\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3020 - val_loss: 0.2270\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2890 - val_loss: 0.2187\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2983 - val_loss: 0.2192\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2924 - val_loss: 0.2590\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2985 - val_loss: 0.2186\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2806 - val_loss: 0.2188\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2789 - val_loss: 0.2193\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2914 - val_loss: 0.2241\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2857 - val_loss: 0.2193\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2842 - val_loss: 0.2187\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.3022 - val_loss: 0.2201\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2857 - val_loss: 0.2188\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 0.2783 - val_loss: 0.2242\n",
      "Epoch 00062: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 4.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 2.2017 - val_loss: 0.5275\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2562 - val_loss: 0.6414\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0731 - val_loss: 0.5286\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9137 - val_loss: 0.4181\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8401 - val_loss: 0.7035\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7582 - val_loss: 0.7181\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7100 - val_loss: 1.1309\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5967 - val_loss: 1.0690\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5282 - val_loss: 0.5523\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4675 - val_loss: 0.6876\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4156 - val_loss: 0.7292\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4033 - val_loss: 0.4357\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4032 - val_loss: 0.7154\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3813 - val_loss: 0.5569\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3926 - val_loss: 0.5366\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3484 - val_loss: 0.4525\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3510 - val_loss: 0.4326\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3274 - val_loss: 0.3913\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3354 - val_loss: 0.3037\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3239 - val_loss: 0.3669\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3093 - val_loss: 0.2852\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3139 - val_loss: 0.3247\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3080 - val_loss: 0.2729\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3058 - val_loss: 0.2893\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3074 - val_loss: 0.2600\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3011 - val_loss: 0.2946\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3143 - val_loss: 0.2671\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2908 - val_loss: 0.2613\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2927 - val_loss: 0.2316\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2921 - val_loss: 0.2362\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2958 - val_loss: 0.2700\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2923 - val_loss: 0.2356\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2998 - val_loss: 0.2592\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2911 - val_loss: 0.2377\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2939 - val_loss: 0.2371\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2843 - val_loss: 0.2294\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2963 - val_loss: 0.2264\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2874 - val_loss: 0.2403\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2804 - val_loss: 0.2211\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2788 - val_loss: 0.2244\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2882 - val_loss: 0.2220\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2858 - val_loss: 0.2186\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2887 - val_loss: 0.2222\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2785 - val_loss: 0.2261\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2779 - val_loss: 0.2318\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2881 - val_loss: 0.2322\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2788 - val_loss: 0.2245\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2767 - val_loss: 0.2337\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2724 - val_loss: 0.2202\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2995 - val_loss: 0.2190\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2760 - val_loss: 0.2251\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2788 - val_loss: 0.2238\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2858 - val_loss: 0.2191\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2832 - val_loss: 0.2189\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2851 - val_loss: 0.2201\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2741 - val_loss: 0.2194\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2713 - val_loss: 0.2216\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2781 - val_loss: 0.2206\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2727 - val_loss: 0.2269\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2703 - val_loss: 0.2186\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2682 - val_loss: 0.2204\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2715 - val_loss: 0.2215\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2708 - val_loss: 0.2190\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2769 - val_loss: 0.2206\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2755 - val_loss: 0.2194\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2751 - val_loss: 0.2228\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2782 - val_loss: 0.2193\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 4.9min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 16s 12ms/step - loss: 2.4371 - val_loss: 0.9399\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4014 - val_loss: 0.5962\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1506 - val_loss: 0.4137\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0051 - val_loss: 0.8837\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9082 - val_loss: 0.4666\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7940 - val_loss: 1.4541\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7434 - val_loss: 0.8276\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6274 - val_loss: 0.9725\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6140 - val_loss: 0.7524\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5747 - val_loss: 0.9324\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5236 - val_loss: 0.9998\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4688 - val_loss: 0.8197\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4077 - val_loss: 1.0246\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4214 - val_loss: 0.8260\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4298 - val_loss: 0.7058\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3913 - val_loss: 0.4453\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3752 - val_loss: 0.5104\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3799 - val_loss: 0.4864\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3611 - val_loss: 0.4671\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3426 - val_loss: 0.3896\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3362 - val_loss: 0.3871\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3346 - val_loss: 0.3434\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3278 - val_loss: 0.3534\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3162 - val_loss: 0.2966\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3179 - val_loss: 0.3154\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3034 - val_loss: 0.3125\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3214 - val_loss: 0.2887\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3223 - val_loss: 0.2536\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3090 - val_loss: 0.3000\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3036 - val_loss: 0.3106\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2967 - val_loss: 0.2626\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2987 - val_loss: 0.2649\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2994 - val_loss: 0.2510\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3030 - val_loss: 0.2713\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3050 - val_loss: 0.2457\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2979 - val_loss: 0.2298\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2831 - val_loss: 0.2200\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2964 - val_loss: 0.2451\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2952 - val_loss: 0.2510\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3005 - val_loss: 0.2358\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2859 - val_loss: 0.2337\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2918 - val_loss: 0.2317\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2917 - val_loss: 0.2302\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2801 - val_loss: 0.2188\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3089 - val_loss: 0.2317\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2825 - val_loss: 0.2455\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2894 - val_loss: 0.2376\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2864 - val_loss: 0.2213\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2998 - val_loss: 0.2290\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2906 - val_loss: 0.2611\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2898 - val_loss: 0.2418\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2838 - val_loss: 0.2485\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2900 - val_loss: 0.2403\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2866 - val_loss: 0.2259\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2917 - val_loss: 0.2295\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2857 - val_loss: 0.2885\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2857 - val_loss: 0.2247\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2837 - val_loss: 0.2173\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.2328\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2762 - val_loss: 0.2248\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2686 - val_loss: 0.2171\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2721 - val_loss: 0.2444\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2754 - val_loss: 0.2249\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2694 - val_loss: 0.2198\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2714 - val_loss: 0.2402\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2898 - val_loss: 0.2366\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2781 - val_loss: 0.2242\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2590 - val_loss: 0.2115\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2582 - val_loss: 0.2100\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2646 - val_loss: 0.2370\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2599 - val_loss: 0.2101\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2463 - val_loss: 0.2026\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2645 - val_loss: 0.2630\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2492 - val_loss: 0.2168\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2771 - val_loss: 0.2478\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2632 - val_loss: 0.2560\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2700 - val_loss: 0.2013\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2428 - val_loss: 0.2191\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2881 - val_loss: 0.2392\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2468 - val_loss: 0.2090\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2565 - val_loss: 0.2369\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2563 - val_loss: 0.2370\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2544 - val_loss: 0.2165\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2505 - val_loss: 0.2058\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2516 - val_loss: 0.2104\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2421 - val_loss: 0.2461\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2475 - val_loss: 0.2018\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2428 - val_loss: 0.1979\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2429 - val_loss: 0.2000\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2339 - val_loss: 0.2003\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2514 - val_loss: 0.2000\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2352 - val_loss: 0.2420\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2351 - val_loss: 0.2058\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2443 - val_loss: 0.2282\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2413 - val_loss: 0.1948\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2353 - val_loss: 0.2064\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2434 - val_loss: 0.2087\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2409 - val_loss: 0.2193\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2465 - val_loss: 0.1997\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2450 - val_loss: 0.2043\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2289 - val_loss: 0.1944\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2383 - val_loss: 0.2219\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2386 - val_loss: 0.1970\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2359 - val_loss: 0.1978\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2391 - val_loss: 0.1922\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2329 - val_loss: 0.2394\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2250 - val_loss: 0.2239\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2228 - val_loss: 0.2011\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2229 - val_loss: 0.2117\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2288 - val_loss: 0.2060\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2377 - val_loss: 0.2200\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2282 - val_loss: 0.2025\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2379 - val_loss: 0.1960\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2269 - val_loss: 0.1994\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2248 - val_loss: 0.2004\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2291 - val_loss: 0.1968\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2273 - val_loss: 0.1945\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2267 - val_loss: 0.2027\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2263 - val_loss: 0.2120\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2400 - val_loss: 0.2004\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2194 - val_loss: 0.2090\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2192 - val_loss: 0.1984\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2231 - val_loss: 0.1974\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2161 - val_loss: 0.1910\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2222 - val_loss: 0.1997\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2259 - val_loss: 0.2184\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2250 - val_loss: 0.1930\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2208 - val_loss: 0.1920\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2243 - val_loss: 0.1940\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2126 - val_loss: 0.1896\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2249 - val_loss: 0.1994\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2146 - val_loss: 0.2100\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2177 - val_loss: 0.1969\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2249 - val_loss: 0.2019\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2156 - val_loss: 0.2053\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2198 - val_loss: 0.1973\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2160 - val_loss: 0.2035\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2030 - val_loss: 0.1997\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2277 - val_loss: 0.1958\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2082 - val_loss: 0.2011\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2156 - val_loss: 0.2022\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2101 - val_loss: 0.1898\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2277 - val_loss: 0.2154\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2189 - val_loss: 0.2098\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2116 - val_loss: 0.2133\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2167 - val_loss: 0.2014\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2131 - val_loss: 0.1909\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2129 - val_loss: 0.2040\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2192 - val_loss: 0.1994\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2207 - val_loss: 0.2137\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2114 - val_loss: 0.2101\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2069 - val_loss: 0.2166\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2063 - val_loss: 0.1956\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2103 - val_loss: 0.1980\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2203 - val_loss: 0.1966\n",
      "Epoch 00155: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total=10.9min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 12ms/step - loss: 2.2434 - val_loss: 0.4229\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2448 - val_loss: 0.3856\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1094 - val_loss: 0.8390\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8772 - val_loss: 0.5520\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7875 - val_loss: 0.4806\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6769 - val_loss: 1.0740\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6332 - val_loss: 0.4509\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5547 - val_loss: 0.6042\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5554 - val_loss: 0.7043\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5053 - val_loss: 0.6165\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4754 - val_loss: 0.5765\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4405 - val_loss: 0.5579\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3937 - val_loss: 0.5341\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4078 - val_loss: 0.4129\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3716 - val_loss: 0.3938\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3616 - val_loss: 0.4469\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3433 - val_loss: 0.4323\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3357 - val_loss: 0.3261\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3141 - val_loss: 0.3701\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3361 - val_loss: 0.3096\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3258 - val_loss: 0.3060\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3126 - val_loss: 0.3051\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3186 - val_loss: 0.2474\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3065 - val_loss: 0.3352\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3028 - val_loss: 0.2432\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3005 - val_loss: 0.2560\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3025 - val_loss: 0.2257\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2906 - val_loss: 0.2652\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2869 - val_loss: 0.2386\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2876 - val_loss: 0.2585\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2856 - val_loss: 0.2333\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3100 - val_loss: 0.2657\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2836 - val_loss: 0.2168\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2900 - val_loss: 0.2413\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2877 - val_loss: 0.2383\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2773 - val_loss: 0.2221\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2963 - val_loss: 0.2250\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2974 - val_loss: 0.2421\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2781 - val_loss: 0.2483\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2718 - val_loss: 0.2209\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2814 - val_loss: 0.2478\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2931 - val_loss: 0.2341\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2723 - val_loss: 0.2533\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2802 - val_loss: 0.2591\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2760 - val_loss: 0.2538\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2730 - val_loss: 0.2265\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2939 - val_loss: 0.2118\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2710 - val_loss: 0.2182\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2712 - val_loss: 0.2098\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2739 - val_loss: 0.2069\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2664 - val_loss: 0.2165\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2671 - val_loss: 0.2447\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2724 - val_loss: 0.2362\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2663 - val_loss: 0.2228\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2605 - val_loss: 0.2017\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2681 - val_loss: 0.2075\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2511 - val_loss: 0.2078\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2638 - val_loss: 0.2062\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2597 - val_loss: 0.2022\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2860 - val_loss: 0.2392\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2790 - val_loss: 0.2105\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2642 - val_loss: 0.2071\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2465 - val_loss: 0.2194\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2545 - val_loss: 0.2118\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2456 - val_loss: 0.2220\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2554 - val_loss: 0.2023\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2541 - val_loss: 0.2051\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2488 - val_loss: 0.2036\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2515 - val_loss: 0.2141\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2455 - val_loss: 0.2107\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2592 - val_loss: 0.2031\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2480 - val_loss: 0.1881\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2473 - val_loss: 0.2036\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2713 - val_loss: 0.2605\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2450 - val_loss: 0.1999\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2381 - val_loss: 0.2015\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2418 - val_loss: 0.1920\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2470 - val_loss: 0.1880\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2557 - val_loss: 0.2104\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2322 - val_loss: 0.2312\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2298 - val_loss: 0.2330\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2639 - val_loss: 0.1893\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2422 - val_loss: 0.1894\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2398 - val_loss: 0.2009\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2385 - val_loss: 0.1854\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2471 - val_loss: 0.1868\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2378 - val_loss: 0.2217\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2414 - val_loss: 0.2144\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2496 - val_loss: 0.2044\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2354 - val_loss: 0.1946\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2395 - val_loss: 0.1912\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2321 - val_loss: 0.1921\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2298 - val_loss: 0.1973\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2390 - val_loss: 0.1913\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2300 - val_loss: 0.1916\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2268 - val_loss: 0.2000\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2328 - val_loss: 0.2340\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2306 - val_loss: 0.2074\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2220 - val_loss: 0.1887\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2210 - val_loss: 0.1853\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2398 - val_loss: 0.1912\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2279 - val_loss: 0.1912\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2319 - val_loss: 0.1875\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2280 - val_loss: 0.2356\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2305 - val_loss: 0.2037\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2442 - val_loss: 0.1918\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2220 - val_loss: 0.2050\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2375 - val_loss: 0.2009\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2342 - val_loss: 0.2100\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2174 - val_loss: 0.2022\n",
      "Epoch 00110: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 8.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 12ms/step - loss: 2.5267 - val_loss: 0.3034\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s 4ms/step - loss: 1.3096 - val_loss: 0.6262\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 1.1498 - val_loss: 0.5315\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9273 - val_loss: 0.7582\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.8527 - val_loss: 0.7173\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.7762 - val_loss: 0.7736\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6991 - val_loss: 0.7666\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6301 - val_loss: 1.1154\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6002 - val_loss: 1.0748\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.5418 - val_loss: 0.7145\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4958 - val_loss: 0.6633\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4362 - val_loss: 0.9023\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4275 - val_loss: 0.5752\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3933 - val_loss: 0.8271\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3962 - val_loss: 0.5826\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3908 - val_loss: 0.5849\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3654 - val_loss: 0.5504\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3453 - val_loss: 0.4720\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3324 - val_loss: 0.3737\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3158 - val_loss: 0.3971\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3211 - val_loss: 0.2809\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3186 - val_loss: 0.3185\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3183 - val_loss: 0.2614\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3057 - val_loss: 0.3369\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3072 - val_loss: 0.2639\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2985 - val_loss: 0.3055\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3021 - val_loss: 0.2575\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3070 - val_loss: 0.3012\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3043 - val_loss: 0.2742\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2914 - val_loss: 0.2245\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3013 - val_loss: 0.2739\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2833 - val_loss: 0.2583\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2846 - val_loss: 0.2329\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2983 - val_loss: 0.2553\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2937 - val_loss: 0.2364\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2841 - val_loss: 0.2277\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2909 - val_loss: 0.2702\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2976 - val_loss: 0.2555\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2882 - val_loss: 0.2289\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2957 - val_loss: 0.2193\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2743 - val_loss: 0.2251\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2905 - val_loss: 0.2380\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2926 - val_loss: 0.2434\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2819 - val_loss: 0.2316\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2861 - val_loss: 0.2481\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2749 - val_loss: 0.2363\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2728 - val_loss: 0.2266\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2788 - val_loss: 0.2258\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2731 - val_loss: 0.2202\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2943 - val_loss: 0.2327\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2721 - val_loss: 0.2226\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2728 - val_loss: 0.2196\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2846 - val_loss: 0.2188\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2812 - val_loss: 0.2208\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2762 - val_loss: 0.2237\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2823 - val_loss: 0.2241\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2918 - val_loss: 0.2204\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2802 - val_loss: 0.2282\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2738 - val_loss: 0.2203\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2800 - val_loss: 0.2255\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2725 - val_loss: 0.2186\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2674 - val_loss: 0.2187\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2741 - val_loss: 0.2248\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.2257\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2728 - val_loss: 0.2187\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 5.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 18s 13ms/step - loss: 1.7049 - val_loss: 1.5658\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 1.1506 - val_loss: 1.8422\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 1.0238 - val_loss: 2.3545\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.8572 - val_loss: 1.4259\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.7359 - val_loss: 1.2962\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.6446 - val_loss: 1.2102\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.5704 - val_loss: 1.0622\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.5225 - val_loss: 1.0120\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.4988 - val_loss: 0.7545\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.4425 - val_loss: 0.6793\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.4605 - val_loss: 0.8807\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.4130 - val_loss: 0.5254\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3917 - val_loss: 0.6150\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3749 - val_loss: 0.4957\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3474 - val_loss: 0.4087\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3480 - val_loss: 0.3839\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3542 - val_loss: 0.4008\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3330 - val_loss: 0.3668\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3250 - val_loss: 0.3270\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3173 - val_loss: 0.3742\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3234 - val_loss: 0.2993\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3121 - val_loss: 0.3076\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3091 - val_loss: 0.3778\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3139 - val_loss: 0.3038\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3166 - val_loss: 0.2764\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3066 - val_loss: 0.3076\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3120 - val_loss: 0.2956\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3010 - val_loss: 0.2488\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3129 - val_loss: 0.2621\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3036 - val_loss: 0.2309\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2947 - val_loss: 0.2509\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2919 - val_loss: 0.2543\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2912 - val_loss: 0.2825\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2872 - val_loss: 0.2322\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2908 - val_loss: 0.2533\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2893 - val_loss: 0.3022\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.3012 - val_loss: 0.3073\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2730 - val_loss: 0.2360\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2821 - val_loss: 0.2658\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2872 - val_loss: 0.2240\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2906 - val_loss: 0.2315\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2694 - val_loss: 0.2467\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2810 - val_loss: 0.2228\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2780 - val_loss: 0.2529\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2767 - val_loss: 0.2419\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2878 - val_loss: 0.2645\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2882 - val_loss: 0.2219\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2874 - val_loss: 0.2191\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2952 - val_loss: 0.2335\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2983 - val_loss: 0.2188\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2902 - val_loss: 0.2357\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2888 - val_loss: 0.2224\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.2830 - val_loss: 0.2202\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.2913 - val_loss: 0.2225\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.2882 - val_loss: 0.2189\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.2789 - val_loss: 0.2191\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 5s 3ms/step - loss: 0.2812 - val_loss: 0.2206\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2915 - val_loss: 0.2246\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2889 - val_loss: 0.2191\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2933 - val_loss: 0.2210\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2833 - val_loss: 0.2235\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2905 - val_loss: 0.2242\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2902 - val_loss: 0.2220\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2756 - val_loss: 0.2191\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2730 - val_loss: 0.2190\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2850 - val_loss: 0.2206\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2836 - val_loss: 0.2194\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2745 - val_loss: 0.2196\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2808 - val_loss: 0.2186\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2839 - val_loss: 0.2194\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2760 - val_loss: 0.2189\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2791 - val_loss: 0.2234\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 5s 4ms/step - loss: 0.2868 - val_loss: 0.2270\n",
      "Epoch 00073: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 6.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 13ms/step - loss: 1.5630 - val_loss: 1.6044\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1063 - val_loss: 1.3593\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.8989 - val_loss: 1.1992\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.8500 - val_loss: 1.0740\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7599 - val_loss: 1.3412\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6385 - val_loss: 1.0825\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5617 - val_loss: 1.1167\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5259 - val_loss: 0.6811\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4769 - val_loss: 0.7877\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.4417 - val_loss: 0.9648\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4224 - val_loss: 0.6191\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3876 - val_loss: 0.4426\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3503 - val_loss: 0.6351\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3460 - val_loss: 0.5478\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3375 - val_loss: 0.4067\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3368 - val_loss: 0.4329\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3233 - val_loss: 0.3603\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3239 - val_loss: 0.3370\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3193 - val_loss: 0.3554\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3100 - val_loss: 0.2729\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2988 - val_loss: 0.3342\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3154 - val_loss: 0.3041\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3090 - val_loss: 0.2476\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3002 - val_loss: 0.2330\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3008 - val_loss: 0.3220\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2885 - val_loss: 0.2569\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2831 - val_loss: 0.2445\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2838 - val_loss: 0.2703\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2958 - val_loss: 0.2684\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2963 - val_loss: 0.2742\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2961 - val_loss: 0.2293\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2878 - val_loss: 0.2238\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2766 - val_loss: 0.2250\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2688 - val_loss: 0.2431\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2903 - val_loss: 0.2313\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2874 - val_loss: 0.2416\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2786 - val_loss: 0.2401\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2922 - val_loss: 0.2322\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2925 - val_loss: 0.2332\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2825 - val_loss: 0.2193\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2825 - val_loss: 0.2292\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2778 - val_loss: 0.2197\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2799 - val_loss: 0.2295\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2786 - val_loss: 0.2223\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2877 - val_loss: 0.2205\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2664 - val_loss: 0.2361\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2914 - val_loss: 0.2287\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2826 - val_loss: 0.2266\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2736 - val_loss: 0.2232\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2741 - val_loss: 0.2420\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2784 - val_loss: 0.2188\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2713 - val_loss: 0.2348\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2781 - val_loss: 0.2217\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2813 - val_loss: 0.2219\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2756 - val_loss: 0.2365\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2755 - val_loss: 0.2233\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2688 - val_loss: 0.2186\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2723 - val_loss: 0.2210\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2724 - val_loss: 0.2195\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2721 - val_loss: 0.2192\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2840 - val_loss: 0.2187\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2905 - val_loss: 0.2186\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2638 - val_loss: 0.2274\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2716 - val_loss: 0.2351\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2775 - val_loss: 0.2274\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 5.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 13ms/step - loss: 1.6354 - val_loss: 0.5511\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1512 - val_loss: 1.0490\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9733 - val_loss: 1.1790\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8028 - val_loss: 1.3496\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7500 - val_loss: 1.0198\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6286 - val_loss: 0.9504\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.5938 - val_loss: 0.7843\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.5256 - val_loss: 0.7599\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4958 - val_loss: 1.0087\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4802 - val_loss: 0.9646\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4129 - val_loss: 0.6244\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3965 - val_loss: 0.5934\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3962 - val_loss: 0.4438\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3655 - val_loss: 0.5279\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3341 - val_loss: 0.5073\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3558 - val_loss: 0.3457\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3402 - val_loss: 0.3609\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3304 - val_loss: 0.4137\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3252 - val_loss: 0.3234\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3285 - val_loss: 0.3511\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3161 - val_loss: 0.2930\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2990 - val_loss: 0.2721\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.3111 - val_loss: 0.2654\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3018 - val_loss: 0.2590\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3060 - val_loss: 0.2342\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2964 - val_loss: 0.2573\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3003 - val_loss: 0.2254\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3046 - val_loss: 0.2620\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3065 - val_loss: 0.2910\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2873 - val_loss: 0.2706\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3128 - val_loss: 0.2533\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2930 - val_loss: 0.2192\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3104 - val_loss: 0.2289\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2904 - val_loss: 0.2587\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2970 - val_loss: 0.2391\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2910 - val_loss: 0.2492\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2763 - val_loss: 0.2200\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2850 - val_loss: 0.2389\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2813 - val_loss: 0.2222\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2824 - val_loss: 0.2244\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2898 - val_loss: 0.2306\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2985 - val_loss: 0.2202\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2817 - val_loss: 0.2227\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2785 - val_loss: 0.2343\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2906 - val_loss: 0.2567\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2921 - val_loss: 0.2197\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2749 - val_loss: 0.2188\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2894 - val_loss: 0.2497\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2947 - val_loss: 0.2233\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2871 - val_loss: 0.2192\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2772 - val_loss: 0.2207\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2844 - val_loss: 0.2197\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2709 - val_loss: 0.2208\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2793 - val_loss: 0.2292\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3000 - val_loss: 0.2460\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2733 - val_loss: 0.2201\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2749 - val_loss: 0.2204\n",
      "Epoch 00057: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 4.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 17s 13ms/step - loss: 1.3935 - val_loss: 1.6722\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.0188 - val_loss: 0.9533\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7607 - val_loss: 1.5015\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6509 - val_loss: 1.2580\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5821 - val_loss: 1.1139\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5223 - val_loss: 0.8806\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5302 - val_loss: 0.8329\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4540 - val_loss: 0.7757\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4208 - val_loss: 0.5806\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4020 - val_loss: 0.5676\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3670 - val_loss: 0.5396\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3536 - val_loss: 0.4462\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3293 - val_loss: 0.3503\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3574 - val_loss: 0.3271\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3359 - val_loss: 0.3631\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3047 - val_loss: 0.2765\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3090 - val_loss: 0.2575\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3037 - val_loss: 0.2918\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3155 - val_loss: 0.2582\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2940 - val_loss: 0.2948\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3025 - val_loss: 0.2819\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2950 - val_loss: 0.2676\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3026 - val_loss: 0.2470\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3029 - val_loss: 0.2553\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2838 - val_loss: 0.2282\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2957 - val_loss: 0.2259\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2928 - val_loss: 0.2620\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2908 - val_loss: 0.2799\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2955 - val_loss: 0.2219\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2967 - val_loss: 0.2438\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2814 - val_loss: 0.2280\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2843 - val_loss: 0.2359\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2790 - val_loss: 0.2217\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2867 - val_loss: 0.2231\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2945 - val_loss: 0.2187\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2972 - val_loss: 0.2281\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2906 - val_loss: 0.2186\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2809 - val_loss: 0.2189\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2929 - val_loss: 0.2321\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2761 - val_loss: 0.2230\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2780 - val_loss: 0.2186\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2910 - val_loss: 0.2187\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2888 - val_loss: 0.2251\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2780 - val_loss: 0.2203\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2901 - val_loss: 0.2252\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2836 - val_loss: 0.2263\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2791 - val_loss: 0.2217\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2722 - val_loss: 0.2187\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2777 - val_loss: 0.2813\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2755 - val_loss: 0.2214\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2822 - val_loss: 0.2219\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2769 - val_loss: 0.2187\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2868 - val_loss: 0.2206\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2791 - val_loss: 0.2350\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2866 - val_loss: 0.2199\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2739 - val_loss: 0.2186\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2936 - val_loss: 0.2689\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2917 - val_loss: 0.2460\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2796 - val_loss: 0.2188\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2777 - val_loss: 0.2191\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 4.7min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 13ms/step - loss: 1.6832 - val_loss: 1.6828\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2044 - val_loss: 0.9496\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9923 - val_loss: 1.1159\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8100 - val_loss: 0.7687\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7455 - val_loss: 0.9810\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6697 - val_loss: 0.6311\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5970 - val_loss: 1.0042\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5334 - val_loss: 0.6232\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4811 - val_loss: 0.6324\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4540 - val_loss: 0.8841\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.4240 - val_loss: 0.5484\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3952 - val_loss: 0.6477\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3824 - val_loss: 0.5545\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3497 - val_loss: 0.3779\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3612 - val_loss: 0.4526\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3530 - val_loss: 0.3250\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3171 - val_loss: 0.3438\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3194 - val_loss: 0.4034\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3100 - val_loss: 0.3781\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3140 - val_loss: 0.3242\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3031 - val_loss: 0.2818\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3121 - val_loss: 0.2545\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3133 - val_loss: 0.2388\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3195 - val_loss: 0.2903\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2924 - val_loss: 0.2186\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3092 - val_loss: 0.2718\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.3042 - val_loss: 0.2704\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2948 - val_loss: 0.2320\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2848 - val_loss: 0.2344\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2877 - val_loss: 0.2662\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2879 - val_loss: 0.2643\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2869 - val_loss: 0.2493\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2930 - val_loss: 0.2588\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2799 - val_loss: 0.2289\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 0.2837 - val_loss: 0.2296\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2844 - val_loss: 0.2518\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2809 - val_loss: 0.2190\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2765 - val_loss: 0.2198\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2808 - val_loss: 0.2233\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2862 - val_loss: 0.2301\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2779 - val_loss: 0.2186\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2663 - val_loss: 0.2216\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2743 - val_loss: 0.2194\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2805 - val_loss: 0.2206\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2822 - val_loss: 0.2189\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2802 - val_loss: 0.2362\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2784 - val_loss: 0.2338\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2675 - val_loss: 0.2217\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2833 - val_loss: 0.2196\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.2753 - val_loss: 0.2214\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 4.0min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 19s 14ms/step - loss: 186.0909 - val_loss: 72.0288\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 30.9055 - val_loss: 6.2530\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 2.5568 - val_loss: 0.3621\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.8059 - val_loss: 0.2190\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7829 - val_loss: 0.2197\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7700 - val_loss: 0.2186\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.8088 - val_loss: 0.2199\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7637 - val_loss: 0.2189\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7824 - val_loss: 0.2187\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7601 - val_loss: 0.2189\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7281 - val_loss: 0.2187\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7374 - val_loss: 0.2186\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7170 - val_loss: 0.2196\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.7002 - val_loss: 0.2188\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7128 - val_loss: 0.2187\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6807 - val_loss: 0.2191\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6550 - val_loss: 0.2193\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6218 - val_loss: 0.2187\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6547 - val_loss: 0.2186\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6411 - val_loss: 0.2204\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6287 - val_loss: 0.2206\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6322 - val_loss: 0.2186\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5522 - val_loss: 0.2186\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5743 - val_loss: 0.2187\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.6023 - val_loss: 0.2191\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5603 - val_loss: 0.2187\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5682 - val_loss: 0.2207\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5137 - val_loss: 0.2189\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 4ms/step - loss: 0.5315 - val_loss: 0.2189\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 3.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 158.3940 - val_loss: 55.9533\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 22.1611 - val_loss: 3.4451\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.6256 - val_loss: 0.2418\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7896 - val_loss: 0.2187\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8199 - val_loss: 0.2220\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7990 - val_loss: 0.2189\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7460 - val_loss: 0.2186\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7592 - val_loss: 0.2229\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7505 - val_loss: 0.2212\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7541 - val_loss: 0.2203\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7259 - val_loss: 0.2187\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7304 - val_loss: 0.2217\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7150 - val_loss: 0.2186\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7370 - val_loss: 0.2187\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7094 - val_loss: 0.2195\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6343 - val_loss: 0.2188\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6641 - val_loss: 0.2201\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6925 - val_loss: 0.2245\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6595 - val_loss: 0.2203\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6152 - val_loss: 0.2186\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6152 - val_loss: 0.2187\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6107 - val_loss: 0.2213\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6064 - val_loss: 0.2186\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5474 - val_loss: 0.2188\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5436 - val_loss: 0.2186\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5072 - val_loss: 0.2205\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5475 - val_loss: 0.2213\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.4908 - val_loss: 0.2188\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5090 - val_loss: 0.2191\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 163.4296 - val_loss: 59.2797\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 24.1043 - val_loss: 3.9359\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8318 - val_loss: 0.2444\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7318 - val_loss: 0.2188\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7642 - val_loss: 0.2187\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7261 - val_loss: 0.2187\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7747 - val_loss: 0.2187\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7746 - val_loss: 0.2188\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7149 - val_loss: 0.2189\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7059 - val_loss: 0.2188\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7304 - val_loss: 0.2209\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6707 - val_loss: 0.2186\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6614 - val_loss: 0.2191\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6712 - val_loss: 0.2196\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6485 - val_loss: 0.2187\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6695 - val_loss: 0.2191\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6524 - val_loss: 0.2210\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6474 - val_loss: 0.2229\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6548 - val_loss: 0.2208\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6405 - val_loss: 0.2187\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6605 - val_loss: 0.2196\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5943 - val_loss: 0.2200\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5928 - val_loss: 0.2193\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5590 - val_loss: 0.2194\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5542 - val_loss: 0.2201\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5690 - val_loss: 0.2186\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5626 - val_loss: 0.2212\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5248 - val_loss: 0.2195\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5121 - val_loss: 0.2189\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 132.7600 - val_loss: 40.7805\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 15.0557 - val_loss: 1.6633\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 1.1330 - val_loss: 0.2187\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7718 - val_loss: 0.2193\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7825 - val_loss: 0.2187\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7761 - val_loss: 0.2189\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8011 - val_loss: 0.2190\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8024 - val_loss: 0.2199\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7711 - val_loss: 0.2190\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6838 - val_loss: 0.2187\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7385 - val_loss: 0.2187\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6924 - val_loss: 0.2213\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7353 - val_loss: 0.2236\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6718 - val_loss: 0.2188\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6431 - val_loss: 0.2201\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6502 - val_loss: 0.2192\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6087 - val_loss: 0.2212\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6404 - val_loss: 0.2190\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6418 - val_loss: 0.2196\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6435 - val_loss: 0.2195\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5817 - val_loss: 0.2187\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5856 - val_loss: 0.2186\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5809 - val_loss: 0.2213\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5596 - val_loss: 0.2192\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5411 - val_loss: 0.2198\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5301 - val_loss: 0.2187\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5315 - val_loss: 0.2209\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5324 - val_loss: 0.2192\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 3.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 165.3783 - val_loss: 59.8897\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 24.5524 - val_loss: 4.0837\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.8814 - val_loss: 0.2523\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9377 - val_loss: 0.2191\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7690 - val_loss: 0.2187\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8356 - val_loss: 0.2186\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7622 - val_loss: 0.2186\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7773 - val_loss: 0.2186\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7792 - val_loss: 0.2214\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7531 - val_loss: 0.2213\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7753 - val_loss: 0.2196\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7230 - val_loss: 0.2189\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7137 - val_loss: 0.2190\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6720 - val_loss: 0.2188\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7679 - val_loss: 0.2190\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6745 - val_loss: 0.2222\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.7005 - val_loss: 0.2189\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6785 - val_loss: 0.2191\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6293 - val_loss: 0.2224\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6497 - val_loss: 0.2201\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.6413 - val_loss: 0.2224\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5912 - val_loss: 0.2190\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5860 - val_loss: 0.2203\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5703 - val_loss: 0.2186\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5866 - val_loss: 0.2187\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5629 - val_loss: 0.2226\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5378 - val_loss: 0.2202\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5299 - val_loss: 0.2195\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.5191 - val_loss: 0.2217\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 20s 15ms/step - loss: 4.2292 - val_loss: 0.3240\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.5023 - val_loss: 0.3834\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.3294 - val_loss: 0.3978\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.1749 - val_loss: 0.4904\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9726 - val_loss: 1.0798\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9675 - val_loss: 0.3891\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8389 - val_loss: 0.5837\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8038 - val_loss: 0.4868\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.6925 - val_loss: 0.5021\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5836 - val_loss: 0.5637\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5508 - val_loss: 0.5524\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5203 - val_loss: 0.5154\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4847 - val_loss: 0.7469\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4510 - val_loss: 0.5392\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4199 - val_loss: 0.4933\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3713 - val_loss: 0.6570\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3783 - val_loss: 0.4127\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3708 - val_loss: 0.6501\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3567 - val_loss: 0.4588\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3349 - val_loss: 0.5111\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3177 - val_loss: 0.4389\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3346 - val_loss: 0.3295\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3094 - val_loss: 0.3683\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3012 - val_loss: 0.4326\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3011 - val_loss: 0.4122\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3085 - val_loss: 0.3340\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 3.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 15ms/step - loss: 3.5915 - val_loss: 0.2492\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4331 - val_loss: 0.3391\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.3435 - val_loss: 0.3160\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2132 - val_loss: 0.2447\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1093 - val_loss: 0.3374\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9024 - val_loss: 1.1522\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8691 - val_loss: 0.4234\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7280 - val_loss: 0.6124\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6797 - val_loss: 0.3989\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5968 - val_loss: 0.3655\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5459 - val_loss: 0.4408\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5354 - val_loss: 0.8467\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4490 - val_loss: 0.4990\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4262 - val_loss: 0.5987\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3878 - val_loss: 0.4565\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3834 - val_loss: 0.4949\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3467 - val_loss: 0.4476\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3452 - val_loss: 0.4105\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3334 - val_loss: 0.5147\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3167 - val_loss: 0.7747\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3205 - val_loss: 0.5483\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2945 - val_loss: 0.4791\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3092 - val_loss: 0.4424\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2846 - val_loss: 0.3895\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2814 - val_loss: 0.3834\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2787 - val_loss: 0.4406\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2967 - val_loss: 0.2618\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2835 - val_loss: 0.2725\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2748 - val_loss: 0.3374\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 3.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 15ms/step - loss: 3.8104 - val_loss: 0.2235\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4378 - val_loss: 0.2558\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2390 - val_loss: 0.2199\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.0607 - val_loss: 0.5177\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9154 - val_loss: 0.6844\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9034 - val_loss: 0.3670\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7547 - val_loss: 0.7556\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6714 - val_loss: 0.4027\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6629 - val_loss: 0.6667\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5665 - val_loss: 0.7098\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5119 - val_loss: 0.4523\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4618 - val_loss: 0.5263\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4164 - val_loss: 0.6658\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4261 - val_loss: 0.7649\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3661 - val_loss: 0.5881\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3581 - val_loss: 0.4428\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3436 - val_loss: 0.5541\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3393 - val_loss: 0.5922\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3215 - val_loss: 0.5240\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3199 - val_loss: 0.5670\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3087 - val_loss: 0.4070\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3011 - val_loss: 0.4168\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2925 - val_loss: 0.3524\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2861 - val_loss: 0.3419\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2757 - val_loss: 0.3757\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2749 - val_loss: 0.4373\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2687 - val_loss: 0.3968\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2707 - val_loss: 0.3096\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 3.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 15ms/step - loss: 4.1372 - val_loss: 0.5543\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4424 - val_loss: 0.3726\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2523 - val_loss: 0.4305\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2005 - val_loss: 0.4080\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.0301 - val_loss: 0.2948\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9452 - val_loss: 0.3385\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8389 - val_loss: 0.2806\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7495 - val_loss: 0.4928\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6315 - val_loss: 1.0494\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6587 - val_loss: 0.6503\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5517 - val_loss: 0.7368\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5243 - val_loss: 0.8248\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4971 - val_loss: 0.3983\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4428 - val_loss: 0.5610\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4232 - val_loss: 0.4199\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3845 - val_loss: 0.5267\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3898 - val_loss: 0.5289\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3618 - val_loss: 0.5673\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3408 - val_loss: 0.3854\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3298 - val_loss: 0.4323\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3106 - val_loss: 0.5713\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3101 - val_loss: 0.4015\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2760 - val_loss: 0.3983\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2993 - val_loss: 0.3943\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2874 - val_loss: 0.3276\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2938 - val_loss: 0.2753\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2842 - val_loss: 0.3245\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2821 - val_loss: 0.3798\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2803 - val_loss: 0.3063\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2870 - val_loss: 0.2483\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2862 - val_loss: 0.2432\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2781 - val_loss: 0.3047\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2770 - val_loss: 0.3133\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2777 - val_loss: 0.2910\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2722 - val_loss: 0.2539\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2771 - val_loss: 0.2876\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2807 - val_loss: 0.2906\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2698 - val_loss: 0.2270\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2651 - val_loss: 0.2364\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2681 - val_loss: 0.2369\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2711 - val_loss: 0.2452\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2860 - val_loss: 0.2344\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2762 - val_loss: 0.2188\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2770 - val_loss: 0.2899\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2651 - val_loss: 0.2416\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2739 - val_loss: 0.2468\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2638 - val_loss: 0.2242\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2814 - val_loss: 0.2248\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2670 - val_loss: 0.2679\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2738 - val_loss: 0.2476\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2685 - val_loss: 0.2233\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2528 - val_loss: 0.2818\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2750 - val_loss: 0.2350\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2657 - val_loss: 0.2214\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2599 - val_loss: 0.2353\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2711 - val_loss: 0.2249\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2653 - val_loss: 0.2222\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2666 - val_loss: 0.2243\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2651 - val_loss: 0.2361\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2674 - val_loss: 0.2866\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2654 - val_loss: 0.2189\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2716 - val_loss: 0.2343\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2626 - val_loss: 0.2223\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2670 - val_loss: 0.2265\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2748 - val_loss: 0.2187\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2709 - val_loss: 0.2188\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2782 - val_loss: 0.2317\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2719 - val_loss: 0.2187\n",
      "Epoch 00068: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 7.7min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 23s 17ms/step - loss: 4.3507 - val_loss: 0.2540\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.4333 - val_loss: 0.3610\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.2447 - val_loss: 0.3684\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1337 - val_loss: 0.3250\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0200 - val_loss: 0.2191\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9999 - val_loss: 0.2458\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9225 - val_loss: 0.3225\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7668 - val_loss: 0.3025\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6549 - val_loss: 0.4723\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6236 - val_loss: 0.4279\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6187 - val_loss: 0.6114\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5328 - val_loss: 0.4680\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4689 - val_loss: 0.5899\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4536 - val_loss: 0.4551\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4184 - val_loss: 0.3944\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4006 - val_loss: 0.7049\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3574 - val_loss: 0.4690\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3367 - val_loss: 0.4588\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3430 - val_loss: 0.5355\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3425 - val_loss: 0.4182\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3188 - val_loss: 0.4218\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2955 - val_loss: 0.4285\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3057 - val_loss: 0.5046\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3076 - val_loss: 0.3701\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2845 - val_loss: 0.4780\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2976 - val_loss: 0.4170\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2742 - val_loss: 0.3734\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2732 - val_loss: 0.3577\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2687 - val_loss: 0.3968\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2829 - val_loss: 0.3712\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 3.8min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 21s 15ms/step - loss: 1.9136 - val_loss: 0.2931\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.1307 - val_loss: 0.6250\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9952 - val_loss: 0.5018\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8640 - val_loss: 0.8275\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.7975 - val_loss: 0.9500\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.6486 - val_loss: 0.7379\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5790 - val_loss: 0.7257\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5110 - val_loss: 0.8812\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5034 - val_loss: 0.6473\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4242 - val_loss: 0.8213\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3960 - val_loss: 0.7709\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3748 - val_loss: 0.4497\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3540 - val_loss: 0.6120\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3338 - val_loss: 0.4918\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3192 - val_loss: 0.3526\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3136 - val_loss: 0.4092\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3114 - val_loss: 0.3302\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2970 - val_loss: 0.3101\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2994 - val_loss: 0.2904\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2877 - val_loss: 0.2528\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2862 - val_loss: 0.2989\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2975 - val_loss: 0.3518\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2896 - val_loss: 0.2902\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2912 - val_loss: 0.2353\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2941 - val_loss: 0.2285\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2929 - val_loss: 0.2768\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2930 - val_loss: 0.2768\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2854 - val_loss: 0.3534\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2995 - val_loss: 0.2599\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2765 - val_loss: 0.2532\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2864 - val_loss: 0.2716\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2910 - val_loss: 0.2737\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2779 - val_loss: 0.2334\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2852 - val_loss: 0.2440\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2798 - val_loss: 0.2235\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2778 - val_loss: 0.2965\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2930 - val_loss: 0.2400\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2795 - val_loss: 0.2616\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2830 - val_loss: 0.2214\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2795 - val_loss: 0.2312\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2664 - val_loss: 0.2359\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2772 - val_loss: 0.2236\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2779 - val_loss: 0.2678\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2796 - val_loss: 0.2185\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2816 - val_loss: 0.2525\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2714 - val_loss: 0.2188\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2744 - val_loss: 0.2827\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2694 - val_loss: 0.2298\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2713 - val_loss: 0.2752\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2721 - val_loss: 0.3033\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2839 - val_loss: 0.2224\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2820 - val_loss: 0.2683\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2696 - val_loss: 0.2152\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2791 - val_loss: 0.2187\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2684 - val_loss: 0.2470\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2689 - val_loss: 0.2247\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2642 - val_loss: 0.2163\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2693 - val_loss: 0.2810\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2772 - val_loss: 0.2225\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2671 - val_loss: 0.2461\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2717 - val_loss: 0.2266\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2501 - val_loss: 0.2123\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2747 - val_loss: 0.2605\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2570 - val_loss: 0.2171\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2601 - val_loss: 0.2122\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2542 - val_loss: 0.3024\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2510 - val_loss: 0.2415\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2535 - val_loss: 0.2901\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2484 - val_loss: 0.2398\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2598 - val_loss: 0.2239\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2868 - val_loss: 0.2954\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2678 - val_loss: 0.2588\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2815 - val_loss: 0.2333\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2794 - val_loss: 0.2506\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2725 - val_loss: 0.3022\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2780 - val_loss: 0.2187\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2673 - val_loss: 0.2413\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2668 - val_loss: 0.2191\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2621 - val_loss: 0.2229\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2623 - val_loss: 0.2196\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2735 - val_loss: 0.2204\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2838 - val_loss: 0.2467\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2793 - val_loss: 0.2206\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2616 - val_loss: 0.2302\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2728 - val_loss: 0.2188\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2693 - val_loss: 0.2203\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2695 - val_loss: 0.2239\n",
      "Epoch 00087: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total=10.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 21s 15ms/step - loss: 1.7697 - val_loss: 1.0087\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0924 - val_loss: 1.6520\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9464 - val_loss: 0.6860\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7246 - val_loss: 0.7428\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6859 - val_loss: 0.3267\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5893 - val_loss: 0.7185\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4966 - val_loss: 1.0651\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4450 - val_loss: 0.5118\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4202 - val_loss: 0.4627\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3901 - val_loss: 0.7812\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3514 - val_loss: 0.5327\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3225 - val_loss: 0.4798\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3141 - val_loss: 0.4467\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3118 - val_loss: 0.4527\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3010 - val_loss: 0.5319\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3007 - val_loss: 0.3182\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2764 - val_loss: 0.4056\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2868 - val_loss: 0.4160\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2922 - val_loss: 0.2855\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2827 - val_loss: 0.2780\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2809 - val_loss: 0.4439\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2783 - val_loss: 0.2450\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2853 - val_loss: 0.2616\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2863 - val_loss: 0.4807\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2876 - val_loss: 0.2474\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2754 - val_loss: 0.2614\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2681 - val_loss: 0.2231\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2785 - val_loss: 0.3060\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2754 - val_loss: 0.2269\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2615 - val_loss: 0.2396\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2865 - val_loss: 0.2627\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2695 - val_loss: 0.2305\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2684 - val_loss: 0.2774\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2666 - val_loss: 0.2586\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2566 - val_loss: 0.2543\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2627 - val_loss: 0.2751\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2673 - val_loss: 0.2651\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2661 - val_loss: 0.2251\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2672 - val_loss: 0.3331\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2562 - val_loss: 0.2148\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2600 - val_loss: 0.2618\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2667 - val_loss: 0.3780\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2616 - val_loss: 0.2776\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2676 - val_loss: 0.3848\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2579 - val_loss: 0.2167\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2613 - val_loss: 0.2480\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2436 - val_loss: 0.2355\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2502 - val_loss: 0.2050\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2430 - val_loss: 0.2031\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2591 - val_loss: 0.3220\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2546 - val_loss: 0.2971\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2451 - val_loss: 0.2415\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2468 - val_loss: 0.2687\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2449 - val_loss: 0.2075\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2544 - val_loss: 0.2422\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2550 - val_loss: 0.2416\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2531 - val_loss: 0.2648\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2609 - val_loss: 0.2363\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2442 - val_loss: 0.2242\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2323 - val_loss: 0.2182\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2303 - val_loss: 0.2192\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2342 - val_loss: 0.2023\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2464 - val_loss: 0.2095\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2327 - val_loss: 0.1942\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2377 - val_loss: 0.2008\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2399 - val_loss: 0.2340\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2291 - val_loss: 0.2006\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2361 - val_loss: 0.1967\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2290 - val_loss: 0.2011\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2350 - val_loss: 0.1911\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2318 - val_loss: 0.2009\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2245 - val_loss: 0.1886\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2368 - val_loss: 0.1897\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2239 - val_loss: 0.1890\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2389 - val_loss: 0.2217\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2389 - val_loss: 0.2117\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2376 - val_loss: 0.2013\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2391 - val_loss: 0.1959\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2445 - val_loss: 0.2297\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2303 - val_loss: 0.1907\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2301 - val_loss: 0.2343\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2201 - val_loss: 0.1918\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2207 - val_loss: 0.1996\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2330 - val_loss: 0.2626\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2381 - val_loss: 0.2048\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2221 - val_loss: 0.1871\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2229 - val_loss: 0.2226\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2297 - val_loss: 0.1999\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2246 - val_loss: 0.1929\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2249 - val_loss: 0.1973\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2322 - val_loss: 0.1908\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2312 - val_loss: 0.1932\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2239 - val_loss: 0.1918\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2113 - val_loss: 0.1912\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2102 - val_loss: 0.1974\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2187 - val_loss: 0.2279\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2043 - val_loss: 0.1991\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2216 - val_loss: 0.1954\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2135 - val_loss: 0.2443\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2191 - val_loss: 0.2102\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2253 - val_loss: 0.1920\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2265 - val_loss: 0.2102\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2135 - val_loss: 0.2072\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2153 - val_loss: 0.1996\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2207 - val_loss: 0.1981\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2257 - val_loss: 0.2159\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2207 - val_loss: 0.1874\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2181 - val_loss: 0.1895\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2163 - val_loss: 0.2015\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2163 - val_loss: 0.1917\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2077 - val_loss: 0.1922\n",
      "Epoch 00111: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total=12.7min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 21s 16ms/step - loss: 1.7457 - val_loss: 1.2362\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.1284 - val_loss: 1.0256\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9324 - val_loss: 0.5706\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8098 - val_loss: 0.8222\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6502 - val_loss: 0.4284\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5731 - val_loss: 0.7133\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5506 - val_loss: 0.6217\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4827 - val_loss: 0.6430\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4231 - val_loss: 0.5012\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4092 - val_loss: 0.8248\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3696 - val_loss: 0.4343\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3352 - val_loss: 0.5153\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3311 - val_loss: 0.4047\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3086 - val_loss: 0.6172\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2919 - val_loss: 0.4699\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2974 - val_loss: 0.3413\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2975 - val_loss: 0.4499\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2966 - val_loss: 0.2763\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2764 - val_loss: 0.3916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2761 - val_loss: 0.4183\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2907 - val_loss: 0.3485\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2867 - val_loss: 0.4113\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2774 - val_loss: 0.2484\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2724 - val_loss: 0.2609\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2688 - val_loss: 0.2722\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2667 - val_loss: 0.3868\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2467 - val_loss: 0.3784\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2680 - val_loss: 0.3265\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2654 - val_loss: 0.2588\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2462 - val_loss: 0.3113\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2592 - val_loss: 0.3399\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2648 - val_loss: 0.2930\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2640 - val_loss: 0.2584\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2467 - val_loss: 0.3509\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2514 - val_loss: 0.2508\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2274 - val_loss: 0.3083\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2555 - val_loss: 0.2668\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2387 - val_loss: 0.3044\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2324 - val_loss: 0.2391\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2285 - val_loss: 0.2655\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2277 - val_loss: 0.3642\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2335 - val_loss: 0.2306\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2189 - val_loss: 0.2025\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2259 - val_loss: 0.1878\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2430 - val_loss: 0.2375\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2285 - val_loss: 0.2297\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2290 - val_loss: 0.2910\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2409 - val_loss: 0.2377\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2342 - val_loss: 0.2322\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2188 - val_loss: 0.2505\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2132 - val_loss: 0.1937\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1979 - val_loss: 0.2132\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2034 - val_loss: 0.1877\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2024 - val_loss: 0.1788\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2220 - val_loss: 0.1803\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2083 - val_loss: 0.2051\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2139 - val_loss: 0.2004\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2000 - val_loss: 0.2209\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1984 - val_loss: 0.2489\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1934 - val_loss: 0.2028\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2037 - val_loss: 0.2074\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2012 - val_loss: 0.2709\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2289 - val_loss: 0.2212\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1834 - val_loss: 0.2031\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1993 - val_loss: 0.1899\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1986 - val_loss: 0.1990\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1968 - val_loss: 0.2044\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1910 - val_loss: 0.1940\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1895 - val_loss: 0.1995\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2147 - val_loss: 0.1903\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1814 - val_loss: 0.2070\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1887 - val_loss: 0.1939\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1802 - val_loss: 0.1965\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2103 - val_loss: 0.2053\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1952 - val_loss: 0.1970\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2043 - val_loss: 0.2167\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2026 - val_loss: 0.1942\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2082 - val_loss: 0.1903\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1845 - val_loss: 0.1843\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 9.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 21s 16ms/step - loss: 1.9550 - val_loss: 0.7536\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1473 - val_loss: 0.5067\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9575 - val_loss: 0.9326\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8070 - val_loss: 1.0358\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7128 - val_loss: 1.0392\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6227 - val_loss: 0.5602\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5974 - val_loss: 0.9989\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5252 - val_loss: 0.5446\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4591 - val_loss: 0.5327\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4273 - val_loss: 0.4708\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3963 - val_loss: 0.4878\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3597 - val_loss: 0.6118\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3286 - val_loss: 0.5019\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3158 - val_loss: 0.3776\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3072 - val_loss: 0.4713\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3055 - val_loss: 0.5241\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3014 - val_loss: 0.3526\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3053 - val_loss: 0.2969\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2989 - val_loss: 0.3280\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2847 - val_loss: 0.2687\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2921 - val_loss: 0.2934\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2843 - val_loss: 0.3037\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2793 - val_loss: 0.3211\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2757 - val_loss: 0.3440\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2786 - val_loss: 0.2633\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2745 - val_loss: 0.2629\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2730 - val_loss: 0.2412\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2702 - val_loss: 0.2736\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2756 - val_loss: 0.2213\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2769 - val_loss: 0.2294\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2720 - val_loss: 0.3120\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2723 - val_loss: 0.2485\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2748 - val_loss: 0.2224\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2629 - val_loss: 0.3178\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2824 - val_loss: 0.2466\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2781 - val_loss: 0.2299\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2580 - val_loss: 0.2553\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2601 - val_loss: 0.2187\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2719 - val_loss: 0.2343\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2762 - val_loss: 0.2331\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2669 - val_loss: 0.2814\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2741 - val_loss: 0.2977\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2818 - val_loss: 0.2252\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2822 - val_loss: 0.3081\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2747 - val_loss: 0.2380\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2727 - val_loss: 0.2287\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2742 - val_loss: 0.2625\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2734 - val_loss: 0.2401\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2607 - val_loss: 0.2312\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2621 - val_loss: 0.2210\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2754 - val_loss: 0.2366\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2726 - val_loss: 0.2880\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2802 - val_loss: 0.2288\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2827 - val_loss: 0.2188\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2741 - val_loss: 0.2257\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2777 - val_loss: 0.2189\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2797 - val_loss: 0.2353\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2658 - val_loss: 0.2378\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2714 - val_loss: 0.2187\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2725 - val_loss: 0.2938\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2696 - val_loss: 0.2189\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2642 - val_loss: 0.2197\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2661 - val_loss: 0.2187\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 7.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 21s 16ms/step - loss: 1.9746 - val_loss: 0.3489\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1792 - val_loss: 0.5591\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0435 - val_loss: 0.6802\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8831 - val_loss: 0.8226\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7330 - val_loss: 0.9448\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6931 - val_loss: 0.9823\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5858 - val_loss: 0.6261\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4886 - val_loss: 0.9077\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4589 - val_loss: 0.4489\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4274 - val_loss: 0.8562\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3841 - val_loss: 0.8125\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3761 - val_loss: 1.0054\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3288 - val_loss: 0.4853\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3197 - val_loss: 0.6227\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3147 - val_loss: 0.4979\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2918 - val_loss: 0.5809\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2891 - val_loss: 0.3989\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2873 - val_loss: 0.3254\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2970 - val_loss: 0.2757\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2856 - val_loss: 0.4179\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2720 - val_loss: 0.3819\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2885 - val_loss: 0.2985\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2890 - val_loss: 0.2667\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2868 - val_loss: 0.3287\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2854 - val_loss: 0.2545\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2785 - val_loss: 0.2828\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2711 - val_loss: 0.2892\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2705 - val_loss: 0.2649\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2732 - val_loss: 0.2693\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2697 - val_loss: 0.2445\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2703 - val_loss: 0.3091\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2666 - val_loss: 0.2957\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2568 - val_loss: 0.2482\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2631 - val_loss: 0.2300\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2684 - val_loss: 0.3457\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2755 - val_loss: 0.2696\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2815 - val_loss: 0.2791\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.2641 - val_loss: 0.2287\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2564 - val_loss: 0.2206\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2757 - val_loss: 0.2497\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2761 - val_loss: 0.3284\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.2759 - val_loss: 0.3152\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2713 - val_loss: 0.2895\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2703 - val_loss: 0.2479\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2707 - val_loss: 0.3373\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2729 - val_loss: 0.2195\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2621 - val_loss: 0.2195\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2733 - val_loss: 0.2219\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2621 - val_loss: 0.2201\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2691 - val_loss: 0.2585\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2657 - val_loss: 0.2500\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 6ms/step - loss: 0.2608 - val_loss: 0.2242\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2591 - val_loss: 0.2348\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2676 - val_loss: 0.2204\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2636 - val_loss: 0.2196\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2619 - val_loss: 0.2221\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2560 - val_loss: 0.2620\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2544 - val_loss: 0.2188\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2577 - val_loss: 0.2254\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2487 - val_loss: 0.2244\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 6ms/step - loss: 0.2723 - val_loss: 0.2291\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2662 - val_loss: 0.2187\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2771 - val_loss: 0.2219\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2570 - val_loss: 0.2526\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2603 - val_loss: 0.2191\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2506 - val_loss: 0.2244\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2617 - val_loss: 0.2202\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2626 - val_loss: 0.2219\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2644 - val_loss: 0.2251\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2561 - val_loss: 0.2191\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2548 - val_loss: 0.2215\n",
      "Epoch 00071: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 8.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 910.2min finished\n",
      "/opt/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 24s 14ms/step - loss: 216.6275 - val_loss: 0.9575\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 46.4373 - val_loss: 1.1314\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 34.3369 - val_loss: 1.4810\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 36.6794 - val_loss: 0.5727\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 37.1268 - val_loss: 1.8217\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 29.1872 - val_loss: 2.1201\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 22.1374 - val_loss: 0.6533\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 17.9287 - val_loss: 0.2715\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 15.8136 - val_loss: 0.4162\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 14.2862 - val_loss: 0.6567\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 10.9831 - val_loss: 0.3072\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 8.3369 - val_loss: 0.3405\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 7.3787 - val_loss: 0.2748\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 8.4252 - val_loss: 0.4605\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 5.5653 - val_loss: 0.2020\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 4.2557 - val_loss: 0.1949\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 4.6183 - val_loss: 0.4580\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 3.4595 - val_loss: 0.2631\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 2.7200 - val_loss: 0.1940\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 2.5492 - val_loss: 0.2050\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 2.3611 - val_loss: 0.2464\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.9462 - val_loss: 0.2361\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.9646 - val_loss: 0.2460\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.8162 - val_loss: 0.2443\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.6760 - val_loss: 0.3016\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.4309 - val_loss: 0.3170\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.2684 - val_loss: 0.2368\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.2345 - val_loss: 0.2074\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.1418 - val_loss: 0.1794\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 1.0166 - val_loss: 0.2223\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.8900 - val_loss: 0.1798\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.8359 - val_loss: 0.1778\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.7579 - val_loss: 0.1932\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.7599 - val_loss: 0.1837\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.7510 - val_loss: 0.2725\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.6444 - val_loss: 0.1699\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.5274 - val_loss: 0.1733\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.5232 - val_loss: 0.2848\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.5588 - val_loss: 0.1760\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.4903 - val_loss: 0.1675\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.4367 - val_loss: 0.1813\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.4215 - val_loss: 0.1843\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.4026 - val_loss: 0.1723\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3873 - val_loss: 0.1936\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3691 - val_loss: 0.1737\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3569 - val_loss: 0.1717\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.3298 - val_loss: 0.2208\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.3335 - val_loss: 0.1741\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3322 - val_loss: 0.2034\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3132 - val_loss: 0.1933\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3242 - val_loss: 0.1834\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.3286 - val_loss: 0.1810\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2815 - val_loss: 0.1694\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2832 - val_loss: 0.2316\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.2807 - val_loss: 0.1724\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2482 - val_loss: 0.1688\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2619 - val_loss: 0.1702\n",
      "Epoch 58/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.2507 - val_loss: 0.1835\n",
      "Epoch 59/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.2662 - val_loss: 0.1844\n",
      "Epoch 60/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2543 - val_loss: 0.1852\n",
      "Epoch 61/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2587 - val_loss: 0.2053\n",
      "Epoch 62/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.2450 - val_loss: 0.1885\n",
      "Epoch 63/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2461 - val_loss: 0.1741\n",
      "Epoch 64/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 0.2432 - val_loss: 0.1842\n",
      "Epoch 65/200\n",
      "1696/1696 [==============================] - 9s 6ms/step - loss: 0.2260 - val_loss: 0.1840\n",
      "Epoch 00065: early stopping\n",
      "The parameters of the best model are: \n",
      "{'activation_function': 'linear', 'hidden_layer_size': 256, 'num_hidden_layers': 3}\n",
      "CPU times: user 1d 2h 4min 52s, sys: 3h 24min 16s, total: 1d 5h 29min 9s\n",
      "Wall time: 15h 20min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "classifier = KerasRegressor(make_model, batch_size=32, epochs=200)\n",
    "\n",
    "params = [{'num_hidden_layers': [0],\n",
    "          'hidden_layer_size': [0],\n",
    "          'activation_function': ['linear', 'sigmoid', 'relu', 'tanh']},\n",
    "          {'num_hidden_layers': [1,2,3],\n",
    "          'hidden_layer_size': [64, 128, 256],\n",
    "          'activation_function': ['linear', 'sigmoid', 'relu', 'tanh']}]\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(classifier,\n",
    "                         param_grid=params,\n",
    "                         scoring='neg_mean_squared_error', #sklearn optimizing by maximizing negative MSE\n",
    "                         n_jobs=1,\n",
    "                         verbose=2,\n",
    "                         cv=KFold(n_splits=5, shuffle=True, random_state=42),# Number of folds for CV\n",
    "                         return_train_score=True,\n",
    "                         error_score='raise'\n",
    "                   )\n",
    "\n",
    "grid.fit(np.array(X_train), np.array(y_train),\n",
    "        **{'callbacks': [EarlyStopping(monitor='val_loss', \n",
    "                                                                 min_delta=0.001, \n",
    "                                                                 patience=25, \n",
    "                                                                 mode='min',\n",
    "                                                                 verbose=2)],\n",
    "                                    'validation_data': (np.array(X_test), np.array(y_test))\n",
    "                                    })\n",
    "\n",
    "print('The parameters of the best model are: ')\n",
    "print(grid.best_params_)\n",
    "\n",
    "best_model = grid.best_estimator_ #scikit-wrapped best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_function': 'linear',\n",
       " 'hidden_layer_size': 256,\n",
       " 'num_hidden_layers': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores can the be extracted to view performance of every model on every fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_activation_function', 'param_hidden_layer_size',\n",
       "       'param_num_hidden_layers', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
       "       'split4_test_score', 'mean_test_score', 'std_test_score',\n",
       "       'rank_test_score', 'split0_train_score', 'split1_train_score',\n",
       "       'split2_train_score', 'split3_train_score', 'split4_train_score',\n",
       "       'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation_function</th>\n",
       "      <th>param_hidden_layer_size</th>\n",
       "      <th>param_num_hidden_layers</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>533.480620</td>\n",
       "      <td>61.981618</td>\n",
       "      <td>1.604587</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.156356</td>\n",
       "      <td>-0.208734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178297</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031412</td>\n",
       "      <td>-0.058933</td>\n",
       "      <td>-0.038213</td>\n",
       "      <td>-0.021005</td>\n",
       "      <td>-0.046250</td>\n",
       "      <td>-0.039163</td>\n",
       "      <td>0.012898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>351.657404</td>\n",
       "      <td>70.296554</td>\n",
       "      <td>2.456750</td>\n",
       "      <td>0.040858</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.156284</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>0.026759</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.057074</td>\n",
       "      <td>-0.034073</td>\n",
       "      <td>-0.040690</td>\n",
       "      <td>-0.057128</td>\n",
       "      <td>-0.046569</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>0.009068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>582.432157</td>\n",
       "      <td>68.998469</td>\n",
       "      <td>0.916782</td>\n",
       "      <td>0.027519</td>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.166008</td>\n",
       "      <td>-0.207982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190766</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.011178</td>\n",
       "      <td>-0.014782</td>\n",
       "      <td>-0.013335</td>\n",
       "      <td>-0.010347</td>\n",
       "      <td>-0.010373</td>\n",
       "      <td>-0.012003</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>331.651672</td>\n",
       "      <td>11.740114</td>\n",
       "      <td>2.851909</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.196655</td>\n",
       "      <td>-0.191436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192184</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.231256</td>\n",
       "      <td>-0.062534</td>\n",
       "      <td>-0.089309</td>\n",
       "      <td>-0.108107</td>\n",
       "      <td>-0.102943</td>\n",
       "      <td>-0.118830</td>\n",
       "      <td>0.058391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>213.031170</td>\n",
       "      <td>47.286451</td>\n",
       "      <td>0.632164</td>\n",
       "      <td>0.034216</td>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.164358</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192473</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>-0.011843</td>\n",
       "      <td>-0.022393</td>\n",
       "      <td>-0.045349</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>0.011344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>353.847553</td>\n",
       "      <td>60.673596</td>\n",
       "      <td>1.056034</td>\n",
       "      <td>0.039973</td>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.167493</td>\n",
       "      <td>-0.203110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193223</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.019599</td>\n",
       "      <td>-0.029946</td>\n",
       "      <td>-0.044178</td>\n",
       "      <td>-0.057379</td>\n",
       "      <td>-0.042451</td>\n",
       "      <td>-0.038710</td>\n",
       "      <td>0.012919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>354.522098</td>\n",
       "      <td>31.779977</td>\n",
       "      <td>1.241264</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.162437</td>\n",
       "      <td>-0.224477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195314</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.031552</td>\n",
       "      <td>-0.059955</td>\n",
       "      <td>-0.026487</td>\n",
       "      <td>-0.019075</td>\n",
       "      <td>-0.058209</td>\n",
       "      <td>-0.039056</td>\n",
       "      <td>0.016836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>499.845629</td>\n",
       "      <td>185.975525</td>\n",
       "      <td>2.821082</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.190206</td>\n",
       "      <td>-0.204223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197968</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.094053</td>\n",
       "      <td>-0.066915</td>\n",
       "      <td>-0.230878</td>\n",
       "      <td>-0.083936</td>\n",
       "      <td>-0.108919</td>\n",
       "      <td>-0.116940</td>\n",
       "      <td>0.058586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>421.269787</td>\n",
       "      <td>148.231854</td>\n",
       "      <td>2.633213</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.173075</td>\n",
       "      <td>-0.236252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199689</td>\n",
       "      <td>0.028723</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-0.221440</td>\n",
       "      <td>-0.099368</td>\n",
       "      <td>-0.134007</td>\n",
       "      <td>-0.164970</td>\n",
       "      <td>-0.150926</td>\n",
       "      <td>0.040921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200.024234</td>\n",
       "      <td>66.062712</td>\n",
       "      <td>0.792366</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.185885</td>\n",
       "      <td>-0.207872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206377</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.052365</td>\n",
       "      <td>-0.054430</td>\n",
       "      <td>-0.135198</td>\n",
       "      <td>-0.045380</td>\n",
       "      <td>-0.016374</td>\n",
       "      <td>-0.060749</td>\n",
       "      <td>0.039644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>231.058185</td>\n",
       "      <td>146.032240</td>\n",
       "      <td>2.080906</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.158427</td>\n",
       "      <td>-0.237342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208554</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.121330</td>\n",
       "      <td>-0.221982</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.130627</td>\n",
       "      <td>-0.219861</td>\n",
       "      <td>-0.183829</td>\n",
       "      <td>0.047358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>574.152614</td>\n",
       "      <td>106.859661</td>\n",
       "      <td>5.508796</td>\n",
       "      <td>0.103761</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.205062</td>\n",
       "      <td>-0.201409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211628</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.237134</td>\n",
       "      <td>-0.125121</td>\n",
       "      <td>-0.104452</td>\n",
       "      <td>-0.223372</td>\n",
       "      <td>-0.224478</td>\n",
       "      <td>-0.182911</td>\n",
       "      <td>0.056215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>399.034078</td>\n",
       "      <td>145.717701</td>\n",
       "      <td>4.840754</td>\n",
       "      <td>0.059388</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.205447</td>\n",
       "      <td>-0.236568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214155</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.237452</td>\n",
       "      <td>-0.221705</td>\n",
       "      <td>-0.134537</td>\n",
       "      <td>-0.163921</td>\n",
       "      <td>-0.220734</td>\n",
       "      <td>-0.195670</td>\n",
       "      <td>0.039489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>228.254828</td>\n",
       "      <td>114.659138</td>\n",
       "      <td>2.239141</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.196777</td>\n",
       "      <td>-0.236103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218155</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.232489</td>\n",
       "      <td>-0.220881</td>\n",
       "      <td>-0.126527</td>\n",
       "      <td>-0.228839</td>\n",
       "      <td>-0.220551</td>\n",
       "      <td>-0.205857</td>\n",
       "      <td>0.039931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>306.530452</td>\n",
       "      <td>143.504055</td>\n",
       "      <td>2.400970</td>\n",
       "      <td>0.054322</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.196865</td>\n",
       "      <td>-0.214877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218680</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.232659</td>\n",
       "      <td>-0.161852</td>\n",
       "      <td>-0.159142</td>\n",
       "      <td>-0.225384</td>\n",
       "      <td>-0.171930</td>\n",
       "      <td>-0.190193</td>\n",
       "      <td>0.032071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>231.351712</td>\n",
       "      <td>66.048873</td>\n",
       "      <td>3.595038</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.196869</td>\n",
       "      <td>-0.237894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219349</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.232888</td>\n",
       "      <td>-0.222900</td>\n",
       "      <td>-0.226662</td>\n",
       "      <td>-0.165573</td>\n",
       "      <td>-0.145405</td>\n",
       "      <td>-0.198686</td>\n",
       "      <td>0.035984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>210.502111</td>\n",
       "      <td>102.688570</td>\n",
       "      <td>4.269154</td>\n",
       "      <td>0.042565</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.202425</td>\n",
       "      <td>-0.239147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220677</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.235001</td>\n",
       "      <td>-0.224769</td>\n",
       "      <td>-0.131133</td>\n",
       "      <td>-0.224620</td>\n",
       "      <td>-0.227832</td>\n",
       "      <td>-0.208671</td>\n",
       "      <td>0.038951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245.377212</td>\n",
       "      <td>47.310742</td>\n",
       "      <td>0.487355</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.179391</td>\n",
       "      <td>-0.311087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222170</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.124082</td>\n",
       "      <td>-0.039679</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>-0.048821</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>0.038955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>502.579788</td>\n",
       "      <td>168.483454</td>\n",
       "      <td>1.418930</td>\n",
       "      <td>0.045170</td>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.178085</td>\n",
       "      <td>-0.380480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224537</td>\n",
       "      <td>0.080845</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.034846</td>\n",
       "      <td>-0.783732</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.028045</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.181299</td>\n",
       "      <td>0.301230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>136.617612</td>\n",
       "      <td>1.595075</td>\n",
       "      <td>4.705369</td>\n",
       "      <td>0.045895</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.196456</td>\n",
       "      <td>-0.236148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224703</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.231362</td>\n",
       "      <td>-0.221379</td>\n",
       "      <td>-0.226254</td>\n",
       "      <td>-0.223410</td>\n",
       "      <td>-0.220890</td>\n",
       "      <td>-0.224659</td>\n",
       "      <td>0.003847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>195.613859</td>\n",
       "      <td>4.465094</td>\n",
       "      <td>5.145208</td>\n",
       "      <td>0.027091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.196429</td>\n",
       "      <td>-0.236410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225795</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.231434</td>\n",
       "      <td>-0.221573</td>\n",
       "      <td>-0.225463</td>\n",
       "      <td>-0.223467</td>\n",
       "      <td>-0.222155</td>\n",
       "      <td>-0.224818</td>\n",
       "      <td>0.003567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>150.663524</td>\n",
       "      <td>26.972251</td>\n",
       "      <td>3.060753</td>\n",
       "      <td>0.047939</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.197517</td>\n",
       "      <td>-0.238964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226589</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.233934</td>\n",
       "      <td>-0.223900</td>\n",
       "      <td>-0.226856</td>\n",
       "      <td>-0.224120</td>\n",
       "      <td>-0.223250</td>\n",
       "      <td>-0.226412</td>\n",
       "      <td>0.003959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>179.069814</td>\n",
       "      <td>9.940175</td>\n",
       "      <td>4.475766</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.196515</td>\n",
       "      <td>-0.239355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226715</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.231298</td>\n",
       "      <td>-0.224268</td>\n",
       "      <td>-0.225337</td>\n",
       "      <td>-0.223438</td>\n",
       "      <td>-0.233528</td>\n",
       "      <td>-0.227574</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>189.328727</td>\n",
       "      <td>59.447426</td>\n",
       "      <td>3.261559</td>\n",
       "      <td>0.050417</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.196945</td>\n",
       "      <td>-0.236459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226730</td>\n",
       "      <td>0.016899</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.232796</td>\n",
       "      <td>-0.221613</td>\n",
       "      <td>-0.229985</td>\n",
       "      <td>-0.227169</td>\n",
       "      <td>-0.221890</td>\n",
       "      <td>-0.226691</td>\n",
       "      <td>0.004409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>249.702263</td>\n",
       "      <td>45.894048</td>\n",
       "      <td>3.755433</td>\n",
       "      <td>0.043215</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.202529</td>\n",
       "      <td>-0.237307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226818</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.240058</td>\n",
       "      <td>-0.222362</td>\n",
       "      <td>-0.227212</td>\n",
       "      <td>-0.223673</td>\n",
       "      <td>-0.222418</td>\n",
       "      <td>-0.227145</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>291.120146</td>\n",
       "      <td>48.486737</td>\n",
       "      <td>5.012955</td>\n",
       "      <td>0.059402</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.201604</td>\n",
       "      <td>-0.244115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227151</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.239049</td>\n",
       "      <td>-0.228822</td>\n",
       "      <td>-0.227222</td>\n",
       "      <td>-0.223433</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.228583</td>\n",
       "      <td>0.005578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>83.685453</td>\n",
       "      <td>2.954401</td>\n",
       "      <td>4.081301</td>\n",
       "      <td>0.063113</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.197702</td>\n",
       "      <td>-0.240813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228268</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.233968</td>\n",
       "      <td>-0.225653</td>\n",
       "      <td>-0.226055</td>\n",
       "      <td>-0.226364</td>\n",
       "      <td>-0.224937</td>\n",
       "      <td>-0.227395</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70.938486</td>\n",
       "      <td>5.698213</td>\n",
       "      <td>1.747982</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.198990</td>\n",
       "      <td>-0.236779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228600</td>\n",
       "      <td>0.016883</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.235741</td>\n",
       "      <td>-0.221888</td>\n",
       "      <td>-0.236186</td>\n",
       "      <td>-0.226751</td>\n",
       "      <td>-0.224847</td>\n",
       "      <td>-0.229083</td>\n",
       "      <td>0.005830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85.845923</td>\n",
       "      <td>18.334763</td>\n",
       "      <td>1.931586</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.201779</td>\n",
       "      <td>-0.243327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229115</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.239262</td>\n",
       "      <td>-0.228062</td>\n",
       "      <td>-0.237446</td>\n",
       "      <td>-0.224976</td>\n",
       "      <td>-0.221348</td>\n",
       "      <td>-0.230219</td>\n",
       "      <td>0.006998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>78.821601</td>\n",
       "      <td>29.201884</td>\n",
       "      <td>1.586589</td>\n",
       "      <td>0.026512</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-0.206600</td>\n",
       "      <td>-0.239329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234236</td>\n",
       "      <td>0.018224</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.244986</td>\n",
       "      <td>-0.224244</td>\n",
       "      <td>-0.230915</td>\n",
       "      <td>-0.239614</td>\n",
       "      <td>-0.225474</td>\n",
       "      <td>-0.233046</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>414.319877</td>\n",
       "      <td>113.498782</td>\n",
       "      <td>4.174578</td>\n",
       "      <td>0.061544</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.199759</td>\n",
       "      <td>-0.236384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257736</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.231950</td>\n",
       "      <td>-0.221551</td>\n",
       "      <td>-0.226625</td>\n",
       "      <td>-0.228295</td>\n",
       "      <td>-0.216298</td>\n",
       "      <td>-0.224944</td>\n",
       "      <td>0.005466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>406.746533</td>\n",
       "      <td>179.311350</td>\n",
       "      <td>3.348204</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.649795</td>\n",
       "      <td>-0.199647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301792</td>\n",
       "      <td>0.181063</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.579378</td>\n",
       "      <td>-0.079933</td>\n",
       "      <td>-0.068540</td>\n",
       "      <td>-0.072941</td>\n",
       "      <td>-0.145699</td>\n",
       "      <td>-0.189298</td>\n",
       "      <td>0.197051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>254.722134</td>\n",
       "      <td>100.902196</td>\n",
       "      <td>5.286748</td>\n",
       "      <td>0.037380</td>\n",
       "      <td>tanh</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-0.325768</td>\n",
       "      <td>-0.357938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325679</td>\n",
       "      <td>0.052779</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.349121</td>\n",
       "      <td>-0.345410</td>\n",
       "      <td>-0.307383</td>\n",
       "      <td>-0.223371</td>\n",
       "      <td>-0.382141</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.054480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>513.730981</td>\n",
       "      <td>349.592034</td>\n",
       "      <td>3.790669</td>\n",
       "      <td>0.037556</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.162908</td>\n",
       "      <td>-0.541465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360402</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.085792</td>\n",
       "      <td>-0.400448</td>\n",
       "      <td>-0.457921</td>\n",
       "      <td>-0.215694</td>\n",
       "      <td>-0.220208</td>\n",
       "      <td>-0.276013</td>\n",
       "      <td>0.135286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>278.199999</td>\n",
       "      <td>103.981110</td>\n",
       "      <td>3.972265</td>\n",
       "      <td>0.032277</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-0.494256</td>\n",
       "      <td>-0.378280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557093</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.440188</td>\n",
       "      <td>-0.323708</td>\n",
       "      <td>-0.584131</td>\n",
       "      <td>-0.344877</td>\n",
       "      <td>-0.579167</td>\n",
       "      <td>-0.454414</td>\n",
       "      <td>0.111063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>377.221346</td>\n",
       "      <td>346.312438</td>\n",
       "      <td>1.272435</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-0.651232</td>\n",
       "      <td>-1.673771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.985738</td>\n",
       "      <td>0.554892</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.873479</td>\n",
       "      <td>-2.286804</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>-1.523011</td>\n",
       "      <td>-1.789221</td>\n",
       "      <td>-1.296389</td>\n",
       "      <td>0.788705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.877625</td>\n",
       "      <td>1.608140</td>\n",
       "      <td>0.138699</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation_function': 'linear', 'hidden_laye...</td>\n",
       "      <td>-2.373923</td>\n",
       "      <td>-2.081822</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.044422</td>\n",
       "      <td>0.784499</td>\n",
       "      <td>37</td>\n",
       "      <td>-2.306027</td>\n",
       "      <td>-1.837597</td>\n",
       "      <td>-1.176133</td>\n",
       "      <td>-3.024336</td>\n",
       "      <td>-1.095315</td>\n",
       "      <td>-1.887882</td>\n",
       "      <td>0.721616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.805012</td>\n",
       "      <td>0.312548</td>\n",
       "      <td>0.343594</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation_function': 'tanh', 'hidden_layer_...</td>\n",
       "      <td>-3.334007</td>\n",
       "      <td>-3.429019</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.408203</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>38</td>\n",
       "      <td>-3.426807</td>\n",
       "      <td>-3.403003</td>\n",
       "      <td>-3.437868</td>\n",
       "      <td>-3.386606</td>\n",
       "      <td>-3.386745</td>\n",
       "      <td>-3.408206</td>\n",
       "      <td>0.020881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.494315</td>\n",
       "      <td>0.124183</td>\n",
       "      <td>0.203067</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation_function': 'sigmoid', 'hidden_lay...</td>\n",
       "      <td>-3.334007</td>\n",
       "      <td>-3.429019</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.408203</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>38</td>\n",
       "      <td>-3.426807</td>\n",
       "      <td>-3.403003</td>\n",
       "      <td>-3.437868</td>\n",
       "      <td>-3.386606</td>\n",
       "      <td>-3.386745</td>\n",
       "      <td>-3.408206</td>\n",
       "      <td>0.020881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.943288</td>\n",
       "      <td>0.287599</td>\n",
       "      <td>0.295754</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'activation_function': 'relu', 'hidden_layer_...</td>\n",
       "      <td>-7.876654</td>\n",
       "      <td>-8.002765</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.976894</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>40</td>\n",
       "      <td>-8.002028</td>\n",
       "      <td>-7.970431</td>\n",
       "      <td>-8.022614</td>\n",
       "      <td>-7.943718</td>\n",
       "      <td>-7.945698</td>\n",
       "      <td>-7.976898</td>\n",
       "      <td>0.031105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12     533.480620     61.981618         1.604587        0.053123   \n",
       "19     351.657404     70.296554         2.456750        0.040858   \n",
       "7      582.432157     68.998469         0.916782        0.027519   \n",
       "22     331.651672     11.740114         2.851909        0.024441   \n",
       "5      213.031170     47.286451         0.632164        0.034216   \n",
       "8      353.847553     60.673596         1.056034        0.039973   \n",
       "9      354.522098     31.779977         1.241264        0.038938   \n",
       "21     499.845629    185.975525         2.821082        0.055262   \n",
       "20     421.269787    148.231854         2.633213        0.051035   \n",
       "6      200.024234     66.062712         0.792366        0.051966   \n",
       "16     231.058185    146.032240         2.080906        0.041032   \n",
       "39     574.152614    106.859661         5.508796        0.103761   \n",
       "35     399.034078    145.717701         4.840754        0.059388   \n",
       "17     228.254828    114.659138         2.239141        0.030579   \n",
       "18     306.530452    143.504055         2.400970        0.054322   \n",
       "26     231.351712     66.048873         3.595038        0.022401   \n",
       "32     210.502111    102.688570         4.269154        0.042565   \n",
       "4      245.377212     47.310742         0.487355        0.024138   \n",
       "11     502.579788    168.483454         1.418930        0.045170   \n",
       "34     136.617612      1.595075         4.705369        0.045895   \n",
       "37     195.613859      4.465094         5.145208        0.027091   \n",
       "23     150.663524     26.972251         3.060753        0.047939   \n",
       "33     179.069814      9.940175         4.475766        0.048540   \n",
       "24     189.328727     59.447426         3.261559        0.050417   \n",
       "27     249.702263     45.894048         3.755433        0.043215   \n",
       "36     291.120146     48.486737         5.012955        0.059402   \n",
       "31      83.685453      2.954401         4.081301        0.063113   \n",
       "14      70.938486      5.698213         1.747982        0.044350   \n",
       "15      85.845923     18.334763         1.931586        0.060699   \n",
       "13      78.821601     29.201884         1.586589        0.026512   \n",
       "30     414.319877    113.498782         4.174578        0.061544   \n",
       "25     406.746533    179.311350         3.348204        0.032848   \n",
       "38     254.722134    100.902196         5.286748        0.037380   \n",
       "28     513.730981    349.592034         3.790669        0.037556   \n",
       "29     278.199999    103.981110         3.972265        0.032277   \n",
       "10     377.221346    346.312438         1.272435        0.018364   \n",
       "0       18.877625      1.608140         0.138699        0.025194   \n",
       "3       12.805012      0.312548         0.343594        0.019401   \n",
       "1       12.494315      0.124183         0.203067        0.020734   \n",
       "2       13.943288      0.287599         0.295754        0.018892   \n",
       "\n",
       "   param_activation_function param_hidden_layer_size param_num_hidden_layers  \\\n",
       "12                    linear                     256                       3   \n",
       "19                   sigmoid                     256                       1   \n",
       "7                     linear                     128                       1   \n",
       "22                      relu                      64                       1   \n",
       "5                     linear                      64                       2   \n",
       "8                     linear                     128                       2   \n",
       "9                     linear                     128                       3   \n",
       "21                   sigmoid                     256                       3   \n",
       "20                   sigmoid                     256                       2   \n",
       "6                     linear                      64                       3   \n",
       "16                   sigmoid                     128                       1   \n",
       "39                      tanh                     256                       3   \n",
       "35                      tanh                     128                       2   \n",
       "17                   sigmoid                     128                       2   \n",
       "18                   sigmoid                     128                       3   \n",
       "26                      relu                     128                       2   \n",
       "32                      tanh                      64                       2   \n",
       "4                     linear                      64                       1   \n",
       "11                    linear                     256                       2   \n",
       "34                      tanh                     128                       1   \n",
       "37                      tanh                     256                       1   \n",
       "23                      relu                      64                       2   \n",
       "33                      tanh                      64                       3   \n",
       "24                      relu                      64                       3   \n",
       "27                      relu                     128                       3   \n",
       "36                      tanh                     128                       3   \n",
       "31                      tanh                      64                       1   \n",
       "14                   sigmoid                      64                       2   \n",
       "15                   sigmoid                      64                       3   \n",
       "13                   sigmoid                      64                       1   \n",
       "30                      relu                     256                       3   \n",
       "25                      relu                     128                       1   \n",
       "38                      tanh                     256                       2   \n",
       "28                      relu                     256                       1   \n",
       "29                      relu                     256                       2   \n",
       "10                    linear                     256                       1   \n",
       "0                     linear                       0                       0   \n",
       "3                       tanh                       0                       0   \n",
       "1                    sigmoid                       0                       0   \n",
       "2                       relu                       0                       0   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "12  {'activation_function': 'linear', 'hidden_laye...          -0.156356   \n",
       "19  {'activation_function': 'sigmoid', 'hidden_lay...          -0.156284   \n",
       "7   {'activation_function': 'linear', 'hidden_laye...          -0.166008   \n",
       "22  {'activation_function': 'relu', 'hidden_layer_...          -0.196655   \n",
       "5   {'activation_function': 'linear', 'hidden_laye...          -0.164358   \n",
       "8   {'activation_function': 'linear', 'hidden_laye...          -0.167493   \n",
       "9   {'activation_function': 'linear', 'hidden_laye...          -0.162437   \n",
       "21  {'activation_function': 'sigmoid', 'hidden_lay...          -0.190206   \n",
       "20  {'activation_function': 'sigmoid', 'hidden_lay...          -0.173075   \n",
       "6   {'activation_function': 'linear', 'hidden_laye...          -0.185885   \n",
       "16  {'activation_function': 'sigmoid', 'hidden_lay...          -0.158427   \n",
       "39  {'activation_function': 'tanh', 'hidden_layer_...          -0.205062   \n",
       "35  {'activation_function': 'tanh', 'hidden_layer_...          -0.205447   \n",
       "17  {'activation_function': 'sigmoid', 'hidden_lay...          -0.196777   \n",
       "18  {'activation_function': 'sigmoid', 'hidden_lay...          -0.196865   \n",
       "26  {'activation_function': 'relu', 'hidden_layer_...          -0.196869   \n",
       "32  {'activation_function': 'tanh', 'hidden_layer_...          -0.202425   \n",
       "4   {'activation_function': 'linear', 'hidden_laye...          -0.179391   \n",
       "11  {'activation_function': 'linear', 'hidden_laye...          -0.178085   \n",
       "34  {'activation_function': 'tanh', 'hidden_layer_...          -0.196456   \n",
       "37  {'activation_function': 'tanh', 'hidden_layer_...          -0.196429   \n",
       "23  {'activation_function': 'relu', 'hidden_layer_...          -0.197517   \n",
       "33  {'activation_function': 'tanh', 'hidden_layer_...          -0.196515   \n",
       "24  {'activation_function': 'relu', 'hidden_layer_...          -0.196945   \n",
       "27  {'activation_function': 'relu', 'hidden_layer_...          -0.202529   \n",
       "36  {'activation_function': 'tanh', 'hidden_layer_...          -0.201604   \n",
       "31  {'activation_function': 'tanh', 'hidden_layer_...          -0.197702   \n",
       "14  {'activation_function': 'sigmoid', 'hidden_lay...          -0.198990   \n",
       "15  {'activation_function': 'sigmoid', 'hidden_lay...          -0.201779   \n",
       "13  {'activation_function': 'sigmoid', 'hidden_lay...          -0.206600   \n",
       "30  {'activation_function': 'relu', 'hidden_layer_...          -0.199759   \n",
       "25  {'activation_function': 'relu', 'hidden_layer_...          -0.649795   \n",
       "38  {'activation_function': 'tanh', 'hidden_layer_...          -0.325768   \n",
       "28  {'activation_function': 'relu', 'hidden_layer_...          -0.162908   \n",
       "29  {'activation_function': 'relu', 'hidden_layer_...          -0.494256   \n",
       "10  {'activation_function': 'linear', 'hidden_laye...          -0.651232   \n",
       "0   {'activation_function': 'linear', 'hidden_laye...          -2.373923   \n",
       "3   {'activation_function': 'tanh', 'hidden_layer_...          -3.334007   \n",
       "1   {'activation_function': 'sigmoid', 'hidden_lay...          -3.334007   \n",
       "2   {'activation_function': 'relu', 'hidden_layer_...          -7.876654   \n",
       "\n",
       "    split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "12          -0.208734       ...               -0.178297        0.020033   \n",
       "19          -0.205128       ...               -0.186706        0.026759   \n",
       "7           -0.207982       ...               -0.190766        0.018947   \n",
       "22          -0.191436       ...               -0.192184        0.008545   \n",
       "5           -0.194529       ...               -0.192473        0.027502   \n",
       "8           -0.203110       ...               -0.193223        0.022042   \n",
       "9           -0.224477       ...               -0.195314        0.033756   \n",
       "21          -0.204223       ...               -0.197968        0.016305   \n",
       "20          -0.236252       ...               -0.199689        0.028723   \n",
       "6           -0.207872       ...               -0.206377        0.019039   \n",
       "16          -0.237342       ...               -0.208554        0.031880   \n",
       "39          -0.201409       ...               -0.211628        0.021150   \n",
       "35          -0.236568       ...               -0.214155        0.020321   \n",
       "17          -0.236103       ...               -0.218155        0.025173   \n",
       "18          -0.214877       ...               -0.218680        0.016952   \n",
       "26          -0.237894       ...               -0.219349        0.013147   \n",
       "32          -0.239147       ...               -0.220677        0.021047   \n",
       "4           -0.311087       ...               -0.222170        0.052945   \n",
       "11          -0.380480       ...               -0.224537        0.080845   \n",
       "34          -0.236148       ...               -0.224703        0.016161   \n",
       "37          -0.236410       ...               -0.225795        0.016547   \n",
       "23          -0.238964       ...               -0.226589        0.017160   \n",
       "33          -0.239355       ...               -0.226715        0.017881   \n",
       "24          -0.236459       ...               -0.226730        0.016899   \n",
       "27          -0.237307       ...               -0.226818        0.014911   \n",
       "36          -0.244115       ...               -0.227151        0.015656   \n",
       "31          -0.240813       ...               -0.228268        0.018125   \n",
       "14          -0.236779       ...               -0.228600        0.016883   \n",
       "15          -0.243327       ...               -0.229115        0.015494   \n",
       "13          -0.239329       ...               -0.234236        0.018224   \n",
       "30          -0.236384       ...               -0.257736        0.049834   \n",
       "25          -0.199647       ...               -0.301792        0.181063   \n",
       "38          -0.357938       ...               -0.325679        0.052779   \n",
       "28          -0.541465       ...               -0.360402        0.150330   \n",
       "29          -0.378280       ...               -0.557093        0.140428   \n",
       "10          -1.673771       ...               -0.985738        0.554892   \n",
       "0           -2.081822       ...               -2.044422        0.784499   \n",
       "3           -3.429019       ...               -3.408203        0.083531   \n",
       "1           -3.429019       ...               -3.408203        0.083531   \n",
       "2           -8.002765       ...               -7.976894        0.124440   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "12                1           -0.031412           -0.058933   \n",
       "19                2           -0.057074           -0.034073   \n",
       "7                 3           -0.011178           -0.014782   \n",
       "22                4           -0.231256           -0.062534   \n",
       "5                 5           -0.022234           -0.018154   \n",
       "8                 6           -0.019599           -0.029946   \n",
       "9                 7           -0.031552           -0.059955   \n",
       "21                8           -0.094053           -0.066915   \n",
       "20                9           -0.134844           -0.221440   \n",
       "6                10           -0.052365           -0.054430   \n",
       "16               11           -0.121330           -0.221982   \n",
       "39               12           -0.237134           -0.125121   \n",
       "35               13           -0.237452           -0.221705   \n",
       "17               14           -0.232489           -0.220881   \n",
       "18               15           -0.232659           -0.161852   \n",
       "26               16           -0.232888           -0.222900   \n",
       "32               17           -0.235001           -0.224769   \n",
       "4                18           -0.023453           -0.124082   \n",
       "11               19           -0.034846           -0.783732   \n",
       "34               20           -0.231362           -0.221379   \n",
       "37               21           -0.231434           -0.221573   \n",
       "23               22           -0.233934           -0.223900   \n",
       "33               23           -0.231298           -0.224268   \n",
       "24               24           -0.232796           -0.221613   \n",
       "27               25           -0.240058           -0.222362   \n",
       "36               26           -0.239049           -0.228822   \n",
       "31               27           -0.233968           -0.225653   \n",
       "14               28           -0.235741           -0.221888   \n",
       "15               29           -0.239262           -0.228062   \n",
       "13               30           -0.244986           -0.224244   \n",
       "30               31           -0.231950           -0.221551   \n",
       "25               32           -0.579378           -0.079933   \n",
       "38               33           -0.349121           -0.345410   \n",
       "28               34           -0.085792           -0.400448   \n",
       "29               35           -0.440188           -0.323708   \n",
       "10               36           -0.873479           -2.286804   \n",
       "0                37           -2.306027           -1.837597   \n",
       "3                38           -3.426807           -3.403003   \n",
       "1                38           -3.426807           -3.403003   \n",
       "2                40           -8.002028           -7.970431   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "12           -0.038213           -0.021005           -0.046250   \n",
       "19           -0.040690           -0.057128           -0.046569   \n",
       "7            -0.013335           -0.010347           -0.010373   \n",
       "22           -0.089309           -0.108107           -0.102943   \n",
       "5            -0.011843           -0.022393           -0.045349   \n",
       "8            -0.044178           -0.057379           -0.042451   \n",
       "9            -0.026487           -0.019075           -0.058209   \n",
       "21           -0.230878           -0.083936           -0.108919   \n",
       "20           -0.099368           -0.134007           -0.164970   \n",
       "6            -0.135198           -0.045380           -0.016374   \n",
       "16           -0.225343           -0.130627           -0.219861   \n",
       "39           -0.104452           -0.223372           -0.224478   \n",
       "35           -0.134537           -0.163921           -0.220734   \n",
       "17           -0.126527           -0.228839           -0.220551   \n",
       "18           -0.159142           -0.225384           -0.171930   \n",
       "26           -0.226662           -0.165573           -0.145405   \n",
       "32           -0.131133           -0.224620           -0.227832   \n",
       "4            -0.039679           -0.014129           -0.048821   \n",
       "11           -0.027176           -0.028045           -0.032696   \n",
       "34           -0.226254           -0.223410           -0.220890   \n",
       "37           -0.225463           -0.223467           -0.222155   \n",
       "23           -0.226856           -0.224120           -0.223250   \n",
       "33           -0.225337           -0.223438           -0.233528   \n",
       "24           -0.229985           -0.227169           -0.221890   \n",
       "27           -0.227212           -0.223673           -0.222418   \n",
       "36           -0.227222           -0.223433           -0.224387   \n",
       "31           -0.226055           -0.226364           -0.224937   \n",
       "14           -0.236186           -0.226751           -0.224847   \n",
       "15           -0.237446           -0.224976           -0.221348   \n",
       "13           -0.230915           -0.239614           -0.225474   \n",
       "30           -0.226625           -0.228295           -0.216298   \n",
       "25           -0.068540           -0.072941           -0.145699   \n",
       "38           -0.307383           -0.223371           -0.382141   \n",
       "28           -0.457921           -0.215694           -0.220208   \n",
       "29           -0.584131           -0.344877           -0.579167   \n",
       "10           -0.009430           -1.523011           -1.789221   \n",
       "0            -1.176133           -3.024336           -1.095315   \n",
       "3            -3.437868           -3.386606           -3.386745   \n",
       "1            -3.437868           -3.386606           -3.386745   \n",
       "2            -8.022614           -7.943718           -7.945698   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "12         -0.039163         0.012898  \n",
       "19         -0.047107         0.009068  \n",
       "7          -0.012003         0.001765  \n",
       "22         -0.118830         0.058391  \n",
       "5          -0.023995         0.011344  \n",
       "8          -0.038710         0.012919  \n",
       "9          -0.039056         0.016836  \n",
       "21         -0.116940         0.058586  \n",
       "20         -0.150926         0.040921  \n",
       "6          -0.060749         0.039644  \n",
       "16         -0.183829         0.047358  \n",
       "39         -0.182911         0.056215  \n",
       "35         -0.195670         0.039489  \n",
       "17         -0.205857         0.039931  \n",
       "18         -0.190193         0.032071  \n",
       "26         -0.198686         0.035984  \n",
       "32         -0.208671         0.038951  \n",
       "4          -0.050033         0.038955  \n",
       "11         -0.181299         0.301230  \n",
       "34         -0.224659         0.003847  \n",
       "37         -0.224818         0.003567  \n",
       "23         -0.226412         0.003959  \n",
       "33         -0.227574         0.004058  \n",
       "24         -0.226691         0.004409  \n",
       "27         -0.227145         0.006694  \n",
       "36         -0.228583         0.005578  \n",
       "31         -0.227395         0.003321  \n",
       "14         -0.229083         0.005830  \n",
       "15         -0.230219         0.006998  \n",
       "13         -0.233046         0.008063  \n",
       "30         -0.224944         0.005466  \n",
       "25         -0.189298         0.197051  \n",
       "38         -0.321485         0.054480  \n",
       "28         -0.276013         0.135286  \n",
       "29         -0.454414         0.111063  \n",
       "10         -1.296389         0.788705  \n",
       "0          -1.887882         0.721616  \n",
       "3          -3.408206         0.020881  \n",
       "1          -3.408206         0.020881  \n",
       "2          -7.976898         0.031105  \n",
       "\n",
       "[40 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(['rank_test_score'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing models (based on the grid-search) can then be identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_num_hidden_layers</th>\n",
       "      <th>param_hidden_layer_size</th>\n",
       "      <th>param_activation_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>linear</th>\n",
       "      <td>18.877625</td>\n",
       "      <td>1.608140</td>\n",
       "      <td>0.138699</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>-2.373923</td>\n",
       "      <td>-2.081822</td>\n",
       "      <td>-1.334480</td>\n",
       "      <td>-3.312315</td>\n",
       "      <td>-1.118598</td>\n",
       "      <td>-2.044422</td>\n",
       "      <td>0.784499</td>\n",
       "      <td>37</td>\n",
       "      <td>-2.306027</td>\n",
       "      <td>-1.837597</td>\n",
       "      <td>-1.176133</td>\n",
       "      <td>-3.024336</td>\n",
       "      <td>-1.095315</td>\n",
       "      <td>-1.887882</td>\n",
       "      <td>0.721616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>13.943288</td>\n",
       "      <td>0.287599</td>\n",
       "      <td>0.295754</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>-7.876654</td>\n",
       "      <td>-8.002765</td>\n",
       "      <td>-7.793879</td>\n",
       "      <td>-8.109698</td>\n",
       "      <td>-8.101770</td>\n",
       "      <td>-7.976894</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>40</td>\n",
       "      <td>-8.002028</td>\n",
       "      <td>-7.970431</td>\n",
       "      <td>-8.022614</td>\n",
       "      <td>-7.943718</td>\n",
       "      <td>-7.945698</td>\n",
       "      <td>-7.976898</td>\n",
       "      <td>0.031105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>12.494315</td>\n",
       "      <td>0.124183</td>\n",
       "      <td>0.203067</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>-3.334007</td>\n",
       "      <td>-3.429019</td>\n",
       "      <td>-3.289454</td>\n",
       "      <td>-3.494653</td>\n",
       "      <td>-3.494100</td>\n",
       "      <td>-3.408203</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>38</td>\n",
       "      <td>-3.426807</td>\n",
       "      <td>-3.403003</td>\n",
       "      <td>-3.437868</td>\n",
       "      <td>-3.386606</td>\n",
       "      <td>-3.386745</td>\n",
       "      <td>-3.408206</td>\n",
       "      <td>0.020881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>12.805012</td>\n",
       "      <td>0.312548</td>\n",
       "      <td>0.343594</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>-3.334007</td>\n",
       "      <td>-3.429019</td>\n",
       "      <td>-3.289454</td>\n",
       "      <td>-3.494653</td>\n",
       "      <td>-3.494100</td>\n",
       "      <td>-3.408203</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>38</td>\n",
       "      <td>-3.426807</td>\n",
       "      <td>-3.403003</td>\n",
       "      <td>-3.437868</td>\n",
       "      <td>-3.386606</td>\n",
       "      <td>-3.386745</td>\n",
       "      <td>-3.408206</td>\n",
       "      <td>0.020881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">64</th>\n",
       "      <th>linear</th>\n",
       "      <td>245.377212</td>\n",
       "      <td>47.310742</td>\n",
       "      <td>0.487355</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>-0.179391</td>\n",
       "      <td>-0.311087</td>\n",
       "      <td>-0.196488</td>\n",
       "      <td>-0.170677</td>\n",
       "      <td>-0.253335</td>\n",
       "      <td>-0.222170</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.124082</td>\n",
       "      <td>-0.039679</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>-0.048821</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>0.038955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>331.651672</td>\n",
       "      <td>11.740114</td>\n",
       "      <td>2.851909</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>-0.196655</td>\n",
       "      <td>-0.191436</td>\n",
       "      <td>-0.180250</td>\n",
       "      <td>-0.187100</td>\n",
       "      <td>-0.205466</td>\n",
       "      <td>-0.192184</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.231256</td>\n",
       "      <td>-0.062534</td>\n",
       "      <td>-0.089309</td>\n",
       "      <td>-0.108107</td>\n",
       "      <td>-0.102943</td>\n",
       "      <td>-0.118830</td>\n",
       "      <td>0.058391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>78.821601</td>\n",
       "      <td>29.201884</td>\n",
       "      <td>1.586589</td>\n",
       "      <td>0.026512</td>\n",
       "      <td>-0.206600</td>\n",
       "      <td>-0.239329</td>\n",
       "      <td>-0.220430</td>\n",
       "      <td>-0.255227</td>\n",
       "      <td>-0.249676</td>\n",
       "      <td>-0.234236</td>\n",
       "      <td>0.018224</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.244986</td>\n",
       "      <td>-0.224244</td>\n",
       "      <td>-0.230915</td>\n",
       "      <td>-0.239614</td>\n",
       "      <td>-0.225474</td>\n",
       "      <td>-0.233046</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>83.685453</td>\n",
       "      <td>2.954401</td>\n",
       "      <td>4.081301</td>\n",
       "      <td>0.063113</td>\n",
       "      <td>-0.197702</td>\n",
       "      <td>-0.240813</td>\n",
       "      <td>-0.219352</td>\n",
       "      <td>-0.234556</td>\n",
       "      <td>-0.249006</td>\n",
       "      <td>-0.228268</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.233968</td>\n",
       "      <td>-0.225653</td>\n",
       "      <td>-0.226055</td>\n",
       "      <td>-0.226364</td>\n",
       "      <td>-0.224937</td>\n",
       "      <td>-0.227395</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128</th>\n",
       "      <th>linear</th>\n",
       "      <td>582.432157</td>\n",
       "      <td>68.998469</td>\n",
       "      <td>0.916782</td>\n",
       "      <td>0.027519</td>\n",
       "      <td>-0.166008</td>\n",
       "      <td>-0.207982</td>\n",
       "      <td>-0.194951</td>\n",
       "      <td>-0.171726</td>\n",
       "      <td>-0.213234</td>\n",
       "      <td>-0.190766</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.011178</td>\n",
       "      <td>-0.014782</td>\n",
       "      <td>-0.013335</td>\n",
       "      <td>-0.010347</td>\n",
       "      <td>-0.010373</td>\n",
       "      <td>-0.012003</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>406.746533</td>\n",
       "      <td>179.311350</td>\n",
       "      <td>3.348204</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>-0.649795</td>\n",
       "      <td>-0.199647</td>\n",
       "      <td>-0.180657</td>\n",
       "      <td>-0.169859</td>\n",
       "      <td>-0.307973</td>\n",
       "      <td>-0.301792</td>\n",
       "      <td>0.181063</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.579378</td>\n",
       "      <td>-0.079933</td>\n",
       "      <td>-0.068540</td>\n",
       "      <td>-0.072941</td>\n",
       "      <td>-0.145699</td>\n",
       "      <td>-0.189298</td>\n",
       "      <td>0.197051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>231.058185</td>\n",
       "      <td>146.032240</td>\n",
       "      <td>2.080906</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>-0.158427</td>\n",
       "      <td>-0.237342</td>\n",
       "      <td>-0.220197</td>\n",
       "      <td>-0.185621</td>\n",
       "      <td>-0.241332</td>\n",
       "      <td>-0.208554</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.121330</td>\n",
       "      <td>-0.221982</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.130627</td>\n",
       "      <td>-0.219861</td>\n",
       "      <td>-0.183829</td>\n",
       "      <td>0.047358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>136.617612</td>\n",
       "      <td>1.595075</td>\n",
       "      <td>4.705369</td>\n",
       "      <td>0.045895</td>\n",
       "      <td>-0.196456</td>\n",
       "      <td>-0.236148</td>\n",
       "      <td>-0.219283</td>\n",
       "      <td>-0.228882</td>\n",
       "      <td>-0.242831</td>\n",
       "      <td>-0.224703</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.231362</td>\n",
       "      <td>-0.221379</td>\n",
       "      <td>-0.226254</td>\n",
       "      <td>-0.223410</td>\n",
       "      <td>-0.220890</td>\n",
       "      <td>-0.224659</td>\n",
       "      <td>0.003847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">256</th>\n",
       "      <th>linear</th>\n",
       "      <td>377.221346</td>\n",
       "      <td>346.312438</td>\n",
       "      <td>1.272435</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>-0.651232</td>\n",
       "      <td>-1.673771</td>\n",
       "      <td>-0.180109</td>\n",
       "      <td>-1.530982</td>\n",
       "      <td>-0.893585</td>\n",
       "      <td>-0.985738</td>\n",
       "      <td>0.554892</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.873479</td>\n",
       "      <td>-2.286804</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>-1.523011</td>\n",
       "      <td>-1.789221</td>\n",
       "      <td>-1.296389</td>\n",
       "      <td>0.788705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>513.730981</td>\n",
       "      <td>349.592034</td>\n",
       "      <td>3.790669</td>\n",
       "      <td>0.037556</td>\n",
       "      <td>-0.162908</td>\n",
       "      <td>-0.541465</td>\n",
       "      <td>-0.522369</td>\n",
       "      <td>-0.334934</td>\n",
       "      <td>-0.240915</td>\n",
       "      <td>-0.360402</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.085792</td>\n",
       "      <td>-0.400448</td>\n",
       "      <td>-0.457921</td>\n",
       "      <td>-0.215694</td>\n",
       "      <td>-0.220208</td>\n",
       "      <td>-0.276013</td>\n",
       "      <td>0.135286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>351.657404</td>\n",
       "      <td>70.296554</td>\n",
       "      <td>2.456750</td>\n",
       "      <td>0.040858</td>\n",
       "      <td>-0.156284</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>-0.177878</td>\n",
       "      <td>-0.165401</td>\n",
       "      <td>-0.228931</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>0.026759</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.057074</td>\n",
       "      <td>-0.034073</td>\n",
       "      <td>-0.040690</td>\n",
       "      <td>-0.057128</td>\n",
       "      <td>-0.046569</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>0.009068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>195.613859</td>\n",
       "      <td>4.465094</td>\n",
       "      <td>5.145208</td>\n",
       "      <td>0.027091</td>\n",
       "      <td>-0.196429</td>\n",
       "      <td>-0.236410</td>\n",
       "      <td>-0.222135</td>\n",
       "      <td>-0.229114</td>\n",
       "      <td>-0.244972</td>\n",
       "      <td>-0.225795</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.231434</td>\n",
       "      <td>-0.221573</td>\n",
       "      <td>-0.225463</td>\n",
       "      <td>-0.223467</td>\n",
       "      <td>-0.222155</td>\n",
       "      <td>-0.224818</td>\n",
       "      <td>0.003567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">64</th>\n",
       "      <th>linear</th>\n",
       "      <td>213.031170</td>\n",
       "      <td>47.286451</td>\n",
       "      <td>0.632164</td>\n",
       "      <td>0.034216</td>\n",
       "      <td>-0.164358</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>-0.181527</td>\n",
       "      <td>-0.178006</td>\n",
       "      <td>-0.244027</td>\n",
       "      <td>-0.192473</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>-0.011843</td>\n",
       "      <td>-0.022393</td>\n",
       "      <td>-0.045349</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>0.011344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>150.663524</td>\n",
       "      <td>26.972251</td>\n",
       "      <td>3.060753</td>\n",
       "      <td>0.047939</td>\n",
       "      <td>-0.197517</td>\n",
       "      <td>-0.238964</td>\n",
       "      <td>-0.219206</td>\n",
       "      <td>-0.230741</td>\n",
       "      <td>-0.246604</td>\n",
       "      <td>-0.226589</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.233934</td>\n",
       "      <td>-0.223900</td>\n",
       "      <td>-0.226856</td>\n",
       "      <td>-0.224120</td>\n",
       "      <td>-0.223250</td>\n",
       "      <td>-0.226412</td>\n",
       "      <td>0.003959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>70.938486</td>\n",
       "      <td>5.698213</td>\n",
       "      <td>1.747982</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>-0.198990</td>\n",
       "      <td>-0.236779</td>\n",
       "      <td>-0.223343</td>\n",
       "      <td>-0.235141</td>\n",
       "      <td>-0.248832</td>\n",
       "      <td>-0.228600</td>\n",
       "      <td>0.016883</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.235741</td>\n",
       "      <td>-0.221888</td>\n",
       "      <td>-0.236186</td>\n",
       "      <td>-0.226751</td>\n",
       "      <td>-0.224847</td>\n",
       "      <td>-0.229083</td>\n",
       "      <td>0.005830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>210.502111</td>\n",
       "      <td>102.688570</td>\n",
       "      <td>4.269154</td>\n",
       "      <td>0.042565</td>\n",
       "      <td>-0.202425</td>\n",
       "      <td>-0.239147</td>\n",
       "      <td>-0.190053</td>\n",
       "      <td>-0.227562</td>\n",
       "      <td>-0.244249</td>\n",
       "      <td>-0.220677</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.235001</td>\n",
       "      <td>-0.224769</td>\n",
       "      <td>-0.131133</td>\n",
       "      <td>-0.224620</td>\n",
       "      <td>-0.227832</td>\n",
       "      <td>-0.208671</td>\n",
       "      <td>0.038951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128</th>\n",
       "      <th>linear</th>\n",
       "      <td>353.847553</td>\n",
       "      <td>60.673596</td>\n",
       "      <td>1.056034</td>\n",
       "      <td>0.039973</td>\n",
       "      <td>-0.167493</td>\n",
       "      <td>-0.203110</td>\n",
       "      <td>-0.191670</td>\n",
       "      <td>-0.174446</td>\n",
       "      <td>-0.229473</td>\n",
       "      <td>-0.193223</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.019599</td>\n",
       "      <td>-0.029946</td>\n",
       "      <td>-0.044178</td>\n",
       "      <td>-0.057379</td>\n",
       "      <td>-0.042451</td>\n",
       "      <td>-0.038710</td>\n",
       "      <td>0.012919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>231.351712</td>\n",
       "      <td>66.048873</td>\n",
       "      <td>3.595038</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>-0.196869</td>\n",
       "      <td>-0.237894</td>\n",
       "      <td>-0.219214</td>\n",
       "      <td>-0.219769</td>\n",
       "      <td>-0.223067</td>\n",
       "      <td>-0.219349</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.232888</td>\n",
       "      <td>-0.222900</td>\n",
       "      <td>-0.226662</td>\n",
       "      <td>-0.165573</td>\n",
       "      <td>-0.145405</td>\n",
       "      <td>-0.198686</td>\n",
       "      <td>0.035984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>228.254828</td>\n",
       "      <td>114.659138</td>\n",
       "      <td>2.239141</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>-0.196777</td>\n",
       "      <td>-0.236103</td>\n",
       "      <td>-0.179456</td>\n",
       "      <td>-0.238186</td>\n",
       "      <td>-0.240314</td>\n",
       "      <td>-0.218155</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.232489</td>\n",
       "      <td>-0.220881</td>\n",
       "      <td>-0.126527</td>\n",
       "      <td>-0.228839</td>\n",
       "      <td>-0.220551</td>\n",
       "      <td>-0.205857</td>\n",
       "      <td>0.039931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>399.034078</td>\n",
       "      <td>145.717701</td>\n",
       "      <td>4.840754</td>\n",
       "      <td>0.059388</td>\n",
       "      <td>-0.205447</td>\n",
       "      <td>-0.236568</td>\n",
       "      <td>-0.191734</td>\n",
       "      <td>-0.196769</td>\n",
       "      <td>-0.240282</td>\n",
       "      <td>-0.214155</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.237452</td>\n",
       "      <td>-0.221705</td>\n",
       "      <td>-0.134537</td>\n",
       "      <td>-0.163921</td>\n",
       "      <td>-0.220734</td>\n",
       "      <td>-0.195670</td>\n",
       "      <td>0.039489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">256</th>\n",
       "      <th>linear</th>\n",
       "      <td>502.579788</td>\n",
       "      <td>168.483454</td>\n",
       "      <td>1.418930</td>\n",
       "      <td>0.045170</td>\n",
       "      <td>-0.178085</td>\n",
       "      <td>-0.380480</td>\n",
       "      <td>-0.177424</td>\n",
       "      <td>-0.161322</td>\n",
       "      <td>-0.225509</td>\n",
       "      <td>-0.224537</td>\n",
       "      <td>0.080845</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.034846</td>\n",
       "      <td>-0.783732</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.028045</td>\n",
       "      <td>-0.032696</td>\n",
       "      <td>-0.181299</td>\n",
       "      <td>0.301230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>278.199999</td>\n",
       "      <td>103.981110</td>\n",
       "      <td>3.972265</td>\n",
       "      <td>0.032277</td>\n",
       "      <td>-0.494256</td>\n",
       "      <td>-0.378280</td>\n",
       "      <td>-0.673658</td>\n",
       "      <td>-0.476042</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.557093</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.440188</td>\n",
       "      <td>-0.323708</td>\n",
       "      <td>-0.584131</td>\n",
       "      <td>-0.344877</td>\n",
       "      <td>-0.579167</td>\n",
       "      <td>-0.454414</td>\n",
       "      <td>0.111063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>421.269787</td>\n",
       "      <td>148.231854</td>\n",
       "      <td>2.633213</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>-0.173075</td>\n",
       "      <td>-0.236252</td>\n",
       "      <td>-0.183115</td>\n",
       "      <td>-0.173183</td>\n",
       "      <td>-0.232900</td>\n",
       "      <td>-0.199689</td>\n",
       "      <td>0.028723</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-0.221440</td>\n",
       "      <td>-0.099368</td>\n",
       "      <td>-0.134007</td>\n",
       "      <td>-0.164970</td>\n",
       "      <td>-0.150926</td>\n",
       "      <td>0.040921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>254.722134</td>\n",
       "      <td>100.902196</td>\n",
       "      <td>5.286748</td>\n",
       "      <td>0.037380</td>\n",
       "      <td>-0.325768</td>\n",
       "      <td>-0.357938</td>\n",
       "      <td>-0.333361</td>\n",
       "      <td>-0.228089</td>\n",
       "      <td>-0.383236</td>\n",
       "      <td>-0.325679</td>\n",
       "      <td>0.052779</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.349121</td>\n",
       "      <td>-0.345410</td>\n",
       "      <td>-0.307383</td>\n",
       "      <td>-0.223371</td>\n",
       "      <td>-0.382141</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.054480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">64</th>\n",
       "      <th>linear</th>\n",
       "      <td>200.024234</td>\n",
       "      <td>66.062712</td>\n",
       "      <td>0.792366</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>-0.185885</td>\n",
       "      <td>-0.207872</td>\n",
       "      <td>-0.239976</td>\n",
       "      <td>-0.190288</td>\n",
       "      <td>-0.207927</td>\n",
       "      <td>-0.206377</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.052365</td>\n",
       "      <td>-0.054430</td>\n",
       "      <td>-0.135198</td>\n",
       "      <td>-0.045380</td>\n",
       "      <td>-0.016374</td>\n",
       "      <td>-0.060749</td>\n",
       "      <td>0.039644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>189.328727</td>\n",
       "      <td>59.447426</td>\n",
       "      <td>3.261559</td>\n",
       "      <td>0.050417</td>\n",
       "      <td>-0.196945</td>\n",
       "      <td>-0.236459</td>\n",
       "      <td>-0.220019</td>\n",
       "      <td>-0.235761</td>\n",
       "      <td>-0.244556</td>\n",
       "      <td>-0.226730</td>\n",
       "      <td>0.016899</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.232796</td>\n",
       "      <td>-0.221613</td>\n",
       "      <td>-0.229985</td>\n",
       "      <td>-0.227169</td>\n",
       "      <td>-0.221890</td>\n",
       "      <td>-0.226691</td>\n",
       "      <td>0.004409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>85.845923</td>\n",
       "      <td>18.334763</td>\n",
       "      <td>1.931586</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>-0.201779</td>\n",
       "      <td>-0.243327</td>\n",
       "      <td>-0.224133</td>\n",
       "      <td>-0.232756</td>\n",
       "      <td>-0.243660</td>\n",
       "      <td>-0.229115</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.239262</td>\n",
       "      <td>-0.228062</td>\n",
       "      <td>-0.237446</td>\n",
       "      <td>-0.224976</td>\n",
       "      <td>-0.221348</td>\n",
       "      <td>-0.230219</td>\n",
       "      <td>0.006998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>179.069814</td>\n",
       "      <td>9.940175</td>\n",
       "      <td>4.475766</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>-0.196515</td>\n",
       "      <td>-0.239355</td>\n",
       "      <td>-0.220219</td>\n",
       "      <td>-0.229002</td>\n",
       "      <td>-0.248572</td>\n",
       "      <td>-0.226715</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.231298</td>\n",
       "      <td>-0.224268</td>\n",
       "      <td>-0.225337</td>\n",
       "      <td>-0.223438</td>\n",
       "      <td>-0.233528</td>\n",
       "      <td>-0.227574</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128</th>\n",
       "      <th>linear</th>\n",
       "      <td>354.522098</td>\n",
       "      <td>31.779977</td>\n",
       "      <td>1.241264</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>-0.162437</td>\n",
       "      <td>-0.224477</td>\n",
       "      <td>-0.172168</td>\n",
       "      <td>-0.170931</td>\n",
       "      <td>-0.246653</td>\n",
       "      <td>-0.195314</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.031552</td>\n",
       "      <td>-0.059955</td>\n",
       "      <td>-0.026487</td>\n",
       "      <td>-0.019075</td>\n",
       "      <td>-0.058209</td>\n",
       "      <td>-0.039056</td>\n",
       "      <td>0.016836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>249.702263</td>\n",
       "      <td>45.894048</td>\n",
       "      <td>3.755433</td>\n",
       "      <td>0.043215</td>\n",
       "      <td>-0.202529</td>\n",
       "      <td>-0.237307</td>\n",
       "      <td>-0.219221</td>\n",
       "      <td>-0.229729</td>\n",
       "      <td>-0.245375</td>\n",
       "      <td>-0.226818</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.240058</td>\n",
       "      <td>-0.222362</td>\n",
       "      <td>-0.227212</td>\n",
       "      <td>-0.223673</td>\n",
       "      <td>-0.222418</td>\n",
       "      <td>-0.227145</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>306.530452</td>\n",
       "      <td>143.504055</td>\n",
       "      <td>2.400970</td>\n",
       "      <td>0.054322</td>\n",
       "      <td>-0.196865</td>\n",
       "      <td>-0.214877</td>\n",
       "      <td>-0.205971</td>\n",
       "      <td>-0.233010</td>\n",
       "      <td>-0.242743</td>\n",
       "      <td>-0.218680</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.232659</td>\n",
       "      <td>-0.161852</td>\n",
       "      <td>-0.159142</td>\n",
       "      <td>-0.225384</td>\n",
       "      <td>-0.171930</td>\n",
       "      <td>-0.190193</td>\n",
       "      <td>0.032071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>291.120146</td>\n",
       "      <td>48.486737</td>\n",
       "      <td>5.012955</td>\n",
       "      <td>0.059402</td>\n",
       "      <td>-0.201604</td>\n",
       "      <td>-0.244115</td>\n",
       "      <td>-0.219223</td>\n",
       "      <td>-0.228986</td>\n",
       "      <td>-0.241905</td>\n",
       "      <td>-0.227151</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.239049</td>\n",
       "      <td>-0.228822</td>\n",
       "      <td>-0.227222</td>\n",
       "      <td>-0.223433</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.228583</td>\n",
       "      <td>0.005578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">256</th>\n",
       "      <th>linear</th>\n",
       "      <td>533.480620</td>\n",
       "      <td>61.981618</td>\n",
       "      <td>1.604587</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>-0.156356</td>\n",
       "      <td>-0.208734</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.161771</td>\n",
       "      <td>-0.194438</td>\n",
       "      <td>-0.178297</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031412</td>\n",
       "      <td>-0.058933</td>\n",
       "      <td>-0.038213</td>\n",
       "      <td>-0.021005</td>\n",
       "      <td>-0.046250</td>\n",
       "      <td>-0.039163</td>\n",
       "      <td>0.012898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>414.319877</td>\n",
       "      <td>113.498782</td>\n",
       "      <td>4.174578</td>\n",
       "      <td>0.061544</td>\n",
       "      <td>-0.199759</td>\n",
       "      <td>-0.236384</td>\n",
       "      <td>-0.219217</td>\n",
       "      <td>-0.308112</td>\n",
       "      <td>-0.325379</td>\n",
       "      <td>-0.257736</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.231950</td>\n",
       "      <td>-0.221551</td>\n",
       "      <td>-0.226625</td>\n",
       "      <td>-0.228295</td>\n",
       "      <td>-0.216298</td>\n",
       "      <td>-0.224944</td>\n",
       "      <td>0.005466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>499.845629</td>\n",
       "      <td>185.975525</td>\n",
       "      <td>2.821082</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>-0.190206</td>\n",
       "      <td>-0.204223</td>\n",
       "      <td>-0.220412</td>\n",
       "      <td>-0.171572</td>\n",
       "      <td>-0.203452</td>\n",
       "      <td>-0.197968</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.094053</td>\n",
       "      <td>-0.066915</td>\n",
       "      <td>-0.230878</td>\n",
       "      <td>-0.083936</td>\n",
       "      <td>-0.108919</td>\n",
       "      <td>-0.116940</td>\n",
       "      <td>0.058586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>574.152614</td>\n",
       "      <td>106.859661</td>\n",
       "      <td>5.508796</td>\n",
       "      <td>0.103761</td>\n",
       "      <td>-0.205062</td>\n",
       "      <td>-0.201409</td>\n",
       "      <td>-0.181641</td>\n",
       "      <td>-0.228085</td>\n",
       "      <td>-0.241961</td>\n",
       "      <td>-0.211628</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.237134</td>\n",
       "      <td>-0.125121</td>\n",
       "      <td>-0.104452</td>\n",
       "      <td>-0.223372</td>\n",
       "      <td>-0.224478</td>\n",
       "      <td>-0.182911</td>\n",
       "      <td>0.056215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           mean_fit_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                  \n",
       "0                       0                       linear                         18.877625   \n",
       "                                                relu                           13.943288   \n",
       "                                                sigmoid                        12.494315   \n",
       "                                                tanh                           12.805012   \n",
       "1                       64                      linear                        245.377212   \n",
       "                                                relu                          331.651672   \n",
       "                                                sigmoid                        78.821601   \n",
       "                                                tanh                           83.685453   \n",
       "                        128                     linear                        582.432157   \n",
       "                                                relu                          406.746533   \n",
       "                                                sigmoid                       231.058185   \n",
       "                                                tanh                          136.617612   \n",
       "                        256                     linear                        377.221346   \n",
       "                                                relu                          513.730981   \n",
       "                                                sigmoid                       351.657404   \n",
       "                                                tanh                          195.613859   \n",
       "2                       64                      linear                        213.031170   \n",
       "                                                relu                          150.663524   \n",
       "                                                sigmoid                        70.938486   \n",
       "                                                tanh                          210.502111   \n",
       "                        128                     linear                        353.847553   \n",
       "                                                relu                          231.351712   \n",
       "                                                sigmoid                       228.254828   \n",
       "                                                tanh                          399.034078   \n",
       "                        256                     linear                        502.579788   \n",
       "                                                relu                          278.199999   \n",
       "                                                sigmoid                       421.269787   \n",
       "                                                tanh                          254.722134   \n",
       "3                       64                      linear                        200.024234   \n",
       "                                                relu                          189.328727   \n",
       "                                                sigmoid                        85.845923   \n",
       "                                                tanh                          179.069814   \n",
       "                        128                     linear                        354.522098   \n",
       "                                                relu                          249.702263   \n",
       "                                                sigmoid                       306.530452   \n",
       "                                                tanh                          291.120146   \n",
       "                        256                     linear                        533.480620   \n",
       "                                                relu                          414.319877   \n",
       "                                                sigmoid                       499.845629   \n",
       "                                                tanh                          574.152614   \n",
       "\n",
       "                                                                           std_fit_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                 \n",
       "0                       0                       linear                         1.608140   \n",
       "                                                relu                           0.287599   \n",
       "                                                sigmoid                        0.124183   \n",
       "                                                tanh                           0.312548   \n",
       "1                       64                      linear                        47.310742   \n",
       "                                                relu                          11.740114   \n",
       "                                                sigmoid                       29.201884   \n",
       "                                                tanh                           2.954401   \n",
       "                        128                     linear                        68.998469   \n",
       "                                                relu                         179.311350   \n",
       "                                                sigmoid                      146.032240   \n",
       "                                                tanh                           1.595075   \n",
       "                        256                     linear                       346.312438   \n",
       "                                                relu                         349.592034   \n",
       "                                                sigmoid                       70.296554   \n",
       "                                                tanh                           4.465094   \n",
       "2                       64                      linear                        47.286451   \n",
       "                                                relu                          26.972251   \n",
       "                                                sigmoid                        5.698213   \n",
       "                                                tanh                         102.688570   \n",
       "                        128                     linear                        60.673596   \n",
       "                                                relu                          66.048873   \n",
       "                                                sigmoid                      114.659138   \n",
       "                                                tanh                         145.717701   \n",
       "                        256                     linear                       168.483454   \n",
       "                                                relu                         103.981110   \n",
       "                                                sigmoid                      148.231854   \n",
       "                                                tanh                         100.902196   \n",
       "3                       64                      linear                        66.062712   \n",
       "                                                relu                          59.447426   \n",
       "                                                sigmoid                       18.334763   \n",
       "                                                tanh                           9.940175   \n",
       "                        128                     linear                        31.779977   \n",
       "                                                relu                          45.894048   \n",
       "                                                sigmoid                      143.504055   \n",
       "                                                tanh                          48.486737   \n",
       "                        256                     linear                        61.981618   \n",
       "                                                relu                         113.498782   \n",
       "                                                sigmoid                      185.975525   \n",
       "                                                tanh                         106.859661   \n",
       "\n",
       "                                                                           mean_score_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                    \n",
       "0                       0                       linear                            0.138699   \n",
       "                                                relu                              0.295754   \n",
       "                                                sigmoid                           0.203067   \n",
       "                                                tanh                              0.343594   \n",
       "1                       64                      linear                            0.487355   \n",
       "                                                relu                              2.851909   \n",
       "                                                sigmoid                           1.586589   \n",
       "                                                tanh                              4.081301   \n",
       "                        128                     linear                            0.916782   \n",
       "                                                relu                              3.348204   \n",
       "                                                sigmoid                           2.080906   \n",
       "                                                tanh                              4.705369   \n",
       "                        256                     linear                            1.272435   \n",
       "                                                relu                              3.790669   \n",
       "                                                sigmoid                           2.456750   \n",
       "                                                tanh                              5.145208   \n",
       "2                       64                      linear                            0.632164   \n",
       "                                                relu                              3.060753   \n",
       "                                                sigmoid                           1.747982   \n",
       "                                                tanh                              4.269154   \n",
       "                        128                     linear                            1.056034   \n",
       "                                                relu                              3.595038   \n",
       "                                                sigmoid                           2.239141   \n",
       "                                                tanh                              4.840754   \n",
       "                        256                     linear                            1.418930   \n",
       "                                                relu                              3.972265   \n",
       "                                                sigmoid                           2.633213   \n",
       "                                                tanh                              5.286748   \n",
       "3                       64                      linear                            0.792366   \n",
       "                                                relu                              3.261559   \n",
       "                                                sigmoid                           1.931586   \n",
       "                                                tanh                              4.475766   \n",
       "                        128                     linear                            1.241264   \n",
       "                                                relu                              3.755433   \n",
       "                                                sigmoid                           2.400970   \n",
       "                                                tanh                              5.012955   \n",
       "                        256                     linear                            1.604587   \n",
       "                                                relu                              4.174578   \n",
       "                                                sigmoid                           2.821082   \n",
       "                                                tanh                              5.508796   \n",
       "\n",
       "                                                                           std_score_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                   \n",
       "0                       0                       linear                           0.025194   \n",
       "                                                relu                             0.018892   \n",
       "                                                sigmoid                          0.020734   \n",
       "                                                tanh                             0.019401   \n",
       "1                       64                      linear                           0.024138   \n",
       "                                                relu                             0.024441   \n",
       "                                                sigmoid                          0.026512   \n",
       "                                                tanh                             0.063113   \n",
       "                        128                     linear                           0.027519   \n",
       "                                                relu                             0.032848   \n",
       "                                                sigmoid                          0.041032   \n",
       "                                                tanh                             0.045895   \n",
       "                        256                     linear                           0.018364   \n",
       "                                                relu                             0.037556   \n",
       "                                                sigmoid                          0.040858   \n",
       "                                                tanh                             0.027091   \n",
       "2                       64                      linear                           0.034216   \n",
       "                                                relu                             0.047939   \n",
       "                                                sigmoid                          0.044350   \n",
       "                                                tanh                             0.042565   \n",
       "                        128                     linear                           0.039973   \n",
       "                                                relu                             0.022401   \n",
       "                                                sigmoid                          0.030579   \n",
       "                                                tanh                             0.059388   \n",
       "                        256                     linear                           0.045170   \n",
       "                                                relu                             0.032277   \n",
       "                                                sigmoid                          0.051035   \n",
       "                                                tanh                             0.037380   \n",
       "3                       64                      linear                           0.051966   \n",
       "                                                relu                             0.050417   \n",
       "                                                sigmoid                          0.060699   \n",
       "                                                tanh                             0.048540   \n",
       "                        128                     linear                           0.038938   \n",
       "                                                relu                             0.043215   \n",
       "                                                sigmoid                          0.054322   \n",
       "                                                tanh                             0.059402   \n",
       "                        256                     linear                           0.053123   \n",
       "                                                relu                             0.061544   \n",
       "                                                sigmoid                          0.055262   \n",
       "                                                tanh                             0.103761   \n",
       "\n",
       "                                                                           split0_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "0                       0                       linear                             -2.373923   \n",
       "                                                relu                               -7.876654   \n",
       "                                                sigmoid                            -3.334007   \n",
       "                                                tanh                               -3.334007   \n",
       "1                       64                      linear                             -0.179391   \n",
       "                                                relu                               -0.196655   \n",
       "                                                sigmoid                            -0.206600   \n",
       "                                                tanh                               -0.197702   \n",
       "                        128                     linear                             -0.166008   \n",
       "                                                relu                               -0.649795   \n",
       "                                                sigmoid                            -0.158427   \n",
       "                                                tanh                               -0.196456   \n",
       "                        256                     linear                             -0.651232   \n",
       "                                                relu                               -0.162908   \n",
       "                                                sigmoid                            -0.156284   \n",
       "                                                tanh                               -0.196429   \n",
       "2                       64                      linear                             -0.164358   \n",
       "                                                relu                               -0.197517   \n",
       "                                                sigmoid                            -0.198990   \n",
       "                                                tanh                               -0.202425   \n",
       "                        128                     linear                             -0.167493   \n",
       "                                                relu                               -0.196869   \n",
       "                                                sigmoid                            -0.196777   \n",
       "                                                tanh                               -0.205447   \n",
       "                        256                     linear                             -0.178085   \n",
       "                                                relu                               -0.494256   \n",
       "                                                sigmoid                            -0.173075   \n",
       "                                                tanh                               -0.325768   \n",
       "3                       64                      linear                             -0.185885   \n",
       "                                                relu                               -0.196945   \n",
       "                                                sigmoid                            -0.201779   \n",
       "                                                tanh                               -0.196515   \n",
       "                        128                     linear                             -0.162437   \n",
       "                                                relu                               -0.202529   \n",
       "                                                sigmoid                            -0.196865   \n",
       "                                                tanh                               -0.201604   \n",
       "                        256                     linear                             -0.156356   \n",
       "                                                relu                               -0.199759   \n",
       "                                                sigmoid                            -0.190206   \n",
       "                                                tanh                               -0.205062   \n",
       "\n",
       "                                                                           split1_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "0                       0                       linear                             -2.081822   \n",
       "                                                relu                               -8.002765   \n",
       "                                                sigmoid                            -3.429019   \n",
       "                                                tanh                               -3.429019   \n",
       "1                       64                      linear                             -0.311087   \n",
       "                                                relu                               -0.191436   \n",
       "                                                sigmoid                            -0.239329   \n",
       "                                                tanh                               -0.240813   \n",
       "                        128                     linear                             -0.207982   \n",
       "                                                relu                               -0.199647   \n",
       "                                                sigmoid                            -0.237342   \n",
       "                                                tanh                               -0.236148   \n",
       "                        256                     linear                             -1.673771   \n",
       "                                                relu                               -0.541465   \n",
       "                                                sigmoid                            -0.205128   \n",
       "                                                tanh                               -0.236410   \n",
       "2                       64                      linear                             -0.194529   \n",
       "                                                relu                               -0.238964   \n",
       "                                                sigmoid                            -0.236779   \n",
       "                                                tanh                               -0.239147   \n",
       "                        128                     linear                             -0.203110   \n",
       "                                                relu                               -0.237894   \n",
       "                                                sigmoid                            -0.236103   \n",
       "                                                tanh                               -0.236568   \n",
       "                        256                     linear                             -0.380480   \n",
       "                                                relu                               -0.378280   \n",
       "                                                sigmoid                            -0.236252   \n",
       "                                                tanh                               -0.357938   \n",
       "3                       64                      linear                             -0.207872   \n",
       "                                                relu                               -0.236459   \n",
       "                                                sigmoid                            -0.243327   \n",
       "                                                tanh                               -0.239355   \n",
       "                        128                     linear                             -0.224477   \n",
       "                                                relu                               -0.237307   \n",
       "                                                sigmoid                            -0.214877   \n",
       "                                                tanh                               -0.244115   \n",
       "                        256                     linear                             -0.208734   \n",
       "                                                relu                               -0.236384   \n",
       "                                                sigmoid                            -0.204223   \n",
       "                                                tanh                               -0.201409   \n",
       "\n",
       "                                                                           split2_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "0                       0                       linear                             -1.334480   \n",
       "                                                relu                               -7.793879   \n",
       "                                                sigmoid                            -3.289454   \n",
       "                                                tanh                               -3.289454   \n",
       "1                       64                      linear                             -0.196488   \n",
       "                                                relu                               -0.180250   \n",
       "                                                sigmoid                            -0.220430   \n",
       "                                                tanh                               -0.219352   \n",
       "                        128                     linear                             -0.194951   \n",
       "                                                relu                               -0.180657   \n",
       "                                                sigmoid                            -0.220197   \n",
       "                                                tanh                               -0.219283   \n",
       "                        256                     linear                             -0.180109   \n",
       "                                                relu                               -0.522369   \n",
       "                                                sigmoid                            -0.177878   \n",
       "                                                tanh                               -0.222135   \n",
       "2                       64                      linear                             -0.181527   \n",
       "                                                relu                               -0.219206   \n",
       "                                                sigmoid                            -0.223343   \n",
       "                                                tanh                               -0.190053   \n",
       "                        128                     linear                             -0.191670   \n",
       "                                                relu                               -0.219214   \n",
       "                                                sigmoid                            -0.179456   \n",
       "                                                tanh                               -0.191734   \n",
       "                        256                     linear                             -0.177424   \n",
       "                                                relu                               -0.673658   \n",
       "                                                sigmoid                            -0.183115   \n",
       "                                                tanh                               -0.333361   \n",
       "3                       64                      linear                             -0.239976   \n",
       "                                                relu                               -0.220019   \n",
       "                                                sigmoid                            -0.224133   \n",
       "                                                tanh                               -0.220219   \n",
       "                        128                     linear                             -0.172168   \n",
       "                                                relu                               -0.219221   \n",
       "                                                sigmoid                            -0.205971   \n",
       "                                                tanh                               -0.219223   \n",
       "                        256                     linear                             -0.170248   \n",
       "                                                relu                               -0.219217   \n",
       "                                                sigmoid                            -0.220412   \n",
       "                                                tanh                               -0.181641   \n",
       "\n",
       "                                                                           split3_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "0                       0                       linear                             -3.312315   \n",
       "                                                relu                               -8.109698   \n",
       "                                                sigmoid                            -3.494653   \n",
       "                                                tanh                               -3.494653   \n",
       "1                       64                      linear                             -0.170677   \n",
       "                                                relu                               -0.187100   \n",
       "                                                sigmoid                            -0.255227   \n",
       "                                                tanh                               -0.234556   \n",
       "                        128                     linear                             -0.171726   \n",
       "                                                relu                               -0.169859   \n",
       "                                                sigmoid                            -0.185621   \n",
       "                                                tanh                               -0.228882   \n",
       "                        256                     linear                             -1.530982   \n",
       "                                                relu                               -0.334934   \n",
       "                                                sigmoid                            -0.165401   \n",
       "                                                tanh                               -0.229114   \n",
       "2                       64                      linear                             -0.178006   \n",
       "                                                relu                               -0.230741   \n",
       "                                                sigmoid                            -0.235141   \n",
       "                                                tanh                               -0.227562   \n",
       "                        128                     linear                             -0.174446   \n",
       "                                                relu                               -0.219769   \n",
       "                                                sigmoid                            -0.238186   \n",
       "                                                tanh                               -0.196769   \n",
       "                        256                     linear                             -0.161322   \n",
       "                                                relu                               -0.476042   \n",
       "                                                sigmoid                            -0.173183   \n",
       "                                                tanh                               -0.228089   \n",
       "3                       64                      linear                             -0.190288   \n",
       "                                                relu                               -0.235761   \n",
       "                                                sigmoid                            -0.232756   \n",
       "                                                tanh                               -0.229002   \n",
       "                        128                     linear                             -0.170931   \n",
       "                                                relu                               -0.229729   \n",
       "                                                sigmoid                            -0.233010   \n",
       "                                                tanh                               -0.228986   \n",
       "                        256                     linear                             -0.161771   \n",
       "                                                relu                               -0.308112   \n",
       "                                                sigmoid                            -0.171572   \n",
       "                                                tanh                               -0.228085   \n",
       "\n",
       "                                                                           split4_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "0                       0                       linear                             -1.118598   \n",
       "                                                relu                               -8.101770   \n",
       "                                                sigmoid                            -3.494100   \n",
       "                                                tanh                               -3.494100   \n",
       "1                       64                      linear                             -0.253335   \n",
       "                                                relu                               -0.205466   \n",
       "                                                sigmoid                            -0.249676   \n",
       "                                                tanh                               -0.249006   \n",
       "                        128                     linear                             -0.213234   \n",
       "                                                relu                               -0.307973   \n",
       "                                                sigmoid                            -0.241332   \n",
       "                                                tanh                               -0.242831   \n",
       "                        256                     linear                             -0.893585   \n",
       "                                                relu                               -0.240915   \n",
       "                                                sigmoid                            -0.228931   \n",
       "                                                tanh                               -0.244972   \n",
       "2                       64                      linear                             -0.244027   \n",
       "                                                relu                               -0.246604   \n",
       "                                                sigmoid                            -0.248832   \n",
       "                                                tanh                               -0.244249   \n",
       "                        128                     linear                             -0.229473   \n",
       "                                                relu                               -0.223067   \n",
       "                                                sigmoid                            -0.240314   \n",
       "                                                tanh                               -0.240282   \n",
       "                        256                     linear                             -0.225509   \n",
       "                                                relu                               -0.763412   \n",
       "                                                sigmoid                            -0.232900   \n",
       "                                                tanh                               -0.383236   \n",
       "3                       64                      linear                             -0.207927   \n",
       "                                                relu                               -0.244556   \n",
       "                                                sigmoid                            -0.243660   \n",
       "                                                tanh                               -0.248572   \n",
       "                        128                     linear                             -0.246653   \n",
       "                                                relu                               -0.245375   \n",
       "                                                sigmoid                            -0.242743   \n",
       "                                                tanh                               -0.241905   \n",
       "                        256                     linear                             -0.194438   \n",
       "                                                relu                               -0.325379   \n",
       "                                                sigmoid                            -0.203452   \n",
       "                                                tanh                               -0.241961   \n",
       "\n",
       "                                                                           mean_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                    \n",
       "0                       0                       linear                           -2.044422   \n",
       "                                                relu                             -7.976894   \n",
       "                                                sigmoid                          -3.408203   \n",
       "                                                tanh                             -3.408203   \n",
       "1                       64                      linear                           -0.222170   \n",
       "                                                relu                             -0.192184   \n",
       "                                                sigmoid                          -0.234236   \n",
       "                                                tanh                             -0.228268   \n",
       "                        128                     linear                           -0.190766   \n",
       "                                                relu                             -0.301792   \n",
       "                                                sigmoid                          -0.208554   \n",
       "                                                tanh                             -0.224703   \n",
       "                        256                     linear                           -0.985738   \n",
       "                                                relu                             -0.360402   \n",
       "                                                sigmoid                          -0.186706   \n",
       "                                                tanh                             -0.225795   \n",
       "2                       64                      linear                           -0.192473   \n",
       "                                                relu                             -0.226589   \n",
       "                                                sigmoid                          -0.228600   \n",
       "                                                tanh                             -0.220677   \n",
       "                        128                     linear                           -0.193223   \n",
       "                                                relu                             -0.219349   \n",
       "                                                sigmoid                          -0.218155   \n",
       "                                                tanh                             -0.214155   \n",
       "                        256                     linear                           -0.224537   \n",
       "                                                relu                             -0.557093   \n",
       "                                                sigmoid                          -0.199689   \n",
       "                                                tanh                             -0.325679   \n",
       "3                       64                      linear                           -0.206377   \n",
       "                                                relu                             -0.226730   \n",
       "                                                sigmoid                          -0.229115   \n",
       "                                                tanh                             -0.226715   \n",
       "                        128                     linear                           -0.195314   \n",
       "                                                relu                             -0.226818   \n",
       "                                                sigmoid                          -0.218680   \n",
       "                                                tanh                             -0.227151   \n",
       "                        256                     linear                           -0.178297   \n",
       "                                                relu                             -0.257736   \n",
       "                                                sigmoid                          -0.197968   \n",
       "                                                tanh                             -0.211628   \n",
       "\n",
       "                                                                           std_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                   \n",
       "0                       0                       linear                           0.784499   \n",
       "                                                relu                             0.124440   \n",
       "                                                sigmoid                          0.083531   \n",
       "                                                tanh                             0.083531   \n",
       "1                       64                      linear                           0.052945   \n",
       "                                                relu                             0.008545   \n",
       "                                                sigmoid                          0.018224   \n",
       "                                                tanh                             0.018125   \n",
       "                        128                     linear                           0.018947   \n",
       "                                                relu                             0.181063   \n",
       "                                                sigmoid                          0.031880   \n",
       "                                                tanh                             0.016161   \n",
       "                        256                     linear                           0.554892   \n",
       "                                                relu                             0.150330   \n",
       "                                                sigmoid                          0.026759   \n",
       "                                                tanh                             0.016547   \n",
       "2                       64                      linear                           0.027502   \n",
       "                                                relu                             0.017160   \n",
       "                                                sigmoid                          0.016883   \n",
       "                                                tanh                             0.021047   \n",
       "                        128                     linear                           0.022042   \n",
       "                                                relu                             0.013147   \n",
       "                                                sigmoid                          0.025173   \n",
       "                                                tanh                             0.020321   \n",
       "                        256                     linear                           0.080845   \n",
       "                                                relu                             0.140428   \n",
       "                                                sigmoid                          0.028723   \n",
       "                                                tanh                             0.052779   \n",
       "3                       64                      linear                           0.019039   \n",
       "                                                relu                             0.016899   \n",
       "                                                sigmoid                          0.015494   \n",
       "                                                tanh                             0.017881   \n",
       "                        128                     linear                           0.033756   \n",
       "                                                relu                             0.014911   \n",
       "                                                sigmoid                          0.016952   \n",
       "                                                tanh                             0.015656   \n",
       "                        256                     linear                           0.020033   \n",
       "                                                relu                             0.049834   \n",
       "                                                sigmoid                          0.016305   \n",
       "                                                tanh                             0.021150   \n",
       "\n",
       "                                                                           rank_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                    \n",
       "0                       0                       linear                                  37   \n",
       "                                                relu                                    40   \n",
       "                                                sigmoid                                 38   \n",
       "                                                tanh                                    38   \n",
       "1                       64                      linear                                  18   \n",
       "                                                relu                                     4   \n",
       "                                                sigmoid                                 30   \n",
       "                                                tanh                                    27   \n",
       "                        128                     linear                                   3   \n",
       "                                                relu                                    32   \n",
       "                                                sigmoid                                 11   \n",
       "                                                tanh                                    20   \n",
       "                        256                     linear                                  36   \n",
       "                                                relu                                    34   \n",
       "                                                sigmoid                                  2   \n",
       "                                                tanh                                    21   \n",
       "2                       64                      linear                                   5   \n",
       "                                                relu                                    22   \n",
       "                                                sigmoid                                 28   \n",
       "                                                tanh                                    17   \n",
       "                        128                     linear                                   6   \n",
       "                                                relu                                    16   \n",
       "                                                sigmoid                                 14   \n",
       "                                                tanh                                    13   \n",
       "                        256                     linear                                  19   \n",
       "                                                relu                                    35   \n",
       "                                                sigmoid                                  9   \n",
       "                                                tanh                                    33   \n",
       "3                       64                      linear                                  10   \n",
       "                                                relu                                    24   \n",
       "                                                sigmoid                                 29   \n",
       "                                                tanh                                    23   \n",
       "                        128                     linear                                   7   \n",
       "                                                relu                                    25   \n",
       "                                                sigmoid                                 15   \n",
       "                                                tanh                                    26   \n",
       "                        256                     linear                                   1   \n",
       "                                                relu                                    31   \n",
       "                                                sigmoid                                  8   \n",
       "                                                tanh                                    12   \n",
       "\n",
       "                                                                           split0_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "0                       0                       linear                              -2.306027   \n",
       "                                                relu                                -8.002028   \n",
       "                                                sigmoid                             -3.426807   \n",
       "                                                tanh                                -3.426807   \n",
       "1                       64                      linear                              -0.023453   \n",
       "                                                relu                                -0.231256   \n",
       "                                                sigmoid                             -0.244986   \n",
       "                                                tanh                                -0.233968   \n",
       "                        128                     linear                              -0.011178   \n",
       "                                                relu                                -0.579378   \n",
       "                                                sigmoid                             -0.121330   \n",
       "                                                tanh                                -0.231362   \n",
       "                        256                     linear                              -0.873479   \n",
       "                                                relu                                -0.085792   \n",
       "                                                sigmoid                             -0.057074   \n",
       "                                                tanh                                -0.231434   \n",
       "2                       64                      linear                              -0.022234   \n",
       "                                                relu                                -0.233934   \n",
       "                                                sigmoid                             -0.235741   \n",
       "                                                tanh                                -0.235001   \n",
       "                        128                     linear                              -0.019599   \n",
       "                                                relu                                -0.232888   \n",
       "                                                sigmoid                             -0.232489   \n",
       "                                                tanh                                -0.237452   \n",
       "                        256                     linear                              -0.034846   \n",
       "                                                relu                                -0.440188   \n",
       "                                                sigmoid                             -0.134844   \n",
       "                                                tanh                                -0.349121   \n",
       "3                       64                      linear                              -0.052365   \n",
       "                                                relu                                -0.232796   \n",
       "                                                sigmoid                             -0.239262   \n",
       "                                                tanh                                -0.231298   \n",
       "                        128                     linear                              -0.031552   \n",
       "                                                relu                                -0.240058   \n",
       "                                                sigmoid                             -0.232659   \n",
       "                                                tanh                                -0.239049   \n",
       "                        256                     linear                              -0.031412   \n",
       "                                                relu                                -0.231950   \n",
       "                                                sigmoid                             -0.094053   \n",
       "                                                tanh                                -0.237134   \n",
       "\n",
       "                                                                           split1_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "0                       0                       linear                              -1.837597   \n",
       "                                                relu                                -7.970431   \n",
       "                                                sigmoid                             -3.403003   \n",
       "                                                tanh                                -3.403003   \n",
       "1                       64                      linear                              -0.124082   \n",
       "                                                relu                                -0.062534   \n",
       "                                                sigmoid                             -0.224244   \n",
       "                                                tanh                                -0.225653   \n",
       "                        128                     linear                              -0.014782   \n",
       "                                                relu                                -0.079933   \n",
       "                                                sigmoid                             -0.221982   \n",
       "                                                tanh                                -0.221379   \n",
       "                        256                     linear                              -2.286804   \n",
       "                                                relu                                -0.400448   \n",
       "                                                sigmoid                             -0.034073   \n",
       "                                                tanh                                -0.221573   \n",
       "2                       64                      linear                              -0.018154   \n",
       "                                                relu                                -0.223900   \n",
       "                                                sigmoid                             -0.221888   \n",
       "                                                tanh                                -0.224769   \n",
       "                        128                     linear                              -0.029946   \n",
       "                                                relu                                -0.222900   \n",
       "                                                sigmoid                             -0.220881   \n",
       "                                                tanh                                -0.221705   \n",
       "                        256                     linear                              -0.783732   \n",
       "                                                relu                                -0.323708   \n",
       "                                                sigmoid                             -0.221440   \n",
       "                                                tanh                                -0.345410   \n",
       "3                       64                      linear                              -0.054430   \n",
       "                                                relu                                -0.221613   \n",
       "                                                sigmoid                             -0.228062   \n",
       "                                                tanh                                -0.224268   \n",
       "                        128                     linear                              -0.059955   \n",
       "                                                relu                                -0.222362   \n",
       "                                                sigmoid                             -0.161852   \n",
       "                                                tanh                                -0.228822   \n",
       "                        256                     linear                              -0.058933   \n",
       "                                                relu                                -0.221551   \n",
       "                                                sigmoid                             -0.066915   \n",
       "                                                tanh                                -0.125121   \n",
       "\n",
       "                                                                           split2_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "0                       0                       linear                              -1.176133   \n",
       "                                                relu                                -8.022614   \n",
       "                                                sigmoid                             -3.437868   \n",
       "                                                tanh                                -3.437868   \n",
       "1                       64                      linear                              -0.039679   \n",
       "                                                relu                                -0.089309   \n",
       "                                                sigmoid                             -0.230915   \n",
       "                                                tanh                                -0.226055   \n",
       "                        128                     linear                              -0.013335   \n",
       "                                                relu                                -0.068540   \n",
       "                                                sigmoid                             -0.225343   \n",
       "                                                tanh                                -0.226254   \n",
       "                        256                     linear                              -0.009430   \n",
       "                                                relu                                -0.457921   \n",
       "                                                sigmoid                             -0.040690   \n",
       "                                                tanh                                -0.225463   \n",
       "2                       64                      linear                              -0.011843   \n",
       "                                                relu                                -0.226856   \n",
       "                                                sigmoid                             -0.236186   \n",
       "                                                tanh                                -0.131133   \n",
       "                        128                     linear                              -0.044178   \n",
       "                                                relu                                -0.226662   \n",
       "                                                sigmoid                             -0.126527   \n",
       "                                                tanh                                -0.134537   \n",
       "                        256                     linear                              -0.027176   \n",
       "                                                relu                                -0.584131   \n",
       "                                                sigmoid                             -0.099368   \n",
       "                                                tanh                                -0.307383   \n",
       "3                       64                      linear                              -0.135198   \n",
       "                                                relu                                -0.229985   \n",
       "                                                sigmoid                             -0.237446   \n",
       "                                                tanh                                -0.225337   \n",
       "                        128                     linear                              -0.026487   \n",
       "                                                relu                                -0.227212   \n",
       "                                                sigmoid                             -0.159142   \n",
       "                                                tanh                                -0.227222   \n",
       "                        256                     linear                              -0.038213   \n",
       "                                                relu                                -0.226625   \n",
       "                                                sigmoid                             -0.230878   \n",
       "                                                tanh                                -0.104452   \n",
       "\n",
       "                                                                           split3_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "0                       0                       linear                              -3.024336   \n",
       "                                                relu                                -7.943718   \n",
       "                                                sigmoid                             -3.386606   \n",
       "                                                tanh                                -3.386606   \n",
       "1                       64                      linear                              -0.014129   \n",
       "                                                relu                                -0.108107   \n",
       "                                                sigmoid                             -0.239614   \n",
       "                                                tanh                                -0.226364   \n",
       "                        128                     linear                              -0.010347   \n",
       "                                                relu                                -0.072941   \n",
       "                                                sigmoid                             -0.130627   \n",
       "                                                tanh                                -0.223410   \n",
       "                        256                     linear                              -1.523011   \n",
       "                                                relu                                -0.215694   \n",
       "                                                sigmoid                             -0.057128   \n",
       "                                                tanh                                -0.223467   \n",
       "2                       64                      linear                              -0.022393   \n",
       "                                                relu                                -0.224120   \n",
       "                                                sigmoid                             -0.226751   \n",
       "                                                tanh                                -0.224620   \n",
       "                        128                     linear                              -0.057379   \n",
       "                                                relu                                -0.165573   \n",
       "                                                sigmoid                             -0.228839   \n",
       "                                                tanh                                -0.163921   \n",
       "                        256                     linear                              -0.028045   \n",
       "                                                relu                                -0.344877   \n",
       "                                                sigmoid                             -0.134007   \n",
       "                                                tanh                                -0.223371   \n",
       "3                       64                      linear                              -0.045380   \n",
       "                                                relu                                -0.227169   \n",
       "                                                sigmoid                             -0.224976   \n",
       "                                                tanh                                -0.223438   \n",
       "                        128                     linear                              -0.019075   \n",
       "                                                relu                                -0.223673   \n",
       "                                                sigmoid                             -0.225384   \n",
       "                                                tanh                                -0.223433   \n",
       "                        256                     linear                              -0.021005   \n",
       "                                                relu                                -0.228295   \n",
       "                                                sigmoid                             -0.083936   \n",
       "                                                tanh                                -0.223372   \n",
       "\n",
       "                                                                           split4_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "0                       0                       linear                              -1.095315   \n",
       "                                                relu                                -7.945698   \n",
       "                                                sigmoid                             -3.386745   \n",
       "                                                tanh                                -3.386745   \n",
       "1                       64                      linear                              -0.048821   \n",
       "                                                relu                                -0.102943   \n",
       "                                                sigmoid                             -0.225474   \n",
       "                                                tanh                                -0.224937   \n",
       "                        128                     linear                              -0.010373   \n",
       "                                                relu                                -0.145699   \n",
       "                                                sigmoid                             -0.219861   \n",
       "                                                tanh                                -0.220890   \n",
       "                        256                     linear                              -1.789221   \n",
       "                                                relu                                -0.220208   \n",
       "                                                sigmoid                             -0.046569   \n",
       "                                                tanh                                -0.222155   \n",
       "2                       64                      linear                              -0.045349   \n",
       "                                                relu                                -0.223250   \n",
       "                                                sigmoid                             -0.224847   \n",
       "                                                tanh                                -0.227832   \n",
       "                        128                     linear                              -0.042451   \n",
       "                                                relu                                -0.145405   \n",
       "                                                sigmoid                             -0.220551   \n",
       "                                                tanh                                -0.220734   \n",
       "                        256                     linear                              -0.032696   \n",
       "                                                relu                                -0.579167   \n",
       "                                                sigmoid                             -0.164970   \n",
       "                                                tanh                                -0.382141   \n",
       "3                       64                      linear                              -0.016374   \n",
       "                                                relu                                -0.221890   \n",
       "                                                sigmoid                             -0.221348   \n",
       "                                                tanh                                -0.233528   \n",
       "                        128                     linear                              -0.058209   \n",
       "                                                relu                                -0.222418   \n",
       "                                                sigmoid                             -0.171930   \n",
       "                                                tanh                                -0.224387   \n",
       "                        256                     linear                              -0.046250   \n",
       "                                                relu                                -0.216298   \n",
       "                                                sigmoid                             -0.108919   \n",
       "                                                tanh                                -0.224478   \n",
       "\n",
       "                                                                           mean_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                     \n",
       "0                       0                       linear                            -1.887882   \n",
       "                                                relu                              -7.976898   \n",
       "                                                sigmoid                           -3.408206   \n",
       "                                                tanh                              -3.408206   \n",
       "1                       64                      linear                            -0.050033   \n",
       "                                                relu                              -0.118830   \n",
       "                                                sigmoid                           -0.233046   \n",
       "                                                tanh                              -0.227395   \n",
       "                        128                     linear                            -0.012003   \n",
       "                                                relu                              -0.189298   \n",
       "                                                sigmoid                           -0.183829   \n",
       "                                                tanh                              -0.224659   \n",
       "                        256                     linear                            -1.296389   \n",
       "                                                relu                              -0.276013   \n",
       "                                                sigmoid                           -0.047107   \n",
       "                                                tanh                              -0.224818   \n",
       "2                       64                      linear                            -0.023995   \n",
       "                                                relu                              -0.226412   \n",
       "                                                sigmoid                           -0.229083   \n",
       "                                                tanh                              -0.208671   \n",
       "                        128                     linear                            -0.038710   \n",
       "                                                relu                              -0.198686   \n",
       "                                                sigmoid                           -0.205857   \n",
       "                                                tanh                              -0.195670   \n",
       "                        256                     linear                            -0.181299   \n",
       "                                                relu                              -0.454414   \n",
       "                                                sigmoid                           -0.150926   \n",
       "                                                tanh                              -0.321485   \n",
       "3                       64                      linear                            -0.060749   \n",
       "                                                relu                              -0.226691   \n",
       "                                                sigmoid                           -0.230219   \n",
       "                                                tanh                              -0.227574   \n",
       "                        128                     linear                            -0.039056   \n",
       "                                                relu                              -0.227145   \n",
       "                                                sigmoid                           -0.190193   \n",
       "                                                tanh                              -0.228583   \n",
       "                        256                     linear                            -0.039163   \n",
       "                                                relu                              -0.224944   \n",
       "                                                sigmoid                           -0.116940   \n",
       "                                                tanh                              -0.182911   \n",
       "\n",
       "                                                                           std_train_score  \n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                   \n",
       "0                       0                       linear                            0.721616  \n",
       "                                                relu                              0.031105  \n",
       "                                                sigmoid                           0.020881  \n",
       "                                                tanh                              0.020881  \n",
       "1                       64                      linear                            0.038955  \n",
       "                                                relu                              0.058391  \n",
       "                                                sigmoid                           0.008063  \n",
       "                                                tanh                              0.003321  \n",
       "                        128                     linear                            0.001765  \n",
       "                                                relu                              0.197051  \n",
       "                                                sigmoid                           0.047358  \n",
       "                                                tanh                              0.003847  \n",
       "                        256                     linear                            0.788705  \n",
       "                                                relu                              0.135286  \n",
       "                                                sigmoid                           0.009068  \n",
       "                                                tanh                              0.003567  \n",
       "2                       64                      linear                            0.011344  \n",
       "                                                relu                              0.003959  \n",
       "                                                sigmoid                           0.005830  \n",
       "                                                tanh                              0.038951  \n",
       "                        128                     linear                            0.012919  \n",
       "                                                relu                              0.035984  \n",
       "                                                sigmoid                           0.039931  \n",
       "                                                tanh                              0.039489  \n",
       "                        256                     linear                            0.301230  \n",
       "                                                relu                              0.111063  \n",
       "                                                sigmoid                           0.040921  \n",
       "                                                tanh                              0.054480  \n",
       "3                       64                      linear                            0.039644  \n",
       "                                                relu                              0.004409  \n",
       "                                                sigmoid                           0.006998  \n",
       "                                                tanh                              0.004058  \n",
       "                        128                     linear                            0.016836  \n",
       "                                                relu                              0.006694  \n",
       "                                                sigmoid                           0.032071  \n",
       "                                                tanh                              0.005578  \n",
       "                        256                     linear                            0.012898  \n",
       "                                                relu                              0.005466  \n",
       "                                                sigmoid                           0.058586  \n",
       "                                                tanh                              0.056215  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = results.groupby(['param_num_hidden_layers','param_hidden_layer_size','param_activation_function'])\n",
    "grouped = grouped.mean()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv('../output/model_params_and_results.csv') # Save csv so it can be used as a table in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find the top 5 best performing models and look more closely at their performance. \n",
    "\n",
    "Note that they all have very similar scores, all of which are far better than we would expect (none of the leaderboard scores are better than 0.38). This suggests that there is some overfitting in these models, despite the use of dropout, cross-validation, and early stopping using validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_num_hidden_layers</th>\n",
       "      <th>param_hidden_layer_size</th>\n",
       "      <th>param_activation_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>256</th>\n",
       "      <th>linear</th>\n",
       "      <td>533.480620</td>\n",
       "      <td>61.981618</td>\n",
       "      <td>1.604587</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>-0.156356</td>\n",
       "      <td>-0.208734</td>\n",
       "      <td>-0.170248</td>\n",
       "      <td>-0.161771</td>\n",
       "      <td>-0.194438</td>\n",
       "      <td>-0.178297</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031412</td>\n",
       "      <td>-0.058933</td>\n",
       "      <td>-0.038213</td>\n",
       "      <td>-0.021005</td>\n",
       "      <td>-0.046250</td>\n",
       "      <td>-0.039163</td>\n",
       "      <td>0.012898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>256</th>\n",
       "      <th>sigmoid</th>\n",
       "      <td>351.657404</td>\n",
       "      <td>70.296554</td>\n",
       "      <td>2.456750</td>\n",
       "      <td>0.040858</td>\n",
       "      <td>-0.156284</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>-0.177878</td>\n",
       "      <td>-0.165401</td>\n",
       "      <td>-0.228931</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>0.026759</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.057074</td>\n",
       "      <td>-0.034073</td>\n",
       "      <td>-0.040690</td>\n",
       "      <td>-0.057128</td>\n",
       "      <td>-0.046569</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>0.009068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <th>linear</th>\n",
       "      <td>582.432157</td>\n",
       "      <td>68.998469</td>\n",
       "      <td>0.916782</td>\n",
       "      <td>0.027519</td>\n",
       "      <td>-0.166008</td>\n",
       "      <td>-0.207982</td>\n",
       "      <td>-0.194951</td>\n",
       "      <td>-0.171726</td>\n",
       "      <td>-0.213234</td>\n",
       "      <td>-0.190766</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.011178</td>\n",
       "      <td>-0.014782</td>\n",
       "      <td>-0.013335</td>\n",
       "      <td>-0.010347</td>\n",
       "      <td>-0.010373</td>\n",
       "      <td>-0.012003</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <th>relu</th>\n",
       "      <td>331.651672</td>\n",
       "      <td>11.740114</td>\n",
       "      <td>2.851909</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>-0.196655</td>\n",
       "      <td>-0.191436</td>\n",
       "      <td>-0.180250</td>\n",
       "      <td>-0.187100</td>\n",
       "      <td>-0.205466</td>\n",
       "      <td>-0.192184</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.231256</td>\n",
       "      <td>-0.062534</td>\n",
       "      <td>-0.089309</td>\n",
       "      <td>-0.108107</td>\n",
       "      <td>-0.102943</td>\n",
       "      <td>-0.118830</td>\n",
       "      <td>0.058391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>64</th>\n",
       "      <th>linear</th>\n",
       "      <td>213.031170</td>\n",
       "      <td>47.286451</td>\n",
       "      <td>0.632164</td>\n",
       "      <td>0.034216</td>\n",
       "      <td>-0.164358</td>\n",
       "      <td>-0.194529</td>\n",
       "      <td>-0.181527</td>\n",
       "      <td>-0.178006</td>\n",
       "      <td>-0.244027</td>\n",
       "      <td>-0.192473</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>-0.011843</td>\n",
       "      <td>-0.022393</td>\n",
       "      <td>-0.045349</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>0.011344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           mean_fit_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                  \n",
       "3                       256                     linear                        533.480620   \n",
       "1                       256                     sigmoid                       351.657404   \n",
       "                        128                     linear                        582.432157   \n",
       "                        64                      relu                          331.651672   \n",
       "2                       64                      linear                        213.031170   \n",
       "\n",
       "                                                                           std_fit_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                 \n",
       "3                       256                     linear                        61.981618   \n",
       "1                       256                     sigmoid                       70.296554   \n",
       "                        128                     linear                        68.998469   \n",
       "                        64                      relu                          11.740114   \n",
       "2                       64                      linear                        47.286451   \n",
       "\n",
       "                                                                           mean_score_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                    \n",
       "3                       256                     linear                            1.604587   \n",
       "1                       256                     sigmoid                           2.456750   \n",
       "                        128                     linear                            0.916782   \n",
       "                        64                      relu                              2.851909   \n",
       "2                       64                      linear                            0.632164   \n",
       "\n",
       "                                                                           std_score_time  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                   \n",
       "3                       256                     linear                           0.053123   \n",
       "1                       256                     sigmoid                          0.040858   \n",
       "                        128                     linear                           0.027519   \n",
       "                        64                      relu                             0.024441   \n",
       "2                       64                      linear                           0.034216   \n",
       "\n",
       "                                                                           split0_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "3                       256                     linear                             -0.156356   \n",
       "1                       256                     sigmoid                            -0.156284   \n",
       "                        128                     linear                             -0.166008   \n",
       "                        64                      relu                               -0.196655   \n",
       "2                       64                      linear                             -0.164358   \n",
       "\n",
       "                                                                           split1_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "3                       256                     linear                             -0.208734   \n",
       "1                       256                     sigmoid                            -0.205128   \n",
       "                        128                     linear                             -0.207982   \n",
       "                        64                      relu                               -0.191436   \n",
       "2                       64                      linear                             -0.194529   \n",
       "\n",
       "                                                                           split2_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "3                       256                     linear                             -0.170248   \n",
       "1                       256                     sigmoid                            -0.177878   \n",
       "                        128                     linear                             -0.194951   \n",
       "                        64                      relu                               -0.180250   \n",
       "2                       64                      linear                             -0.181527   \n",
       "\n",
       "                                                                           split3_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "3                       256                     linear                             -0.161771   \n",
       "1                       256                     sigmoid                            -0.165401   \n",
       "                        128                     linear                             -0.171726   \n",
       "                        64                      relu                               -0.187100   \n",
       "2                       64                      linear                             -0.178006   \n",
       "\n",
       "                                                                           split4_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                      \n",
       "3                       256                     linear                             -0.194438   \n",
       "1                       256                     sigmoid                            -0.228931   \n",
       "                        128                     linear                             -0.213234   \n",
       "                        64                      relu                               -0.205466   \n",
       "2                       64                      linear                             -0.244027   \n",
       "\n",
       "                                                                           mean_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                    \n",
       "3                       256                     linear                           -0.178297   \n",
       "1                       256                     sigmoid                          -0.186706   \n",
       "                        128                     linear                           -0.190766   \n",
       "                        64                      relu                             -0.192184   \n",
       "2                       64                      linear                           -0.192473   \n",
       "\n",
       "                                                                           std_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                   \n",
       "3                       256                     linear                           0.020033   \n",
       "1                       256                     sigmoid                          0.026759   \n",
       "                        128                     linear                           0.018947   \n",
       "                        64                      relu                             0.008545   \n",
       "2                       64                      linear                           0.027502   \n",
       "\n",
       "                                                                           rank_test_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                    \n",
       "3                       256                     linear                                   1   \n",
       "1                       256                     sigmoid                                  2   \n",
       "                        128                     linear                                   3   \n",
       "                        64                      relu                                     4   \n",
       "2                       64                      linear                                   5   \n",
       "\n",
       "                                                                           split0_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "3                       256                     linear                              -0.031412   \n",
       "1                       256                     sigmoid                             -0.057074   \n",
       "                        128                     linear                              -0.011178   \n",
       "                        64                      relu                                -0.231256   \n",
       "2                       64                      linear                              -0.022234   \n",
       "\n",
       "                                                                           split1_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "3                       256                     linear                              -0.058933   \n",
       "1                       256                     sigmoid                             -0.034073   \n",
       "                        128                     linear                              -0.014782   \n",
       "                        64                      relu                                -0.062534   \n",
       "2                       64                      linear                              -0.018154   \n",
       "\n",
       "                                                                           split2_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "3                       256                     linear                              -0.038213   \n",
       "1                       256                     sigmoid                             -0.040690   \n",
       "                        128                     linear                              -0.013335   \n",
       "                        64                      relu                                -0.089309   \n",
       "2                       64                      linear                              -0.011843   \n",
       "\n",
       "                                                                           split3_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "3                       256                     linear                              -0.021005   \n",
       "1                       256                     sigmoid                             -0.057128   \n",
       "                        128                     linear                              -0.010347   \n",
       "                        64                      relu                                -0.108107   \n",
       "2                       64                      linear                              -0.022393   \n",
       "\n",
       "                                                                           split4_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                       \n",
       "3                       256                     linear                              -0.046250   \n",
       "1                       256                     sigmoid                             -0.046569   \n",
       "                        128                     linear                              -0.010373   \n",
       "                        64                      relu                                -0.102943   \n",
       "2                       64                      linear                              -0.045349   \n",
       "\n",
       "                                                                           mean_train_score  \\\n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                     \n",
       "3                       256                     linear                            -0.039163   \n",
       "1                       256                     sigmoid                           -0.047107   \n",
       "                        128                     linear                            -0.012003   \n",
       "                        64                      relu                              -0.118830   \n",
       "2                       64                      linear                            -0.023995   \n",
       "\n",
       "                                                                           std_train_score  \n",
       "param_num_hidden_layers param_hidden_layer_size param_activation_function                   \n",
       "3                       256                     linear                            0.012898  \n",
       "1                       256                     sigmoid                           0.009068  \n",
       "                        128                     linear                            0.001765  \n",
       "                        64                      relu                              0.058391  \n",
       "2                       64                      linear                            0.011344  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = grouped.sort_values(['rank_test_score'],ascending=True).head(5)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = []\n",
    "for _, r in best.iterrows():\n",
    "    p = {'num_hidden_layers': [_[0]],\n",
    "          'hidden_layer_size': [_[1]],\n",
    "          'activation_function': [_[2]]}\n",
    "    final_models.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to retrain the 5 best models and assess the out-of-sample performance of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can use the same gridsearch with a single set of parameters to iterate over the models and get predictions. The only changes I'm making are the inclusion of additional callback parameters to store the results and a slight decrease in the `patience` parameter to help prevent overfitting.\n",
    "\n",
    "This time I also store each estimator, its predictions, and its history in a dictionary.\n",
    "\n",
    "***Note: It takes at least 2 hours to run these models.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds again to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(54321)\n",
    "tf.set_random_seed(56789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 22s 16ms/step - loss: 270.6423 - val_loss: 12.8371\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 50.1722 - val_loss: 0.7841\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 33.7031 - val_loss: 2.2142\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 33.3865 - val_loss: 0.3802\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 42.1130 - val_loss: 1.2484\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 46.0891 - val_loss: 0.7626\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 34.2729 - val_loss: 0.5276\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 26.5323 - val_loss: 0.5406\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 22.5459 - val_loss: 0.5835\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 16.3448 - val_loss: 4.1760\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 15.1157 - val_loss: 0.3050\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 12.2901 - val_loss: 0.3707\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 9.4811 - val_loss: 0.3052\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 9.4252 - val_loss: 0.6111\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 8.6706 - val_loss: 0.4425\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 7.7899 - val_loss: 0.3009\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 6.8851 - val_loss: 0.2440\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 5.6395 - val_loss: 0.3687\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 5.1334 - val_loss: 0.2269\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 4.5842 - val_loss: 0.6317\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 4.4133 - val_loss: 0.2200\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 3.9230 - val_loss: 0.2374\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 3.6755 - val_loss: 0.2452\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 3.1773 - val_loss: 0.3005\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.9633 - val_loss: 0.3268\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.6663 - val_loss: 0.2326\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.6301 - val_loss: 0.3114\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.5113 - val_loss: 0.4131\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 2.2602 - val_loss: 0.2513\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.8970 - val_loss: 0.3165\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.8108 - val_loss: 0.2951\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.6840 - val_loss: 0.2254\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.5397 - val_loss: 0.2144\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.3572 - val_loss: 0.2189\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 1.2886 - val_loss: 0.2106\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.2614 - val_loss: 0.1874\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.1284 - val_loss: 0.2689\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9839 - val_loss: 0.2147\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 1.0234 - val_loss: 0.2892\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.9630 - val_loss: 0.2204\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8805 - val_loss: 0.2298\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.8528 - val_loss: 0.1952\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7794 - val_loss: 0.2413\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.7095 - val_loss: 0.1974\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.6606 - val_loss: 0.1808\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.6666 - val_loss: 0.1992\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.6309 - val_loss: 0.1975\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5836 - val_loss: 0.1846\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5588 - val_loss: 0.2060\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.5268 - val_loss: 0.1834\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4921 - val_loss: 0.1817\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4507 - val_loss: 0.2247\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4538 - val_loss: 0.1927\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4000 - val_loss: 0.2239\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4099 - val_loss: 0.2005\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.4316 - val_loss: 0.1924\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3622 - val_loss: 0.1836\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3700 - val_loss: 0.1770\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3406 - val_loss: 0.1765\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3630 - val_loss: 0.1786\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3016 - val_loss: 0.1813\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.3027 - val_loss: 0.2221\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2854 - val_loss: 0.1900\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2772 - val_loss: 0.1759\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2859 - val_loss: 0.2028\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2703 - val_loss: 0.1780\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2770 - val_loss: 0.1775\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2785 - val_loss: 0.2110\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2692 - val_loss: 0.1907\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2561 - val_loss: 0.1886\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2484 - val_loss: 0.1894\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2535 - val_loss: 0.2025\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2603 - val_loss: 0.1795\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2397 - val_loss: 0.2027\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2348 - val_loss: 0.1818\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2169 - val_loss: 0.1847\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2267 - val_loss: 0.1838\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2334 - val_loss: 0.1819\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 7s 5ms/step - loss: 0.2269 - val_loss: 0.1896\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 9.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 22s 17ms/step - loss: 246.3026 - val_loss: 4.2038\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 83.3552 - val_loss: 5.3296\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 46.9196 - val_loss: 0.5382\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 42.1053 - val_loss: 0.8114\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 40.1407 - val_loss: 1.6513\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 35.1598 - val_loss: 0.6396\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 30.5421 - val_loss: 1.6059\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 27.6129 - val_loss: 0.9183\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 22.5929 - val_loss: 1.5768\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 16.5847 - val_loss: 0.3578\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 14.5269 - val_loss: 0.5383\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 11.7890 - val_loss: 0.6596\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 10.0675 - val_loss: 0.4148\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 11.2577 - val_loss: 0.4398\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 9.1562 - val_loss: 0.2528\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.5243 - val_loss: 0.3283\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.4012 - val_loss: 0.6369\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.9701 - val_loss: 0.7798\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.3126 - val_loss: 0.2719\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.8317 - val_loss: 0.2259\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.4380 - val_loss: 0.2059\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.9776 - val_loss: 0.4787\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.1898 - val_loss: 0.3279\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.8488 - val_loss: 0.3864\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.4586 - val_loss: 0.3564\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 2.2395 - val_loss: 0.2833\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.5469 - val_loss: 0.2605\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.8609 - val_loss: 0.2029\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 1.5520 - val_loss: 0.1927\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.5895 - val_loss: 0.2487\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3481 - val_loss: 0.2303\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2718 - val_loss: 0.2279\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2819 - val_loss: 0.2528\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1088 - val_loss: 0.2022\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0063 - val_loss: 0.1762\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9103 - val_loss: 0.1741\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8232 - val_loss: 0.1784\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7573 - val_loss: 0.1827\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7251 - val_loss: 0.1702\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6623 - val_loss: 0.1902\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7155 - val_loss: 0.2308\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6020 - val_loss: 0.2124\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5589 - val_loss: 0.1825\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5464 - val_loss: 0.2143\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5199 - val_loss: 0.1822\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4713 - val_loss: 0.1708\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4338 - val_loss: 0.1771\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4345 - val_loss: 0.1855\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4109 - val_loss: 0.1936\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4290 - val_loss: 0.1719\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3582 - val_loss: 0.1751\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3962 - val_loss: 0.1926\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3432 - val_loss: 0.1678\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3439 - val_loss: 0.1843\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3369 - val_loss: 0.1694\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3594 - val_loss: 0.1738\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3416 - val_loss: 0.1813\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3310 - val_loss: 0.1785\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3268 - val_loss: 0.1769\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3077 - val_loss: 0.1857\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2952 - val_loss: 0.1684\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2932 - val_loss: 0.2206\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2770 - val_loss: 0.1711\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2798 - val_loss: 0.1952\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2596 - val_loss: 0.1722\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2689 - val_loss: 0.1691\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2739 - val_loss: 0.2035\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2666 - val_loss: 0.1778\n",
      "Epoch 00068: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 7.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 22s 16ms/step - loss: 335.2440 - val_loss: 23.4127\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 56.4159 - val_loss: 2.5560\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 33.3019 - val_loss: 0.5119\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 27.7144 - val_loss: 0.8915\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 28.1278 - val_loss: 0.5294\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 30.8317 - val_loss: 0.8379\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 32.4459 - val_loss: 1.1997\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 30.4035 - val_loss: 2.2621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 35.1881 - val_loss: 0.9216\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 41.7846 - val_loss: 2.4106\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 29.1685 - val_loss: 0.3829\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 20.7493 - val_loss: 5.3921\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 19.5208 - val_loss: 1.0744\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 13.5835 - val_loss: 1.2231\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 22.8232 - val_loss: 1.6811\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 12.0283 - val_loss: 1.0163\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 8.1964 - val_loss: 0.8302\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 15.0873 - val_loss: 1.7752\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 12.3677 - val_loss: 2.1200\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 9.3654 - val_loss: 1.8447\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.4244 - val_loss: 0.4336\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.2027 - val_loss: 0.4607\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.8372 - val_loss: 0.7379\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 3.3423 - val_loss: 0.7538\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.0723 - val_loss: 0.4167\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.5769 - val_loss: 1.2220\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 3.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 22s 16ms/step - loss: 271.0017 - val_loss: 1.9510\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 76.6301 - val_loss: 1.7123\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 41.6586 - val_loss: 1.7890\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 39.6847 - val_loss: 3.4484\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 40.2114 - val_loss: 0.4689\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 41.7404 - val_loss: 3.1458\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 42.6007 - val_loss: 7.7811\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 37.6758 - val_loss: 7.3918\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 58.5321 - val_loss: 4.5036\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 31.9669 - val_loss: 0.5931\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 16.3649 - val_loss: 0.8839\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 12.4259 - val_loss: 0.4120\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 9.6445 - val_loss: 0.8877\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.9703 - val_loss: 0.2991\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.5508 - val_loss: 0.4575\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.3262 - val_loss: 0.5531\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.8149 - val_loss: 0.4784\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.3615 - val_loss: 0.6367\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.9698 - val_loss: 0.5473\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.0605 - val_loss: 1.8882\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.6738 - val_loss: 0.4180\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.3672 - val_loss: 0.5145\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.2765 - val_loss: 0.2165\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.4222 - val_loss: 0.2585\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.5573 - val_loss: 0.8651\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.7873 - val_loss: 0.2168\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.7451 - val_loss: 0.4038\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.5581 - val_loss: 0.6029\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.5613 - val_loss: 0.6234\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.9187 - val_loss: 0.4083\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.7758 - val_loss: 0.4078\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.1345 - val_loss: 0.2922\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.1889 - val_loss: 0.2153\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6056 - val_loss: 0.2567\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.6663 - val_loss: 0.2949\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3003 - val_loss: 0.1922\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4761 - val_loss: 0.3022\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1409 - val_loss: 0.2992\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0605 - val_loss: 0.2598\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9556 - val_loss: 0.1888\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8632 - val_loss: 0.1791\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9077 - val_loss: 0.2001\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7774 - val_loss: 0.1931\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7985 - val_loss: 0.2248\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8461 - val_loss: 0.1766\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9580 - val_loss: 0.1950\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8600 - val_loss: 0.3193\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9803 - val_loss: 0.2817\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6924 - val_loss: 0.2061\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6488 - val_loss: 0.1801\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5661 - val_loss: 0.1803\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5378 - val_loss: 0.1730\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5041 - val_loss: 0.1977\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4740 - val_loss: 0.2459\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4375 - val_loss: 0.1716\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4393 - val_loss: 0.2056\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5405 - val_loss: 0.1681\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4344 - val_loss: 0.1726\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4285 - val_loss: 0.1902\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3704 - val_loss: 0.1636\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4543 - val_loss: 0.1962\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4269 - val_loss: 0.1725\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3305 - val_loss: 0.1687\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3300 - val_loss: 0.1755\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3502 - val_loss: 0.2092\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3129 - val_loss: 0.1744\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2905 - val_loss: 0.1711\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3063 - val_loss: 0.2008\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2888 - val_loss: 0.1685\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2696 - val_loss: 0.1729\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2687 - val_loss: 0.1671\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2758 - val_loss: 0.1663\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2826 - val_loss: 0.1787\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2610 - val_loss: 0.1766\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2609 - val_loss: 0.1875\n",
      "Epoch 00075: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 8.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 25s 19ms/step - loss: 326.6061 - val_loss: 4.6988\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 71.0229 - val_loss: 2.7484\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 38.5299 - val_loss: 0.8572\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 39.4702 - val_loss: 3.0230\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 43.2700 - val_loss: 1.1144\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 41.5694 - val_loss: 0.4325\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 42.8527 - val_loss: 0.8167\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 35.4197 - val_loss: 2.0897\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 25.8241 - val_loss: 0.5757\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 22.0572 - val_loss: 0.5396\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 20.5849 - val_loss: 1.2902\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 16.8259 - val_loss: 0.9388\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 13.5054 - val_loss: 0.8795\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 11.1594 - val_loss: 0.7917\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 11.6171 - val_loss: 0.9546\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 8.9493 - val_loss: 0.5761\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.8481 - val_loss: 0.8844\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 8.7551 - val_loss: 0.5890\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 7.5079 - val_loss: 0.5792\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.7731 - val_loss: 0.2209\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.4616 - val_loss: 0.5579\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.4111 - val_loss: 0.3640\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 6.3220 - val_loss: 0.5888\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 5.0236 - val_loss: 0.5595\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 4.2172 - val_loss: 0.9691\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.3101 - val_loss: 0.2040\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 3.0641 - val_loss: 0.5219\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.7452 - val_loss: 0.3021\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.7349 - val_loss: 0.2184\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 2.0718 - val_loss: 0.2305\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.9770 - val_loss: 0.2354\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.9297 - val_loss: 0.3664\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.5582 - val_loss: 0.3409\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.7375 - val_loss: 0.3555\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.4450 - val_loss: 0.3606\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.2818 - val_loss: 0.3760\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.3066 - val_loss: 0.2706\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1603 - val_loss: 0.2172\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.1273 - val_loss: 0.1985\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0111 - val_loss: 0.1911\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0004 - val_loss: 0.2114\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9058 - val_loss: 0.2062\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8820 - val_loss: 0.2532\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7986 - val_loss: 0.2291\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7498 - val_loss: 0.2081\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7275 - val_loss: 0.1797\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7087 - val_loss: 0.2425\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6717 - val_loss: 0.1742\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6129 - val_loss: 0.1768\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5967 - val_loss: 0.1942\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5148 - val_loss: 0.1932\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6068 - val_loss: 0.1887\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5072 - val_loss: 0.1741\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5290 - val_loss: 0.2016\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4534 - val_loss: 0.1766\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4258 - val_loss: 0.1861\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4237 - val_loss: 0.1762\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4294 - val_loss: 0.1761\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3895 - val_loss: 0.1734\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4064 - val_loss: 0.1817\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3595 - val_loss: 0.2185\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3396 - val_loss: 0.1777\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3197 - val_loss: 0.1959\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 36.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 24s 14ms/step - loss: 260.5705 - val_loss: 3.3399\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 34.5894 - val_loss: 2.0257\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 23.4421 - val_loss: 0.3073\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 23.8912 - val_loss: 0.5724\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 30.9920 - val_loss: 0.9406\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 32.4400 - val_loss: 1.8169\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 23.1693 - val_loss: 0.5330\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 20.2099 - val_loss: 0.9223\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 18.4297 - val_loss: 1.2182\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 15.1641 - val_loss: 0.5053\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 12.1107 - val_loss: 1.3087\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 11.1540 - val_loss: 0.3579\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 8.8164 - val_loss: 0.3129\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 8.0884 - val_loss: 1.1407\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 7.6058 - val_loss: 0.4057\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 6.6111 - val_loss: 0.3099\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 9s 5ms/step - loss: 7.0998 - val_loss: 0.4098\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 5.0772 - val_loss: 0.6346\n",
      "Epoch 00018: early stopping\n",
      "Out-of-sample MSE:  0.6346324251893312\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 22s 16ms/step - loss: 6.9667 - val_loss: 0.2630\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.9546 - val_loss: 0.2198\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.8847 - val_loss: 0.2067\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7984 - val_loss: 0.2007\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.7718 - val_loss: 0.1933\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6522 - val_loss: 0.1967\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.6274 - val_loss: 0.1981\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5781 - val_loss: 0.1849\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.5271 - val_loss: 0.1852\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4610 - val_loss: 0.1813\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4421 - val_loss: 0.1776\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4241 - val_loss: 0.1870\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.4062 - val_loss: 0.1772\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3496 - val_loss: 0.1772\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3133 - val_loss: 0.1785\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.3113 - val_loss: 0.1788\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2960 - val_loss: 0.1797\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2799 - val_loss: 0.1877\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2384 - val_loss: 0.1740\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2436 - val_loss: 0.1726\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2448 - val_loss: 0.1719\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2316 - val_loss: 0.1705\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2128 - val_loss: 0.1704\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1927 - val_loss: 0.1824\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2004 - val_loss: 0.1914\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.2046 - val_loss: 0.1745\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1927 - val_loss: 0.1749\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1830 - val_loss: 0.1783\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1719 - val_loss: 0.1782\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1707 - val_loss: 0.1737\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1647 - val_loss: 0.1818\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1713 - val_loss: 0.1837\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1575 - val_loss: 0.1796\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1488 - val_loss: 0.1753\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1452 - val_loss: 0.1829\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1560 - val_loss: 0.1791\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 6s 5ms/step - loss: 0.1563 - val_loss: 0.1769\n",
      "Epoch 00037: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 24s 18ms/step - loss: 12.8390 - val_loss: 0.5279\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9672 - val_loss: 0.2248\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.9184 - val_loss: 0.2028\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8358 - val_loss: 0.2016\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.8060 - val_loss: 0.1994\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.8021 - val_loss: 0.1997\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6870 - val_loss: 0.1993\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6605 - val_loss: 0.1960\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6379 - val_loss: 0.1916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.6112 - val_loss: 0.1928\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5481 - val_loss: 0.1879\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5249 - val_loss: 0.1888\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4770 - val_loss: 0.1882\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4655 - val_loss: 0.1869\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4226 - val_loss: 0.1863\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4072 - val_loss: 0.1840\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3553 - val_loss: 0.1787\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3601 - val_loss: 0.1798\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.3406 - val_loss: 0.1817\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3177 - val_loss: 0.1802\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2972 - val_loss: 0.1820\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2918 - val_loss: 0.1792\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2620 - val_loss: 0.1721\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2552 - val_loss: 0.1727\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2400 - val_loss: 0.1745\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2489 - val_loss: 0.1791\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2123 - val_loss: 0.1817\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1960 - val_loss: 0.1743\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1977 - val_loss: 0.1758\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1844 - val_loss: 0.1712\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1860 - val_loss: 0.1730\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1718 - val_loss: 0.1747\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1774 - val_loss: 0.1730\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1842 - val_loss: 0.1710\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1711 - val_loss: 0.1696\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1539 - val_loss: 0.1773\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1604 - val_loss: 0.1665\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1616 - val_loss: 0.1734\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1543 - val_loss: 0.1722\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1469 - val_loss: 0.1701\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1417 - val_loss: 0.1687\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1485 - val_loss: 0.1732\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1472 - val_loss: 0.1654\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1416 - val_loss: 0.1697\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1396 - val_loss: 0.1729\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1448 - val_loss: 0.1700\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1407 - val_loss: 0.1717\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1479 - val_loss: 0.1799\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1490 - val_loss: 0.1751\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1475 - val_loss: 0.1716\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1511 - val_loss: 0.1792\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1463 - val_loss: 0.1734\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1398 - val_loss: 0.1735\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1571 - val_loss: 0.1747\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1467 - val_loss: 0.1690\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1410 - val_loss: 0.1743\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1396 - val_loss: 0.1849\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1744 - val_loss: 0.1730\n",
      "Epoch 00058: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 6.5min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 22s 16ms/step - loss: 11.7216 - val_loss: 1.5235\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.7639 - val_loss: 0.2251\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4761 - val_loss: 0.2193\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4911 - val_loss: 0.2185\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4937 - val_loss: 0.2192\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4779 - val_loss: 0.2197\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4760 - val_loss: 0.2202\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4418 - val_loss: 0.2219\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4320 - val_loss: 0.2197\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4414 - val_loss: 0.2188\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4203 - val_loss: 0.2217\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4029 - val_loss: 0.2185\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4074 - val_loss: 0.2185\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3800 - val_loss: 0.2204\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3816 - val_loss: 0.2271\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3770 - val_loss: 0.2192\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3456 - val_loss: 0.2188\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3416 - val_loss: 0.2198\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 23s 17ms/step - loss: 17.3689 - val_loss: 1.9480\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 1.0750 - val_loss: 0.2227\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6787 - val_loss: 0.2082\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6781 - val_loss: 0.2057\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6227 - val_loss: 0.2063\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5501 - val_loss: 0.2081\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5762 - val_loss: 0.2040\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6003 - val_loss: 0.1992\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5824 - val_loss: 0.1989\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5406 - val_loss: 0.2017\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.5057 - val_loss: 0.1948\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4919 - val_loss: 0.2013\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4578 - val_loss: 0.1935\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4601 - val_loss: 0.1942\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4250 - val_loss: 0.2032\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3804 - val_loss: 0.1956\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3937 - val_loss: 0.1941\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3652 - val_loss: 0.1949\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3513 - val_loss: 0.1934\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3213 - val_loss: 0.1833\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.3149 - val_loss: 0.1923\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2895 - val_loss: 0.1869\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2768 - val_loss: 0.1797\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2762 - val_loss: 0.1819\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2665 - val_loss: 0.1802\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2597 - val_loss: 0.1805\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2396 - val_loss: 0.1819\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2309 - val_loss: 0.1814\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2316 - val_loss: 0.1819\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 8s 6ms/step - loss: 0.2253 - val_loss: 0.1808\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2084 - val_loss: 0.1796\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2066 - val_loss: 0.1764\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.2032 - val_loss: 0.1753\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1917 - val_loss: 0.1782\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1926 - val_loss: 0.1757\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1666 - val_loss: 0.1720\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1758 - val_loss: 0.1729\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1849 - val_loss: 0.1748\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1773 - val_loss: 0.1738\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1622 - val_loss: 0.1734\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1647 - val_loss: 0.1740\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1573 - val_loss: 0.1873\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1580 - val_loss: 0.1719\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1457 - val_loss: 0.1729\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1537 - val_loss: 0.1696\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1443 - val_loss: 0.1760\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1529 - val_loss: 0.1706\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1559 - val_loss: 0.1826\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1543 - val_loss: 0.1634\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1382 - val_loss: 0.1727\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1456 - val_loss: 0.1681\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1305 - val_loss: 0.1652\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1399 - val_loss: 0.1687\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1487 - val_loss: 0.1726\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1491 - val_loss: 0.1711\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1395 - val_loss: 0.1749\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1351 - val_loss: 0.1742\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1350 - val_loss: 0.1738\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1415 - val_loss: 0.1696\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1357 - val_loss: 0.1818\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1375 - val_loss: 0.1698\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1380 - val_loss: 0.1724\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1305 - val_loss: 0.1712\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.1293 - val_loss: 0.1770\n",
      "Epoch 00064: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 7.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 25s 18ms/step - loss: 8.0729 - val_loss: 0.2836\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.9284 - val_loss: 0.2243\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8642 - val_loss: 0.2193\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.8174 - val_loss: 0.2084\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.7455 - val_loss: 0.2069\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6643 - val_loss: 0.2060\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.6633 - val_loss: 0.2010\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5992 - val_loss: 0.2002\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5506 - val_loss: 0.1974\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.5288 - val_loss: 0.1894\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 7s 5ms/step - loss: 0.4798 - val_loss: 0.1885\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.4068 - val_loss: 0.1864\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3992 - val_loss: 0.1927\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3859 - val_loss: 0.1927\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3492 - val_loss: 0.1972\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3186 - val_loss: 0.1854\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2996 - val_loss: 0.1835\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.3039 - val_loss: 0.1746\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2843 - val_loss: 0.1848\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2523 - val_loss: 0.1848\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.2528 - val_loss: 0.1812\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2214 - val_loss: 0.1758\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2309 - val_loss: 0.1743\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2206 - val_loss: 0.1808\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.2110 - val_loss: 0.1796\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1992 - val_loss: 0.1748\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1898 - val_loss: 0.1758\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1970 - val_loss: 0.1789\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 6s 4ms/step - loss: 0.1815 - val_loss: 0.1860\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1823 - val_loss: 0.1768\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1683 - val_loss: 0.1793\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1785 - val_loss: 0.1744\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 6s 5ms/step - loss: 0.1775 - val_loss: 0.1878\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 25.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 24s 14ms/step - loss: 8.9499 - val_loss: 0.2415\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.9370 - val_loss: 0.2169\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.9065 - val_loss: 0.2061\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.8073 - val_loss: 0.1921\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.7066 - val_loss: 0.1960\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.7050 - val_loss: 0.1952\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.6209 - val_loss: 0.1856\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.5688 - val_loss: 0.1844\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.5414 - val_loss: 0.1839\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.4827 - val_loss: 0.1840\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.4356 - val_loss: 0.1854\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.4187 - val_loss: 0.1797\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.3636 - val_loss: 0.1792\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.3286 - val_loss: 0.1763\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.3140 - val_loss: 0.1778\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.2623 - val_loss: 0.1701\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.2638 - val_loss: 0.1775\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.2419 - val_loss: 0.1692\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.2226 - val_loss: 0.1698\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.2051 - val_loss: 0.1767\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 7s 4ms/step - loss: 0.2088 - val_loss: 0.1686\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1779 - val_loss: 0.1734\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.1745 - val_loss: 0.1683\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1705 - val_loss: 0.1678\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.1552 - val_loss: 0.1665\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.1634 - val_loss: 0.1752\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1545 - val_loss: 0.1833\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.1544 - val_loss: 0.1762\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.1521 - val_loss: 0.1722\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1291 - val_loss: 0.1704\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 8s 4ms/step - loss: 0.1536 - val_loss: 0.1708\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1324 - val_loss: 0.1757\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1338 - val_loss: 0.1658\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1449 - val_loss: 0.1746\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1267 - val_loss: 0.1780\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1310 - val_loss: 0.1698\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1221 - val_loss: 0.1702\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1291 - val_loss: 0.1750\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1254 - val_loss: 0.1719\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 8s 5ms/step - loss: 0.1190 - val_loss: 0.1728\n",
      "Epoch 00040: early stopping\n",
      "Out-of-sample MSE:  0.1728477837956951\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 19s 14ms/step - loss: 314.8687 - val_loss: 4.2570\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 20.1150 - val_loss: 11.2429\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 8.7741 - val_loss: 1.3329\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.4217 - val_loss: 0.9031\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.9423 - val_loss: 1.1338\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0956 - val_loss: 1.7683\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0408 - val_loss: 0.6122\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.0811 - val_loss: 2.4238\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8504 - val_loss: 0.6255\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6285 - val_loss: 0.5619\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.6536 - val_loss: 0.7312\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 1.8189 - val_loss: 0.9270\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.6919 - val_loss: 1.2101\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 2.7975 - val_loss: 2.3817\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.2942 - val_loss: 2.0404\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.1391 - val_loss: 2.7270\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.1986 - val_loss: 2.2398\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 3.5582 - val_loss: 2.5977\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 5.7442 - val_loss: 4.7204\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 7.5924 - val_loss: 3.2866\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 9.8535 - val_loss: 1.9444\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 6.6293 - val_loss: 1.2651\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 6.1366 - val_loss: 2.1601\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.8744 - val_loss: 2.5346\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s 3ms/step - loss: 4.5744 - val_loss: 2.0820\n",
      "Epoch 00025: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 2.1min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 14ms/step - loss: 280.4279 - val_loss: 7.3967\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 14.7277 - val_loss: 2.7814\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.5980 - val_loss: 1.3085\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.4121 - val_loss: 3.3742\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7500 - val_loss: 0.8951\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4211 - val_loss: 0.6047\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9634 - val_loss: 1.0312\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5874 - val_loss: 1.6094\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.4446 - val_loss: 1.9528\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7269 - val_loss: 1.7555\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2622 - val_loss: 0.8571\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4385 - val_loss: 1.8448\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9586 - val_loss: 0.9036\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.1117 - val_loss: 1.5524\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9036 - val_loss: 3.2481\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.3437 - val_loss: 3.2784\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.0731 - val_loss: 6.8223\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.3587 - val_loss: 8.8858\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 18.0597 - val_loss: 2.5029\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.1017 - val_loss: 2.2132\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.2990 - val_loss: 1.5273\n",
      "Epoch 00021: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 1.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 15ms/step - loss: 253.4768 - val_loss: 3.9282\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 17.0361 - val_loss: 2.8933\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 6.3498 - val_loss: 1.0662\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 4.0941 - val_loss: 1.2833\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 2.9064 - val_loss: 1.0943\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 2.3938 - val_loss: 0.8668\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 2.4323 - val_loss: 1.4624\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 3.0737 - val_loss: 1.1019\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 4.0447 - val_loss: 2.2882\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.7046 - val_loss: 1.0144\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.3220 - val_loss: 0.8559\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.4747 - val_loss: 1.2423\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.3112 - val_loss: 2.7178\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.8634 - val_loss: 6.3073\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.7268 - val_loss: 3.9284\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9321 - val_loss: 1.7078\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8702 - val_loss: 1.6274\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 5.4946 - val_loss: 1.2095\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9393 - val_loss: 3.0703\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5822 - val_loss: 0.9450\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.5281 - val_loss: 3.2085\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.8927 - val_loss: 0.9190\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5370 - val_loss: 1.3180\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 9.2493 - val_loss: 4.3228\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s 3ms/step - loss: 5.4333 - val_loss: 5.0773\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9398 - val_loss: 1.3118\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 15ms/step - loss: 229.5756 - val_loss: 3.6573\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 13.5156 - val_loss: 3.5931\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.1937 - val_loss: 2.1748\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.6950 - val_loss: 0.7221\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2114 - val_loss: 1.3163\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4635 - val_loss: 1.2208\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.1604 - val_loss: 1.0610\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.4216 - val_loss: 0.9593\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0445 - val_loss: 1.3012\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.0153 - val_loss: 0.7115\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8839 - val_loss: 2.0058\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0754 - val_loss: 0.5137\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5679 - val_loss: 2.5893\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.6450 - val_loss: 1.4882\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8537 - val_loss: 0.6995\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0957 - val_loss: 3.6649\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.8255 - val_loss: 2.0735\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9666 - val_loss: 4.6310\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9828 - val_loss: 1.2240\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.6440 - val_loss: 2.8244\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 10.6472 - val_loss: 7.5656\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 6.1089 - val_loss: 1.4138\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.7821 - val_loss: 1.1448\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.9121 - val_loss: 1.1421\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.0274 - val_loss: 0.3927\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5721 - val_loss: 0.9607\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.6730 - val_loss: 0.7221\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.2213 - val_loss: 0.4386\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9648 - val_loss: 1.2451\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.2187 - val_loss: 1.3031\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.4941 - val_loss: 0.3562\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9777 - val_loss: 0.5822\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.1822 - val_loss: 0.4114\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8714 - val_loss: 0.3708\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.7982 - val_loss: 0.4110\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5919 - val_loss: 0.3683\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6007 - val_loss: 0.2614\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5878 - val_loss: 0.4544\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8711 - val_loss: 1.0372\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.8225 - val_loss: 0.3342\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.9761 - val_loss: 0.3714\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6956 - val_loss: 0.3516\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5191 - val_loss: 0.2800\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5253 - val_loss: 0.5291\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5702 - val_loss: 0.3584\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6609 - val_loss: 0.2823\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.5095 - val_loss: 0.4498\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5949 - val_loss: 0.3229\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5910 - val_loss: 0.4307\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.6501 - val_loss: 0.2922\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5327 - val_loss: 0.2774\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 0.5754 - val_loss: 0.4346\n",
      "Epoch 00052: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 4.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 20s 15ms/step - loss: 291.2698 - val_loss: 5.9099\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 17.4110 - val_loss: 3.0453\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 8.0295 - val_loss: 4.5564\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 5.0186 - val_loss: 1.1815\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8709 - val_loss: 1.1263\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.3133 - val_loss: 1.1630\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9953 - val_loss: 0.7654\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.8619 - val_loss: 0.9083\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 1.9847 - val_loss: 1.0382\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.5561 - val_loss: 0.6642\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5466 - val_loss: 3.1662\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5786 - val_loss: 1.9415\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7411 - val_loss: 0.8874\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.5578 - val_loss: 0.9618\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 2.8333 - val_loss: 1.0009\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.7103 - val_loss: 1.1152\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.7273 - val_loss: 15.0985\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 15.8620 - val_loss: 9.6481\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 11.4183 - val_loss: 2.1847\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 7.3595 - val_loss: 1.9485\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.6571 - val_loss: 1.1315\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.6311 - val_loss: 1.2917\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 4.0049 - val_loss: 0.9454\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.9397 - val_loss: 5.7784\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s 3ms/step - loss: 3.1682 - val_loss: 0.7500\n",
      "Epoch 00025: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.4min finished\n",
      "/opt/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 21s 12ms/step - loss: 202.6049 - val_loss: 7.9710\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 10.1948 - val_loss: 1.7816\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 4.9981 - val_loss: 1.4358\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 4.0540 - val_loss: 1.0021\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.4408 - val_loss: 0.8266\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.8911 - val_loss: 1.3179\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.4775 - val_loss: 0.6871\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.9406 - val_loss: 0.9097\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.2547 - val_loss: 0.8809\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.9023 - val_loss: 1.0740\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.9271 - val_loss: 0.9999\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.8980 - val_loss: 0.6783\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.1058 - val_loss: 0.9111\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.9283 - val_loss: 1.0301\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 6s 3ms/step - loss: 3.8250 - val_loss: 1.6491\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 3.5803 - val_loss: 0.8821\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 3.7797 - val_loss: 2.0447\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 3.2437 - val_loss: 2.2711\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 6s 3ms/step - loss: 3.3334 - val_loss: 0.7671\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 3.7236 - val_loss: 1.4752\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 5.6005 - val_loss: 1.9178\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 4.9584 - val_loss: 0.9099\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 4.6625 - val_loss: 1.6386\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 4.0269 - val_loss: 0.9331\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.5106 - val_loss: 0.6355\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 2.2165 - val_loss: 0.8582\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.7707 - val_loss: 0.7169\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.1720 - val_loss: 0.5032\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.0897 - val_loss: 0.7536\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.1608 - val_loss: 0.8729\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.9779 - val_loss: 0.3351\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.8490 - val_loss: 0.4758\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.7083 - val_loss: 0.2581\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.6878 - val_loss: 0.3385\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.7680 - val_loss: 0.3039\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.5998 - val_loss: 0.3109\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.6166 - val_loss: 0.5479\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.5409 - val_loss: 0.3333\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.5410 - val_loss: 0.2632\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.5287 - val_loss: 0.3518\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 1.3447 - val_loss: 0.3156\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.6705 - val_loss: 0.3353\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.6612 - val_loss: 0.2792\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.4987 - val_loss: 0.2840\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3896 - val_loss: 0.2570\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3822 - val_loss: 0.3846\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.4093 - val_loss: 0.2589\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3375 - val_loss: 0.2991\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2983 - val_loss: 0.4095\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3169 - val_loss: 0.2275\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3138 - val_loss: 0.2638\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3002 - val_loss: 0.2285\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3863 - val_loss: 0.3380\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2702 - val_loss: 0.2687\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2357 - val_loss: 0.3241\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2696 - val_loss: 0.2589\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2536 - val_loss: 0.2253\n",
      "Epoch 58/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2320 - val_loss: 0.2149\n",
      "Epoch 59/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.4007 - val_loss: 0.5232\n",
      "Epoch 60/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.3190 - val_loss: 0.3206\n",
      "Epoch 61/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2254 - val_loss: 0.2814\n",
      "Epoch 62/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2147 - val_loss: 0.1994\n",
      "Epoch 63/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1871 - val_loss: 0.2299\n",
      "Epoch 64/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1867 - val_loss: 0.2012\n",
      "Epoch 65/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.2063 - val_loss: 0.2510\n",
      "Epoch 66/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1724 - val_loss: 0.2166\n",
      "Epoch 67/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1614 - val_loss: 0.2380\n",
      "Epoch 68/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1589 - val_loss: 0.2257\n",
      "Epoch 69/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1685 - val_loss: 0.2076\n",
      "Epoch 70/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1645 - val_loss: 0.2192\n",
      "Epoch 71/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1660 - val_loss: 0.2669\n",
      "Epoch 72/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1967 - val_loss: 0.2181\n",
      "Epoch 73/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1865 - val_loss: 0.1953\n",
      "Epoch 74/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1439 - val_loss: 0.2020\n",
      "Epoch 75/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1517 - val_loss: 0.2465\n",
      "Epoch 76/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1305 - val_loss: 0.1979\n",
      "Epoch 77/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1447 - val_loss: 0.2003\n",
      "Epoch 78/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1527 - val_loss: 0.2415\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1386 - val_loss: 0.1907\n",
      "Epoch 80/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1604 - val_loss: 0.2137\n",
      "Epoch 81/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1280 - val_loss: 0.1945\n",
      "Epoch 82/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1149 - val_loss: 0.1891\n",
      "Epoch 83/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1078 - val_loss: 0.1982\n",
      "Epoch 84/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1000 - val_loss: 0.2071\n",
      "Epoch 85/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0984 - val_loss: 0.1960\n",
      "Epoch 86/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1041 - val_loss: 0.1905\n",
      "Epoch 87/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0982 - val_loss: 0.1993\n",
      "Epoch 88/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1094 - val_loss: 0.1924\n",
      "Epoch 89/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1027 - val_loss: 0.1907\n",
      "Epoch 90/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0963 - val_loss: 0.2088\n",
      "Epoch 91/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1031 - val_loss: 0.1851\n",
      "Epoch 92/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0957 - val_loss: 0.2027\n",
      "Epoch 93/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0995 - val_loss: 0.1894\n",
      "Epoch 94/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0915 - val_loss: 0.1817\n",
      "Epoch 95/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0930 - val_loss: 0.1841\n",
      "Epoch 96/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.1008 - val_loss: 0.1923\n",
      "Epoch 97/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0987 - val_loss: 0.2002\n",
      "Epoch 98/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0964 - val_loss: 0.1885\n",
      "Epoch 99/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0869 - val_loss: 0.1843\n",
      "Epoch 100/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0839 - val_loss: 0.1870\n",
      "Epoch 101/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0859 - val_loss: 0.2106\n",
      "Epoch 102/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0944 - val_loss: 0.1978\n",
      "Epoch 103/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0923 - val_loss: 0.1904\n",
      "Epoch 104/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0850 - val_loss: 0.1941\n",
      "Epoch 105/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0803 - val_loss: 0.1808\n",
      "Epoch 106/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0854 - val_loss: 0.1858\n",
      "Epoch 107/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0827 - val_loss: 0.1831\n",
      "Epoch 108/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0879 - val_loss: 0.1875\n",
      "Epoch 109/200\n",
      "1696/1696 [==============================] - 5s 3ms/step - loss: 0.0812 - val_loss: 0.1889\n",
      "Epoch 00109: early stopping\n",
      "Out-of-sample MSE:  0.18892284947139587\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 18s 13ms/step - loss: 11.4897 - val_loss: 7.8760\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.7703 - val_loss: 7.6675\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.5588 - val_loss: 7.4541\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.3455 - val_loss: 7.2410\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.1337 - val_loss: 7.0304\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.9245 - val_loss: 6.8224\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.7188 - val_loss: 6.6186\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.5172 - val_loss: 6.4185\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.3199 - val_loss: 6.2232\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 6.1264 - val_loss: 6.0321\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 5.9371 - val_loss: 5.8446\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.7519 - val_loss: 5.6605\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.5706 - val_loss: 5.4819\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.3939 - val_loss: 5.3071\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.2215 - val_loss: 5.1359\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 5.0529 - val_loss: 4.9694\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.8886 - val_loss: 4.8070\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.7283 - val_loss: 4.6486\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.5717 - val_loss: 4.4938\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.4193 - val_loss: 4.3428\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.2704 - val_loss: 4.1961\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 4.1256 - val_loss: 4.0531\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.9844 - val_loss: 3.9135\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.8469 - val_loss: 3.7773\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.7129 - val_loss: 3.6449\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.5825 - val_loss: 3.5168\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.4558 - val_loss: 3.3908\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.3324 - val_loss: 3.2694\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.2128 - val_loss: 3.1511\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 3.0962 - val_loss: 3.0363\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.9832 - val_loss: 2.9246\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.8731 - val_loss: 2.8156\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.7662 - val_loss: 2.7103\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.6625 - val_loss: 2.6081\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.5618 - val_loss: 2.5088\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.4641 - val_loss: 2.4123\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.3694 - val_loss: 2.3186\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.2775 - val_loss: 2.2282\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.1886 - val_loss: 2.1407\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.1024 - val_loss: 2.0555\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.0189 - val_loss: 1.9735\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.9384 - val_loss: 1.8940\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.8605 - val_loss: 1.8169\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.7851 - val_loss: 1.7427\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.7123 - val_loss: 1.6710\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.6419 - val_loss: 1.6020\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.5741 - val_loss: 1.5350\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.5086 - val_loss: 1.4705\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.4455 - val_loss: 1.4087\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.3847 - val_loss: 1.3487\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.3260 - val_loss: 1.2908\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2695 - val_loss: 1.2354\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.2152 - val_loss: 1.1819\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.1629 - val_loss: 1.1307\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.1129 - val_loss: 1.0813\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.0648 - val_loss: 1.0339\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 1.0184 - val_loss: 0.9886\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9738 - val_loss: 0.9448\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9314 - val_loss: 0.9028\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8906 - val_loss: 0.8634\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8517 - val_loss: 0.8251\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.8147 - val_loss: 0.7884\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7792 - val_loss: 0.7539\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7453 - val_loss: 0.7208\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.7130 - val_loss: 0.6890\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6822 - val_loss: 0.6590\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6530 - val_loss: 0.6301\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6252 - val_loss: 0.6031\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5989 - val_loss: 0.5771\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5737 - val_loss: 0.5527\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5499 - val_loss: 0.5295\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5275 - val_loss: 0.5070\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5060 - val_loss: 0.4865\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4862 - val_loss: 0.4668\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4673 - val_loss: 0.4486\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4495 - val_loss: 0.4311\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4327 - val_loss: 0.4149\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4170 - val_loss: 0.3995\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.4021 - val_loss: 0.3853\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3883 - val_loss: 0.3715\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3752 - val_loss: 0.3589\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3631 - val_loss: 0.3469\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3518 - val_loss: 0.3359\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3413 - val_loss: 0.3257\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3315 - val_loss: 0.3162\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3224 - val_loss: 0.3075\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3140 - val_loss: 0.2992\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.3062 - val_loss: 0.2917\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2990 - val_loss: 0.2846\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2924 - val_loss: 0.2782\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2863 - val_loss: 0.2724\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2808 - val_loss: 0.2670\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2757 - val_loss: 0.2619\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2709 - val_loss: 0.2575\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2667 - val_loss: 0.2531\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2628 - val_loss: 0.2496\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2592 - val_loss: 0.2460\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2560 - val_loss: 0.2429\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2531 - val_loss: 0.2401\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2505 - val_loss: 0.2376\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2482 - val_loss: 0.2354\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2461 - val_loss: 0.2333\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2443 - val_loss: 0.2316\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2426 - val_loss: 0.2299\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2412 - val_loss: 0.2285\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2399 - val_loss: 0.2272\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2387 - val_loss: 0.2261\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2377 - val_loss: 0.2252\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2368 - val_loss: 0.2242\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2360 - val_loss: 0.2235\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.2353 - val_loss: 0.2227\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2347 - val_loss: 0.2221\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2341 - val_loss: 0.2217\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2337 - val_loss: 0.2213\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2333 - val_loss: 0.2209\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2330 - val_loss: 0.2205\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2327 - val_loss: 0.2202\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2325 - val_loss: 0.2200\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2323 - val_loss: 0.2198\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2321 - val_loss: 0.2196\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2320 - val_loss: 0.2195\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2319 - val_loss: 0.2193\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2317 - val_loss: 0.2192\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2316 - val_loss: 0.2191\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2316 - val_loss: 0.2191\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2315 - val_loss: 0.2190\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2315 - val_loss: 0.2189\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2189\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2189\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2188\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2188\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2188\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2188\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2188\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.2313 - val_loss: 0.2187\n",
      "Epoch 00136: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 13ms/step - loss: 8.4696 - val_loss: 2.5159\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.0468 - val_loss: 1.9808\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5096 - val_loss: 1.1377\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.7679 - val_loss: 0.9510\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5196 - val_loss: 0.9980\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6232 - val_loss: 0.8695\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3868 - val_loss: 0.8490\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5164 - val_loss: 0.9939\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3594 - val_loss: 1.0229\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3022 - val_loss: 1.2322\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.2757 - val_loss: 0.7522\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1604 - val_loss: 1.2166\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0708 - val_loss: 0.9026\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1126 - val_loss: 1.2542\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1475 - val_loss: 1.1601\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9497 - val_loss: 0.8486\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.9824 - val_loss: 0.7948\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8887 - val_loss: 0.7290\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8511 - val_loss: 0.5860\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7813 - val_loss: 0.6975\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7486 - val_loss: 0.8477\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6501 - val_loss: 0.4139\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7345 - val_loss: 0.8300\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5669 - val_loss: 0.7509\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5482 - val_loss: 0.7314\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5202 - val_loss: 0.8553\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4612 - val_loss: 0.5504\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3737 - val_loss: 0.6319\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3082 - val_loss: 0.5537\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3784 - val_loss: 0.4171\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3048 - val_loss: 0.5735\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2430 - val_loss: 0.4753\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2185 - val_loss: 0.6456\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2303 - val_loss: 0.4852\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1657 - val_loss: 0.5111\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1003 - val_loss: 0.4004\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0304 - val_loss: 0.4952\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9869 - val_loss: 0.5195\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9732 - val_loss: 0.5708\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9762 - val_loss: 0.4362\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8791 - val_loss: 0.3763\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8426 - val_loss: 0.4961\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8883 - val_loss: 0.5023\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7898 - val_loss: 0.4803\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7579 - val_loss: 0.4467\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8251 - val_loss: 0.4147\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7377 - val_loss: 0.4030\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6970 - val_loss: 0.4572\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6916 - val_loss: 0.3284\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6771 - val_loss: 0.3733\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6571 - val_loss: 0.3858\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6451 - val_loss: 0.3012\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5452 - val_loss: 0.3476\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5680 - val_loss: 0.3353\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5294 - val_loss: 0.3621\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5337 - val_loss: 0.3371\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5005 - val_loss: 0.3282\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4893 - val_loss: 0.3110\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4716 - val_loss: 0.2688\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4496 - val_loss: 0.3327\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4490 - val_loss: 0.3132\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4216 - val_loss: 0.3292\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3956 - val_loss: 0.2475\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4017 - val_loss: 0.3059\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3927 - val_loss: 0.2691\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3516 - val_loss: 0.2649\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3219 - val_loss: 0.2748\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3240 - val_loss: 0.2643\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3202 - val_loss: 0.2408\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2957 - val_loss: 0.2322\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2865 - val_loss: 0.2321\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2956 - val_loss: 0.2850\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2694 - val_loss: 0.2277\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2495 - val_loss: 0.2376\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2597 - val_loss: 0.2470\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2462 - val_loss: 0.2387\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2175 - val_loss: 0.2437\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2120 - val_loss: 0.2222\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2084 - val_loss: 0.2007\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2344 - val_loss: 0.2219\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2167 - val_loss: 0.2028\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1827 - val_loss: 0.2023\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1761 - val_loss: 0.2152\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1770 - val_loss: 0.1868\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1692 - val_loss: 0.2018\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1615 - val_loss: 0.1995\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1702 - val_loss: 0.2024\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1649 - val_loss: 0.1839\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1621 - val_loss: 0.1859\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1429 - val_loss: 0.1935\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1545 - val_loss: 0.1930\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1513 - val_loss: 0.2027\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1442 - val_loss: 0.2044\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1327 - val_loss: 0.1796\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1327 - val_loss: 0.1833\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1287 - val_loss: 0.1839\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1312 - val_loss: 0.1899\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1225 - val_loss: 0.1853\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1178 - val_loss: 0.1777\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1339 - val_loss: 0.1911\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1301 - val_loss: 0.1834\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1319 - val_loss: 0.1895\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1227 - val_loss: 0.1911\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1314 - val_loss: 0.1849\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1357 - val_loss: 0.1753\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1265 - val_loss: 0.1887\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1238 - val_loss: 0.1758\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1184 - val_loss: 0.1782\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1312 - val_loss: 0.1772\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1248 - val_loss: 0.1795\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1258 - val_loss: 0.1779\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1220 - val_loss: 0.1775\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1265 - val_loss: 0.1723\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1187 - val_loss: 0.1758\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1212 - val_loss: 0.1757\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1173 - val_loss: 0.1780\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1217 - val_loss: 0.1733\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1235 - val_loss: 0.1758\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1298 - val_loss: 0.1794\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1251 - val_loss: 0.1858\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1247 - val_loss: 0.1775\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1197 - val_loss: 0.1773\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1208 - val_loss: 0.1774\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1251 - val_loss: 0.1787\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1212 - val_loss: 0.1779\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1252 - val_loss: 0.1735\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1297 - val_loss: 0.1731\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1168 - val_loss: 0.1747\n",
      "Epoch 00128: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 18s 14ms/step - loss: 10.7843 - val_loss: 1.5987\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9058 - val_loss: 2.2154\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.0190 - val_loss: 2.1193\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7652 - val_loss: 1.9379\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.8414 - val_loss: 2.0731\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.6734 - val_loss: 1.9810\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.7468 - val_loss: 1.7691\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5772 - val_loss: 1.5999\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4563 - val_loss: 1.8999\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2071 - val_loss: 1.7214\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1316 - val_loss: 1.6350\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9413 - val_loss: 1.6417\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8232 - val_loss: 1.6630\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8906 - val_loss: 1.4997\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8204 - val_loss: 1.5972\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6096 - val_loss: 1.4634\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8250 - val_loss: 1.5163\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6571 - val_loss: 1.3937\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.3930 - val_loss: 1.3812\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3790 - val_loss: 1.3918\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.5076 - val_loss: 1.3147\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3585 - val_loss: 1.2649\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1805 - val_loss: 1.2623\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1488 - val_loss: 1.2106\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1563 - val_loss: 1.1463\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0983 - val_loss: 1.1466\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9187 - val_loss: 1.0811\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9181 - val_loss: 1.0724\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8702 - val_loss: 1.0305\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8990 - val_loss: 1.0098\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7779 - val_loss: 0.9817\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6912 - val_loss: 0.9523\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6040 - val_loss: 0.9251\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5089 - val_loss: 0.9129\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4750 - val_loss: 0.8427\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4274 - val_loss: 0.8612\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.3600 - val_loss: 0.8192\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2837 - val_loss: 0.7974\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3097 - val_loss: 0.7124\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2683 - val_loss: 0.8050\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1892 - val_loss: 0.8373\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1342 - val_loss: 0.6233\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1141 - val_loss: 0.6886\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0771 - val_loss: 0.6932\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0909 - val_loss: 0.6235\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9711 - val_loss: 0.6501\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9560 - val_loss: 0.5444\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9334 - val_loss: 0.5673\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8413 - val_loss: 0.5921\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8646 - val_loss: 0.5694\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8293 - val_loss: 0.5236\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7690 - val_loss: 0.5329\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7006 - val_loss: 0.5142\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6807 - val_loss: 0.5158\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6623 - val_loss: 0.4518\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6448 - val_loss: 0.4802\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6675 - val_loss: 0.4138\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5807 - val_loss: 0.4501\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5882 - val_loss: 0.4119\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5808 - val_loss: 0.4193\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5112 - val_loss: 0.3669\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5167 - val_loss: 0.3591\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4794 - val_loss: 0.3565\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4697 - val_loss: 0.3428\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4507 - val_loss: 0.3480\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4372 - val_loss: 0.3414\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3870 - val_loss: 0.3303\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3722 - val_loss: 0.3345\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3912 - val_loss: 0.3319\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3648 - val_loss: 0.2953\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3599 - val_loss: 0.3044\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3384 - val_loss: 0.2899\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3431 - val_loss: 0.2797\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3283 - val_loss: 0.2734\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2923 - val_loss: 0.2494\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2829 - val_loss: 0.2601\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2790 - val_loss: 0.2642\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2814 - val_loss: 0.2579\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2576 - val_loss: 0.2564\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2679 - val_loss: 0.2442\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2445 - val_loss: 0.2357\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2407 - val_loss: 0.2295\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2268 - val_loss: 0.2341\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2197 - val_loss: 0.2302\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2298 - val_loss: 0.2306\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.1931 - val_loss: 0.2179\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2023 - val_loss: 0.2293\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2031 - val_loss: 0.2099\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1942 - val_loss: 0.2117\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2056 - val_loss: 0.2168\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1839 - val_loss: 0.2036\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1768 - val_loss: 0.2225\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1871 - val_loss: 0.1997\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1759 - val_loss: 0.1956\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1757 - val_loss: 0.1923\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1648 - val_loss: 0.1978\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1628 - val_loss: 0.1976\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1719 - val_loss: 0.1901\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1656 - val_loss: 0.1978\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1674 - val_loss: 0.1927\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1667 - val_loss: 0.2042\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1655 - val_loss: 0.1969\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1639 - val_loss: 0.1889\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1588 - val_loss: 0.1815\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1663 - val_loss: 0.1873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1477 - val_loss: 0.1846\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1506 - val_loss: 0.1906\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1420 - val_loss: 0.1854\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1519 - val_loss: 0.1862\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1558 - val_loss: 0.1942\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1664 - val_loss: 0.1852\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1530 - val_loss: 0.1864\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1398 - val_loss: 0.1853\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1543 - val_loss: 0.1919\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1621 - val_loss: 0.1912\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1525 - val_loss: 0.1868\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1514 - val_loss: 0.1881\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1631 - val_loss: 0.1864\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.1588 - val_loss: 0.1886\n",
      "Epoch 00119: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 5.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 13.3826 - val_loss: 7.8901\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.7319 - val_loss: 7.6932\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.5302 - val_loss: 7.4866\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.3236 - val_loss: 7.2782\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.1168 - val_loss: 7.0715\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.9120 - val_loss: 6.8664\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.7093 - val_loss: 6.6647\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.5102 - val_loss: 6.4663\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.3148 - val_loss: 6.2719\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.1229 - val_loss: 6.0816\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.9354 - val_loss: 5.8948\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 5.7515 - val_loss: 5.7116\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.5713 - val_loss: 5.5327\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.3954 - val_loss: 5.3581\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.2236 - val_loss: 5.1879\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.0558 - val_loss: 5.0206\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.8916 - val_loss: 4.8580\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.7318 - val_loss: 4.6990\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.5757 - val_loss: 4.5435\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.4236 - val_loss: 4.3926\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.2753 - val_loss: 4.2457\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.1309 - val_loss: 4.1017\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.9899 - val_loss: 3.9622\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.8527 - val_loss: 3.8254\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7188 - val_loss: 3.6927\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5888 - val_loss: 3.5633\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.4620 - val_loss: 3.4384\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3390 - val_loss: 3.3156\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.2189 - val_loss: 3.1965\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.1022 - val_loss: 3.0807\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9890 - val_loss: 2.9682\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8789 - val_loss: 2.8589\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.7720 - val_loss: 2.7529\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6683 - val_loss: 2.6496\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5675 - val_loss: 2.5501\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4698 - val_loss: 2.4529\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3750 - val_loss: 2.3586\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.2830 - val_loss: 2.2675\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.1938 - val_loss: 2.1791\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.1076 - val_loss: 2.0931\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0239 - val_loss: 2.0107\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9431 - val_loss: 1.9301\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8647 - val_loss: 1.8523\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.7890 - val_loss: 1.7773\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.7158 - val_loss: 1.7044\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6451 - val_loss: 1.6342\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.5770 - val_loss: 1.5666\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5112 - val_loss: 1.5015\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4477 - val_loss: 1.4385\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3864 - val_loss: 1.3774\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3273 - val_loss: 1.3191\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2707 - val_loss: 1.2627\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2161 - val_loss: 1.2088\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1637 - val_loss: 1.1568\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1132 - val_loss: 1.1066\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0649 - val_loss: 1.0584\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0183 - val_loss: 1.0126\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9737 - val_loss: 0.9678\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9308 - val_loss: 0.9254\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8899 - val_loss: 0.8850\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8508 - val_loss: 0.8462\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8133 - val_loss: 0.8090\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7775 - val_loss: 0.7736\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7434 - val_loss: 0.7396\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7110 - val_loss: 0.7073\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6799 - val_loss: 0.6765\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6504 - val_loss: 0.6472\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6224 - val_loss: 0.6195\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5957 - val_loss: 0.5929\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5703 - val_loss: 0.5680\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5465 - val_loss: 0.5442\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5238 - val_loss: 0.5217\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5024 - val_loss: 0.5000\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4820 - val_loss: 0.4799\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4629 - val_loss: 0.4611\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4450 - val_loss: 0.4429\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4280 - val_loss: 0.4264\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4122 - val_loss: 0.4103\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3971 - val_loss: 0.3955\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3831 - val_loss: 0.3814\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3700 - val_loss: 0.3682\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3577 - val_loss: 0.3560\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3462 - val_loss: 0.3447\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3356 - val_loss: 0.3340\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3256 - val_loss: 0.3240\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3165 - val_loss: 0.3147\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3079 - val_loss: 0.3064\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3000 - val_loss: 0.2983\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2927 - val_loss: 0.2910\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2859 - val_loss: 0.2843\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2798 - val_loss: 0.2779\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2740 - val_loss: 0.2722\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2688 - val_loss: 0.2670\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2641 - val_loss: 0.2620\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2597 - val_loss: 0.2576\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2557 - val_loss: 0.2535\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2521 - val_loss: 0.2499\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2488 - val_loss: 0.2465\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2459 - val_loss: 0.2435\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2432 - val_loss: 0.2407\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2407 - val_loss: 0.2383\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2386 - val_loss: 0.2360\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2367 - val_loss: 0.2340\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2350 - val_loss: 0.2323\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2335 - val_loss: 0.2306\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2322 - val_loss: 0.2292\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2310 - val_loss: 0.2279\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2299 - val_loss: 0.2268\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2290 - val_loss: 0.2258\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2282 - val_loss: 0.2249\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2275 - val_loss: 0.2242\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2269 - val_loss: 0.2234\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2264 - val_loss: 0.2228\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2259 - val_loss: 0.2223\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2255 - val_loss: 0.2219\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2251 - val_loss: 0.2214\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2249 - val_loss: 0.2210\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2246 - val_loss: 0.2208\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2244 - val_loss: 0.2204\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2242 - val_loss: 0.2202\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2241 - val_loss: 0.2200\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2239 - val_loss: 0.2199\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2238 - val_loss: 0.2197\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2237 - val_loss: 0.2196\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2237 - val_loss: 0.2195\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2236 - val_loss: 0.2194\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2236 - val_loss: 0.2193\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2235 - val_loss: 0.2192\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2235 - val_loss: 0.2192\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2191\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2234 - val_loss: 0.2190\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2190\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2190\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2189\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2189\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2189\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2189\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2234 - val_loss: 0.2188\n",
      "Epoch 00144: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 6.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 15.4025 - val_loss: 7.9122\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.7619 - val_loss: 7.7265\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.5693 - val_loss: 7.5276\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.3693 - val_loss: 7.3253\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.1672 - val_loss: 7.1225\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.9658 - val_loss: 6.9208\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.7662 - val_loss: 6.7215\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.5692 - val_loss: 6.5252\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.3754 - val_loss: 6.3320\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.1847 - val_loss: 6.1425\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.9979 - val_loss: 5.9564\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.8148 - val_loss: 5.7744\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.6354 - val_loss: 5.5966\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.4599 - val_loss: 5.4219\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 5.2882 - val_loss: 5.2508\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.1201 - val_loss: 5.0850\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.9564 - val_loss: 4.9209\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.7956 - val_loss: 4.7620\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.6391 - val_loss: 4.6063\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.4863 - val_loss: 4.4554\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.3375 - val_loss: 4.3070\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.1918 - val_loss: 4.1627\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.0499 - val_loss: 4.0214\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.9116 - val_loss: 3.8843\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.7769 - val_loss: 3.7507\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.6458 - val_loss: 3.6202\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.5181 - val_loss: 3.4939\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.3940 - val_loss: 3.3707\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.2732 - val_loss: 3.2504\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.1555 - val_loss: 3.1337\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 3.0411 - val_loss: 3.0205\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9300 - val_loss: 2.9102\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.8219 - val_loss: 2.8030\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.7170 - val_loss: 2.6987\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.6150 - val_loss: 2.5972\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.5159 - val_loss: 2.4995\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.4201 - val_loss: 2.4041\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.3269 - val_loss: 2.3117\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.2367 - val_loss: 2.2223\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.1492 - val_loss: 2.1355\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0645 - val_loss: 2.0512\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9823 - val_loss: 1.9700\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.9029 - val_loss: 1.8914\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8264 - val_loss: 1.8150\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.7519 - val_loss: 1.7418\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6801 - val_loss: 1.6707\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.6107 - val_loss: 1.6012\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.5436 - val_loss: 1.5344\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.4789 - val_loss: 1.4709\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4168 - val_loss: 1.4089\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.3566 - val_loss: 1.3496\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2990 - val_loss: 1.2918\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.2432 - val_loss: 1.2374\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1899 - val_loss: 1.1840\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.1383 - val_loss: 1.1331\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0888 - val_loss: 1.0840\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0415 - val_loss: 1.0368\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9959 - val_loss: 0.9919\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9523 - val_loss: 0.9485\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9104 - val_loss: 0.9070\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8704 - val_loss: 0.8674\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8322 - val_loss: 0.8293\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7954 - val_loss: 0.7932\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7605 - val_loss: 0.7585\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7271 - val_loss: 0.7254\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6951 - val_loss: 0.6934\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6646 - val_loss: 0.6634\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6357 - val_loss: 0.6346\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6083 - val_loss: 0.6075\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5823 - val_loss: 0.5817\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5576 - val_loss: 0.5569\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5342 - val_loss: 0.5337\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5120 - val_loss: 0.5119\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4911 - val_loss: 0.4912\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4713 - val_loss: 0.4713\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4526 - val_loss: 0.4528\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4351 - val_loss: 0.4355\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4187 - val_loss: 0.4193\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.4033 - val_loss: 0.4040\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3887 - val_loss: 0.3896\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3751 - val_loss: 0.3757\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3622 - val_loss: 0.3630\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3502 - val_loss: 0.3510\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3390 - val_loss: 0.3400\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3286 - val_loss: 0.3295\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3189 - val_loss: 0.3198\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.3100 - val_loss: 0.3110\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.3017 - val_loss: 0.3027\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2940 - val_loss: 0.2950\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2869 - val_loss: 0.2879\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2804 - val_loss: 0.2812\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2744 - val_loss: 0.2753\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2689 - val_loss: 0.2698\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2639 - val_loss: 0.2648\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2594 - val_loss: 0.2599\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2551 - val_loss: 0.2559\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2514 - val_loss: 0.2520\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2480 - val_loss: 0.2484\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2448 - val_loss: 0.2454\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2419 - val_loss: 0.2425\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2394 - val_loss: 0.2398\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2370 - val_loss: 0.2376\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2349 - val_loss: 0.2352\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2330 - val_loss: 0.2332\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2314 - val_loss: 0.2316\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2300 - val_loss: 0.2300\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2286 - val_loss: 0.2286\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2275 - val_loss: 0.2274\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2265 - val_loss: 0.2264\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2256 - val_loss: 0.2254\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2248 - val_loss: 0.2246\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2241 - val_loss: 0.2238\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2235 - val_loss: 0.2231\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2230 - val_loss: 0.2225\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2226 - val_loss: 0.2220\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2222 - val_loss: 0.2215\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2219 - val_loss: 0.2211\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2216 - val_loss: 0.2209\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2214 - val_loss: 0.2206\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2212 - val_loss: 0.2203\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2210 - val_loss: 0.2201\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2209 - val_loss: 0.2199\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2208 - val_loss: 0.2197\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2207 - val_loss: 0.2196\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2206 - val_loss: 0.2195\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2205 - val_loss: 0.2193\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2204 - val_loss: 0.2193\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2204 - val_loss: 0.2191\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2191\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2189\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2189\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2203 - val_loss: 0.2189\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.2202 - val_loss: 0.2189\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.2202 - val_loss: 0.2188\n",
      "Epoch 00138: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 6.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 29.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 20s 12ms/step - loss: 15.4013 - val_loss: 7.8839\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 7.7428 - val_loss: 7.6564\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 7.5071 - val_loss: 7.4146\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 7.2635 - val_loss: 7.1683\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 7.0184 - val_loss: 6.9235\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 6.7753 - val_loss: 6.6814\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 6.5356 - val_loss: 6.4430\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 6.3003 - val_loss: 6.2098\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 6.0699 - val_loss: 5.9816\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 5.8449 - val_loss: 5.7585\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 5.6252 - val_loss: 5.5411\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 5.4112 - val_loss: 5.3293\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 5.2029 - val_loss: 5.1230\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 5.0002 - val_loss: 4.9227\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 4.8030 - val_loss: 4.7282\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 4.6117 - val_loss: 4.5387\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 4.4258 - val_loss: 4.3550\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 4.2455 - val_loss: 4.1770\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 4.0707 - val_loss: 4.0040\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 3.9011 - val_loss: 3.8366\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 3.7368 - val_loss: 3.6748\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 3.5779 - val_loss: 3.5177\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 3.4240 - val_loss: 3.3659\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 3.2753 - val_loss: 3.2185\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 3.1313 - val_loss: 3.0768\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 2.9923 - val_loss: 2.9399\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 2.8579 - val_loss: 2.8078\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.7285 - val_loss: 2.6796\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 2.6033 - val_loss: 2.5565\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 2.4828 - val_loss: 2.4379\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.3668 - val_loss: 2.3229\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 2.2548 - val_loss: 2.2129\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.1473 - val_loss: 2.1067\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.0437 - val_loss: 2.0051\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.9443 - val_loss: 1.9070\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.8489 - val_loss: 1.8127\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.7571 - val_loss: 1.7227\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.6692 - val_loss: 1.6362\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.5850 - val_loss: 1.5535\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.5044 - val_loss: 1.4739\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.4272 - val_loss: 1.3979\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.3534 - val_loss: 1.3256\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.2831 - val_loss: 1.2563\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.2158 - val_loss: 1.1905\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.1518 - val_loss: 1.1275\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.0908 - val_loss: 1.0676\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 1.0328 - val_loss: 1.0106\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.9776 - val_loss: 0.9565\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.9254 - val_loss: 0.9048\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.8756 - val_loss: 0.8566\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.8288 - val_loss: 0.8103\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.7843 - val_loss: 0.7668\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.7423 - val_loss: 0.7255\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.7027 - val_loss: 0.6870\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.6654 - val_loss: 0.6505\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.6303 - val_loss: 0.6162\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.5973 - val_loss: 0.5842\n",
      "Epoch 58/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.5665 - val_loss: 0.5536\n",
      "Epoch 59/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.5375 - val_loss: 0.5254\n",
      "Epoch 60/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.5105 - val_loss: 0.4988\n",
      "Epoch 61/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.4853 - val_loss: 0.4742\n",
      "Epoch 62/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.4618 - val_loss: 0.4512\n",
      "Epoch 63/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.4399 - val_loss: 0.4299\n",
      "Epoch 64/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.4197 - val_loss: 0.4101\n",
      "Epoch 65/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.4009 - val_loss: 0.3919\n",
      "Epoch 66/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.3836 - val_loss: 0.3749\n",
      "Epoch 67/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.3676 - val_loss: 0.3593\n",
      "Epoch 68/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.3529 - val_loss: 0.3448\n",
      "Epoch 69/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.3393 - val_loss: 0.3318\n",
      "Epoch 70/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.3270 - val_loss: 0.3198\n",
      "Epoch 71/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.3157 - val_loss: 0.3087\n",
      "Epoch 72/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.3055 - val_loss: 0.2985\n",
      "Epoch 73/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2961 - val_loss: 0.2898\n",
      "Epoch 74/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2877 - val_loss: 0.2814\n",
      "Epoch 75/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.2801 - val_loss: 0.2739\n",
      "Epoch 76/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2732 - val_loss: 0.2673\n",
      "Epoch 77/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2670 - val_loss: 0.2611\n",
      "Epoch 78/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2615 - val_loss: 0.2557\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2566 - val_loss: 0.2509\n",
      "Epoch 80/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2522 - val_loss: 0.2468\n",
      "Epoch 81/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2484 - val_loss: 0.2430\n",
      "Epoch 82/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2450 - val_loss: 0.2396\n",
      "Epoch 83/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2419 - val_loss: 0.2367\n",
      "Epoch 84/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2394 - val_loss: 0.2340\n",
      "Epoch 85/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2370 - val_loss: 0.2318\n",
      "Epoch 86/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2351 - val_loss: 0.2298\n",
      "Epoch 87/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2334 - val_loss: 0.2281\n",
      "Epoch 88/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2319 - val_loss: 0.2266\n",
      "Epoch 89/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2306 - val_loss: 0.2254\n",
      "Epoch 90/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2295 - val_loss: 0.2243\n",
      "Epoch 91/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2286 - val_loss: 0.2234\n",
      "Epoch 92/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2278 - val_loss: 0.2226\n",
      "Epoch 93/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2272 - val_loss: 0.2219\n",
      "Epoch 94/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2266 - val_loss: 0.2213\n",
      "Epoch 95/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2262 - val_loss: 0.2208\n",
      "Epoch 96/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2258 - val_loss: 0.2205\n",
      "Epoch 97/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2255 - val_loss: 0.2202\n",
      "Epoch 98/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2253 - val_loss: 0.2199\n",
      "Epoch 99/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2251 - val_loss: 0.2197\n",
      "Epoch 100/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2249 - val_loss: 0.2195\n",
      "Epoch 101/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2248 - val_loss: 0.2193\n",
      "Epoch 102/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2247 - val_loss: 0.2192\n",
      "Epoch 103/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2246 - val_loss: 0.2191\n",
      "Epoch 104/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2245 - val_loss: 0.2190\n",
      "Epoch 105/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2245 - val_loss: 0.2189\n",
      "Epoch 106/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2244 - val_loss: 0.2189\n",
      "Epoch 107/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2244 - val_loss: 0.2189\n",
      "Epoch 108/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.2244 - val_loss: 0.2188\n",
      "Epoch 109/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2244 - val_loss: 0.2188\n",
      "Epoch 110/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2244 - val_loss: 0.2188\n",
      "Epoch 111/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 112/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 113/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 114/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 115/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 116/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 117/200\n",
      "1696/1696 [==============================] - 4s 2ms/step - loss: 0.2243 - val_loss: 0.2187\n",
      "Epoch 00117: early stopping\n",
      "Out-of-sample MSE:  0.2186643873589771\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 19s 14ms/step - loss: 47.6417 - val_loss: 0.3786\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 10.9503 - val_loss: 1.0566\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 8.9568 - val_loss: 0.3479\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 9.2284 - val_loss: 2.4913\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 9.7431 - val_loss: 0.5681\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 9.9343 - val_loss: 0.9234\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 11.7464 - val_loss: 0.4432\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 9.3799 - val_loss: 0.8831\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 7.6417 - val_loss: 0.8561\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 7.1464 - val_loss: 1.0712\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 5.5372 - val_loss: 0.3557\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 4.6936 - val_loss: 0.9209\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 4.0152 - val_loss: 0.6656\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 3.9770 - val_loss: 0.2423\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 3.4059 - val_loss: 0.4262\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 2.7189 - val_loss: 0.3851\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.5659 - val_loss: 0.2086\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.2910 - val_loss: 0.3828\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 2.0132 - val_loss: 0.2008\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.7778 - val_loss: 0.4150\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.6079 - val_loss: 0.1916\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.5613 - val_loss: 0.4293\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.4406 - val_loss: 0.2145\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.3150 - val_loss: 0.1915\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.2219 - val_loss: 0.3496\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.1366 - val_loss: 0.2573\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 1.0614 - val_loss: 0.1870\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.9214 - val_loss: 0.2676\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.8709 - val_loss: 0.2006\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.8578 - val_loss: 0.2623\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7964 - val_loss: 0.2134\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7460 - val_loss: 0.2167\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.7828 - val_loss: 0.2260\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6587 - val_loss: 0.2257\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6118 - val_loss: 0.2048\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.6065 - val_loss: 0.3356\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5421 - val_loss: 0.2739\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5514 - val_loss: 0.1998\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s 2ms/step - loss: 0.5324 - val_loss: 0.1988\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5052 - val_loss: 0.2282\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.5094 - val_loss: 0.2452\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 3s 2ms/step - loss: 0.4907 - val_loss: 0.1971\n",
      "Epoch 00042: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 156.3684 - val_loss: 4.8454\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.9849 - val_loss: 0.7250\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.1620 - val_loss: 1.2662\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.6090 - val_loss: 0.5417\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 9.8770 - val_loss: 1.3525\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.0378 - val_loss: 0.5223\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 10.9247 - val_loss: 0.3429\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.9814 - val_loss: 2.2570\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 12.4794 - val_loss: 0.3550\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 14.1080 - val_loss: 0.3550\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 12.6844 - val_loss: 1.5581\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 11.8396 - val_loss: 0.4209\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 14.2746 - val_loss: 0.4333\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 13.3208 - val_loss: 0.8553\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 11.3525 - val_loss: 0.8339\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 11.2339 - val_loss: 1.3442\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 9.4316 - val_loss: 0.6400\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.8851 - val_loss: 0.3973\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.9523 - val_loss: 1.2689\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.7582 - val_loss: 0.3891\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.3801 - val_loss: 0.3807\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.6989 - val_loss: 0.4187\n",
      "Epoch 00022: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 1.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 93.1424 - val_loss: 1.0811\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.7024 - val_loss: 0.6066\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.9119 - val_loss: 0.4197\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.6334 - val_loss: 0.5556\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.7782 - val_loss: 1.3132\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 8.5506 - val_loss: 0.4838\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.4038 - val_loss: 0.5370\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 12.0735 - val_loss: 1.2645\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.5263 - val_loss: 1.7080\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.0024 - val_loss: 0.3624\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.4152 - val_loss: 0.3702\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.7176 - val_loss: 0.3069\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.7047 - val_loss: 0.2484\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.4083 - val_loss: 0.2919\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 6.7935 - val_loss: 0.4130\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.1776 - val_loss: 0.8043\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 5.2051 - val_loss: 0.3420\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.7310 - val_loss: 0.5903\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.3164 - val_loss: 0.3307\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.0021 - val_loss: 0.3277\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.7127 - val_loss: 0.4422\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.4618 - val_loss: 0.4304\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.0084 - val_loss: 0.5232\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.9424 - val_loss: 0.3193\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.8419 - val_loss: 0.2412\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.4596 - val_loss: 0.2917\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.5670 - val_loss: 0.4126\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.5851 - val_loss: 0.2913\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.0265 - val_loss: 0.3420\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.8710 - val_loss: 0.2109\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.8013 - val_loss: 0.3060\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.6369 - val_loss: 0.2846\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4006 - val_loss: 0.2337\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4343 - val_loss: 0.2345\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2283 - val_loss: 0.3145\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1758 - val_loss: 0.2401\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1592 - val_loss: 0.2835\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1637 - val_loss: 0.2205\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 1.0806 - val_loss: 0.2287\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1723 - val_loss: 0.2783\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9376 - val_loss: 0.3149\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.9117 - val_loss: 0.2169\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8316 - val_loss: 0.2665\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.8589 - val_loss: 0.3293\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.8481 - val_loss: 0.2317\n",
      "Epoch 00045: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 119.6967 - val_loss: 2.9735\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 11.7238 - val_loss: 0.5334\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.2873 - val_loss: 0.6180\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 7.8974 - val_loss: 0.5316\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.7016 - val_loss: 1.2965\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.9619 - val_loss: 0.2501\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.2637 - val_loss: 1.0155\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 10.0596 - val_loss: 0.4508\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 9.7059 - val_loss: 0.3430\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.6498 - val_loss: 0.3309\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 18.8521 - val_loss: 1.2096\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 14.4431 - val_loss: 1.5729\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 9.8551 - val_loss: 0.2820\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.0975 - val_loss: 1.5153\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 13.8398 - val_loss: 0.5579\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.4530 - val_loss: 2.3200\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.1913 - val_loss: 0.3912\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 13.7156 - val_loss: 1.3051\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.9743 - val_loss: 0.4031\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.3612 - val_loss: 0.5442\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.8710 - val_loss: 1.1060\n",
      "Epoch 00021: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 1.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 19s 14ms/step - loss: 69.6858 - val_loss: 0.7111\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 9.2560 - val_loss: 0.5228\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.6971 - val_loss: 0.6894\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.6144 - val_loss: 0.4502\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.0075 - val_loss: 0.3513\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 12.5743 - val_loss: 1.1821\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 14.9751 - val_loss: 0.6166\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 11.5133 - val_loss: 0.3314\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 12.1327 - val_loss: 0.2885\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 11.4702 - val_loss: 0.5243\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 8.5133 - val_loss: 0.4867\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 7.6947 - val_loss: 1.9844\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.8474 - val_loss: 0.4138\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 5.6837 - val_loss: 0.3288\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 5.8816 - val_loss: 0.2404\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 6.0466 - val_loss: 0.4141\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 5.1737 - val_loss: 0.3133\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.9847 - val_loss: 1.1543\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 4.1838 - val_loss: 0.3239\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.0309 - val_loss: 0.3134\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 4.3848 - val_loss: 0.4312\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.3363 - val_loss: 0.3033\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.9896 - val_loss: 0.2685\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.6874 - val_loss: 0.4092\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 3.0718 - val_loss: 0.3824\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 2.0946 - val_loss: 0.2443\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 2.3854 - val_loss: 0.2765\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.7277 - val_loss: 0.3362\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4841 - val_loss: 0.3440\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.4153 - val_loss: 0.1905\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.2866 - val_loss: 0.2633\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.3219 - val_loss: 0.4039\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.1532 - val_loss: 0.2445\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0984 - val_loss: 0.2789\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 1.0607 - val_loss: 0.1838\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9647 - val_loss: 0.2412\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9123 - val_loss: 0.2180\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.9065 - val_loss: 0.3245\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7596 - val_loss: 0.2541\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.7260 - val_loss: 0.2027\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.7061 - val_loss: 0.2401\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.6946 - val_loss: 0.2344\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6697 - val_loss: 0.3651\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6353 - val_loss: 0.1857\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6021 - val_loss: 0.2142\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.6095 - val_loss: 0.2041\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5912 - val_loss: 0.2428\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5841 - val_loss: 0.2006\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s 2ms/step - loss: 0.5482 - val_loss: 0.1935\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s 2ms/step - loss: 0.5126 - val_loss: 0.2191\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.9min finished\n",
      "/opt/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 20s 12ms/step - loss: 79.2620 - val_loss: 1.9476\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 11.3504 - val_loss: 0.6425\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 9.4277 - val_loss: 0.4787\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 13.4782 - val_loss: 1.3585\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 13.0672 - val_loss: 0.4818\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 15.6984 - val_loss: 0.4844\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 13.6521 - val_loss: 0.3421\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 11.1480 - val_loss: 0.5816\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 10.9921 - val_loss: 0.5043\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 11.2110 - val_loss: 0.3339\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 9.5346 - val_loss: 0.8688\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 8.1174 - val_loss: 0.3112\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 6.6777 - val_loss: 1.2619\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 5.7475 - val_loss: 0.2185\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 5.4757 - val_loss: 0.9414\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 5.1243 - val_loss: 0.2802\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 4.1795 - val_loss: 0.3507\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 4.0238 - val_loss: 0.3265\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 3.4587 - val_loss: 0.4761\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 3.8106 - val_loss: 0.2309\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 3.6631 - val_loss: 0.5348\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.6294 - val_loss: 0.2777\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.7037 - val_loss: 0.2179\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 2.2792 - val_loss: 0.2085\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.9381 - val_loss: 0.3947\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.8853 - val_loss: 0.2603\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.8595 - val_loss: 0.3315\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.6635 - val_loss: 0.2558\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.5740 - val_loss: 0.2359\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.4005 - val_loss: 0.2707\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.5447 - val_loss: 0.2161\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.1507 - val_loss: 0.3818\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.1270 - val_loss: 0.2957\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.0024 - val_loss: 0.2426\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 1.1450 - val_loss: 0.3254\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.9659 - val_loss: 0.2333\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.8878 - val_loss: 0.2524\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.9389 - val_loss: 0.2080\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 3s 2ms/step - loss: 0.8358 - val_loss: 0.2161\n",
      "Epoch 00039: early stopping\n",
      "Out-of-sample MSE:  0.21609889833913917\n",
      "CPU times: user 3h 48min 27s, sys: 24min 5s, total: 4h 12min 32s\n",
      "Wall time: 2h 21min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_info = {}\n",
    "for i, p in enumerate(final_models):\n",
    "    history = History() # History callback\n",
    "    model_name = 'model_'+str(i+1)\n",
    "    classifier = KerasRegressor(make_model, batch_size=32, epochs=200)\n",
    "    grid = GridSearchCV(classifier,\n",
    "                             param_grid=p,\n",
    "                             scoring='neg_mean_squared_error', #sklearn optimizing by maximizing negative MSE\n",
    "                             n_jobs=1,\n",
    "                             verbose=2,\n",
    "                             cv=KFold(n_splits=5, shuffle=True, random_state=42),# Number of folds for CV\n",
    "                             return_train_score=True\n",
    "                       )\n",
    "\n",
    "    grid.fit(np.array(X_train), np.array(y_train),\n",
    "            **{'callbacks': [EarlyStopping(monitor='val_loss', \n",
    "                                                                     min_delta=0.001, \n",
    "                                                                     patience=15,\n",
    "                                                                     mode='min',\n",
    "                                                                     verbose=2),\n",
    "                                                      CSVLogger('../output/logs/'+model_name+'.csv', separator=',', append=True),\n",
    "                                                      history], # Added a history callback\n",
    "                                        'validation_data': (np.array(X_test), np.array(y_test))\n",
    "                                        })\n",
    "    y_hats = grid.predict(np.array(X_test))\n",
    "    print(\"Out-of-sample MSE: \", mean_squared_error(y_test, y_hats))\n",
    "    y_hats_full = grid.predict(np.array(X))\n",
    "    model_info[model_name] = {'grid_obj': grid,\n",
    "                              'keras_model': grid.best_estimator_.model,\n",
    "                              'preds': y_hats_full,\n",
    "                              'history': history.history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': {'grid_obj': GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "         error_score='raise-deprecating',\n",
       "         estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f72dfb69eb8>,\n",
       "         fit_params=None, iid='warn', n_jobs=1,\n",
       "         param_grid={'num_hidden_layers': [3], 'hidden_layer_size': [256], 'activation_function': ['linear']},\n",
       "         pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "         scoring='neg_mean_squared_error', verbose=2),\n",
       "  'keras_model': <keras.engine.sequential.Sequential at 0x7f72de78d828>,\n",
       "  'preds': array([2.357138 , 1.9444352, 2.2788858, ..., 1.8491936, 1.7092255,\n",
       "         2.1854386], dtype=float32),\n",
       "  'history': {'val_loss': [3.3399103613460763,\n",
       "    2.0256653031180885,\n",
       "    0.3073396234652575,\n",
       "    0.5723660178745494,\n",
       "    0.9405577987783096,\n",
       "    1.8168666486179128,\n",
       "    0.5329768343532787,\n",
       "    0.9223291803808773,\n",
       "    1.2181899763556088,\n",
       "    0.5052500434482798,\n",
       "    1.3087216983121983,\n",
       "    0.35790845744750077,\n",
       "    0.3128719040926765,\n",
       "    1.1406779951207777,\n",
       "    0.4057245282565846,\n",
       "    0.3098813337438247,\n",
       "    0.40977146835888134,\n",
       "    0.6346324225734262],\n",
       "   'loss': [260.57051613645734,\n",
       "    34.58935575665168,\n",
       "    23.44213816804706,\n",
       "    23.891180596261655,\n",
       "    30.992028398333854,\n",
       "    32.43998601301661,\n",
       "    23.16934166314467,\n",
       "    20.209880954814405,\n",
       "    18.42970515197178,\n",
       "    15.16408453347548,\n",
       "    12.110745483974242,\n",
       "    11.154019607687896,\n",
       "    8.816357878019225,\n",
       "    8.088360336591613,\n",
       "    7.605782229945345,\n",
       "    6.611098887785426,\n",
       "    7.0998284501849485,\n",
       "    5.077216134881073]}},\n",
       " 'model_2': {'grid_obj': GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "         error_score='raise-deprecating',\n",
       "         estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f72dd404780>,\n",
       "         fit_params=None, iid='warn', n_jobs=1,\n",
       "         param_grid={'num_hidden_layers': [1], 'hidden_layer_size': [256], 'activation_function': ['sigmoid']},\n",
       "         pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "         scoring='neg_mean_squared_error', verbose=2),\n",
       "  'keras_model': <keras.engine.sequential.Sequential at 0x7f72de76bfd0>,\n",
       "  'preds': array([2.822726 , 2.756451 , 3.1844049, ..., 2.5395126, 2.971424 ,\n",
       "         2.65307  ], dtype=float32),\n",
       "  'history': {'val_loss': [0.24153771961436551,\n",
       "    0.21685920722344343,\n",
       "    0.20613488148240483,\n",
       "    0.19208089071161608,\n",
       "    0.19599169149118312,\n",
       "    0.19524966681704803,\n",
       "    0.18560055823887095,\n",
       "    0.18442011791117052,\n",
       "    0.18390431677593905,\n",
       "    0.18400116569855635,\n",
       "    0.18538954552482156,\n",
       "    0.17966471118085525,\n",
       "    0.17920012039296768,\n",
       "    0.1762636355792775,\n",
       "    0.17781259719063253,\n",
       "    0.17012580205412473,\n",
       "    0.17749319683103001,\n",
       "    0.1691621994972229,\n",
       "    0.1697840937796761,\n",
       "    0.1766839286509682,\n",
       "    0.16857126909143785,\n",
       "    0.17342157490113203,\n",
       "    0.16831416031893562,\n",
       "    0.16781509175020107,\n",
       "    0.16652604671085583,\n",
       "    0.17522632774184732,\n",
       "    0.18326117529588587,\n",
       "    0.17624954809160792,\n",
       "    0.1722000536848517,\n",
       "    0.17035973177236668,\n",
       "    0.1708028169589884,\n",
       "    0.17574370734831865,\n",
       "    0.16578077049816356,\n",
       "    0.17464180062798892,\n",
       "    0.17800643524702858,\n",
       "    0.16982149562414955,\n",
       "    0.17023259779986213,\n",
       "    0.17502937786719377,\n",
       "    0.17190743940718034,\n",
       "    0.1728477882637697],\n",
       "   'loss': [8.949938438973337,\n",
       "    0.9370363450275278,\n",
       "    0.9064612332380043,\n",
       "    0.8072737792752823,\n",
       "    0.7065810499326238,\n",
       "    0.7050242879480686,\n",
       "    0.6209388127866781,\n",
       "    0.568780134871321,\n",
       "    0.5413521536678638,\n",
       "    0.48270935045098357,\n",
       "    0.4355616142164986,\n",
       "    0.4187146577070344,\n",
       "    0.363601083463093,\n",
       "    0.32864813084872263,\n",
       "    0.3140328340935257,\n",
       "    0.26225795442203303,\n",
       "    0.26383628569683937,\n",
       "    0.24190523405120057,\n",
       "    0.2225719101305278,\n",
       "    0.20508256948219156,\n",
       "    0.20884729851529282,\n",
       "    0.17790493200410087,\n",
       "    0.17452134234162997,\n",
       "    0.1704852152264343,\n",
       "    0.1551837257619174,\n",
       "    0.16339565827599112,\n",
       "    0.15449043391448147,\n",
       "    0.154439962275748,\n",
       "    0.15211262694507274,\n",
       "    0.1291439135400754,\n",
       "    0.153638501352859,\n",
       "    0.13244959515220714,\n",
       "    0.13375193927929085,\n",
       "    0.14494017933337194,\n",
       "    0.1267395220556349,\n",
       "    0.1309969458939894,\n",
       "    0.12206200889821323,\n",
       "    0.12913901077688866,\n",
       "    0.1254284859828229,\n",
       "    0.11904134235854419]}},\n",
       " 'model_3': {'grid_obj': GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "         error_score='raise-deprecating',\n",
       "         estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f72df2cfe80>,\n",
       "         fit_params=None, iid='warn', n_jobs=1,\n",
       "         param_grid={'num_hidden_layers': [1], 'hidden_layer_size': [128], 'activation_function': ['linear']},\n",
       "         pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "         scoring='neg_mean_squared_error', verbose=2),\n",
       "  'keras_model': <keras.engine.sequential.Sequential at 0x7f72da3bae10>,\n",
       "  'preds': array([2.7101357, 2.833236 , 3.2349234, ..., 2.6172667, 3.055548 ,\n",
       "         2.5696254], dtype=float32),\n",
       "  'history': {'val_loss': [7.971021158554975,\n",
       "    1.7815887891545015,\n",
       "    1.4358472198598524,\n",
       "    1.0020627132584068,\n",
       "    0.8266256103796118,\n",
       "    1.3179182821161606,\n",
       "    0.6871488717023064,\n",
       "    0.9097109343023861,\n",
       "    0.880920706356273,\n",
       "    1.0739993925655589,\n",
       "    0.9999124824299532,\n",
       "    0.6783400659000173,\n",
       "    0.9110680545077604,\n",
       "    1.0300773157792933,\n",
       "    1.6490938342318815,\n",
       "    0.8820683153937845,\n",
       "    2.0447387106278363,\n",
       "    2.271143153415007,\n",
       "    0.7671438594425426,\n",
       "    1.4752497889013851,\n",
       "    1.9178473764307358,\n",
       "    0.9099478523871478,\n",
       "    1.6386071968078613,\n",
       "    0.9330630598348729,\n",
       "    0.6354667193749372,\n",
       "    0.8581557027031393,\n",
       "    0.7169110732218799,\n",
       "    0.5032390403572251,\n",
       "    0.7536007419053246,\n",
       "    0.8728534622753368,\n",
       "    0.3350844855168286,\n",
       "    0.47581762524212107,\n",
       "    0.2581088443363414,\n",
       "    0.3384806021522073,\n",
       "    0.3039394028046552,\n",
       "    0.31090786141507765,\n",
       "    0.5479398519151351,\n",
       "    0.33328805432600134,\n",
       "    0.26321899494704076,\n",
       "    0.3517695274072535,\n",
       "    0.31556810477200675,\n",
       "    0.33533120961750257,\n",
       "    0.27922155885135425,\n",
       "    0.2840046737123938,\n",
       "    0.25702437849605786,\n",
       "    0.3846123440125409,\n",
       "    0.2588606247130562,\n",
       "    0.29905189980478847,\n",
       "    0.4094728960710413,\n",
       "    0.22747438760364758,\n",
       "    0.26377036603058085,\n",
       "    0.22846327711554135,\n",
       "    0.33797817580840167,\n",
       "    0.2687483676742105,\n",
       "    0.32405660594210906,\n",
       "    0.2589431834220886,\n",
       "    0.22527594611925236,\n",
       "    0.21490314525716445,\n",
       "    0.5232292582708247,\n",
       "    0.32055168383261734,\n",
       "    0.28140753370874066,\n",
       "    0.1993552147290286,\n",
       "    0.22985630343942082,\n",
       "    0.2012238103501937,\n",
       "    0.251022750489852,\n",
       "    0.21660632172051597,\n",
       "    0.2379739709110821,\n",
       "    0.2256927206586389,\n",
       "    0.2076135852757622,\n",
       "    0.21915610067984637,\n",
       "    0.2668935997345868,\n",
       "    0.21814632889102487,\n",
       "    0.19530713996466467,\n",
       "    0.2019724157627891,\n",
       "    0.2465447196189095,\n",
       "    0.19794351900325102,\n",
       "    0.20026903422439798,\n",
       "    0.24154574516941518,\n",
       "    0.19073547321207382,\n",
       "    0.2137472305578344,\n",
       "    0.19447458109434912,\n",
       "    0.18911943596952102,\n",
       "    0.19824331318630892,\n",
       "    0.20705879260511958,\n",
       "    0.1959995339197271,\n",
       "    0.19049576110699598,\n",
       "    0.199294272591086,\n",
       "    0.19241014270221485,\n",
       "    0.19072439754710477,\n",
       "    0.20880285859107972,\n",
       "    0.18508608435883242,\n",
       "    0.2027213812575621,\n",
       "    0.1893743073239046,\n",
       "    0.18167859634932348,\n",
       "    0.18410817994790918,\n",
       "    0.19230530051624073,\n",
       "    0.2001558600804385,\n",
       "    0.1885282420060214,\n",
       "    0.1843243993029875,\n",
       "    0.18698842970763935,\n",
       "    0.21057525736444135,\n",
       "    0.19780669201822842,\n",
       "    0.19042755526654861,\n",
       "    0.19411845701582292,\n",
       "    0.18082832161118004,\n",
       "    0.18582583658835466,\n",
       "    0.1830633154336144,\n",
       "    0.18753715998986187,\n",
       "    0.18892284509013682],\n",
       "   'loss': [202.6048938823196,\n",
       "    10.194806503799727,\n",
       "    4.99807793689224,\n",
       "    4.054012136639289,\n",
       "    2.4408247054747814,\n",
       "    1.8910936567018617,\n",
       "    2.4774785176762997,\n",
       "    1.9405626947025083,\n",
       "    2.2547480655166336,\n",
       "    1.9022977520834725,\n",
       "    1.9271327425848763,\n",
       "    1.8980416599309669,\n",
       "    2.1057977811345516,\n",
       "    2.9283362132198407,\n",
       "    3.824959435552921,\n",
       "    3.580304260523814,\n",
       "    3.779695114999447,\n",
       "    3.2437019145713664,\n",
       "    3.333362882992007,\n",
       "    3.7235833563894594,\n",
       "    5.600533912766655,\n",
       "    4.958436684788398,\n",
       "    4.662476930978163,\n",
       "    4.026907122360085,\n",
       "    2.5105802720447756,\n",
       "    2.2165006376662344,\n",
       "    1.7706998575408504,\n",
       "    1.171987716881734,\n",
       "    1.0896815061569214,\n",
       "    1.1608191222514745,\n",
       "    0.9779481848455825,\n",
       "    0.8490120352439161,\n",
       "    0.7082917527207788,\n",
       "    0.6878336752360722,\n",
       "    0.7679849042082733,\n",
       "    0.5997898044451228,\n",
       "    0.6165997464701815,\n",
       "    0.5408505167601243,\n",
       "    0.5409780122199148,\n",
       "    0.5286548261372548,\n",
       "    1.3447413568226796,\n",
       "    0.6705177426338196,\n",
       "    0.6611635063616734,\n",
       "    0.4987016151536186,\n",
       "    0.38960658098166845,\n",
       "    0.3822359602968648,\n",
       "    0.4092893277136785,\n",
       "    0.3374678911465519,\n",
       "    0.29833617722088435,\n",
       "    0.31690978793040764,\n",
       "    0.3138103083057224,\n",
       "    0.30021598063549904,\n",
       "    0.38633187424461796,\n",
       "    0.27023755520019893,\n",
       "    0.23565816120156702,\n",
       "    0.26962932789663097,\n",
       "    0.2535667582502905,\n",
       "    0.23197918989748326,\n",
       "    0.40070264139827694,\n",
       "    0.31904385871482344,\n",
       "    0.22540582744580395,\n",
       "    0.21470273272046503,\n",
       "    0.18714346497688653,\n",
       "    0.1867231400507801,\n",
       "    0.20626040309105279,\n",
       "    0.17236462600950925,\n",
       "    0.1614266887026013,\n",
       "    0.15888708337860288,\n",
       "    0.16848697246245617,\n",
       "    0.16453096284618918,\n",
       "    0.16601782025031322,\n",
       "    0.19666916722396635,\n",
       "    0.18652140180457313,\n",
       "    0.14391835047951285,\n",
       "    0.1516849932805547,\n",
       "    0.13051792402874748,\n",
       "    0.14471601793226205,\n",
       "    0.1526684970507082,\n",
       "    0.13856504028135874,\n",
       "    0.16036295848635007,\n",
       "    0.1279832770661363,\n",
       "    0.11489940406578891,\n",
       "    0.10778237190449012,\n",
       "    0.09996848349582474,\n",
       "    0.09836244147341207,\n",
       "    0.10408734677816336,\n",
       "    0.09823461692288236,\n",
       "    0.10941449292706994,\n",
       "    0.10273182771678241,\n",
       "    0.09627158251011146,\n",
       "    0.10308760924721663,\n",
       "    0.09565971440301752,\n",
       "    0.09948828345480955,\n",
       "    0.09149950306932882,\n",
       "    0.09297372372645252,\n",
       "    0.1007796196302153,\n",
       "    0.09872582835971185,\n",
       "    0.0963823600619469,\n",
       "    0.0869286818746126,\n",
       "    0.08386934815712695,\n",
       "    0.08587169141139624,\n",
       "    0.09442519473860848,\n",
       "    0.09231624822571592,\n",
       "    0.08501950458113877,\n",
       "    0.08027748426176468,\n",
       "    0.08539842701745483,\n",
       "    0.08274911674407293,\n",
       "    0.08790503090844964,\n",
       "    0.08124226872932236]}},\n",
       " 'model_4': {'grid_obj': GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "         error_score='raise-deprecating',\n",
       "         estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f72de7671d0>,\n",
       "         fit_params=None, iid='warn', n_jobs=1,\n",
       "         param_grid={'num_hidden_layers': [1], 'hidden_layer_size': [64], 'activation_function': ['relu']},\n",
       "         pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "         scoring='neg_mean_squared_error', verbose=2),\n",
       "  'keras_model': <keras.engine.sequential.Sequential at 0x7f72db142be0>,\n",
       "  'preds': array([2.7830665, 2.7830665, 2.7830665, ..., 2.7830665, 2.7830665,\n",
       "         2.7830665], dtype=float32),\n",
       "  'history': {'val_loss': [7.883874834846048,\n",
       "    7.656385803222657,\n",
       "    7.4145777332081515,\n",
       "    7.168315288319307,\n",
       "    6.9235154825098375,\n",
       "    6.681406245512121,\n",
       "    6.4429708469615266,\n",
       "    6.209792826035444,\n",
       "    5.981587238311768,\n",
       "    5.758514862060547,\n",
       "    5.541061610053568,\n",
       "    5.329305424409754,\n",
       "    5.123027706146241,\n",
       "    4.922693627301385,\n",
       "    4.728193485035616,\n",
       "    4.538706856895896,\n",
       "    4.35504882924697,\n",
       "    4.176961674409754,\n",
       "    4.004029469209559,\n",
       "    3.8365982874702005,\n",
       "    3.674823103512035,\n",
       "    3.5176987131904154,\n",
       "    3.3659406510521386,\n",
       "    3.2184786179486444,\n",
       "    3.076824868707096,\n",
       "    2.9398571940029368,\n",
       "    2.807809374192182,\n",
       "    2.6796349508622113,\n",
       "    2.5564849657170914,\n",
       "    2.4378669211443733,\n",
       "    2.3229367076649385,\n",
       "    2.21289729903726,\n",
       "    2.106669470843147,\n",
       "    2.0050528043859144,\n",
       "    1.9070327590493594,\n",
       "    1.81273408945869,\n",
       "    1.722747169943417,\n",
       "    1.6361879129970776,\n",
       "    1.5534895450928632,\n",
       "    1.4739404218337115,\n",
       "    1.3978830057031968,\n",
       "    1.3256494502460254,\n",
       "    1.2563080650217393,\n",
       "    1.1904518705255844,\n",
       "    1.1275352803398582,\n",
       "    1.0676008908888872,\n",
       "    1.0105959637024824,\n",
       "    0.9564808710883645,\n",
       "    0.904816406474394,\n",
       "    0.8566279071920059,\n",
       "    0.8103046683704151,\n",
       "    0.7667656904108384,\n",
       "    0.7255403064278996,\n",
       "    0.6869670890359317,\n",
       "    0.6504719223695643,\n",
       "    0.6161808716549593,\n",
       "    0.5842272525675156,\n",
       "    0.5535645815905402,\n",
       "    0.5253968428162967,\n",
       "    0.49878373482648064,\n",
       "    0.47422793865203855,\n",
       "    0.4512311698408688,\n",
       "    0.4298766977646772,\n",
       "    0.41005276679992675,\n",
       "    0.39193564092411715,\n",
       "    0.3748545397029204,\n",
       "    0.35934516668319705,\n",
       "    0.34475429016001086,\n",
       "    0.3317529608922846,\n",
       "    0.31978145718574524,\n",
       "    0.3087228946124806,\n",
       "    0.2984793357989367,\n",
       "    0.2897544354550979,\n",
       "    0.28140316016533795,\n",
       "    0.2739108583506416,\n",
       "    0.2672546655290267,\n",
       "    0.26114263730890613,\n",
       "    0.2557300003837137,\n",
       "    0.250877267332638,\n",
       "    0.24676749741329868,\n",
       "    0.24302487155970406,\n",
       "    0.23960816362324883,\n",
       "    0.23669686927514919,\n",
       "    0.23396266684812658,\n",
       "    0.23175245768883648,\n",
       "    0.22983675297568826,\n",
       "    0.2281224347563351,\n",
       "    0.22664407400523914,\n",
       "    0.22538841731408063,\n",
       "    0.22425740950247822,\n",
       "    0.22339517193682054,\n",
       "    0.22261276041760164,\n",
       "    0.22186729494263144,\n",
       "    0.22134032663177042,\n",
       "    0.22084714139209075,\n",
       "    0.22050960982547088,\n",
       "    0.22016344063422258,\n",
       "    0.21989809456993553,\n",
       "    0.21967018772574032,\n",
       "    0.21949473352993235,\n",
       "    0.21933234930038453,\n",
       "    0.21915612024419448,\n",
       "    0.21908870556775262,\n",
       "    0.21897759640918057,\n",
       "    0.21893716952380013,\n",
       "    0.21889861829140608,\n",
       "    0.2188531848963569,\n",
       "    0.2188187069051406,\n",
       "    0.21876737622653736,\n",
       "    0.21876321357839248,\n",
       "    0.218720843371223,\n",
       "    0.21870988488197327,\n",
       "    0.2186983151295606,\n",
       "    0.2186786516273723,\n",
       "    0.21867434284266304,\n",
       "    0.21867445132311653,\n",
       "    0.2186643861321842],\n",
       "   'loss': [15.40125691215947,\n",
       "    7.74276778383075,\n",
       "    7.507084063763888,\n",
       "    7.263468787355243,\n",
       "    7.01839893269089,\n",
       "    6.775270372066858,\n",
       "    6.535628687660649,\n",
       "    6.300270710351332,\n",
       "    6.069923175955719,\n",
       "    5.844862065225278,\n",
       "    5.6252483062024385,\n",
       "    5.411227559143642,\n",
       "    5.202897530681682,\n",
       "    5.0001569154127585,\n",
       "    4.803049618343137,\n",
       "    4.611701218587048,\n",
       "    4.425808195797902,\n",
       "    4.245478904472207,\n",
       "    4.070650847452991,\n",
       "    3.90113413558816,\n",
       "    3.7368459296676346,\n",
       "    3.577940396542819,\n",
       "    3.4239953868793993,\n",
       "    3.2753132964080236,\n",
       "    3.1312752264850543,\n",
       "    2.992281099535384,\n",
       "    2.857932684556493,\n",
       "    2.7284523586057268,\n",
       "    2.6033364511885733,\n",
       "    2.4827753552850687,\n",
       "    2.366769219344517,\n",
       "    2.2548358215475983,\n",
       "    2.1473055515649184,\n",
       "    2.043721907543686,\n",
       "    1.9443342820653375,\n",
       "    1.8488570339274857,\n",
       "    1.7570961151482924,\n",
       "    1.6692436213763255,\n",
       "    1.584960233490422,\n",
       "    1.5043856310394574,\n",
       "    1.4272382630492157,\n",
       "    1.3534163214125723,\n",
       "    1.2830669216389925,\n",
       "    1.2158273323526922,\n",
       "    1.1517946067846045,\n",
       "    1.0908058814282686,\n",
       "    1.0327811364857655,\n",
       "    0.9776421987785483,\n",
       "    0.9253880539030399,\n",
       "    0.8756223815792011,\n",
       "    0.8287643503467992,\n",
       "    0.784269058479453,\n",
       "    0.7423426047810968,\n",
       "    0.702697071826683,\n",
       "    0.6654257408852847,\n",
       "    0.6303255962875655,\n",
       "    0.5973189596859914,\n",
       "    0.5665442336280391,\n",
       "    0.5375230469793644,\n",
       "    0.5105388192635663,\n",
       "    0.48525731406121886,\n",
       "    0.4617746427374066,\n",
       "    0.439925028749232,\n",
       "    0.4196644608142241,\n",
       "    0.40085128540138026,\n",
       "    0.3835741371478675,\n",
       "    0.3675503978189432,\n",
       "    0.3529088134473225,\n",
       "    0.33934693741348554,\n",
       "    0.3270046921833506,\n",
       "    0.31574483047116475,\n",
       "    0.3055133639641528,\n",
       "    0.29607650862549834,\n",
       "    0.2877100180342512,\n",
       "    0.2800604535161324,\n",
       "    0.27317137116531154,\n",
       "    0.26701873597109094,\n",
       "    0.2615103744110971,\n",
       "    0.2566154287108835,\n",
       "    0.25221206500845134,\n",
       "    0.24836055597044387,\n",
       "    0.2449634070947485,\n",
       "    0.2419466033296765,\n",
       "    0.23936522934796675,\n",
       "    0.23704612451904225,\n",
       "    0.2350568616727613,\n",
       "    0.2333575221446325,\n",
       "    0.23187630637636725,\n",
       "    0.23060331788827787,\n",
       "    0.2295311284515093,\n",
       "    0.22859781024590978,\n",
       "    0.2278326285897561,\n",
       "    0.2272011477429912,\n",
       "    0.22664034450953863,\n",
       "    0.22620325647997405,\n",
       "    0.22582299754304705,\n",
       "    0.22552790478715357,\n",
       "    0.22527364079120024,\n",
       "    0.22507427871789573,\n",
       "    0.2249133473016181,\n",
       "    0.22477177389950123,\n",
       "    0.22469333488986176,\n",
       "    0.2245871105565215,\n",
       "    0.22454243926507123,\n",
       "    0.2244786320711082,\n",
       "    0.22443787135043233,\n",
       "    0.22441971948686637,\n",
       "    0.224402979578612,\n",
       "    0.22436063849138763,\n",
       "    0.2243730178419149,\n",
       "    0.22433389189108363,\n",
       "    0.22434253287765216,\n",
       "    0.22433044972284785,\n",
       "    0.22433058495791453,\n",
       "    0.22433035356818504,\n",
       "    0.2243272087202882,\n",
       "    0.2243244321841114]}},\n",
       " 'model_5': {'grid_obj': GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "         error_score='raise-deprecating',\n",
       "         estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f72dc96bd68>,\n",
       "         fit_params=None, iid='warn', n_jobs=1,\n",
       "         param_grid={'num_hidden_layers': [2], 'hidden_layer_size': [64], 'activation_function': ['linear']},\n",
       "         pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "         scoring='neg_mean_squared_error', verbose=2),\n",
       "  'keras_model': <keras.engine.sequential.Sequential at 0x7f7232e78b38>,\n",
       "  'preds': array([2.5347898, 2.8095002, 3.0103142, ..., 2.4485219, 2.5200558,\n",
       "         2.4369326], dtype=float32),\n",
       "  'history': {'val_loss': [1.9475802724501665,\n",
       "    0.6425250760246726,\n",
       "    0.4787398844606736,\n",
       "    1.3585280418395995,\n",
       "    0.481785441496793,\n",
       "    0.4843957835085252,\n",
       "    0.3420885676496169,\n",
       "    0.5815859135459451,\n",
       "    0.5043183649287505,\n",
       "    0.333894339168773,\n",
       "    0.8688400290994083,\n",
       "    0.3112013715154984,\n",
       "    1.2618962624493768,\n",
       "    0.21851399484802694,\n",
       "    0.9414297799503102,\n",
       "    0.2801755330141853,\n",
       "    0.35066809738383575,\n",
       "    0.3264530879609725,\n",
       "    0.4761006550227895,\n",
       "    0.23086992011350743,\n",
       "    0.534827155786402,\n",
       "    0.2777109924484702,\n",
       "    0.2179443665111766,\n",
       "    0.20853120649562162,\n",
       "    0.3947090441339156,\n",
       "    0.2602548545248368,\n",
       "    0.3315304709182066,\n",
       "    0.2558375864169177,\n",
       "    0.23588455652489382,\n",
       "    0.2707177543640137,\n",
       "    0.21612249027280248,\n",
       "    0.38176972122753366,\n",
       "    0.2956588125930113,\n",
       "    0.24262065922512727,\n",
       "    0.32540019575287316,\n",
       "    0.23326027645784267,\n",
       "    0.2523809608291177,\n",
       "    0.20804255345288444,\n",
       "    0.2160988997711855],\n",
       "   'loss': [79.26197242736816,\n",
       "    11.350420331055263,\n",
       "    9.427727087488714,\n",
       "    13.478169702134043,\n",
       "    13.067190656122172,\n",
       "    15.698444186516529,\n",
       "    13.652061210488373,\n",
       "    11.148021329124019,\n",
       "    10.992090657072247,\n",
       "    11.21100154013004,\n",
       "    9.534581256362626,\n",
       "    8.117430758926103,\n",
       "    6.677693524450626,\n",
       "    5.747454895163482,\n",
       "    5.475659752791783,\n",
       "    5.124321330268428,\n",
       "    4.17945108323727,\n",
       "    4.023772334152797,\n",
       "    3.4586782972767667,\n",
       "    3.8105949973160365,\n",
       "    3.66307639400914,\n",
       "    2.6294236498058967,\n",
       "    2.7036636213086687,\n",
       "    2.279150202589215,\n",
       "    1.9381251706267304,\n",
       "    1.8853457603814467,\n",
       "    1.859549247993613,\n",
       "    1.6635099728152436,\n",
       "    1.5739612545607224,\n",
       "    1.4005378012387257,\n",
       "    1.5447480419896684,\n",
       "    1.1506506305820536,\n",
       "    1.126955364110335,\n",
       "    1.0024014756364643,\n",
       "    1.1449749323557008,\n",
       "    0.9658792963567769,\n",
       "    0.8877754796226069,\n",
       "    0.9388867172430146,\n",
       "    0.8358480924705289]}}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {k:v['history'] for k,v in model_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(histories, open('../output/model_histories.p','wb')) # Storing for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess how the different models performed we can plot their performance on the training and test set at each epoch in the learning process. Since the first couple of epochs generally have a very high loss (thus increasing the size of the y-axis and obscuring the future epochs) I present the learn from the results from the second epoch onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [3], 'hidden_layer_size': [256], 'activation_function': ['linear']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd8VfX9+PHXO3snZEEGIRA2CAEjIuIEtxXa2lonjkK1Q1vtoP32+63W9qcdttbaunFUC1p33TgAEVlCkC07g0AWIYvsz++PcwKXkEVyb869ue/n43Ef95xzz3jf9Xmfz+eMjxhjUEop5b8CnA5AKaWUszQRKKWUn9NEoJRSfk4TgVJK+TlNBEop5ec0ESillJ/TRKD8lojcLSLPOx1HfyYim0XkXHfPq9xLE4EPEpG9ItIgIoltpueKiBGRTGciU/2FiGTav6Wg3qzHGDPOGLPE3fMq99JE4Lv2AFe3jojIKUC4c+E4q7cFlru33ZN4RCTQPRGd9HZ79Nk5+Zkr99JE4Lv+BdzgMj4HeM51BhEJFZE/i0ieiBwUkUdFJNx+bYCIvCUiJSJyyB5Od1l2iYjcKyKfiUiViHzQtgbiMm+ivXyFiJSLyKciEmC/NklE1tnreFFEFonI7+zXbhSR5W3WZURkuD18mYisF5FKEckXkbtd5mvdY71FRPKAj+3pU0VkhR3LBtemBhEZKiJL7VgWA+2+H5f5L7drWRX2Oie4vLZXRH4hIl8CNSIS1MG0MfZnWWE3fVzhso5nROQREXlHRGqA89qJIVVE3rQ/150iMtdl+hERiXeZd5KIlIpIsD1+s4hstb/f90VkSJvP+QcisgPY0c7bX2Y/V4hItYicYX9fn4nIX0WkHLhbRLJE5GMRKbO3/YKIxLX5nGbaw3eLyEsi8pz9HWwWkZwezjvZ/m1Uich/7N/W7zr7PlUnjDH68LEHsBeYCWwHxgCBQD4wBDBApj3fg8CbQDwQDfwXuM9+LQH4JhBhv/Yf4HWXbSwBdgEjsWoaS4D7O4jnPuBRINh+nAUIEALsA35iT78SaAR+Zy93I7C8zboMMNwePhc4BWuHZQJwEJhtv5Zpz/scEGnHmAaUAZfay1xgjyfZy3wO/AUIBc4GqoDnO3hPk4Fi4HT7851jf+6hLt9BLjAYCG9vmv2edwK/sj+L8+1tjrLnfwY4DJxpxxvWThxLgX8CYUA2UALMsF/7GJjrMu+fgEft4dn2tscAQcCvgRVtPufF9m8jvJ3ttn6+QS7TbgSagB/Z6wwHhtufcyiQhJVAHmz7W7WH7wbq7O8nEOt3s/Jk5+XY7+oO+zP+BtCA/bvSRw/KFKcD0EcPvrRjieDX9h/kYvtPHWT/eTOxCuIaIMtluTOAPR2sMxs45DK+BPi1y/j3gfc6WPa3wBvYBbjL9LOB/YC4TFtBNxNBO9t5EPirPdxaUA1zef0XwL/aLPM+ViGeYRdikS6v/ZuOE8EjwL1tpm0HznH5Dm5u53u52WX8LOAAEOAybSFwtz38DPBcJ9/zYKAZiHaZdh/wjD38XeBje1iwdgbOtsffBW5xWS4AqAWGuHzO53ey7dbPt20iyOvitzkbWN/2t2oP3w186PLaWODIyc5r/64K2/yulqOJoMcPbRrybf8CrsH6gz7X5rUkrL39L+xmiQrgPXs6IhIhIo+JyD4RqcTak4uT49upD7gM1wJRHcTxJ6y9zw9EZLeIzLenpwKFxv6n2vZ1982JyOki8olYzVeHgVs5sTkn32V4CPCt1vdrv+fpQIodyyFjTE03YxkC3NVmXYPt9bS37fampQL5xpiWNttM62IdrsuXG2OqOlj+ZeAMEUnFKhwN8KlL/H9zib0cK1l0d9sdOW4ZEUm2m/sK7d/R83Te5Nb2NxUmHR9r6Gje9n5XPXkvyqaJwIcZY/ZhHTS+FHi1zculwBFgnDEmzn7EGmNaC/O7gFHA6caYGKyCBKzC4mTjqDLG3GWMGQZ8DbhTRGYARUCaiLiuM8NluAYrWVkbFhnUZtX/xmraGmyMicVqfmobX9vC4F8u7zfOGBNpjLnfjmWAiER2EEtb+cDv26wrwhizsINttzdtPzBY7OMlLtss7GIdrsvHi0h0e8sbYyqAD4BvY+0QLHQpHPOB77WJP9wYs6Kb2+7otbbT77OnTbB/R9fRg9/QSWrvdzXYw9vs1zQR+L5bsKr4rnu62HuhTwB/FZFkABFJE5GL7FmisRJFhX3A8Tc9DcA+qDrc/mNWYjVnNGO1yTcBt9sHTr8BTHFZdAMwTkSyRSQMqznAVTTWHnGdiEzBKuw68zzwNRG5SEQCRSRMRM4VkXQ7aa4F7hGREBGZjpW0OvIEcKtdKxERiRTr4HV0J8u0tQor2f1cRILFOnD9NWBRdxY2xuRjNaXdZ7+XCVjf9wsus/0b66SBb9rDrR4Ffiki4wBEJFZEvnUSsZcALcCwLuaLBqqxfkdpwM9OYhs99TnW7+uH9u9qFsf/rtRJ0kTg44wxu4wxazt4+RdYTTYr7Wr7h1i1ALDa28Oxag4rsZqNemqEve5qrD/pP40xS4wxDVgH8m4EDgFX4VJzMcZ8hXV84UOsM1eWH79avg/8VkSqgP8DXuosCLvgnIV1cLYEa6/4Zxz7nV+DdfC3HCvxtW1Oc13XWmAu8LAd+077fXSb/f6vAC7B+pz/CdxgjNl2Equ5Gqu9fj/wGvAbY8xil9ffxPr8DxpjNrhs+zXgD8Ai+7vfZMfR3dhrgd8Dn9nNS1M7mPUerAPrh4G3ObFm6nYuv6tbgAqsWshbQL2nt91fyfHNbEp5log8AxQYY37tdCyq/xCRVVhnTD3tdCy+SGsESimfIyLniMggu2loDtbpxb2p1fo1vTJQKeWLRmE1FUZhXe9ypTGmyNmQfJc2DSmllJ/TpiGllPJzPtE0lJiYaDIzM50OQymlfMoXX3xRaoxJ6mo+n0gEmZmZrF3b0RmSSiml2iMi3bqSX5uGlFLKz2kiUEopP6eJQCml/JxPHCNoT2NjIwUFBdTV1TkdSp8ICwsjPT2d4OBgp0NRSvUzPpsICgoKiI6OJjMzk+NvQtj/GGMoKyujoKCAoUOHOh2OUqqf8dmmobq6OhISEvp9EgAQERISEvym9qOU6ls+mwgAv0gCrfzpvSql+pZPJwJ1vMbmFt7dWMTK3WVOh6KU8iE+e4zAaWVlZcyYMQOAAwcOEBgYSFKSdQHf6tWrCQkJ6XIdN910E/Pnz2fUqFFdztuZw7WNLFyTx7Mr9lJ0uI7EqBBW/nIGQYGa55VSXdNE0EMJCQnk5uYCcPfddxMVFcVPf/rT4+Y52jF0QPsF8tNP9+7W6btKqnn6sz288kUhRxqbmZaVwKzsNB5duovlO0s5d1Ryr9avlPIPusvoZjt37mT8+PHceuutTJ48maKiIubNm0dOTg7jxo3jt7/97dF5p0+fTm5uLk1NTcTFxTF//nwmTpzIGWecQXFxcbvrN8awfEcpNz29mhkPLOWltQV8bWIK795xFv+eO5WfXDCC2PBg3sjd31dvWSnl4/pFjeCe/25my/5Kt65zbGoMv/nauB4tu2XLFp5++mkeffRRAO6//37i4+NpamrivPPO48orr2Ts2LHHLXP48GHOOecc7r//fu68804WLFjA/Pnzj77e0mKoqW/iogeX8dXBahKjQvnJzJFcOzWDxKjQo/OFBgVy6SkpvJFbSG1DExEh/eIrVkp5kNYIPCArK4vTTjvt6PjChQuZPHkykydPZuvWrWzZsuWEZcLDw7nkEqtL2VNPPZW9e/cC1gHgA4fr2HagikO1jQQGBPDnb03ks/nnccfMEcclgVazs1OpbWhm8ZaDnnmDSql+pV/sLvZ0z91TIiMjjw7v2LGDv/3tb6xevZq4uDiuu+66dq8HcD24HBgYSF1DA/nltVQcacQYQ0xYMElRIbxz+6QuTyU9LTOe1NgwXl9fyKzsNPe9MaVUv6Q1Ag+rrKwkOjqamJgYioqKeP/99zuc1xjD4SONHKyso/JIE4ePNJIQGcKoQdFkJkYSGhzYresJAgKEK7LTWLajlLLqene+HaVUP6SJwMMmT57M2LFjGT9+PHPnzuXMM888YZ7mlhYMsP1gFfvKamhqbiEiJJAxKdGkxoUTGhR40tudPSmV5hbD2xu1G1elVOd8os/inJwc07Zjmq1btzJmzBiHInIPYwwHq+opq6qn2RgiQ4JIjA4hJiy43T3/k33PFz+4jIiQQF79/onJRynV/4nIF8aYnK7m0xqBg2oamimurCMyNIjhyVFkJUcRGx7itttJzMpOY11eBXlltW5Zn1Kqf9JE4KCSqnqCAgLIiI/wyGmeV2SnAvBGbqHb162U6j80ETjkSGMzVXWNJESFEBDgmRvKpcWFM2VoPK/nFuILTYBKKWd4LBGISJiIrBaRDSKyWUTusacPFZFVIrJDRF4Uka5vytMPlVbVEyBCQqRn3/7s7DR2ldSw2c0X3Cml+g9P1gjqgfONMROBbOBiEZkK/AH4qzFmBHAIuMWDMXilhqZmKmobiY8M8fiN4S49ZRDBgcLr67V5SCnVPo+VQsZSbY8G2w8DnA+8bE9/FpjtqRi8VWl1A0C7VwW7W1xECOeOSubNDftpbtHmIaXUiTy6OyoigSKSCxQDi4FdQIUxpsmepQBo99JXEZknImtFZG1JSYknw+yRsrIysrOzyc7OZtCgQaSlpR0db2ho6HC5puYWymsaiIsIJiQogAULFnDgwAGPxjo7O43iqnrtp0Ap1S6PJgJjTLMxJhtIB6YA7Z0E3+5uqjHmcWNMjjEmp/U+/96k9TbUubm53HrrrfzkJz85Ot5ZXwRlNQ20GENStFUb6ItEMGNMMtGhQdo8pJRqV5+cNWSMqQCWAFOBOBFpPVcyHeh390t+9tlnmTJlCtnZ2Xz/+9+npaWFpqYmrrvues46/VS+dcE0Hn/kH7z44ovk5uZy1VVXdVmT6I2w4EAuHj+IdzcdoK6x2SPbUEr5Lo/ddE5EkoBGY0yFiIQDM7EOFH8CXAksAuYAb/R6Y+/OhwMbe72a4ww6BS65/6QX27RpE6+99horVqwgKCiIefPmsWjRIrKysigqLublxZ+RlRRF45Fq4uLi+Pvf/87DDz9Mdna2e+NvY/akNP7zRQEfbS3msgkpHt2WUsq3eLJGkAJ8IiJfAmuAxcaYt4BfAHeKyE4gAXjKgzH0uQ8//JA1a9aQk5NDdnY2S5cuZdeuXWRlZfHV9u08cM+vWL7kI2JjY/s0rqnDEkiODuV1vbhMKdWGx2oExpgvgUntTN+NdbzAfXqw5+4pxhhuvvlm7r333uOmV9Q28J8PlrN97ac89NBDvPLKKzz++ON9FldggHDFxFSe/XwvFbUNxEX45eUbSql26JXFbjZz5kxeeuklSktLAevson379rFtTyHBgQHccM13uOeee1i3bh0A0dHRVFVV9Ulssyel0dhseGejZw9OK6V8S7/omMabnHLKKfzmN79h5syZtLS0EBwczAN/e5iDVQ38fv4dBAiICH/4wx8AuOmmm/jud79LeHg4q1ev7vSMo94alxpDVlIkr+cWcs3pGR7bjlLKt+htqPvArpJqGppaGDUomoBe3FnUHe/57x/t4IHFX/HZ/PNJiwvv1bqUUt5Nb0PtJWobmqipbyIxKrRXScBdWruufDO33521q5TqIU0EHlZSVU9ggBDv4ZvLdVdGQgSTM+L01tRKqaN8OhF4e7NWfWPz0X6HA3t5q2l3vtfZk9LYdqCKbQf0jqRKKR9OBGFhYZSVlXl1MiiprkdESOjlzeWMMZSVlREWFuaWuC47JYXAAOH19do8pJTy4bOG0tPTKSgowBtvSAfQ3GI4UFlHZEggOyt73ywUFhZGenq6GyKDhKhQzh6RyJu5hfz8olEe6xhHKeUbfDYRBAcHM3ToUKfD6ND9727j8WVFfPLTcxmSEOl0OCeYPSmNOxblsnpvOVOHJTgdjlLKQT7bNOTNKusaeWHlPi45JcUrkwDABWMHEhESqAeNlVKaCDzh36vyqKpv4rZzspwOpUMRIUFcNG4Qb39ZRH2T3pFUKX+micDN6puaWbB8D9OHJzI+rW9vLHeyZmWnUlnXxJLt3nmcRSnVNzQRuNlr6woprqrnVi+uDbSaPjyRxKgQbR5Sys9pInCj5hbD48t2My41hjOHe/8B2KDAAC6fkMqHW4uprGt0OhyllEM0EbjR4i0H2F1aw63nZCFecDuJ7piVnUpDUwvvbdI7kirlrzQRuIkxhkeW7iYjPoJLxg9yOpxuyx4cx5CECG0eUsqPaSJwk5W7y9mQX8Hcs4cRFOg7H6uIMCs7jRW7yjhYWed0OEopB/hOieXlHlu2i8SoEL51qnuu/u1Ls7NTMQb+u0FvOaGUP9JE4AZbiypZsr2EG6dlEhYc6HQ4J21YUhQT0mO1P2Ol/JQmAjd4bOkuIkMCuX5qptOh9Nis7DQ2FVays7ja6VCUUn1ME0Ev5ZfX8t8vi7h6SgaxEcFOh9NjX5uYQoCgB42V8kOaCHrpqeV7CBC45SzvvQFedyRHh3Hm8ERezy306lt7K6Xcz2OJQEQGi8gnIrJVRDaLyB329LtFpFBEcu3HpZ6KwdPKaxpYtCaPWdlppMT6fv+/s7PTyC8/wrq8Q06HopTqQ56sETQBdxljxgBTgR+IyFj7tb8aY7LtxzsejMGjnl2xl7rGFm49Z5jTobjFReMHERYcoB3WKOVnPJYIjDFFxph19nAVsBVI89T2+lptQxPPfr6XmWMGMjw52ulw3CIqNIiZYwby9sYiGptbnA5HKdVH+uQYgYhkApOAVfakH4rIlyKyQEQGdLDMPBFZKyJrvbEXshfX5FNR29hvagOtZmenUV7TwKc7vO8zV0p5hscTgYhEAa8APzbGVAKPAFlANlAEPNDecsaYx40xOcaYnKSkJE+HeVIam1t48tM95AwZQE5mvNPhuNXZI5OIiwjW5iGl/IhHE4GIBGMlgReMMa8CGGMOGmOajTEtwBPAFE/G4AlvfbmfwoojPnGr6ZMVEhTAZaeksHjLQWrqm5wORynVBzx51pAATwFbjTF/cZme4jLb14FNnorBE4wxPLZ0NyOSozh/dLLT4XjE7ElpHGls5oMtekdSpfyBJ2sEZwLXA+e3OVX0jyKyUUS+BM4DfuLBGNxuyVclbDtQxffOySIgwDduNX2yTs0YQFpcuDYPKeUngjy1YmPMcqC9ktJnTxcFeHTJLlJiw7hiYqrToXhMQIAwKzuVx5btprS6nsSoUKdDUkp5kMcSgS9raTEUVdaxr6yGvLJa8spr2VdeS15ZLRsLD/Pry8YQEtS/L8qePSmNfy7ZxVsb9nPjmb591bRSqnN+mwjqGpvJL69lX5lVyFvDNewrr6Wg/AgNLufRBwUIaQPCyYiP4LZzs7hu6hAHI+8bIwdGMyYlhtdzNREo1d/160RwuLaRPWU17e7ZH2jTCUtkSCAZCZGMTI7mgjEDyUiIYEh8JEMSIkiJDfOpzmbcZXZ2Kve9u429pTVkJkY6HY5SykP6dSK4792tLFqTf3Q8OTqUjPgIpg1POFrIWwV+BPGRIT7Tz3BfuSI7lfvf28bruYX8eOZIp8NRSnlIv04EV0/J4PzRyQxJiGRwfDgRIf367bpdSmw4pw+N543c/fzo/BEE9tOzpJTyd/26vWPi4DguHDeIUYOiNQn00DWnD2FPaQ0/eGEddY3NToejlPKAfp0IVO9dMTGV/7t8LO9vOcANC1ZzuLbR6ZCUUm6miUB16ebpQ3noO5PIzavgW4+toOjwEadDUkq5kSYC1S1fm5jKMzedxv6KOr7xzxV8dbDK6ZCUUm6iiUB127Thibz0vTNobjFc+cgK1uwtdzokpZQbaCJQJ2Vsagyv3DaNxOhQrntyFe9v1hvTKeXrNBGokzY4PoKXb53GmJQYbnv+C55fuc/pkJRSvaCJQPVIfGQI/557OueOSubXr2/iLx9sxxjjdFhKqR7QRKB6LCIkiMevP5Vv56Tz0Mc7mf/KRpq0r2OlfI5eZaV6JSgwgD98cwKDYsJ46OOdlFbX8/A1kwkPCXQ6NKVUN2mNQPWaiHDnhaO4d/Z4Pt5ezDVPrqS8psHpsJRS3aSJQLnN9VOH8Mi1k9m8v5IrH11Bfnmt0yEppbpBE4Fyq4vHp/D8LadTWlXPNx9ZwZb9lU6HpJTqgiYC5XZThsbz8m3TCAwQrnrsc1bsKnU6JKVUJzQRKI8YOTCaV26bxqDYMG5csIa3vtzvdEhKqQ5oIlAekxoXzsu3TiN7cBw/WrieBcv3OB2SUqodmgiUR8VGBPPcLVO4cOxAfvvWFu57dystLXrhmVLexGOJQEQGi8gnIrJVRDaLyB329HgRWSwiO+znAZ6KQXmHsOBA/nntqVw3NYPHlu7mrv9soL5JO7lRylt4skbQBNxljBkDTAV+ICJjgfnAR8aYEcBH9rjq5wIDhHtnjeenF47ktfWFnP/npby2vkBrB0p5AY8lAmNMkTFmnT1cBWwF0oBZwLP2bM8Csz0Vg/IuIsIPzx/B87ecTlxEMD95cQOX/X05S7YX632KlHKQ9MUfUEQygWXAeCDPGBPn8tohY8wJzUMiMg+YB5CRkXHqvn16h8v+pKXF8NbGIv78/nbyyms5Y1gC8y8ZzcTBcV0vrJTqFhH5whiT0+V8nk4EIhIFLAV+b4x5VUQqupMIXOXk5Ji1a9d6NE7ljIamFv69ah8PfbyT8poGLpuQws8uHEVmYqTToSnl87qbCDx61pCIBAOvAC8YY161Jx8UkRT79RSg2JMxKO8WEhTAjWcOZenPzuX2GSP4ZFsxM/+ylP99fRMlVfVOh6eUX/DkWUMCPAVsNcb8xeWlN4E59vAc4A1PxaB8R3RYMHdeMJIlPzuXq6dksHB1Huf86RP+svgrquubnA5PqX7NY01DIjId+BTYCLTepP5XwCrgJSADyAO+ZYzptPNbbRryP3tKa/jz+9t5e2MRCZEh3D5jBFdPySAkSC99Uaq7vOYYgTtoIvBfufkV3P/uVlbuLicjPoKfXjSKy09JISBAnA5NKa/nFccIlOqt7MFxLJw7lWduOo2IkEBuX7ieWf/4jM926o3slHIXTQTK64kI545K5p3bz+Iv355IeU0D1z65iuufWsWmwsNOh6eUz9NEoHxGQIDwjcnpfHTXOfz6sjFsLDzM5X9fzh2L1lNYccTp8JTyWZoIlM8JCw7ku2cNY9nPz+MH52Xx/uYDfP0fn7GrpNrp0JTySZoIlM+KCQvmZxeN5s0fTqfFGL7z+Ep2Flc5HZZSPkcTgfJ5IwdGs3DuVIyB7zy+ih0HNRkodTI0Eah+YcTAaBbNm4oIXP3ESrYf0GSgVHdpIlD9xvDkKBbNm0qACNc8sZJtByqdDkkpn9BpIhCR61yGz2zz2g89FZRSPZWVFMWL3zuD4MAArnliFVv2azJQqitd1QjudBn+e5vXbnZzLEq5xdDESBbNm0poUADXPLmSzfv1WgOlOtNVIpAOhtsbV8prZNrJICI4kGue0AvPlOpMV4nAdDDc3rhSXmVIQiQvfu8MokKDuOaJlWws0GSgVHu6SgSjReRLEdnoMtw6PqoP4lOqVwbHR7Bo3lRiwoO59smVbMivcDokpbxOp3cfFZEhnS1sjOmT/iP17qOqtwoO1XL1EyupqG3kuZunMCmj007xlOoX3HL3UWPMPtcHUA1MBhL7Kgko5Q7pAyJYNO8MBkSEcMNTq1mXd8jpkJTyGl2dPvqWiIy3h1OATVhnC/1LRH7cB/Ep5TZpceG8+L2pJERZyeCLfZ32h6SU3+jqGMFQY8wme/gmYLEx5mvA6ejpo8oHpcSGs2jeGSRFh3LDU6tZu1eTgVJdJYJGl+EZwDsAxpgqjnU/qZRPGRQbxqJ5UxkYG8YNC1azeo8mA+XfukoE+SLyIxH5OtaxgfcARCQcCPZ0cEp5ysCYMBbNnUpKbBg3Pr2albvLnA5JKcd0lQhuAcYBNwJXGWNaz72bCjztwbiU8rjkmDAWzptKWlw4Nz29hs93aTJQ/kk7r1d+r7S6nmueWEleeS0L5pzGtOGJToeklFu45fRREXmzs0cXyy4QkWIR2eQy7W4RKRSRXPtxafffklKekRgVysK5U8lMiOSmZ9awfEep0yEp1ae6uqCsBMgHFgKraHN/IWPM0k6WPRvruoPnjDGtp6DeDVQbY/58MkFqjUD1hfKaBq55YiV7Smt44oYczh6Z5HRISvWKW2oEwCDgV8B44G/ABUCpMWZpZ0kAwBizDNDTMZTPiI8MYeHcqWQlRfHdZ9fy/uYDToekVJ/o6sriZmPMe8aYOVgHiHcCS0TkR73Y5g/t+xUtEBG9zl95lQGRIfx77umMT4vhtue/4KW1+U6HpJTHddlDmYiEisg3gOeBHwAPAa/2cHuPAFlANlAEPNDJdueJyFoRWVtSUtLDzSl18uIiQnj+u6dz5vBEfv7ylzyxbLfTISnlUV0dLH4WWIF1DcE9xpjTjDH3GmMKe7IxY8xBu5bRAjwBTOlk3seNMTnGmJykJG2rVX0rIiSIp+acxmUTUvj9O1v543vb8IUz7JTqiaAuXr8eqAFGAreLHD1WLIAxxsSczMZEJMUYU2SPfh3r3kVKeaWQoAAe+s4kYsOD+eeSXRyqbeR3s8cTGKB9Mqn+pdNEYIzpcef2IrIQOBdIFJEC4DfAuSKSjdWpzV7gez1dv1J9ITBA+P3s8QyICOYfn+yi8kgjf70qm5CgHv81lPI6XdUIeswYc3U7k5/y1PaU8hQR4WcXjWZARAi/e3srlXWNPHrdqUSGeuzvo1Sf0t0apbrpu2cN449XTuCznaVc99QqKmobnA5JKbfQRKDUSfh2zmAeue5UNhdW8u3HPudgZZ3TISnVa5oIlDpJF40bxDM3n0bhoSN885EV7C2tcTokpXpFE4FSPTAtK5GF86ZSU9/ElY9+zpb9lU6HpFSPaSJQqocmpMfxn1unERwoXPX456zR3s6Uj9JEoFQvDE+O4uXbppEUFcr1T63ik23FToek1EnTRKBUL6XFhfOfW89geHIbsN1iAAAW/ElEQVQUc59byxu5PbrwXinHaCJQyg0S7D4NTh0ygB+/mMtzn+91OiSluk0TgVJuEh0WzLM3T2HG6IH83xub+duHO/T+RMonaCJQyo3CggN59LrJfHNyOn/98Cvu+e8WWlo0GSjvptfIK+VmQYEB/OnKCcSGB7Pgsz0cPtLIH6+cQHCg7ncp76SJQCkPCAgQ/vfyMQyICOaBxV9x+Egjd104krEpMbjcxVcpr6CJQCkPERF+NGMEcZEh3P3mZj7eVszAmFDOHZnMeaOTmT4ikSi9cZ3yAp12Xu8ttPN65euKq+pYur2EJdtLWPZVCVX1TQQHCqdlxnPeKCsxZCVFam1BuVV3O6/XRKBUH2tsbuGLfYf4ZHsxS7aVsP1gFQCD48OtpDAqmTOyEggLDnQ4UuXrNBEo5SMKDtWyZHsJS7YX89nOMo40NhMaFMC0rATOG20lhsHxEU6HqXyQJgKlfFBdYzOr9pTzybZiPtlezL6yWsC6lcV5o5I4b1QyOZnx2kOa6hZNBEr1A3tKa/h4WzFLthezanc5Dc0tRIUGMX14It89ayg5mfFOh6i8mCYCpfqZmvomVuwq4+NtxXy49SBl1fV8/9zh3DFzhF6joNqliUCpfqy6vonf/nczL60tYGJ6LA9+ZxJDEyOdDkt5me4mAt2NUMoHRYUG8ccrJ/LItZPZW1bLZQ99yqLVeXpvI9UjmgiU8mGXnJLCez8+i+zBccx/dSO3Pv8Fh2oanA5L+RiPJQIRWSAixSKyyWVavIgsFpEd9vMAT21fKX+REhvO87eczv9cOoaPtxVz0YPL+HRHidNhKR/iyRrBM8DFbabNBz4yxowAPrLHlVK9FBAgzD17GK//4ExiwoO5/qnV3PvWFuoam50OTfkAjyUCY8wyoG0nrrOAZ+3hZ4HZntq+Uv5oXGosb/1oOnPOGMJTy/cw+x+f8ZV95bJSHenrYwQDjTFFAPZzckczisg8EVkrImtLSrSaq1R3hQUHcs+s8Tx942mUVtdz+d+X8/Rne/RAsuqQ1x4sNsY8bozJMcbkJCUlOR2OUj7nvNHJvPfjs5k+PJF7/ruFG59eQ3FVndNhKS/U14ngoIikANjPxX28faX8SmJUKE/NyeHe2eNZubuMix/8lMVbDjodlvIyfZ0I3gTm2MNzgDf6ePtK+R0R4fqpQ3j79ukMiglj7nNr+dVrG6ltaHI6NOUlPHn66ELgc2CUiBSIyC3A/cAFIrIDuMAeV0r1geHJ0bz2g2l87+xhLFydx+V/X87GgsNOh6W8gN5iQik/tGJXKXe+uIHS6nruvHAk3zs7i8AA7RSnv9FbTCilOjQtK5H3fnwWF40bxB/f2841T6xkT2mN02Eph2iNQCk/ZozhlXWF/OaNTdQ0NJMSG8bkjAFMyohjUsYAxqXGaE9pPqy7NQLtOVspPyYiXHlqOmdkJfD+pgOsz69g3b5DvL2xCICQwADGpsYwKSPuaIJIiwvXvpX7Ga0RKKVOUFxZx7q8CtbnH2L9vgq+LKygrrEFgOToUJfEMIAJ6bFaa/BSWiNQSvVYckwYF48fxMXjBwHQ2NzCtqIq1ucfYt2+Q6zPr+D9zdb1CEEBwpiUGCZnxDF5yAAmDR7A4HitNfgSrREopXqktLqe3LwK1uUdYn1eBRsKKqhtsG5ylxgVwsT0OLKSo8hMiCQzMYJhiVEMjAnVBNGHtEaglPKoxKhQZo4dyMyxAwFoam7hq4PVRxPDxsIKPt1ZSkNTy9FlwoMDyUyMZGhiBEMTI8lMiGRYkvUcHxmiScIhWiNQSnlMS4th/+Ej7C2tZU9pNXvs571lteSX19LUcqz8iQkLYmhipJUg7OfW4ZiwYAffhe/SGoFSynEBAUL6gAjSB0QwfUTica81NrdQcOgIe0tr2F1aw97SGvaU1rBm7yHe2LAf133UxKgQhiZGcvrQBGaOHciEtFgC9AI4t9EagVLK69Q1NpNXXsvukhr2lllJYvvBKjbkV9BiICk6lPNHJTNjTDLTRyQSEaL7tO3RGoFSymeFBQcycmA0IwdGHzf9UE0DS74q5sOtxbyzsYgX1+YTGhTAmcMTmTEmmRmjBzIoNsyhqH2X1giUUj6poamFNXvL+XDrQT7cepD88iMAjE+LYcbogVwwdiDjUmM8dgDaGMOh2kb2lFazu8Rq1goKEG6ZPozYCO84ptHdGoEmAqWUzzPGsKO4mg+3HuSjrcWsyzuEMTAoJozzxyQzc0wy07ISe3ThW21DE3vs4xd77AJ/tz1++Ejj0fkCAwRjDAMiQvjVpWP4xuQ0x8+C0kSglPJbZdX1fLK9hA+3HOTTHSXUNDQTHhzI9BGJzByTzHmjk0mOPtaE1NjcQn557dECf7dLoX+g8vhe3VJiw46e0TQ00Tr9dWhiFOkDwvnqYBW/fn0T6/MqOH1oPL+bPZ4RbZq3+pImAqWUAuqbmlm5u5yP7NpCYYXVhDRxcBwJkSHsKa0hr7yWZpdTWQdEBNsFfZR9zUOUfSprRJcHpltaDIvW5POH97ZRU9/E3LOHcfv5IwgP6fvbcGgiUEqpNowxbC2q4qOtB/l4ezF1jS0Mc9m7H5oUydCESAZEhvR6W6XV9dz3zjZeWVdAWlw491wx7ujFd31FE4FSSnmBVbvL+PXrm9hRXM0FYwdy9xXjSIsL75Nta8c0SinlBU4flsDbt5/FLy4ezfIdpcx8YCmPLt1FY3NL1wv3EU0ESinlYSFBAdx2bhaL7zybM4cncv+727jsoU9Zvafc6dAATQRKKdVn0gdE8OScHJ64IYea+ma+/djn/PQ/Gyirrnc0Lk0ESinVxy4YO5DFd57Nredk8fr6Qs5/YCkLV+fR0uLMMVtNBEop5YCIkCDmXzKad+44i1GDovnlqxu58tEVbNlf2eexOJIIRGSviGwUkVwR0dOBlFJ+a+TAaF6cN5U/f2sie8tq+drDy7n3rS1U1zf1WQxO1gjOM8Zkd+fUJqWU6s9EhCtPTefju87h2zmDeWr5HmY8sIR3NhbRF6f4a9OQUkp5ibiIEO77xim8+v1pxEeG8v0X1vH2xiKPb9eRC8pEZA9wCDDAY8aYx9uZZx4wDyAjI+PUffv29W2QSinloKbmFl5dV8jXJ6cRHNizfXavvrJYRFKNMftFJBlYDPzIGLOso/n1ymKllDp5Xn1lsTFmv/1cDLwGTHEiDqWUUg4kAhGJFJHo1mHgQmBTX8ehlFLK4kRXlQOB1+wOG4KAfxtj3nMgDqWUUjiQCIwxu4GJfb1dpZRS7dPTR5VSys9pIlBKKT+niUAppfycJgKllPJzmgiUUsrPaSJQSik/p4lAKaX8nCYCpZTyc5oIlFLKz2kiUEopP6eJQCml/JwmAqWU8nOaCPqbxjpoPOJ0FEopH+LEbaiVO7U0Q1Eu7F5iPfJWQUAQjP8GTJ4D6Tlg3fJbKaXapYnA1xgD5bth9ydWwb9nGdQdtl4beApMmQt1FbDpFVj/L0gaDZNvgAnfgcgER0NXSnknR/osPll+32dxdbFV4O/+BHYvhcP51vTYwTDsXOsx9ByISjq2TH0VbHoV1j0HhWshIBhGX2YlhWHnQYC2CirV33l15/Uny+8SQX015H1+rLnnoN2TZ1gcDD37WOEfP6x7zT4Ht1i1gw0L4cghiM2ASddC9rUQN9hT78Jz6quhphiqS6znmhIIHwBpORCb7h1NYXWHrWa6fZ9Zj+JtkDYJRlxoPRJHekecql/TROBLmptg/7pjBX/+amhphMBQyJh6rOBPmQgBgT3fTlM9bHvbqiXs/gQQyDrfqiWMuhSCQtzwZnrAGKvgrCmxaj9HC/mS4wv8arvQb6zteF1Rg6zjImmnQvppkDoJQqM8/x5qyiBvBexbYRX8BzaCabFqYmmTIXmM9b0Wb7Hmj8uA4RdYSWHoWRAS6fkYPa2hFvJXwd7l1qNsJwwaD+lTYPAU63sJH+B0lH5FE4G3aaiFykLrcbgQKvdDZQFU5EHBWqivBMQq7Iedaz0ypkJwuGfiObQPcl+A9c9bMUUkwMSrYdL1kDzafdtpqrfWX5EPhwvsR/6JBX5z/YnLSoAVV2Sy1ewVmQxRyRCZZD+3Tk+CqiIo+AIK1lhNYeW7j60jeaydGHKs5JA4sncJFaDqgFXg7/3MKvxLtlrTg8KsbQw5EzLPtGopIRHHlqvIh52LYceHVtJvrLESfuZ0u7ZwASRk9S62vtJQCwWrrUJ/z6dQ+IW1AyOBVvJLHAkHvoSDm62kCNa09Ckw+DTrOWm0NlN6kCaCvtRQaxfshe0U9oVW4VdXceJyEYkQm2bttQ47z2r2iYjv29hbmmHXx1YtYfs70NIEg0+3EsK4r3e+N22M1dRUkXd8Ie/6XH3wxOUikyF6YCcFuz09IqHnBXZNmVUwFa61Em3h2mMH1UOirWaa9NOsgjo9x9peZyry7ELfLvjLd9nrirIS9pBpVuGfOgmCQrsXY1O9ta4di2HHB1C2w5oeP+xYUhgyHYLDevYZuFvjEatW07rHX7gWmhusgj91kpXMMs+CjNMhNPrYcvXVVo03f7WVqPNXw5Fy67XQWEg/9VhySMuB8Dhn3l8/pImgt1parMK7tsx61JRCbam191q533octgv91h+1q4gEiEmzHrFpEJMKMenWc2waRKd6zx+8VXWJdRxh/b+g9CurkBv/TavZ6MghlwLeZe++bTNNUJh1EDs23X4Mto5DtI7HpHW/oHSnlhar8C5YcywxHNgEptl6PS7jWFJIP806HpP3+bGCv/UAfVjcsUJ/yDQYNAEC3XTyXfke2PmhlRT2LIOmOggKt3YQRlxgPQZkumdb3dF4xPq8Wgv+gjV2wR/QpuCfenzB35XWM9/yVx1LDsVbjtUakkZb38HgKVaCSBzZf2oNjXXWf6muAo5UuAwfssZdh1tfu+JhGHJGjzaniaCtpnqXAr3sxAK+tszai6wts8fLjxUSbYXH24V76yPVLuRSj417qkmnLxhj/UnXPQebXzu+sI9M7riQjx1sJUBfOQjaUAtFG+xawxqraamy4Ph5IpPsQt9u6kka0zeFUuMRq/DdsRh2vA+H9lrTE0datYXhM63kFRBk1ZoCgqyHBBw/TQKt4e58J4117RT89dY6U7KPL/jDYtz7fuurrBpc/hqrualgjVUQAoTFHkvSkUkQGGLtcATZz0fHQ61HYOixYdfx7tQujbFqxU11VpnRVO8ybD83dzC9qd76r3RWwDfVdbJxsd5reJx1LCXMfp7+Y6vJuAe8OhGIyMXA34BA4EljzP2dzd/jRLD0j1Y7eE0ZNFR1FI3VHBORaLdHJ7gM28+tj9ZxXy7kT1ZdpXXgM3qQ7ye47qgsshLDkQqrwEsY7nxiMwbKdlk1hZ2LrUK6ueHk1tGaIKQ1abQdD7Ka8Y4W/BPbFPyxnnlvHTHGOticv9pKDPl2rYFelFcBQScmCWOOFebNDdZza82kp0Ki7EK8tUCPtZ6PK+DbFPbhcVYzmZt3Mrw2EYhIIPAVcAFQAKwBrjbGbOlomR4ngi+etf40kYltCvvEY8Phcb0/cKhUX2qosY5XHCm39l5bmq1n09JmvNkedh1vsprJjhu354mIP1bwe2M7fUOt9d5dC+2mepfhhpN7rclOekGuNYowl1qE67Q28xxNKG3nCXfu7Lt2dDcROHFl8RRgpzFmN4CILAJmAR0mgh47dY71UKo/CYmEkRc6HUXfC4k4/gws5TZOHIFJA/JdxgvsaccRkXkislZE1paUlPRZcEop5W+cSATtNbie0D5ljHncGJNjjMlJSkpqZxGllFLu4EQiKABc72uQDux3IA6llFI4kwjWACNEZKiIhADfAd50IA6llFI4cLDYGNMkIj8E3sc6fXSBMWZzX8ehlFLK4kh/BMaYd4B3nNi2Ukqp4/WT67aVUkr1lCYCpZTycz5xryERKQH29XDxRKDUjeF4grfH6O3xgffH6O3xgcboDt4W3xBjTJfn3/tEIugNEVnbnUusneTtMXp7fOD9MXp7fKAxuoO3x9cRbRpSSik/p4lAKaX8nD8kgsedDqAbvD1Gb48PvD9Gb48PNEZ38Pb42tXvjxEopZTqnD/UCJRSSnVCE4FSSvm5fp0IRORiEdkuIjtFZL7T8bgSkcEi8omIbBWRzSJyh9MxdUREAkVkvYi85XQsbYlInIi8LCLb7M+yZ718e5CI/MT+jjeJyEIRCfOCmBaISLGIbHKZFi8ii0Vkh/08wMvi+5P9PX8pIq+JiKPdqLUXo8trPxURIyKJTsR2svptIrC7xPwHcAkwFrhaRMY6G9VxmoC7jDFjgKnAD7wsPld3AFudDqIDfwPeM8aMBibiZXGKSBpwO5BjjBmPdaPF7zgbFQDPABe3mTYf+MgYMwL4yB53yjOcGN9iYLwxZgJWd7e/7Oug2niGE2NERAZjdcWb19cB9VS/TQS4dIlpjGkAWrvE9ArGmCJjzDp7uAqrADuhpzaniUg6cBnwpNOxtCUiMcDZwFMAxpgGY0yFs1G1KwgIF5EgIAIv6H/DGLMMKG8zeRbwrD38LDC7T4Ny0V58xpgPjDFN9uhKrL5MHNPBZwjwV+DntNPhlrfqz4mgW11iegMRyQQmAaucjaRdD2L9qFucDqQdw4AS4Gm76epJEYl0OihXxphC4M9Ye4dFwGFjzAfORtWhgcaYIrB2VIBkh+PpzM3Au04H0ZaIXAEUGmM2OB3LyejPiaBbXWI6TUSigFeAHxtjKp2Ox5WIXA4UG2O+cDqWDgQBk4FHjDGTgBqcbc44gd3OPgsYCqQCkSJynbNR+TYR+R+sptUXnI7FlYhEAP8D/J/TsZys/pwIvL5LTBEJxkoCLxhjXnU6nnacCVwhInuxmtbOF5HnnQ3pOAVAgTGmtSb1MlZi8CYzgT3GmBJjTCPwKjDN4Zg6clBEUgDs52KH4zmBiMwBLgeuNd53EVQWVsLfYP9n0oF1IjLI0ai6oT8nAq/uElNEBKtte6sx5i9Ox9MeY8wvjTHpxphMrM/vY2OM1+zNGmMOAPkiMsqeNAPY4mBI7ckDpopIhP2dz8DLDmi7eBOYYw/PAd5wMJYTiMjFwC+AK4wxtU7H05YxZqMxJtkYk2n/ZwqAyfbv1Kv120RgH1Rq7RJzK/CSl3WJeSZwPdZedq79uNTpoHzQj4AXRORLIBv4fw7Hcxy7tvIysA7YiPWfc/w2BCKyEPgcGCUiBSJyC3A/cIGI7MA66+V+L4vvYSAaWGz/Xx51Kr5OYvRJeosJpZTyc/22RqCUUqp7NBEopZSf00SglFJ+ThOBUkr5OU0ESinl5zQRKAWISLPLaby57rxbrYhktneHSqW8RZDTASjlJY4YY7KdDkIpJ2iNQKlOiMheEfmDiKy2H8Pt6UNE5CP73vgfiUiGPX2gfa/8Dfaj9XYSgSLyhN0vwQciEu7Ym1KqDU0ESlnC2zQNXeXyWqUxZgrWla0P2tMeBp6z743/AvCQPf0hYKkxZiLWfY9ar2YfAfzDGDMOqAC+6eH3o1S36ZXFSgEiUm2MiWpn+l7gfGPMbvsmgQeMMQkiUgqkGGMa7elFxphEESkB0o0x9S7ryAQW2x2+ICK/AIKNMb/z/DtTqmtaI1Cqa6aD4Y7maU+9y3AzenxOeRFNBEp17SqX58/t4RUc63LyWmC5PfwRcBsc7es5pq+CVKqndK9EKUu4iOS6jL9njGk9hTRURFZh7ThdbU+7HVggIj/D6iXtJnv6HcDj9p0om7GSQpHHo1eqF/QYgVKdsI8R5BhjSp2ORSlP0aYhpZTyc1ojUEopP6c1AqWU8nOaCJRSys9pIlBKKT+niUAppfycJgKllPJz/x/hjDiih7+OiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [1], 'hidden_layer_size': [256], 'activation_function': ['sigmoid']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl8VOW5wPHfk8lkDwlkYUkCYYlI2DGAAu5U0VatVav22lu3S2212tb21va2FbWtdrdWW2t7casVqdWKXhX3BVEhKCiLIewJBJIACSH7JM/945yEIWQnk5kkz/fzmc+cc+Y9Z545M3Oec973nPeIqmKMMcYAhAU7AGOMMaHDkoIxxphmlhSMMcY0s6RgjDGmmSUFY4wxzSwpGGOMaWZJwRhARBaJyN+DHUd/JiIbROSMni5repYlhT5ORHaISJ2IJLeYvlZEVEQygxOZ6S9EJNP9LYUfz3JUdaKqvtXTZU3PsqTQP2wHrmwaEZHJQHTwwgmu49149fR7dyceEfH0TERdft9urbtgrnPTsywp9A+PA//pN/414DH/AiISKSK/EZFdIrJPRB4UkWj3tcEi8oKIlIjIQXc43W/et0TkLhF5T0QqROSVlkcmfmWT3fnLROSAiLwrImHua9NF5CN3GU+JyBIR+Zn72tUisqLFslRExrnDnxeRj0XkkIgUiMgiv3JNe7LXicgu4A13+skistKNZZ1/dYSIjBaRt91YXgVa/Tx+5b/gHn2Vucuc4vfaDhH5gYh8AlSKSHgb0ya467LMrR650G8Zj4jIn0XkRRGpBM5sJYYRIrLMXa9bROS//KZXi8gQv7LTRaRURLzu+LUissn9fpeLyKgW6/lGEckH8lv5+O+4z2UiclhETnG/r/dE5PcicgBYJCJjReQNEdnvvvcTIpLYYj3Nd4cXichSEXnM/Q42iEhON8vOcH8bFSLyT/e39bP2vk/TDlW1Rx9+ADuA+UAeMAHwAAXAKECBTLfcvcAyYAgQDzwP3O2+lgRcAsS4r/0T+Lffe7wFbAVOwDkCeQu4p4147gYeBLzu41RAgAhgJ/Add/qlQD3wM3e+q4EVLZalwDh3+AxgMs6OzBRgH/BF97VMt+xjQKwbYxqwHzjfnedz7niKO8/7wO+ASOA0oAL4exufaQZQDMx21+/X3PUe6fcdrAUygOjWprmfeQvwI3ddnOW+53i3/CNAOTDXjTeqlTjeBv4ERAHTgBLgbPe1N4D/8iv7a+BBd/iL7ntPAMKBHwMrW6znV93fRnQr79u0fsP9pl0N+IBvucuMBsa56zkSSMFJJve2/K26w4uAGvf78eD8bj7oalmO/K5ucdfxl4A63N+VPbqxTQl2APY4zi/wSFL4sftnWeD+wcPdP3Imzka5EhjrN98pwPY2ljkNOOg3/hbwY7/xbwIvtzHvncBzuBtzv+mnAXsA8Zu2kk4mhVbe517g9+5w00ZrjN/rPwAebzHPcpwN+kh3gxbr99o/aDsp/Bm4q8W0POB0v+/g2la+l2v9xk8F9gJhftOeBBa5w48Aj7XzPWcADUC837S7gUfc4euBN9xhwdkxOM0dfwm4zm++MKAKGOW3ns9q572b1m/LpLCrg9/mF4GPW/5W3eFFwGt+r2UD1V0t6/6udrf4Xa3AkkK3H1Z91H88DnwF58/6WIvXUnCOAta4VRdlwMvudEQkRkT+IiI7ReQQzh5eohxdr73Xb7gKiGsjjl/j7JW+IiLbROQ2d/oIYLe6/1rXzs5+OBGZLSJvilPFVQ7cwLFVPgV+w6OAy5o+r/uZ5wHD3VgOqmplJ2MZBdzaYlkZ7nJae+/Wpo0AClS1scV7pnWwDP/5D6hqRRvzPw2cIiIjcDaUCrzrF/8f/GI/gJM4OvvebTlqHhFJdasEd7u/o7/TfrVcy99UlLTdNtFW2dZ+V935LMZlSaGfUNWdOA3O5wPPtHi5FKgGJqpqovtIUNWmDfutwHhgtqoOwtmogLPh6GocFap6q6qOAS4AvisiZwNFQJqI+C9zpN9wJU7ict5YZFiLRf8Dp/orQ1UTcKqoWsbXcsPwuN/nTVTVWFW9x41lsIjEthFLSwXAz1ssK0ZVn2zjvVubtgfIELd9xe89d3ewDP/5h4hIfGvzq2oZ8ArwZZydgyf9NpQFwNdbxB+tqis7+d5tvdZy+t3utCnu7+gquvEb6qLWflcZAX7Pfs2SQv9yHU41gP8eMO7e6V+B34tIKoCIpInIuW6ReJykUeY2Vt7e3QDcBtlx7p/0EE6VRwNOHb4PuNltdP0SMMtv1nXARBGZJiJROFUG/uJx9pRrRGQWzoavPX8HLhCRc0XEIyJRInKGiKS7CTQXuENEIkRkHk4Ca8tfgRvcoxURkVhxGr7j25mnpQ9xEt9/i4hXnEbvC4AlnZlZVQtwqtvudj/LFJzv+wm/Yv/AOeHgEne4yYPAD0VkIoCIJIjIZV2IvQRoBMZ0UC4eOIzzO0oDvt+F9+iu93F+Xze5v6uLOPp3ZbrIkkI/oqpbVTW3jZd/gFOt84F7aP8aztEBOPXz0ThHFB/gVC11V5a77MM4f9g/qepbqlqH0wh4NXAQuBy/IxpV3YzTHvEazhkwK45eLN8E7hSRCuCnwNL2gnA3ohfhNOyW4Owtf58jv/mv4DQcH8BJgi2r3PyXlQv8F3C/G/sW93N0mvv5LwTOw1nPfwL+U1U/68JirsSp398DPAvcrqqv+r2+DGf971PVdX7v/SzwS2CJ+92vd+PobOxVwM+B99wqqJPbKHoHTqN8OfB/HHvE2uP8flfXAWU4RycvALWBfu/+So6uijOm94jII0Chqv442LGY/kNEPsQ58+rhYMfSF9mRgjGmTxOR00VkmFt99DWcU5aP52h3QLOrEI0xfd14nOrEOJzraS5V1aLghtR3WfWRMcaYZlZ9ZIwxplmfqz5KTk7WzMzMYIdhjDF9ypo1a0pVNaWjcn0uKWRmZpKb29ZZl8YYY1ojIp3qQcCqj4wxxjSzpGCMMaaZJQVjjDHN+lybQmvq6+spLCykpqYm2KH0mqioKNLT0/F6vcEOxRjTj/SLpFBYWEh8fDyZmZkc3Vli/6Sq7N+/n8LCQkaPHh3scIwx/Ui/qD6qqakhKSlpQCQEABEhKSlpQB0ZGWN6R79ICsCASQhNBtrnNcb0joAmBRFZICJ54txk/LZWXh8lIq+LyCfi3NA8vbXl9ITKWh9F5dWBWrwxxvQLAUsK7q0cH8Dptz0buFJEslsU+w3OfWmn4PSlf3eg4qmpb6Ckopaa+oYeX/b+/fuZNm0a06ZNY9iwYaSlpTWP19XVdWoZ11xzDXl5eT0emzHGdEUgG5pnAVtUdRuAiCzBuenJRr8y2cB33OE3gX8HKphB0V52l1VTXl1PlNfT8QxdkJSUxNq1awFYtGgRcXFxfO973zuqTPNNscNaz8MPP2xdvxtjgi+Q1UdpHH0D7UKOvlE4OLdgvMQdvhiIF5GklgsSkYUikisiuSUlJd0KxusJIzYynPLq+m7N3x1btmxh0qRJ3HDDDcyYMYOioiIWLlxITk4OEydO5M4772wuO2/ePNauXYvP5yMxMZHbbruNqVOncsopp1BcXNxrMRtjBrZAHim01hLasp/u7wH3i8jVwDs4NyH3HTOT6kPAQwA5OTnt9vV9x/Mb2LjnUKuv1Tc0UudrJDrCQ1gXGmqzRwzi9gsmdrq8v40bN/Lwww/z4IMPAnDPPfcwZMgQfD4fZ555JpdeeinZ2UfXqpWXl3P66adzzz338N3vfpfFixdz223HNMkYY0yPC+SRQiGQ4TeejnNv2WaqukdVv6Sq04H/caeVByqgcI/zcRsae+8eEmPHjmXmzJnN408++SQzZsxgxowZbNq0iY0bNx4zT3R0NOed59xC96STTmLHjh29Fa4xZoAL5JHCaiBLREbjHAFcgXOz9GYikgwcUNVG4IfA4uN904726LcWH6ZBlROGxh/vW3VKbGxs83B+fj5/+MMfWLVqFYmJiVx11VWtXmsQERHRPOzxePD5jjl4MsaYgAjYkYKq+oCbgOXAJmCpqm4QkTtF5EK32BlAnohsBoYCPw9UPE0Sor3U1DdQG4CzkDpy6NAh4uPjGTRoEEVFRSxfvrzXYzDGmPYEtJsLVX0ReLHFtJ/6DT8NPB3IGFoaFO1lT7lzFlJqD5+F1JEZM2aQnZ3NpEmTGDNmDHPnzu3V9zfGmI70uXs05+TkaMub7GzatIkJEyZ0ehlbig+jqmT1UhVSoHT1cxtjBi4RWaOqOR2V6zfdXHRFQrSX6iBVIRljTCgbsEkBoLym965ZMMaYvmBAJoWI8DBiIsIpr7KkYIwx/gZkUgC/KiSfVSEZY0yTAZwUnBOverPbC2OMCXUDNilEhHuIifBwyJKCMcY0G7BJAZxrFqrqGqg7ziqknug6G2Dx4sXs3bv3uGIxxpjj0S/u0dxdCdFe9pbXUF5dT0p89y9k60zX2Z2xePFiZsyYwbBhw7odizHGHI8BnRQiwz1Eez2UV/tICdB1bI8++igPPPAAdXV1zJkzh/vvv5/GxkauueYa1q5di6qycOFChg4dytq1a7n88suJjo5m1apVR/WBZIwxvaH/JYWXboO9n3a6+Ci3O+3G9rrTHjYZzruny6GsX7+eZ599lpUrVxIeHs7ChQtZsmQJY8eOpbS0lE8/deIsKysjMTGRP/7xj9x///1Mmzaty+9ljDE9of8lhS4KDxPqAF+jEuHp/D0WOuO1115j9erV5OQ4V5ZXV1eTkZHBueeeS15eHrfccgvnn38+55xzTo++rzHGdFf/Swpd3KMPA4r2VSAijEuN69FQVJVrr72Wu+6665jXPvnkE1566SXuu+8+/vWvf/HQQw/16HsbY0x3DOizj5okRHupqvNR52vs0eXOnz+fpUuXUlpaCjhnKe3atYuSkhJUlcsuu4w77riDjz76CID4+HgqKip6NAZjjOmK/nek0A0J0V72HqrhUHU9yfGRPbbcyZMnc/vttzN//nwaGxvxer08+OCDeDwerrvuOlQVEeGXv/wlANdccw3XX3+9NTQbY4JmQHad3ZrN+yrwiDC2h6uQAsm6zjbGdFZIdJ0tIgtEJE9EtojIMXeeF5GRIvKmiHwsIp+IyPmBjKc9CdFeKut81PdwFZIxxvQlAUsKIuIBHgDOA7KBK0Uku0WxH+PcpnM6zj2c/xSoeDpi3WkbY0xgjxRmAVtUdZuq1gFLgItalFFgkDucAOzp7psdbzVYlNdDVLinz3SQ19eq/YwxfUMgk0IaUOA3XuhO87cIuEpECnHu5fyt1hYkIgtFJFdEcktKSo55PSoqiv379x/3hnJQtJeqWh/1DaFdhaSq7N+/n6ioqGCHYozpZwJ59lFrV4K13GpfCTyiqr8VkVOAx0VkkqoetVVW1YeAh8BpaG650PT0dAoLC2ktYXRFfUMj+w7VUlvqJTYytE/MioqKIj09PdhhGGP6mUBu+QqBDL/xdI6tHroOWACgqu+LSBSQDBR35Y28Xi+jR48+jlAdqsrNv3mLjCExPH7d7ONenjHG9DWBrD5aDWSJyGgRicBpSF7Woswu4GwAEZkARAHHt7t/HESEBZOG8/7W/ZRVdb7La2OM6S8ClhRU1QfcBCwHNuGcZbRBRO4UkQvdYrcC/yUi64Angas1yC2o500ahq9ReXXjvmCGYYwxQRHQinNVfRGnAdl/2k/9hjcCcwMZQ1dNSU8gLTGal9fv5bKcjI5nMMaYfsT6PmrBqUIaxrv5pVTYNQvGmAHGkkIrzps0jLqGRt74rEvt3cYY0+dZUmjFjJGDSY2P5KVP7X7JxpiBxZJCK8LCnCqktzYXU1XnC3Y4xhjTaywptGHBpGHU1DfyVl7QzpA1xpheZ0mhDbMyh5AUG8FL660KyRgzcFhSaEO4J4xzJg7ljU37qKlvCHY4xhjTKywptGPBpOFU1jXwbn5psEMxxpheYUmhHXPGJpEQ7eWl9UXBDsUYY3qFJYV2eD1hzJ8wlNc27qPO7shmjBkALCl04LxJwzhU42PlVqtCMsb0f5YUOjAvK5nYCA8v21lIxpgBwJJCB6K8Hs6eMJRXNu7DF+J3ZDPGmONlSaETzps0jAOVdazafiDYoRhjTEBZUuiE08enEOUNswvZjDH9niWFToiJCOfM8am8vGEvjY1BvQeQMcYEVECTgogsEJE8EdkiIre18vrvRWSt+9gsImWBjOd4LJg0jJKKWh7/YCfvb93PJ4VlbCk+zN7yGg7V1Ft7gzGmXwjYnddExAM8AHwOKARWi8gy925rAKjqd/zKfwuYHqh4jtdZJ6YSFxnO7cs2tFkmMjyMr8weye0XTOzFyIwxpucE8nacs4AtqroNQESWABcBG9sofyVwewDjOS7xUV7e+N7pFJXVUFnno6q2gco6H5W1DVS5zyu3lvLEB7u4+awsBsdGBDtkY4zpskAmhTSgwG+8EJjdWkERGQWMBt5o4/WFwEKAkSNH9myUXZAaH0VqfFSbr58zcSjn/eFdnv14N9fOG92LkRljTM8IZJuCtDKtrVbaK4CnVbXV7khV9SFVzVHVnJSUlB4LsKdNGD6IqekJPLW6AFVrkDbG9D2BTAqFQIbfeDqwp42yVwBPBjCWXnP5zJHk7atgbUHItpkbY0ybApkUVgNZIjJaRCJwNvzLWhYSkfHAYOD9AMbSay6YOpxor4eluQUdFzbGmBATsKSgqj7gJmA5sAlYqqobROROEbnQr+iVwBLtJ/Ut8VFePj9lOMvW7qGy1u7vbIzpWwLZ0Iyqvgi82GLaT1uMLwpkDMFwxcwMnl5TyP99UsSXZ2Z0PIMxxoQIu6I5AE4aNZixKbEsWb0r2KEYY0yXWFIIABHhipkj+WhXGfn7KoIdjjHGdJolhQC5eEYaXo/w1GprcDbG9B2WFAIkOS6S+ROG8szHu6n1tXr5hTHGhBxLCgF0+cwMDlTW8drG4mCHYowxnWJJIYBOzUphREIUT9k1C8aYPsKSQgB5woTLcjJ4N7+EwoNVwQ7HGGM6ZEkhwC7LSQfgn7mFQY7EGGM6ZkkhwNIHxzBvXDL/zC2gwe7aZowJcZYUesEVM0eyp7yGFVtKgx2KMca0y5JCL5ifncqQ2AiesiucjTEhzpJCL4gM9/Cl6Wm8unEfpYdrgx2OMca0yZJCL7l8Zgb1DcqzH+0OdijGGNMmSwq9JGtoPDNGJvLkql34GhqDHY4xxrTKkkIvWnjaWLaVVvLwezuCHYoxxrTKkkIvOnfiUM4+MZXfvbrZLmYzxoSkgCYFEVkgInkiskVEbmujzJdFZKOIbBCRfwQynmATEe784iRE4KfPbaCf3GzOGNOPBCwpiIgHeAA4D8gGrhSR7BZlsoAfAnNVdSLw7UDFEyrSEqP57udO4I3Pinnx073BDscYY44SyCOFWcAWVd2mqnXAEuCiFmX+C3hAVQ8CqOqA6E706jmZTEobxKLnN1BeXR/scIwxplkgk0Ia4N89aKE7zd8JwAki8p6IfCAiC1pbkIgsFJFcEcktKSkJULi9J9wTxt0XT2H/4Vp+9fJnwQ7HGGOaBTIpSCvTWlaihwNZwBnAlcDfRCTxmJlUH1LVHFXNSUlJ6fFAg2FyegJXzxnNEx/uYs3Og8EOxxhjgMAmhUIgw288HdjTSpnnVLVeVbcDeThJYkC49ZwTGJEQxY+e+ZR6u3bBGBMCApkUVgNZIjJaRCKAK4BlLcr8GzgTQESScaqTtgUwppASGxnOnRdNIm9fBQ+9M2A+tjEmhAUsKaiqD7gJWA5sApaq6gYRuVNELnSLLQf2i8hG4E3g+6q6P1AxhaL52UM5b9Iw7ns9n537K4MdjjFmgJO+dq58Tk6O5ubmBjuMHrW3vIb5v3ubaRmJPH7dLERaa44xxpjuE5E1qprTUTm7ojkEDEuI4r8XjGfFllL+vdY6zDPGBI8lhRDxH7NHMS0jkbte2MSOUqtGMsYEhyWFEOEJE3516RQaVfnin97j/a0DqmnFGBMiLCmEkBOGxvPcjXNJio3gq//7od2pzRjT6ywphJhRSbE8e+Nc5oxL5gf/+pSfvbCRhsa+dTKAMabvsqQQggZFeVn8tRyunpPJ31Zs5/pHV1NRY30kGWMCz5JCiAr3hLHowon87IuTeCe/lEv+vJKCA3YPBmNMYFlSCHFXnTyKR6+Zxd7yGi564D1ydxwIdkjGmH6s3aQgIlf5Dc9t8dpNgQrKHG1eVjLP3jiXhGgvX/nrh6zcUhrskIwx/VRHRwrf9Rv+Y4vXru3hWEw7xqbE8ew35zA8MYrbl23AZx3oGWMCoKOkIG0MtzZuAiwxJoIfnnci+cWHeSq3oOMZjDGmizpKCtrGcGvjphecO3EYszKH8PtXN9sZScaYHtdRUjhRRD4RkU/9hpvGx/dCfKYFEeF/Pj+B0sN1PPj21mCHY4zpZ8I7eH1Cr0RhumRqRiJfnDaCv727nf+YPYoRidHBDskY00+0e6Sgqjv9H8BhYAaQ7I6bIPn+ghMB+PXyvCBHYozpTzo6JfUFEZnkDg8H1uOcdfS4iHy7F+IzbUhLjOa6eaN59uPdfFJYFuxwjDH9REdtCqNVdb07fA3wqqpeAMymE6ekisgCEckTkS0iclsrr18tIiUistZ9XN/lTzCAfeOMsSTHRfCz/9tEX7tZkjEmNHWUFPxPbzkbeBFAVSuAdk+UFxEP8ABwHpANXCki2a0UfUpVp7mPv3U6ckN8lJdvzz+BVdsP8MrGfcEOxxjTD3SUFApE5FsicjFOW8LLACISDXg7mHcWsEVVt6lqHbAEuOh4AzZHu2JmBlmpcdzz0mfU+eyCNmPM8ekoKVwHTASuBi5X1abK65OBhzuYNw3wv8Kq0J3W0iXuaa5Pi0hGawsSkYUikisiuSUlJR287cAS7gnjR+dPYHtpJU98aG3/xpjj09HZR8WqeoOqXqSqr/hNf1NVf9PBslu74rllxffzQKaqTgFeAx5tI46HVDVHVXNSUlI6eNuB54zxKcwbl8wfXs+nvMouaDPGdF9HZx8ta+/RwbILAf89/3Rgj38BVd2vqrXu6F+Bk7r6AYxzQduPzp9AeXU9f3wjP9jhGGP6sI4uXjsFpwroSeBDutbf0WogS0RGA7uBK4Cv+BcQkeGqWuSOXghs6sLyjZ/sEYO47KR0Hn1/B189ZRSjkmKDHZIxpg/qqE1hGPAjYBLwB+BzQKmqvq2qb7c3o6r6gJuA5Tgb+6WqukFE7hSRC91iN4vIBhFZB9yM03ZhuunWc8bj9YSxaNkGO0XVGNMt0tmNh4hEAlcCvwbuVNWWXWn3ipycHM3NzQ3GW/cJi1ds584XNvKLiyfzldkjgx2OMSZEiMgaVc3pqFyHd14TkUgR+RLwd+BG4D7gmeMP0QTC1XMymTsuibte2MiO0spgh2OM6WM6amh+FFiJc43CHao6U1XvUtXdvRKd6bKwMOE3l03F6xG+s3St3YzHGNMlHR0pfBU4AbgFWCkih9xHhYgcCnx4pjuGJ0Rz1xcn8fGuMv78lnWvbYzpvHbPPlLVDquXTGi6aFoar20q5g+v53PG+FQmpycEOyRjTB9gG/1+7K6LJpIcF8m3n/qYmvqGYIdjjOkDLCn0Y4kxEfz6silsLanknpc+C3Y4xpg+wJJCP3dqVgpXz8nkkZU7eDff+o0yxrTPksIAcNt5JzI2JZbv/XMdZVV1wQ7HGBPCLCkMAFFeD/dePp39h+v4yXMbgh2OMSaEWVIYICanJ/Dt+Vk8v24Pz35cGOxwjDEhypLCAHLD6WM5adRgvvPUOr75xBry91UEOyRjTIixpDCAhHvCeOSamdx8dhZv55Vwzr3v8O0lH7PdusMwxrg63SFeqLAO8XrGgco6/vLOVh5duYP6BuWSGWl866wsMobEBDs0Y0wAdLZDPEsKA1xxRQ1/fmsrT3y4C1Xl8pkZ3HRmFsMSooIdmjGmB1lSMF1SVF7N/W9s4anVBUR5Pbx0y6l21GBMP9JjXWebgWF4QjQ/v3gyy79zGg2Nyl0vbAx2SMaYIAhoUhCRBSKSJyJbROS2dspdKiIqIh1mMRNYY1Pi+NbZ43hl4z7eyisOdjjGmF4WsKQgIh7gAeA8IBu4UkSyWykXj3Mrzg8DFYvpmuvmjWZ0cix3PL+RWp91pGfMQBLII4VZwBZV3aaqdcAS4KJWyt0F/AqoCWAspgsiwz3cfkE220srWbxiR7DDMcb0okAmhTSgwG+80J3WTESmAxmq+kJ7CxKRhSKSKyK5JSXWqVtvOGN8KudkD+WPb+RTVF4d7HCMMb0kkElBWpnWfKqTiIQBvwdu7WhBqvqQquaoak5KSkoPhmja85MvZNPQqPziRet225iBIpBJoRDI8BtPB/b4jccDk4C3RGQHcDKwzBqbQ0fGkBi+ccZYnl+3h5VbS4MdjjGmFwQyKawGskRktIhEAFcAy5peVNVyVU1W1UxVzQQ+AC5UVbsIIYTccPpYMoZEs2jZBuobGoMdjjEmwAKWFFTVB9wELAc2AUtVdYOI3CkiFwbqfU3PivJ6+OkXJrJ532Eee39nsMMxxgRYeCAXrqovAi+2mPbTNsqeEchYTPfNn5DKGeNTuPfVzVwwdTip8dYFhjH9lV3RbDokItx+wURqfY388qW8YIdjjAkgSwqmU0Ynx3L9qaP510eFrNl5INjhGGMCxJKC6bSbzhrH8IQofvLvDTQ09q2OFI0xnWNJwXRaTEQ4P/58NhuLDvGz/9tIX+th1xjTMUsKpkvOnzyMa+eO5uH3dvCH1/ODHY4xpocF9Owj0/+ICD/+/AQqauq597V84qO8XDdvdLDDMsb0EEsKpsvCwoS7vzSZw7U+7nphI/FR4Xw5J6PjGY0xIc+qj0y3hHvCuPeKaZyalcxt//qElz4tCnZIxpgeYEnBdFtkuIe/fPUkpo8czM1LPubtzdaDrTF9nSUFc1xiIsJZfPVMslLj+frjueTusGsYjOnLLCmY45YQ7eWx62YxIiGaax5ZzYY95cEOyRjTTZYUTI9Ijovk8etnEx8Zzn/+7yrW7DwY7JCMMd1gScH0mLTEaP5+/WzCwoRL/rw0K3u6AAAZ9UlEQVSSyx5cyfINe+3qZ2P6EOlrV6Xm5ORobq7dciGUVdTUszS3kMUrtrO7rJpRSTFcO3c0l56UTmyknQVtTDCIyBpV7fAmZpYUTMD4GhpZvmEff313G2sLykiI9vKV2SP52imZDEuw7reN6U2WFExIWbPzIP+7Yhsvr99LmAg3nTWOb88/IdhhGTNgdDYpBLRNQUQWiEieiGwRkdtaef0GEflURNaKyAoRyQ5kPCZ4Tho1mD/9x0m8/f0zOWfiUO59LZ9V2+30VWNCTcCSgoh4gAeA84Bs4MpWNvr/UNXJqjoN+BXwu0DFY0JDxpAYfnPZVNISo/nhM59Q62sIdkjGGD+BPFKYBWxR1W2qWgcsAS7yL6Cqh/xGY4G+VZdluiUmIpyfXTyJrSWV/PmtrcEOxxjjJ5BJIQ0o8BsvdKcdRURuFJGtOEcKN7e2IBFZKCK5IpJbUmJdKfQHZ45P5cKpI/jTm1vZUlwR7HCMMa5AJgVpZdoxRwKq+oCqjgV+APy4tQWp6kOqmqOqOSkpKT0cpgmWn3whm+gIDz96Zj2Ndi2DMSEhkEmhEPDvTzkd2NNO+SXAFwMYjwkxKfGR/M/5E1i14wBP5RZ0PIMxJuACmRRWA1kiMlpEIoArgGX+BUQky2/084DdymuAuSwnnZPHDOEXL26i+FBNsMMxZsALWFJQVR9wE7Ac2AQsVdUNInKniFzoFrtJRDaIyFrgu8DXAhWPCU0iwi8unkytr5E7XtgY7HCMGfAC2ueAqr4IvNhi2k/9hm8J5PubvmFMShzfOnMcv311M1+avo+zJwwNdkjGDFjWIZ4JCV8/fSxZqXH85N/rqaz1BTscYwYsSwomJESEh3HPJZMpOlTDb1/ZHOxwjBmwLCmYkHHSqCFcNXsUj6zczrqCsqNeU1Uqa30UV9Swo7SSXfurghSlMf2b9WNsQsr3F4znlY17ufrhVSTGRHC41kdVrY+q+gZa9t148fQ0br8gm8SYiOAEa0w/ZEnBhJRBUV4e+MoM/vruNiLCPcRFeoiJCCc2wkNsZDgxkc7w1pLD/OXtbazYUsrdF09mfrY1ThvTE6zrbNNnbdhTzq1L1/HZ3gq+ND2N2y+YSEKMN9hhGROSQqLrbGMCaeKIBJbdNI+bzxrHc+v2cM69b/PGZ/uCHZYxfZolBdOnRYSH8d1zxvPcjXMZHBPBtY/kcuvSdZRX1wc7NGP6JEsKpl+YlJbAczfN5aYzx/Hvtbs59/fv8PL6Ivpa9agxwWZJwfQbkeEevnfueJ795hwSY7zc8PeP+M/Fq9hSfDjYoRnTZ1hSMP3OlPREXvjWPBZdkM26gjIW3PsOP/+/jVTUWJWSMR2xpGD6pXBPGFfPHc2b3zuDS09K528rtnPWb9/mX2sK7d4NxrTDkoLp15LiIrnnkin8+5tzSUuM5tZ/ruPSB1eyfnd5sEMzJiRZUjADwtSMRJ75xhx+dekUdh2o4oL7V/DfT69jT1l1sEMzJqTYxWtmwDlUU899r+Xz2Ps7QeDqOZl884yx1l2G6dc6e/GaJQUzYBUcqOLe1/J55uNC4iLDueH0sVwzN5OYCOv9xfQ/IXFFs4gsEJE8EdkiIre18vp3RWSjiHwiIq+LyKhAxmOMv4whMfz2y1N5+ZbTmD06iV8vz+P0X7/F4x/spL6hsdV5DtXU89neQ7z5WTFvby6x6yBMvxOwIwUR8QCbgc8BhTj3bL5SVTf6lTkT+FBVq0TkG8AZqnp5e8vt9pFC/mvw0SMw6+uQOQ9Eur4M06/l7jjAL1/+jNU7DjIqKYYLp46g9HAte8pqKCqvZk9ZDYdb3ADoqyeP4o4LJxIWZr8nE9o6e6QQyOPkWcAWVd3mBrQEuAhoTgqq+qZf+Q+AqwIWTWUx7FgBm56H1Ikw++sw+TKIiAnYW5q+JSdzCEu/fgpv5hXzq5fz+OMbW0iKjWB4YhSZSbHMGZvMiMQohidEMyIxmlc27OUv72yjstbHry6dQrjHztswfV8gk0IaUOA3XgjMbqf8dcBLAYtm2ldg4sXw6T/hw7/A8zfDa7fDjK/BzOshMaP9+X11UFEE2gCeCAjzgsfrDHsinGE7+ujzRISzThzKmeNTqWtoJDLc02bZGSMTGRTt5dfL86is83HfldPbLW9MXxDIpNDaFrLVuioRuQrIAU5v4/WFwEKAkSNHdj8ibzTM+E+Y/lXYuRI+fBBW3uc8Tvy8kyC0Ecp2QXkhlBc4z2UFTkJoPfwjwrwwZDRknQMnnAsjT3GShelzRKTDDbyIcOOZ44iN8LDo+Y1c/2guf/nqSdZQbfq0QLYpnAIsUtVz3fEfAqjq3S3KzQf+CJyuqsUdLbfHzz4qK4DVf4OPHoXqg0emeyJgUBokpEPiSOd5UJozvbEeGuqgwf+5HhpqoegT2PGuMz1yEIw9E05YAOM+B3EpPRe3CSlPrynkv59ex4yRg/nfq2eSEG07Aya0BP2UVBEJx2loPhvYjdPQ/BVV3eBXZjrwNLBAVfM7s9yAnZJaX+20OUQlOlVJsakQ1s064trDsP1t2PwybH4FDu8FBNJmOEcPEXHgjYLwaOfoxRsN4VFHnj1eCAuHMI/7HH5kXDxONZUqoBy5R6XfsK8W6qugrtL5XPWVUFd1ZJo3BlInwNCJEJvcAyvPALz0aRE3L/mYrNR4Hr9uFklxkcEOyZhmQU8KbhDnA/cCHmCxqv5cRO4EclV1mYi8BkwGitxZdqnqhe0ts89dp6AKResg/xUnSexd7xxRhIrYFEjNdhJE6gSnET5prNtu0pSMrAG1s97KK+aGv68hLTGav18/m+EJ0cEO6WiNDbBvPex4D3a+B4WrIS4V0nIgPcd5Tj7BvvN+KCSSQiD0uaTQmsZG8NU4e/G+aqivcZ+rnemNPufP2+jze/iNNxO3cdttvmkaDo8Ab6xzZpU32m/Yfa6tgH0boHgj7NvoPJd85hxJtKUpQYgHPOEQk+QcTcWlOM+xKUeG41KdZFhXCXWH/Z6bhishegiMPNnZEEXEdn7dHS6GglWwPx+GT4WMk3v+DLKGemed1NfAiGkQ3rU9/lXbD3DtI6tJiPZy0bQRDB0U5T4iGTooipT4SLy9daZSg8/ZKdm5wkkEuz6AWrffp8GZkDHbWae7PzoyPSIe0qYfSRSp2U71abDax3y1TntdTyQqX63TPlix98jzoT1QUwbDpjinq6ec2C9PGrGkYLqmsREObnc2hgd3+CUiNxlpw5FpDXVQtd/ZmFSWOqf7Vu3v3PuIx0kCtRWAOuPDpzrVaiNPdh5xqU7ZBp8TT8GHzh5twYdObP7CvM6GK/NUGH0qpM9yquY6S9X53Ls/gt1rnEfROic5g1Odlz7T2ViMmusMt7f8ukrYv5Wd+Z/w8nuryKuMY3PDcLbpCKpw5hOBpNhIhiVEMjwhmvTB0aQlRpM+OIb0wc54QrQX6c6GSRWKN8G2t5zHzvecZAyQNM75DE2fJSHtyHyNjbB/C+zOhcJc53nfhiM7IRIG8cPd9rUM5znRfY4f7rSfRQ1ydjy6s/FubIRDhVCa78Sxf4s7vNU54SMu1WmbG38+jDnd2dnpSNUBdz286Xy/h/ZA9YFjy3kinCrdptdikiFzrvOb6k6SqD4I+7c5n+HAVvfzbHUST2wqxA+FuKEQN8z5XHFDnWnRQ5z13VDnJC9frVOr4Ktzfo8NtTB8mnMk3w2WFEzvavBBVambKEqcjUhEnJMAImKPDIdHOn+w6jJnQ7/rfWfvdfeaIxviIWOdDc2ej532EHD+OBmznI1+xmxnA7fnI9j+jtOwX7TOOXPME+mUy5wHUQnOXn9jvRNfo3tCQKPPeT6w1XnfphMMwqOdBJV2ktP+Ex7lnKW2413Y+ymgzvLTc5yN6tBsKN99ZCO2fytU7GlzFdVED+NgTCZ7I0ayixHkNQxnR1UEew7Vc7geGvDgI4xGDSMyMpKUQTFkj0zmP+ZNYNywwW1vmMoLYdvbzgZw+9tweN+R9TjmdGfjNmoOxA/r2ndaX+2cOLE/3zkjr6zAfd4Fh3Y7OwrHEIiMd5JEZLzziIhxvpvGxqN3Lhp9znRfrbPhb/r+wTlaSR7nfM9DxkBJHmx5HeoqnO9p7FkwfoGTKJp2Iny1zo7D1jdh6xvObwJ1YsmY7SSx+BHOeogf7jwPGgHRg535y3Y67Yo7VsD2d50kBU6SGDXHOTrWBudzNO8oNRx5Plzs/KaO2kESJ3EmjXU2+pXFTrmKvU6S6KrP/9Y5hb4bLCmYvsVX6/yJm5LE4X3Oxjl9lrORTxzZ/t5adZkz7/Z3Ycc7TtvNMacQi18jvtepEkk/yU0CJ0HKBKdqrL3l71jh7H03JSFw/uxJ7gYsaeyR54QM589futl95B95rqvo0uppIAy8MXiaqwRjnI1tdZmzIQKnCm/MGTD6dCcZJB7H6dsdBuRzEmDZLucz1la4j0NHhmvKnef6KmcnISz8yHPTSRRN1ZEJGc56S86CpCxnQ9/y+/bVOut/88uQ95KTSBAnSUclOAm8vspZbvpMGHOmc/bfiBltf69tUfVLEu/BrpXOUWBTzGFh7rPnyHP0kKO//6RxThVdW9WPvlonQRwudk5GqTpw5Nqn8CinGtgTefRw/DCITuzON2ZJwQxwtYedI4MwNwl4vM4ft6fUlMOB7c6GN2ZI1+ZVdTak+/PdOFtpN3Ifh6uqWLttD5t27SPMV8OoQTA5NYLU6EakvtrZgIya6ySDoROpbWhk7a4y3t+2nw+27SdvbwWT0hI4NSuZU7NSOHFYfPeqpUKNqtNgnvcS5L3onF035nTnCGLUXKcqyxzFkoIx/cjhWh9LVu3ib+9uZ++hGrKHD+KGM8Yyf0IqnxaW88G2A3ywbT8f7TpIra8REcgePogThw3ik8Iy8t37VCfHRXJqVjLzxiVzalYyqYO60P5i+jRLCsb0Q3W+Rv69djd/eXsrW0sqmy9ZaUoCJ49J4uQxSczKHEJCzJGzhYrKq1mRX8q7+aWs2FLKgco6AE4YGkdKvFO9Ie5ZbC0PJKK9HhJjvCTGRDjP0U3PXhJivGQMiWFQVPfOTKqq8/HU6gLOOjGVUUldOAvNdJklBWP6scZG5dVN+1hXUMb0kYOPSQIdzbux6BDv5pfywbb9VNb6mltfmrYHR8ahpr6Bsqp6yqrrqKk/tkvxuMhwFl04kUtmpHWpamrzvgpufOIj8osPE+UN49bPjeeauZnWsWCAWFIwxvQ4/wRRVlVPWVUdi9/bwartBzhv0jB+cfFkBsd2fAe7f+YW8JPn1hMXGc5PL5jIsrW7eW1TMVPTE/jlpVM4cVjPtQnsKatmT1k1J40a3D/aU7rJkoIxplc0NCp/fXcbv30lj8ExEfzmsqmcdkLr/XxV1vr4yXPreeaj3ZwyJok/XDGN1EFRqCovfFLEomUbKK+u55tnjOXGs8Z1u9fZ4kM1vPhpEc9/UsSanc4px9NHJvLjz0/gpFFdPDGgn7CkYIzpVet3l/Odp9aSX3yYq+dkctt5JxLlPbJRz9tbwTefWMO20kpuPiuLm8/OwtPi5kQHK+u464WNPPPxbsalxvHLSyZ3eiN+oLKOl9YX8cK6Ij7Yvh9VOHFYPBdMHUFCtJf7Xs+nuKKW8ycP4wcLThxwbRiWFIwxva6mvoF7XvqMR1buYFxqHPdePo2JIwaxNLeA25dtIC7Sy31XTGPOuPY7Ynwrr5j/eXY9e8qr+dopmVwwdTjVdY1U1fmorm+gpr6BqroGZ7iugbWF5by3pZSGRmVMSixfmDKCC6YMJ2tofPMyq+p8/PWd7fzlna3UNzTy1ZMzufnscSTGdFzd1R9YUjDGBM07m0v43j/XcbCqjpxRQ3h/237mjkvi95dPIzW+c6fBHq718euXP+OxD3bS0WZq5JAYPj9lOF+YMpzs4YPabTsoPlTD717dzNLcAuIiw7n57Cy+esooIsM9VNc1UHiwioKDVRQcqKbgQBW7DlSxp7yaUUmxnJaVzLysFNISO9/RYXVdA5/uLqe4ooZhg6IYnhjN0PjIXm9Qt6RgjAmqg5V1/OjZT1m+YS/fnn8CN5457pjqos7YvK+CveU1REd4iPZ6iPJ6iHGHoyM8RIaHdasB+bO9h7j7xc94e3NJ82m5JRVH92Ac5Q0jfXAMwxOiyNtbQbH7+piUWE7LSuHUrGROHpNEbKRzxXRjo7KttJK1BWV8vOsgawvK+GxvBQ2NR29nwwRS46MYnhjFiIRohidEkTY4mgnDB5E9YlC3T/FtjyUFY0zQqSqHa33EB2Aj11Pe2VzCPz7cxaDocDIGxzAyKYb0wTFkDIkmJS6yOeGoKvnFh3lncwnv5pfy4fb91NQ34vUIM0YOJiI8jLUFZVTUOJ0IxkeGMzUjkWnuI21wNPsO1VBUXkNRWTV7ymsoKq+mqKyGPeXVR53um5kUw8S0BCaNSGBS2iAmjkhgSCfO6mqPJQVjjAmgmvoG1uw86F4QWEJDI0zLSGT6yESmZyQyNiWOsE4eGakqJRW1bCg6xIbd5azffYj1e8opPFjdXCYtMZr/XjCei6altbOktnU2KdjNZI0xphuivB7mjktm7rhk4MTjWpaIkDooitRBUZw5PrV5ellVHRv3OAli/e5DzdVcgWRJwRhjQlRiTARzxiV3eLZWTwpo87eILBCRPBHZIiK3tfL6aSLykYj4ROTSQMZijDGmYwFLCiLiAR4AzgOygStFJLtFsV3A1cA/AhWHMcaYzgtk9dEsYIuqbgMQkSXARcDGpgKqusN97dhetowxxvS6QFYfpQEFfuOF7rQuE5GFIpIrIrklJSU9EpwxxphjBTIptHYuVrfOf1XVh1Q1R1VzUlJa72jLGGPM8QtkUigEMvzG04G272pujDEm6AKZFFYDWSIyWkQigCuAZQF8P2OMMccpYElBVX3ATcByYBOwVFU3iMidInIhgIjMFJFC4DLgLyKyIVDxGGOM6Vif6+ZCREqAnd2cPRko7cFwAqEvxAh9I06LsWdYjD0j2DGOUtUOG2X7XFI4HiKS25m+P4KpL8QIfSNOi7FnWIw9oy/ECAG+otkYY0zfYknBGGNMs4GWFB4KdgCd0BdihL4Rp8XYMyzGntEXYhxYbQrGGGPaN9COFIwxxrTDkoIxxphmAyYpdHRvh1AgIjtE5FMRWSsiIXHPURFZLCLFIrLeb9oQEXlVRPLd58EhGOMiEdntrsu1InJ+kGPMEJE3RWSTiGwQkVvc6SGzLtuJMdTWZZSIrBKRdW6cd7jTR4vIh+66fMrtSSHUYnxERLb7rctpwYqxLQOiTcG9t8Nm4HM4fTKtBq5U1Y3tztjLRGQHkKOqIXMRjoicBhwGHlPVSe60XwEHVPUeN8EOVtUfhFiMi4DDqvqbYMXlT0SGA8NV9SMRiQfWAF/EuZ9ISKzLdmL8MqG1LgWIVdXDIuIFVgC3AN8FnlHVJSLyILBOVf8cYjHeALygqk8HI67OGChHCs33dlDVOqDp3g6mA6r6DnCgxeSLgEfd4UdxNhxB00aMIUVVi1T1I3e4AqfrlzRCaF22E2NIUcdhd9TrPhQ4C2ja2AZ7XbYVY8gbKEmhx+7tEGAKvCIia0RkYbCDacdQVS0CZ0MCpHZQPlhuEpFP3OqloFZx+RORTGA68CEhui5bxAghti5FxCMia4Fi4FVgK1Dm9rkGIfAfbxmjqjaty5+76/L3IhIZxBBbNVCSQo/d2yHA5qrqDJxbmN7oVouY7vkzMBaYBhQBvw1uOA4RiQP+BXxbVQ8FO57WtBJjyK1LVW1Q1Wk4XfLPAia0Vqx3o2rx5i1iFJFJwA+BE4GZwBAgaNWubRkoSaFP3NtBVfe4z8XAszg/9lC0z61/bqqHLg5yPMdQ1X3un7IR+CshsC7duuV/AU+o6jPu5JBal63FGIrrsomqlgFvAScDiSLSdIvhkPmP+8W4wK2iU1WtBR4mhNZlk4GSFEL+3g4iEus27iEiscA5wPr25wqaZcDX3OGvAc8FMZZWNW1oXRcT5HXpNjz+L7BJVX/n91LIrMu2YgzBdZkiIonucDQwH6f9403gUrdYsNdlazF+5rcDIDhtHiH3Hx8QZx8BuKfR3Qt4gMWq+vMgh3QUERmDc3QAEA78IxRiFJEngTNwuv3dB9wO/BtYCowEdgGXqWrQGnrbiPEMnOoOBXYAX2+quw8GEZkHvAt8CjS6k3+EU2cfEuuynRivJLTW5RSchmQPzo7tUlW90/0PLcGplvkYuMrdIw+lGN8AUnCqtNcCN/g1SIeEAZMUjDHGdGygVB8ZY4zpBEsKxhhjmllSMMYY08ySgjHGmGaWFIwxxjSzpGBMCyLS4NeL5VrpwV51RSRT/HpzNSbUhHdcxJgBp9rtnsCYAceOFIzpJHHud/FLt5/8VSIyzp0+SkRedzs5e11ERrrTh4rIs26f+utEZI67KI+I/NXtZ/8V94pXY0KCJQVjjhXdovrocr/XDqnqLOB+nCvkcYcfU9UpwBPAfe70+4C3VXUqMAPY4E7PAh5Q1YlAGXBJgD+PMZ1mVzQb04KIHFbVuFam7wDOUtVtbsdxe1U1SURKcW5OU+9OL1LVZBEpAdL9u1pwu6R+VVWz3PEfAF5V/VngP5kxHbMjBWO6RtsYbqtMa/z742nA2vZMCLGkYEzXXO73/L47vBKn512A/8C59SLA68A3oPmGK4N6K0hjusv2UIw5VrR7x6wmL6tq02mpkSLyIc4O1ZXutJuBxSLyfaAEuMadfgvwkIhch3NE8A2cm9QYE7KsTcGYTnLbFHJUtTTYsRgTKFZ9ZIwxppkdKRhjjGlmRwrGGGOaWVIwxhjTzJKCMcaYZpYUjDHGNLOkYIwxptn/A8o5OS0/ogPLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [1], 'hidden_layer_size': [128], 'activation_function': ['linear']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJztvXl8m9WV//8+kizZlmQ73uLszgZkgxBC2ddCSymlnQ50ZUopLV2gZUqXoTPz+5Z22imdmW4UWkopW0uhlLKVspWt7IQkhJCQhOyJkzjed1uypPv74z6yZceL5FiWLZ/36+WXnvU+99Ejf+55zj33XDHGoCiKomQ/rkxXQFEURRkbVPAVRVEmCSr4iqIokwQVfEVRlEmCCr6iKMokQQVfURRlkqCCr2Q9InKdiPwh0/XIZkRko4icOdrHKqOLCv44RkR2iUhYREr7bV8nIkZEKjNTMyVbEJFK57fkOZxyjDFLjDHPj/axyuiigj/+2Ql8Mr4iIsuAvMxVJ7McrjCN9rVHUh8RcY9OjVK+7oi+u0x+58roooI//vk98JmE9UuBuxIPEBGfiPyfiOwRkYMicrOI5Dn7pojIoyJSKyKNzvLMhHOfF5H/EpGXRaRVRJ7q/0aRcGypc36TiDSIyIsi4nL2HSsia50y/iQi94rID5x9nxWRl/qVZURkgbP8QRF5U0RaRGSviFyXcFzcAr1cRPYAzzrbTxSRV5y6vJXoIhCRuSLyD6cufwcGvJ+E4y9w3pqanDKPTti3S0T+TUTWA+0i4hlk2yLnu2xyXBYXJpRxh4j8WkQeE5F24KwB6jBdRB5xvtdtIvKFhO2dIlKccOyxIlInIjnO+udEZJPzfJ8UkTn9vucrRWQrsHWA23/B+WwSkTYROcl5Xi+LyM9EpAG4TkTmi8izIlLvXPtuESnq9z2d4yxfJyL3ichdzjPYKCIrR3jsCue30Soif3Z+Wz8Y6nkqQ2CM0b9x+gfsAs4BtgCLADewF5gDGKDSOe7nwCNAMRAE/gr8yNlXAvwzkO/s+zPwUMI1nge2A0dg3xyeB64fpD4/Am4Gcpy/0wABvMBu4OvO9ouAbuAHznmfBV7qV5YBFjjLZwLLsAbI0cBB4CPOvkrn2LsAv1PHGUA9cL5zzrnOeplzzqvATwEfcDrQCvxhkHtaAdQAJzjf76XO9+5LeAbrgFlA3kDbnHveBvy7812c7VzzSOf4O4Bm4BSnvrkD1OMfwK+AXGA5UAu819n3LPCFhGP/F7jZWf6Ic+1FgAf4T+CVft/z353fRt4A141/v56EbZ8FIsBXnTLzgAXO9+wDyrANxc/7/1ad5euALuf5uLG/m9dSPZbe39XVznf8USCM87vSvxFoSqYroH9DPJxewf9P5x/hPOef1+P8k1ZiBbcdmJ9w3knAzkHKXA40Jqw/D/xnwvpXgCcGOff7wMM4Qp2w/XRgPyAJ214hScEf4Do/B37mLMcFaV7C/n8Dft/vnCexYj3bESt/wr4/Mrjg/xr4r37btgBnJDyDzw3wXD6XsH4aUA24ErbdA1znLN8B3DXEc54FRIFgwrYfAXc4y58HnnWWBdvon+6sPw5cnnCeC+gA5iR8z2cPce3499tf8PcM89v8CPBm/9+qs3wd8HTCvsVAZ6rHOr+rff1+Vy+hgj/iP3XpTAx+D3wK+494V799ZVjrfY3jTmgCnnC2IyL5IvIbEdktIi1Yy6xI+vqRqxOWO4DAIPX4X6w1+ZSI7BCRa53t04F9xvmPdNid7M2JyAki8pxYt1Mz8CUOdcPsTVieA1wcv1/nnk8Fpjl1aTTGtCdZlznAN/qVNcspZ6BrD7RtOrDXGBPrd80Zw5SReH6DMaZ1kPPvB04SkelYETTAiwn1/0VC3RuwjUKy1x6MPueISLnjptvn/I7+wNCusv6/qVwZvC9gsGMH+l2N5F4UBxX8CYAxZje28/Z84IF+u+uATmCJMabI+Ss0xsRF+xvAkcAJxpgCrGCAFYVU69FqjPmGMWYe8CHgGhF5L3AAmCEiiWXOTlhuxzZK9sIiFf2K/iPWJTXLGFOIdRv1r1//f/rfJ9xvkTHGb4y53qnLFBHxD1KX/uwFftivrHxjzD2DXHugbfuBWeL0ZyRcc98wZSSeXywiwYHON8Y0AU8BH8M2/PckiOBe4Iv96p9njHklyWsPtq//9h852452fkeXMILfUIoM9LualeZrZjUq+BOHy7Gv5omWK45V+VvgZyJSDiAiM0Tk/c4hQWyD0OR0/H13pBVwOjcXOP+ALVg3RBTrM48AX3M6MD8KvCfh1LeAJSKyXERysa/xiQSxFm6XiLwHK2pD8QfgQyLyfhFxi0iuiJwpIjOdxnE18D0R8YrIqdjGaTB+C3zJecsQEfGL7UQODnFOf17HNmrfFpEcsR3IHwLuTeZkY8xerAvsR869HI193ncnHPZHbOf9PzvLcW4GviMiSwBEpFBELk6h7rVADJg3zHFBoA37O5oBfCuFa4yUV7G/r6uc39WH6fu7UlJEBX+CYIzZboxZPcjuf8O6Wl5zXrefxlr1YP3hedg3gdew7p6RstApuw37z/grY8zzxpgwtkPts0Aj8HES3kSMMe9i/f9PYyNFXupbLF8Bvi8ircD/A+4bqhKOQH4Y20lai7Vyv0Xv7/lT2E7YBmwD198NlljWauALwI1O3bc595E0zv1fCHwA+z3/CviMMWZzCsV8EutP3w88CHzXGPP3hP2PYL//g8aYtxKu/SDwY+Be59lvcOqRbN07gB8CLztuoRMHOfR72A7uZuBvHPqmOeok/K4uB5qwbxWPAqF0Xztbkb7uMUUZHUTkDqDKGPOfma6Lkj2IyOvYCKXbM12XiYha+IqijFtE5AwRqXBcOpdiw3YP5y11UqMj6BRFGc8ciXXxBbDjRS4yxhzIbJUmLurSURRFmSSoS0dRFGWSMK5cOqWlpaaysjLT1VAURZkwrFmzps4YU5bMseNK8CsrK1m9erDIQ0VRFKU/IpL0qHZ16SiKokwSVPAVRVEmCSr4iqIok4Rx5cMfiO7ubqqqqujq6sp0VcaE3NxcZs6cSU5OTqaroihKljHuBb+qqopgMEhlZSV9k+ZlH8YY6uvrqaqqYu7cuZmujqIoWca4d+l0dXVRUlKS9WIPICKUlJRMmrcZRVHGlnEv+MCkEPs4k+leFUUZWyaE4E8mYsbQHooQjWnKC0VRRhcV/CGor69n+fLlLF++nIqKCmbMmNGzHg6HkyrjsssuY8uWLUlfsz0UobGjm9d21I+02oqiKAMy7jttM0lJSQnr1q0D4LrrriMQCPDNb36zzzE9kwO7Bm47b789tbTdcct+b0PHCGqsKIoyOGrhj4Bt27axdOlSvvSlL7FixQoOHDjAFVdcwcqVK1myZAnf//73e4499dRTWbduHZFIhKKiIq699lqOOeYYTjrpJGpqag4pO+7JqWrsHKvbURRlkjChLPzv/XUj7+xvGdUyF08v4LsfWpLyee+88w633347N998MwDXX389xcXFRCIRzjrrLC666CIWL17c55zm5mbOOOMMrr/+eq655hpuu+02rr322j7HxJx01VWNauErijK6qIU/QubPn8/xxx/fs37PPfewYsUKVqxYwaZNm3jnnXcOOScvL48PfMBON3rcccexa9euQ46JC/6+JrXwFUUZXSaUhT8SSzxd+P3+nuWtW7fyi1/8glWrVlFUVMQll1wyYCy91+vtWXa73UQikUOOUZeOoijpQi38UaClpYVgMEhBQQEHDhzgySefHHFZxlH86pYuwpHYaFVRURRlYln445UVK1awePFili5dyrx58zjllFNGXFbcpWMMHGjuZE6Jf5gzFEVRkmNczWm7cuVK038ClE2bNrFo0aIM1Wjs2dvQwebNm/nCIwe4+/MncMqC0kxXSVGUcYyIrDHGrEzmWHXpjDNixuBysitopI6iKKOJCv44I2bA4xLcLtGOW0VRRhUV/HFGLGYQESoKclXwFUUZVVTwxxlxl87MKXnq0lEUZVRRwR9nxIxNkTxzSr5a+IqijCoq+OOMmDEI1sLXWHxFUUYTFfwhGI30yAC33XYb1dXVSR0bMwZxXDrxWHxFUZTRQAdeDUEy6ZGT4bbbbmPFihVUVFQMe2yPS6coH7ApFnTwlaIoo4EK/gi58847uemmmwiHw5x88snceOONxGIxLrvsMtatW4cxhiuuuIKpU6eybt06Pv7xj5OXl8eqVav65NRJJJ5bXwRmTMkDNBZfUZTRY2IJ/uPXQvXbo1tmxTL4wPUpnbJhwwYefPBBXnnlFTweD1dccQX33nsv8+fPp66ujrfftnVsamqiqKiIX/7yl9x4440sX758yHLjaRUEYVphrsbiK4oyqqRV8EVkF9AKRIFIssN/xztPP/00b7zxBitX2tvp7Oxk1qxZvP/972fLli1cffXVnH/++bzvfe9Lqdx4pkwR8LhdGouvKMqoMhYW/lnGmLpRKSlFSzxdGGP43Oc+x3/9138dsm/9+vU8/vjj3HDDDfzlL3/hlltuSbrcmKP48dQKGouvKMpoMuGjdIwxbDrQQnXzofnn08U555zDfffdR12dbcfq6+vZs2cPtbW1GGO4+OKL+d73vsfatWsBCAaDtLa2DltuoksH0Fh8RVFGlXRb+AZ4SkQM8BtjzCHmrohcAVwBMHv27JQvICIYA5HY2MWrL1u2jO9+97ucc845xGIxcnJyuPnmm3G73Vx++eVOx6vw4x//GIDLLruMz3/+88N22ia6dKBvLL7XM+HbZkVRMkxa0yOLyHRjzH4RKQf+DnzVGPPCYMePND3yuwdb8bpdVJZO7PDF1q5udta1E2vcx/JlS3h43T6uvncdf73qVJbNLMx09RRFGYeMm/TIxpj9zmcN8CDwnnRcx+MSIrHxk9d/pPRY+M76SfNLAHhxW21mKqQoSlaRNsEXEb+IBOPLwPuADem4lsflIjqGLp10Effhxztty4O5HFUR5KWto9PnrSjK5CadFv5U4CUReQtYBfzNGPPESAoazu3kcQuRaBZY+DHT4/+Pc9rCUlbvaqQzHM1gzRRFyQbSJvjGmB3GmGOcvyXGmB+OpJzc3Fzq6+uHFH2PS4ga0xPWOFGJxgyRjha8Pl/PtlMXlhGOxnh9Z30Ga6YoSjYw7kfazpw5k6qqKmprB/djt4ciNHZ042q2o1MnKi2d3ayv7uCSs4/t2faeymK8Hhcvba3jzCPLM1g7RVEmOuNe8HNycpg7d+6Qxzy1sZorHlnDo189lUUzJm40y4+f2MytL1fxhfN7Lfw8r5vjK6fwovrxFUU5TLIiuLskYOPa69pCGa7J4dEZjpKX4z5k+2kLy9hysJWalrEbXKYoSvaRHYLvtxZxfVvyOerHIx3hCPneQ1+6Tl1QCqBWvqIoh0V2CL5j4de3T2wLvyMcJc97qIW/eFoBJX4vL21TwVcUZeRkheAHfB68Hhf17RPbwh/MpeNyCacsKFXBVxTlsMgKwRcRSvzeLHDpRMkfwMIHWDqjgNrWEM2d3WNcK0VRsoWsEHywbp36Cd5p29E9sEsHbOZMgH2aPVNRlBGSPYLv92WBSycyqIU/yxH8vZofX1GUEZI9gh/IFpfOwEMjZvbMcasWvqIoIyNrBL804KO+PTRs3p3xTNcQLp2i/Bz8XrfOgKUoyojJGsEv9nvp6o7RMYGTjHWEo+QPEKUDtmN6VnE+exvUwlcUZWRkjeCX+J1Y/Anq1jHG0Nk9eJQO6By3iqIcHlkj+KUBZ7TtBB181dUdwxjIG8SHDzZSZ19j54R2WymKkjmyRvB7RttOUAu/IxwBGNbCbw1FNBZfUZQRkTWCX+yf2OkV4n0Pg3XaQm8svkbqKIoyErJG8OMJ1OomqIXf2W0FfzgLH1A/vqIoIyJrBD/P68bvdU9gl87wgj9LLXxFUQ6DrBF8gJKAj4YJ69KxPvy8nME7bQvyPAR9HvY2qIWvKErqZJXgF/u9Eza9QmcSPnwRYWZxvlr4iqKMiKwS/NKAd8L68JNx6UA8Fl8FX1GU1MkqwS/x+yZsxsweC3+QkbZxZk7JY29jh8biK4qSMtkl+AEvDe3hCSmGycThg+247QhHaezQWHxFUVIjywTfRyRmaOmMZLoqKdPRE5Y5eKctaGimoigjJ7sE3xl8VTcBI3U6w1FEIDdn6EcSH3ylSdQURUmV7BL8CZxeIT6frYgMedzMYrXwFUUZGWkXfBFxi8ibIvJouq8VH207EWPxO4bJlBmnIDeHwrwcjdRRFCVlxsLCvxrYNAbX6bHwJ2JoZmd48MlP+qNpkhVFGQlpFXwRmQl8ELg1ndeJE8y1HZ5toQnYaRuOkD/EKNtEZhTlsa9JLXxFUVIj3Rb+z4FvA7E0XwfA8YFDx4QU/OQt/KL8nAkZiaQoSmZJm+CLyAVAjTFmzTDHXSEiq0VkdW1t7eFeE7/XQ1to4k1z2BlOzocP4Pd5aJ+AjZqiKJklnRb+KcCFIrILuBc4W0T+0P8gY8wtxpiVxpiVZWVlh31Rv889IcWwIwXBD/o8tIUjE3KAmaIomSNtgm+M+Y4xZqYxphL4BPCsMeaSdF0vjt8Rw4lGZ3d0yOkNE/H7PBjDhJ6wXVGUsSer4vAB/F7PBPXhR8gfJo9OnMAE7pxWFCVzjIngG2OeN8ZcMBbXsi6diWf5ptJpG/BZwW/tUsFXFCV5ss7CD/g8GbN8n9xYzSdveY1INPWgpFTi8OOCPxH7KhRFyRxZJ/j5Xk9P5smx5tXt9by6o55VOxv6bD/Y0kVNS9eg54UjMSIxk7RLx+9Tl46iKKmTdYLv92UuLLPOycX/2IYDPduMMVxy6+tcc99bg56XzGxXiQRU8BVFGQFZJ/iBDIZlxgX/iQ0HicZsyOTrOxvYWtPG5urWQc/r6I7nwk8uSqdnRLH68BVFSYGsE/x8r4fO7miP4I4ldW1h8r1u6tpCrN5l3Tp/fH2Psy9ES9fAk5Y0ttvtcSEfjrhLp30Chp8qipI5sk7w4+6OTPjx69pCnLekAp/HxeMbqmloD/PEhmrmlNgc9jtr2wc8b8P+ZgAWTStI6joapaMoykjIOsHvsX7H2I/fHY3R1NHN7JJ8zjiijCc2VPPn1XsJR2N8+/1HAbCzbmDBf7uqmYDPw7xSf1LX8nlceFyiUTqKoqREFgq+7fgc6w7Nhnabkrk04OP8ZdOobunil89u47g5UzhncTkugR2DCP76qiaWzijA5Rp68pM4IkIgN3Php4qiTEyyT/C9mXHp1LbaDtvSgI+zF5XjdbtoC0X41Htm4/O4mTklnx21bYecF47E2HSglWNmFqV0PZskTgVfUZTkyT7Bz1DIYjxCpyzopSA3h9OPKKMoP4cPHj0NgHll/gFdOluqWwlHYxydouAHcz0apaMoSkokFxYygQhkyIcfn2WrNGCnWbz+n5fR3NlNrjOYam6pn1U7GzDG9Jm39q2qJgCOnlmY0vX8Po9G6SiKkhJZZ+HnOz78sXbpxC38uOCXBnzMLwv07J9X6qcjHKWmte98u+urmpiSn8PMKXkpXS/gUwtfUZTUyDrBz9Qo1LrWEHk57h6XUn/mllrx397Pj7++qpllM4v6WP3JkMmcQYqiTEyyTvD9GUosVtcWojToHXT/vDIbcpnox+8MR9la08YxKbpzQAVfUZTUyTrBjycgG+t8OnVt4R53zkBUFOSSm+PqM/jqnQPNRGMm5Q5bsDnx1aWjKEoqZJ3gu1xCvtc95pOg1LWFKPEPLvgul1BZ0jdS5629doRtqh22EO+0jRLLQAoJRVEmJlkn+JCZCJa6tjBlQ7h0wLp1Egdfra9qYmqBj6kFuSlfL6j5dBRFSZGsFPzAGKdIjsYMDe2hIV06APNKA+xp6KDbmSBl/b5mls1I3Z0DmUshoSjKxCUrBX+sXTqNHWFihmEFf26pn2jMsLehg4fX7WNHbTvHV04Z0TV757UdOAOnoihKf7Ju4BXEJ0EZO8HvH4M/GHOdSJ0/vLaH37+2ixPmFnPpyZUjumbAl5nOaUVRJi5ZaeEHxtiHX9caH2U7jA/fyYZ528s7mVca4JbPrOwZiZsqAV8OoJOgKIqSPFlr4bfXjZ3l22PhB4e28IvyvZQGfOS4hTs+dzyFeTkjvmamsoIqijJxyU7B947tNIfJunQAfnfpSsqCPqYVppZKoT/BuIWvgq8oSpJkp+D7PGMq+LVtIbxuFwVJTFF4zKyRReX0J27h6yQoiqIkS1b68Md6UFJ9W5iSgDflfDiHQ2+Ujgq+oijJkZ2C77XWb2f32Pjx69qGj8EfbXweNzluUcFXFCVpslPwxziBmhX8oSN00oGmSFYUJRXSJvgikisiq0TkLRHZKCLfS9e1+jPWKZLrWodOnJYuArlj21ehKMrEZkjBF5FLEpZP6bfvqmHKDgFnG2OOAZYD54nIiSOtaCrke+Mdmul36RhjqG8PDRuSmQ78Xg+tKviKoiTJcBb+NQnLv+y373NDnWgs8dk+cpy/MelFDYxhYrHmzm66oyYjFr7Oa6soSioMJ/gyyPJA64eeLOIWkXVADfB3Y8zrAxxzhYisFpHVtbW1w1Y4GcbSh98bgz/2Pnyd11ZRlFQYTvDNIMsDrR96sjFRY8xyYCbwHhFZOsAxtxhjVhpjVpaVlQ1b4WTwj6EPv9ZJq1CWCR++dtoqipICw40UOkpE1mOt+fnOMs76vGQvYoxpEpHngfOADSOpaCr4eyYyT78PP9m0CulApzlUFCUVhhP8RSMtWETKgG5H7POAc4Afj7S8VBhLl05ta/JpFUYbFXxFUVJhSME3xuxOXBeREuB0YI8xZs0wZU8D7hQRN9Z1dJ8x5tHDqWyy+L1j59KpaQ2R4xam5I88EdpI8fs8dISjRGMGt2vsRvkqijIxGVLwReRR4FpjzAYRmQasBVZj3Tu3GGN+Pti5xpj1wLGjWtskcbuE3BzXmFj4Na1dlAV8Y5pWIU4wtzcaqSB37BscRVEmFsN12s41xsR97pdhI20+BJzAMGGZmSbg5NNJN7WtIcpGMCftaDDWI4oVRZnYDCf4ifPnvRd4DMAY0wrE0lWp0WCsMmbWtIQoz0CHLSSMKNZIHUVRkmA4wd8rIl8VkX8CVgBPADidsOPah+D3jpHgt3ZlTvA1Y6aiKCkwnOBfDiwBPgt83BjT5Gw/Ebg9jfU6bPw+d9pTK4QjMRo7uikPZsalM9Y5gxRFmdgMF6VTA3xpgO3PAc+lq1Kjgd/noaE9nNZr1Dox+OUFmXXpqA9fUZRkGC5K55Gh9htjLhzd6owefp+HPQ0dab1GTUsXQMZ9+K3qw1cUJQmGG3h1ErAXuAd4nSTy54wXxmJe2xpn0FWmXTpq4SuKkgzDCX4FcC7wSeBTwN+Ae4wxG9NdscPF7/PQkWYffo/gZ8ilM5Y5gxRFmfgM2WnrJD97whhzKbajdhvwvIh8dUxqdxgEnEySxqQvI3NtSxciUOIf+0yZAF6PC6/HRdsY5P1XFGXiM5yFj4j4gA9irfxK4AbggfRW6/Dx+zzEjJ3XNt877G2OiJrWECV+Hx535maKtPl0uoc/UFGUSc9wnbZ3AkuBx4HvJYy6Hff4E2a9SqfgZ6rDNo6mSFYUJVmGU8J/AdqBI4CvJeSLEeykVgVprNthkZh2oCxNolzT2pUx/32cgM+jUTqKoiTFcD58lzEm6PwVJPwFx7PYw+AdmlsPtvKLp7eOim8/k2kV4swvD7B+X3Na+yoURckOMud8TjPxFMn9J0G5f00VP3v63Z489iMlGjPUtYUyFpIZ57SFpdS2hthysDWj9VAUZfyTtYJfmGdT/TR29B1tu7veDsbaUdd+WOU3tIeJmcyFZMY5bWEpAC++W5fReiiKMv7JWsGfXZwPwO76vsK+2xl9u6P28AS/pjWzo2zjTCvMY2F5gBe2js4E8IqiZC9ZK/iF+TkU+73srOtNr2CMYY/TAOysazus8uODrsoy7NIBOG1hGat2NtDVrfH4iqIMTtYKPkBlSX4fYa9vD/dMirLzMF06tS3xtAqZtfDBunVCkRhv7GrIdFUURRnHZLXgzy0NsCvBwo/77wM+z2H78OMunXSFfKbCCfOKyXELL25VP76iKIOT5YKfT3VLFx1hG5q5p8GK/KkLStlT30F3dOSTdtW0hijI9ZCb407txKa90NU84usORL7Xw8o5xSr4iqIMSVYLfmWpH6DHyt9d34EInH5EGZGYoaqxs+fYh9ft4/41VUmXXdMSojzVuWwjYfjtWfDsD1M7LwlOO6KUTQdaet48FEVR+pPVgj83LvhOR+2e+g6mFeRyZEUQ6Ntx+79PbuF/n9yc9ACmEU1tuP0ZaK+FturUzkuC0xeWAfDyNrXyFUUZmKwW/MoSK/jxDtrdDR3MLslnntMQxEMz9zZ0UNXYycGWEPuaOgcurB8jyqOz/j77GRr9QVKLpxVQlJ/Da9u141ZRlIHJasH3+zyUB329gl/fwZxiP1P8Xoryc3o6bl/dXt9zzprdjcOWa4yxgp+KSyfUClse710eZVwuYcn0AjZXt4x62YqiZAdZLfhg3Tq76tppD0WoawsxuyS/Z/tOx8J/dUc9JX4v+V43a5MQ/JbOCOFILDULf/PfINIJwekQOrwxAINxVEUBWw62Eo1pXh1FUQ5lUgj+zrr2nvlt5ziCP680wM66dowxvLq9nhPnl7B8VhFr9gwv+CMKyVx/HxTOhnlnpsXCBziqIkhXd+yQ0cWKoigwCQS/stRPfXuYDftsKOScYuu/n1fmp7qli437W6hu6eKkeSUcN2cKmw60DjtH7DsHrNtk5pT85CrRVgM7noNlF0FuQdoEf9E0m8B0c7UmUlMU5VDSJvgiMktEnhORTSKyUUSuTte1hiIeqfOPd22umUSXDsAfV+0B4OT5VvCjMcNbe5uGLPPPq6uYUZTHsbOKkqvExgfBxODoj4E3AOFWSEM64wXlAVwCmw+oH19RlENJp4UfAb5hjFmEnQ/3ShFZnMbrDUhc2F/cWkdRfk5PFs349off3MfUAh9zS/0cO3sKMHTH7d6GDl7aVsfFK2ficsmgx/Vhy2NQvhjKF4Hy0JMoAAAgAElEQVQvaMW/u2P481IkN8fNvLIAm9TCVxRlANIm+MaYA8aYtc5yK7AJmJGu6w3G7OJ8RKC5s5s5xb0umHjIZns4ysnzSxERCvNyOGJqYEg//p/XVCECF6+clXwlWg9C8Ty77LNjANLXcRvUSB1FUQZkTHz4IlIJHAu8PsC+K0RktYisrq0d/RS/uTluphfmATDbEXmAPK+b6YU2rPKkeSU924+bM4W1uxuJDRDpEo0Z7l+9l1MXlDKjKC/5SnQ2Qp59e+gV/PT58fc2dNLapRObK4rSl7QLvogEgL8A/2qMOcT0NMbcYoxZaYxZWVZWlpY6xN03iRY+wLyyAAAnze8V/BWzp9DSFWFb7aEW+Evb6tjf3MXHj0/BugfoaoI8x9/fI/jpscKPckYRv6szYCmK0o/hJjE/LEQkByv2dxtjHkjntYaisjSfl7b1dtjGOXFeMa2hCLMSGoLj5lhL/I5XdhGJxnjh3TrmlOTzT8fO4OlNNRTl53Du4qnJX7y7EyJdh1r44UFcOqFWeOlncPq3ISf1XPtHOZE6mw60ctyc4pTPVxQle0mb4IuIAL8DNhljfpqu6yTD3FJryfe38K86eyFXnb2w37F+SgNe/vj6HoI+D6cuLGVLdSvXPvA2AJ89uRKfJ4UMmZ1Of0Bc8L22LoO6dDY/Bi/+BOaebmP2U2R6YS7BXI/68RVFOYR0WvinAP8CvC0i65xt/26MeSyN1xyQs48q59XtdSydUTjssSLC7y49npaubk6YW4LX48IYw1tVzTy/pYZPnTA7tYt3OiGeuf1dOoMI/sEN9rOjfuD9wyAiLKooYPMBdekoitKXtAm+MeYlIMm4xfQyt9TPrZcen/Txx/SLrxcRls8qYnmycfeJ9LfwfdblMrjgb7SfHSNPgnbUtCAPrN2HMQb7oqUoijIJRtpmnC7Hwu8R/GFcOnELv33kaY6PqiigLRTpk+9fURRFBT/d9Fj4ztuBJxdcnoEFv60W2g7a5RG6dMBa+KApFhRF6YsKfrrp79IRcdIrDBClE7fuATpGbuEfOVVDMxVFORQV/HTT2QTi7vXdg10eyMKP+++L5x+Whe/3eSgL+thTP/rpGxRFmbio4KebzkbILbSWfRxfcHDBD0yFsiMPq9MWbEqJeEpoRVEUUMFPP4lpFeL4AoMI/tswdSnklxxWpy2o4CuKcigq+KPJ+vvg5lMhFuvd1tU0gOAPYOFHu6F2C0xdYgW/o75vCuWDG2HVb5OuyqzifPY3dxKOxIY/WFGUSYEK/miy8wWofhs6E9wxnY29ETpxfMFDO23rt0E0DBXLrODHuvs2Cqtvh8e+CZFQUlWZU5yPMSQ9KbuiKNmPCv5o0rTbfrbs793WOYCF7x3ApVPtROhMXQL+UrucGKkTLzOx7CGI5w3S6Q4VRYmjgj+aNO6yn60HercN6MMfIErn4AZw5UDJQmvhQ9+O25Z9fT+HYbaTN2iv+vEVRXFQwR8tohFojouyY4XHYtDV3JtHJ47PicNP9PUf3AhlR4HHC/lxCz8hNDNeZnNygl8W8OHzuLTjVlGUHlTwR4uWKjBRu9xabT9DzYAZuNMW+vrxD26w7hyAfCetcTxSJxKC9pre6ySByyXMLs5nt8biK4rioII/WjTu7l1udazx/qNs4/TPmNnRYN1AFUvteo9Lx7HwE11ESVr4oKGZiqL0ZeILfjQCGx6AfWsyW494h23eFGhxBLp/Hp048Zz4cQu/YYf9LFlgP31BcHt7BT+xozZJHz7Y0My9DR0Yc+h0jYqiTD4mvuCLCx75Gqy7J7P1aNxtUyjMOK7XIu/slykzTv8Uyc2Om6bAmeNdxInFd1w6ccGfMjclC39OST7t4Sj17eEUb0ZRlGxk4gu+y2V939VvZ7YejbugcCYUzkoQ/OFcOs6sVHGrvXBm7zH5Jb1ROvH9s06A5r1JVykeqaNuHUVRIBsEH6zv++DGvlEvY03TbpgyBwqmW1dMJNQr+ANF6QCEHJdO8z7w5PVtGOKjbeP7fYVQdoQduRtOLrZ+PIdmRmOGWExdTYoylmSJ4C+DcGuvH30gBptwZLRo3A1FcyA4za63HkiY/GSAkbaJdWqpgsIZfROsJebTadlnG5IC5w0gSbdOfHL28Zg189O3vsYPH9uU6WooyqQiOwR/6jL7OZhbZ9sz8D/zUvJ/p0S4w4ZNTkkQ/JYD1oef4wePr+/xh/jw9/X67+P4S/t22hZMt40CJB2amZvjZmqBj93j0MLfuL+F9VVNma6GokwqskPwyxfZztvECUQS2bvK5qmpTZNF2bTHfhZVQkHcwt8/cFoFSIjSiVv4+/r678Fa+F1NNgopLvjxRmGCh2Z2dUdp7Yqwv6kr01VRlElFdgi+N9+GNFYPIvi1m+1n4xAun8Mh7kpKtPBbqwdOnAZ2NK3bZy38aLc9tr+FH4/Fbzto/wpmWNGHEYVmjidqWmwCuOqWLiJRzeapKGNFdgg+2Dzyg7l0arfYz7glPtrEG5KiOdai9+Raq3ygPDpx4jnxW6sB0+uuiRMX/IMb7f6C6dY1FJjaG8aZBLOL86lu6aKrO5rybaWLmlZr2UdjhoOtyWX/VBTl8Mkewa9YCs17emPf40S7bephGLpT93Bo3GWjbALltuM1WNHbaTuQhQ9OTvy2Xmu9YACXDkD1W/Yz3iAUzEjJwp9TYtMkVzWOnzTJNQkiv1/TNyvKmJFFgn+0/YzPCxunYafNLQ/ps/DjIZnxKJvgdKfTtvHQkMw48UlQ4tb6YBZ+/K0l7vIpnJGyDx/gtR1958jd29DB/WuqMjIKt6al13e/bxw1RIqS7WSP4E918tD0d+vUOe6ciqPT58OPh2TGKZhmLfyhXDpeZxKUHgt/gCgdSBB8x39fMNM2EkkK9dEzizhuzhSue2QjT220Sd3W7W3iwze9zDf//Bavbh/5ZOkj5WBrCLfLNo46QYuijB3ZI/jBCmsVH+wn+PEO24Xn2lQFSQ5aShpjei38nrpMs6Ic6RrChx+0I22b99kwzdyCvvvznIyZDTtsVE88lLNwBnS398b4D0OO28Xtlx3PkhmFXPnHtfz0qS184pZX8fvcFPu9/O6lnSne8OFT0xKiPOij2O9VwVeUMSR7BF/E6bjtF6lTu8WmOyhfbNeTcevsX9eb0Gw4OhutcPex8Kf3upGG9OG3OoOqZhy63+O1o2vj5cXdRSMIzSzIzeGuy97DEVOD3PDsNo6YGuSBL5/CJSfO4ZnNNeysG9tZsWpauygP+phRlKc+fEUZQ9Im+CJym4jUiMggsZJpoGIZ1GyysetxajdD2ZG9gjyc4Ida4Y4L4DdnwK6Xh79mYkhmnGBF7/KQUTpt9k2gv/8+TjwvftydA73x+il03AIU5ufwh8tP4HsXLuGeL5xIWdDHJSfOxut2ccfLY2vl17aGKAvmMr0oV334ijKGpNPCvwM4L43lH0rFMoiGoH6rXY9FoW6rnUmqaLbdNpwff/19dkCUNwB/+ChseXzo42scl1GihR9MEOghXTpDWPjQ23GbGMETF/wUQjPjTPF7ufTkSvw+DwDlwVw+dMx0/rymiubO7pTLGyk1rSGmFviY7lj4mr5ZUcaGtAm+MeYFoGHYA0eTeMft/nX2s2m39aOXHWlDJj15Q4dmGgNv3ArTjoEvvWRH8N77adj69MDHd7XAcz+0g77KjurdHh9tC0NE6RRApBPaaw8dZRsn3nGbaOEHpoLLk7KFPxiXnVJJRzjKfW8kn4XzcAhHYjS0hykP5jKjKI/2cJSWzsjwJyqKcthk3IcvIleIyGoRWV1bW3t4hZUdZf31a++067Xv9m4XsVb+UIK/51WoeQeO/zz4S+DSv9qG4s3fD3z8U/9hhfcjN1ufe5xgguAPGqUT6F0e1sJPEHyX2+kUHh3BXzqjkBPmFnPbyzvpDKd/cFZtm43BLy+wPnyAqqbxNRJYUbKVjAu+MeYWY8xKY8zKsrKywyvM7YETv2KFe+8bvRE6pUfYz6LZQ/vw37jVdpQuvciu+4Iw9wzY9dKhYZBb/w5r74KTvwazju+7z+PrFeuhXDpxhvXh99uf4uCr4bjm3CM40NzFDc9uHbUyByMeg18e9DFjihV8zamjKGNDxgV/1FnxGcgthFdusBE6gYreSJkpc/r68Ks3wOu/sdZy60F45xE49tM2N0+cylNsOGc8PQNAVzM88lX75nDmdwauR3CanQErUdgT8SVa+IO4dPIHcOkATKm09Rkl3/cJ80q46LiZ/PaFHWypTm8a6fgo2/JgLtMdC39fo1r4ijIWZJ/g+wKw8nLY9FfY+Q/rv49TNNvGr3c12/XH/w0e/zb8bAn87lwbSrny8r7lVZ5qP3e/1Lvt7fvtwKoP3QA5uQPXIzjNNjSJOe771DOhIegv6HFmnWAHjBXP61enU2w65prDyP4Zi/VxC/37+YsI5nr4jwffTuvEJD2CX+CjxO/F53Gxv1ktfEUZC9IZlnkP8CpwpIhUicjlw50zapzwRXDnWLdHYmdqYmhm0x4r4sd/Ac681h6/9J+hdEHfsqbMtS6UXQmCv+EB6yaa9Z7B67DgvbDgnMH3xwdS5RX3faNIZM5J8KUXD90/7yz7ueO5vttf/InN/Z8MT/0n3HBsz6xcxX4v3zl/Eat3N/Kn1enrwK1t6UIESvxeRIQZRXkamqkoY4QnXQUbYz6ZrrKHJVgBR3/cdraWHdG7PR6a2bSn179/8lXWRXLmtQOXJWKt/O3PWhdK6wHY/bI9fjDrHeDELw9dx3in7WD++6EommUjg7Y/Byddabc17oJnvm+jeL66tq/LqD+7XoLXbrLLdVt7Gq6Lj5vJ/Wuq+PETmzl/6TQK83NSr9swHGwJURrw4XFbW2N6UZ6OtlWUMSL7XDpxTv26te7nntG7bUql/WzcDW/9CWaf1LttKCpPteGTde/CxocAY98GDoe4S2cw//1wzDvLNjwRJ/Pk+j/bz7aD8NLPBj8v1AYPX9mbuiGeSRQQEa770BKaO7v5xTPp6cCNj7KNM0MFX1HGjOwV/JL5cOXrULqwd1veFGtZb/qrTap29MeSK2vOKfZz14uw4S/Wr55Y7kiIC/5ILHyA+WdBd4edzcsYWP8nW8+lF8GrN0LTIG6Zp79rG7yP3Wnj+RMEH2Dx9AI+cfws7np1F9tr2w45PRYzPPb2gREP1KppDfUR/OlFedS2hghFxk++fkXJVrJX8AdCxPrx97wCbi8s/khy5xXPs6Nn190D+1YfvnUPVvCLZsOMlSM7v/JUGwW04znY/6YdXXz0x+Cc6+z+p6879Jx9a2zo6Ylfgbmn27ebfoIPcM25R5Kb4+a//9a3UzgWM/x/D2/gK3ev5UcjnIDcCn5vR3c8NLNaO24VJe1MLsGHXj/+wvf1xrkPR9yPv2+1XV/yT4dfD5cb/vVtWD7Cro7cQpi50vrx19/X24AVzYKTvwob7rdjERJZ/2c7teJZTihpyQKo335I0WVBH1edvYBnNtfw17f2E42ZHrG/+/U9zCrO4y9rqzjQnJorJhoz1LeFKC9ItPCt+GvHraKkn8kn+PEkZ0d/PLXz4uGZM9/TN1FaJpl3lrXu1/8Jjjivd7zBKf9qUzqs+k3vscZYV9aC9/a6k+KCHzt0XtnLTqlkbqmfr97zJsu//xQX3vQSd7++hy+fOZ8/fv5EjIFbXkgyo6hDfVuImKGPS2dmkY1AUj++oqSfySf4886y8e0L35fieWeAuOCYFBuKdDL/LMBAZ0PfBswXgGUXW4GPjznY/ya0VMGiD/UeVzLf5vMZYNSuz+Pmoa+cwi8+sZwLjp5GJGq45twj+Pb7j2RWcT4fXj6De1btob4t+TlpDzqTl5cluHQqCnNxCfzwsU189Fcv8/U/rVPxV5Q0kbawzHHLkefZv1SZUglXrbZx+eOFGcfZmbPcnkMbsOWfgjd+a8cMrLzMir+47ZtAnBJnzEH9NusK6kdhfg4fXj6DDy8/tGP5y2fO44E3q7j95V188/12cJsxBhkiVDU+efnUBJeO1+Pi+o8ezapdDRxo7uTxDQfo6o7y60uOS/ZbUBQlSSaf4B8OJfMzXYO+uHPgjG+B1983eRvA9GOhbBGs+yMc91nY9AjMPa1vv0Wi4M8/K6VLLygPct6SCu58ZRe76tt5q6qJpo5u/veiYzhvacWA5/SOsu07Ovljx8/iY8fbBuenT23hhme3saW6lSMrBklLoSjKiJh8Lp1s45SrbXbP/ohYK79qFWx+1Ip6ojsHbPqHHP+AHbfJcNXZCwhFYry5p4ml0wupLPFz5R/X8sDagXP118RdOgHfgPsBPnfqXAI+D78cg0RuijLZUAs/mzn6YzY8869XAwJHXdB3v4h9axkgNDMZlkwv5J3vv9+Omu1oILzqNi73ncA1973FnoYOFpZbCz3f52ZeqZ/qlk6m5Ofg9QxuZxTle7n05Dn86vntXH2wlYVT1cpXlNFCBT+bCVbYfD5bn7Qd1cEBXC0lC2yH7giJp0jgjVvxPv9DfvdPt/IV31x+/vTAFvqRSQj45afO4/aXd3Hjc9v4xSeOHXHdxozuTpub6NSvDz6ZjaKMA1Tws53ln7KC39+6j1OyAN55yKZo8AzuahmWDQ8A4H37Xm75l/vZUddGNGZfIlo6u9lR2872ujZWzB5kfoAEiv1ePnNSJbe8sJ0vnzmfoyoKRl6vsWD7c3ZAm7jh/P/JdG0UZVBU8LOdoy6AD/5k8HEHJQvAxGzytbIjbZ7/jgb4xN3JX6NmE9RugsLZsP1ZXG3VLCif1ueQlZVJDnJzuOL0edy/Zi9fu+dNHr7yVPK87pTOH1N2vmA/198L534PcvIyWx9FGQTttM123B7bqTvYRCyJkTq7X7WzeG1+NLWO3I0PAgIf/Y1tPNb/6bCrXez38tOPLefdg218/9F3Dru8tLLzH+Avs2Me3nk407VRlEFRwZ/sxENN696FJ78D/nJAkhdtY6zgV54Kc06GWSfaUNBRmI3r9CPK+PKZ87ln1R4eXb+/z779TZ3c+uIO/vDa7kMnbFn7e5tUbixoq4Gad6hdcjmmeB6suXNsrqsoI0AFf7KTV2St09dutp237/uBHVX81j0Dplw4hIMbbWMRzy+0/FM2E+n+taNSvWvOPYJjZxdxzX1v8YFfvMj3f3Ubj/z4Uk67/u/84G+b+M+HNnDNfesIR5y6bnwIHrkKHvxSUvV/ZVsdV969luaOkWX/jLtzPv9iPg/wXpuYr/bdkZWlKGlGBV+xbp22ajtyd9nFcMyn7CQxe1/rPSYSHthq3/igTTmx+MN2fclHwJNrrfz+bH0aVt8G4fakq5bjdvHrTx/HJ46fxbwCw5fr/psLOx/i94tX8/w3z+Rb7z+Sh9bt53N3vEF7zU7469fsBPIN221n9RCs2d3I5Xeu5vG39/H/HtmQdJ36sPMftIuf7TkL+dH+FURxE1tzx8jKUpQ0o4Kv9Lp1zrseXC5YdIGdNyAu2gffsfP+3ng8rPothJyJzqMRK/hzTwe/M+F6bqEd4LX+z30t3a1Pwz0fh0e/Dj9dbGfneu3XcO+n4SeL4KEre/P+9KOiMJfvf3gpN017nLJYHUxbzsl7bqHSdZArz1rA/118DKt21LDt15+guztC+NLHoGAGkZdv5JVtdTy/pYbXd9TzdlVzTx7/zdUtXHb7Kq7Ie4Z38r9IeP2Dfd1G7z5lXUPDuKZCW5/n5chRfP19i/jSB0/kyehxdLzxe6Jt9Sk/BkVJN2JGwdc6WqxcudKsXr0609WYfNS+CwfegqMv7t320FfgnUfg0ofh7ott+uXgNOuq8QZsCGdHA2DsZO7HXdp7bs1muPMCiHbDJ++xKZnvvMA2LOf+lw1h3Pw3e27RbJi6FN59ws7+9dHf2IykoRYbKhqssLGd+9+E354Nx10Gp38TbnwPzFgBn3kYupo4+MC1TN16L18LX8kbwffyBdcjfK7zDs4P/TfvmMo+t1tRkEtnd5Rj3Lu4M/bv4PIgkU5+yiVccuV1lL/8XVjnRCktuxgu/OXAkTeNu+EXR/M/chlXfef/yPd6eOih+7jwzSvodufhO/mLcOKVECgb7SemKD2IyBpjTFITa6jgKwOz8wW480PgyrHW+6WPWsGuWg1vOZa/vxwKpsExnzw0hr9xF/zhImjaDTn5tq/gc09BcKrd31xlred40ra9q+CBK6BxZ99yShba/oF3H7cdpFeusmWt+i089k1YdCHseB5CLZgTvsxLC77BLS/sIDfawq+qL6G+8oPsP/MnhNtb8O19gbdj81nXnE9XezM/b74abywEX3iGtoe/RWD7o7SLn3w6kdO+AR4f5tkfUhc4kr8s+BGz5y9i2YxCZk7JQ0TY/9wtTP/Ht/jDij9xyYW9Sel+fd8jzHz7Ji5wv474gnDJX4ae8H60MMY2nN2d9jsbas5lJWtQwVcOn1gMblgO0bAV+9IFqZfR0QB/usSGfF72+PDJ50Jt1vqPhCC3wIZ4bnnczt1rYnDxHb2dw7EY3P4B28+w6EI449+gYmnf8v72DRtmesIXrXumq8lO67j4IxDpgi2PwaV/tRFGsRib7rmWyLt/5/+FLyWw4CRK/F46NvyNn7hvJJcwT8SO567I+9gbOIZTFpbxTzu/y1Eda8n59jYK/b3J66Ixwxd/v5rdW97k4ZKbyA83wGcesn0kAF0t9u3HX9Jb1+3PwtPfs/0PJ3wRFpwLJgr71tqJdwJTbV9L6UKbLK8/dVvh8W/bcgBmn2zHX0xdPPB3bYxNqLf+Plh2kf1O+jcQ0Yid0rOj3mZc1fEF4xIVfGV0aDlgLfdkZwYbCGOsgOfkDn/sYLTVWEGbc3JfUepqhva6wRuSum1wo/N/sOhDcOy/2LeBtXdBuBXOuLZ39i+H+rYQ976xl7te3UVbV4SLjpvJZUvczNx6F7z5BzzhFrokj72mlOmmhl2lZ7Dkq38+5NLtoQgf+82rNBzYyf2+H1Ao7fx91tc4zb2Bkr1PIdGw7ftYepGt04b76QzMJseE8bRXQ+Es6Gyy9eyDQPlimHU8FM+3nesN22Hni1aQz/oP+/n0d23DsvSjsPD9MP9sOxajo95GVT3337ax9AYg3Gb3v/+/bcRWpAv2vAbP/6g3z1LxPLjg5/YZ7H3dNixun12fufLQxsAY28C27Ld/Xc32norn2mv0b1xCbbaB8xUM0PB0Q/V6qN4AFctg2nLb1xT/DTTttenLfYGBfwcDEe22v528KcP/Nrua7f02VzmN7hF2qlT3+Bi3qoKvKHF2vWzdTsXzerd1tdgsovPOslNNDkA0ZogZQ447Ia4h3GE7qavXYxp3EWrch+d938ez8OwBy6hrC3H3a3toqd7Ol3Z8lbJYDc0mn6fcp+MvKuX41mcp695PNx5uilzIryMXEhMX35i5hYtzXqZwaqUte9YJ9m2pfqsd1bx3FVS9Yfs5fAX23mYeD2d8GwLl7Kpr52+vbaBi7U85K/YyxfRvNLBvDGf9h3XHrbkdnv2BLS+R8sX2GF/AdrY37OhtIFweiEUBY91+wQo7y5ovCB110LwPugeJxvLk2mPzptjzWw5AyOmwd/tsg+D12/TfIraxjyTMeRyYal1kdVuhdostA2x/UMkCCFRY16HXb6PLIl12kqDWaufvgG34ABCnIaqEvGJ7rzl+iIagu8uK/N7XIBbpdxNi38YC5fY3FG63v49AOZQdZRsFjG0sQi32O8rJs99buN1uC7fbcqPd9o324jsG/r6GQQVfUcYbLfsJ7VnN0+FlPLyhnm21bRAzLIxtwxssY/4Ri1kxewqrdzXwx1V7qGsLA3aymFlT8gnkevB5XAjCgZYu9je0E+tsIuwtIOCzGUgjUUN3NEZNawiXwBlHlDF7ig/PwfVMrXuV1o4QOQXlnH7sYnIWvpfqLjctXd0snV7Igvx25J2HAaFbPNRQzI6ik6hp7cYAR5Z4OGrHHUSa9rHet5K/tR1BedDDJ6bup7RxnRXSzkYbwZU/xXbAF86AAucvt8Ba4o07oXmvfXvpbLTfTcEMKJhuhbO91lre3R1WCKPdVsRnHQ/lS2zQwLtPwr41VlhnHm/fGhp22vQeDTuh7aD9i0UAcRqYQtvwByps4xSssH1T7XV2VHnjTkec22xD5fZZyz+vGOadaScOKjvSHlu3xd5L20H79mlitnHJybXfQ+0We49gG0hvAGLdtgGJhm2j4ivobdRcHsgvhU/fN6Kflgq+okxgQpEoz22u5d2Dreyu76CqsYOu7iihSIxIzFBRkMuMojym+L10dUfpCEcIRWJ4XC5y3MLsknw+euxMKgp7XRWxmOFvbx/gJ09tYVd9xyHXLA/6WDqjkN317eysa6f/4GUAl9CzvSDXQ2vIWr1nHFHG6QvLWDg1wILyAOXBXNyuDHcYx2JW8ONvCWNNd6e16sfA7aOCryjKgHRHYzy7uQbBzjyW73WzdncjL2+vZ0t1C5Ulfo6qCDK/PEBFQS5TC3KJGsO71a1srm7F63Fx2sJSlkwvpLqliz+t2sN9q6uobul1uYhAcb6X0oCPsqCP8qCPkoAXr8eFx+XCGENzZzdNnd1EYoaivBym5HvpCEfZXd/O7oYOBCgJeCnx+yj2eyn2eynMy6EtFKG+LURLV4Si/BzKgj4KcnOchi9KzBjKg7mUB30Ecj32rScWo6Wzm9rWELWtIaIxQ47Hhdftwutx4fO48OW4mRr0Mb0oj2mFufh9zhuVCMYYIjFDW1eE6pYuqpu76AhH8XpsA1uQl0OZc6+5OYe6CGMxgwg903/GYobWUIRwJEZRfk5ft+EIUMFXFGXMMMZQ1xZmW00b22rbqG3porYtTF1bqEdk69tDdEcNUUf8CnJzKMrPwS3SI/5et4s5JfnMLs5HBBraw9S3h2loD9OUkPqiINdDMDeH5s5u2mbjgZQAAAdVSURBVEL9fetD4/W4yHEJ3VFDODp06g0RyHG56I7Fkk4N5fO4CObmEPC56eqO0dLVTUc4iksgN8eN2yW0hyJ93qAK83KYU5LPI1edmtK99NYzecFP6/uGiJwH/AJwA7caY65P5/UURRl7RISyoLVwT5pfMuSx8UR3rn4un7jhKYO4XyLRGK1dEfw+T58Z0zrCEVq7IuR53eTnuDHYzvKDLSE6QhE8bhcetxD0eSgP5lKQ5+m5hjFW9EORGJ3hKAdbutjf1Gkt+O4oXeEo4ajB6xZy3C7yfR6mFdq3noDPQ3c0RigSpaUzYhu2thAtnd20dEVoC0XIy3FRkJvT86YRikTpjhqCuR4K82y/S4PToI2V0yltFr6IuIF3gXOBKuAN4JPGmEFz3aqFryiKkhqpWPjpzKXzHmCbMWaHMSYM3At8OI3XUxRFUYYgnYI/A9ibsF7lbOuDiFwhIqtFZHVtbW0aq6MoijK5SafgD+SWOsR/ZIy5xRiz0hizsqxMk0wpiqKki3QKfhUwK2F9JrB/kGMVRVGUNJNOwX8DWCgic0XEC3wCeCSN11MURVGGIG1hmcaYiIhcBTyJDcu8zRizMV3XUxRFUYYmrXH4xpjHgMfSeQ1FURQlOXSKQ0VRlEnCuEqtICK1wO4Rnl4K1I1idcYjk+EeYXLc52S4R5gc95npe5xjjEkqxHFcCf7hICKrkx1tNlGZDPcIk+M+J8M9wuS4z4l0j+rSURRFmSSo4CuKokwSsknwb8l0BcaAyXCPMDnuczLcI0yO+5ww95g1PnxFURRlaLLJwlcURVGGQAVfURRlkjDhBV9EzhORLSKyTUSuzXR9RgsRmSUiz4nIJhHZKCJXO9uLReTvIrLV+ZyS6boeLiLiFpE3ReRRZ32uiLzu3OOfnFxMExoRKRKR+0Vks/NMT8q2ZykiX3d+qxtE5B4Ryc2GZykit4lIjYhsSNg24LMTyw2OHq0XkRWZq/mhTGjBd2bVugn4ALAY+KSILM5srUaNCPANY8wi4ETgSufergWeMcYsBJ5x1ic6VwObEtZ/DPzMucdG4PKM1Gp0+QXwhDHmKOAY7P1mzbMUkRnA14CVxpil2PxZnyA7nuUdwHn9tg327D4ALHT+rgB+PUZ1TIoJLfhk8axaxpgDxpi1znIrViBmYO/vTuewO4GPZKaGo4OIzAQ+CNzqrAtwNnC/c0g23GMBcDrwOwBjTNgY00SWPUtsbq48EfEA+cABsuBZGmNeABr6bR7s2X0YuMtYXgOKRGTa2NR0eCa64Cc1q9ZER0QqgWOB14GpxpgDYBsFoDxzNRsVfg58G4g56yVAkzEm4qxnwzOdB9QCtzuuq1tFxE8WPUtjzD7g/4A9WKFvBtaQfc8yzmDPblxr0kQX/KRm1ZrIiEgA+Avwr8aYlkzXZzQRkQuAGmPMmsTNAxw60Z+pB1gB/NoYcyzQzgR23wyE48P+MDAXmA74se6N/kz0Zzkc4/r3O9EFP6tn1RKRHKzY322MecDZfDD+iuh81mSqfqPAKcCFIrIL6447G2vxFzluAciOZ1oFVBljXnfW78c2ANn0LM8Bdhpjao0x3cADwMlk37OMM9izG9eaNNEFP2tn1XJ82b8DNhljfpqw6xHgUmf5UuDhsa7baGGM+Y4xZqYxphL77J41xnwaeA64yDlsQt8jgDGmGtgrIkc6m94LvEMWPUusK+dEEcl3frvxe8yqZ5nAYM/uEeAzTrTOiUBz3PUzLjDGTOg/4HzgXWA78B+Zrs8o3tep2FfB9cA65+98rI/7GWCr81mc6bqO0v2eCTzqLM8DVgHbgD8DvkzXbxTubzmw2nmeDwFTsu1ZAt8DNgMbgN8Dvmx4lsA92H6JbqwFf/lgzw7r0rnJ0aO3sVFLGb+H+J+mVlAURZkkTHSXjqIoipIkKviKoiiTBBV8RVGUSYIKvqIoyiRBBV9RFGWSoIKvTCpEJCoi6xL+Rm3Eq4hUJmZUVJTxhmf4QxQlq+g0xizPdCUUJROoha8ogIjsEpEfi8gq52+Bs32OiDzj5DZ/RkRmO9unisiDIvKW83eyU5RbRH7r5IV/SkTyMnZTitIPFXxlspHXz6Xz8YR9LcaY9wA3YnP64CzfZYw5GrgbuMHZfgPwD2PMMdi8OBud7QuBm4wxS4Am4J/TfD+KkjQ60laZVIhImzEmMMD2XcDZxpgdTtK6amNMiYjUAdOMMd3O9gPGmFIRqQVmGmNCCWVUAn83dlIMROTfgBxjzA/Sf2eKMjxq4StKL2aQ5cGOGYhQwnIU7SdTxhEq+IrSy8cTPl91ll/BZvIE+DTwkrP8DPBl6JmTt2CsKqkoI0WtD2WykSci6xLWnzDGxEMzfSLyOtYQ+qSz7WvAbSLyLeysVZc5268GbhGRy7GW/JexGRUVZdyiPnxFoceHv9IYU5fpuihKulCXjqIoyiRBLXxFUZRJglr4iqIokwQVfEVRlEmCCr6iKMokQQVfURRlkqCCryiKMkn4/wHE0yU66d48NgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [1], 'hidden_layer_size': [64], 'activation_function': ['relu']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XeYVOX5//H3PTPbgKUsLIKAgopEBEVcFSKxYiOxfBMTTWIsUYmJBY3RGFPEkqiJP42o0RC7ItaYKDEqqFiCgIsuiiCCiIJSlt62z/37Yw46rtvZ2dmZ+byua649/bnPnNl7nnnOOc8xd0dERNJfKNkBiIhI21DCFxHJEEr4IiIZQglfRCRDKOGLiGQIJXwRkQyhhC9pz8zGm9nDyY4jnZnZ+2Z2WGsvK61LCb8dM7OlZlZpZj1qTS8xMzez/smJTNKFmfUPPkuRHdmOu+/t7tNbe1lpXUr47d/HwA+3j5jZUCAveeEk144mptYuuyXxmFm4dSJqdrkteu+S+Z5L61LCb/8eAk6PGz8DeDB+ATPLMbObzOxTM1tlZneZWV4wr5uZTTGzUjNbHwz3jVt3uplda2b/M7PNZvZi7V8Uccv2CNbfYGbrzOx1MwsF8/Yzs7eDbTxmZo+a2XXBvDPN7I1a23Iz2yMY/raZvWNmm8xsmZmNj1tuew30bDP7FHg5mD7CzGYEscyNbyIwswFm9moQy1Sgzv2JW/47wa+mDcE294mbt9TMfm1m7wJbzSxSz7S9gvdyQ9BkcULcNu43szvN7Dkz2wocXkcMO5vZM8H7utjMzo2bXmZmBXHL7mdma8wsKxj/qZktCI7vC2a2a633+XwzWwQsqmP3Xwv+bjCzLWY2Mjhe/zOzW8xsHTDezHY3s5fNbG1Q9iQz61rrfRodDI83s8fN7MHgGLxvZkUtXHZ48NnYbGZPBJ+t6xo6ntIAd9ernb6ApcBoYCGwFxAGlgG7Ag70D5b7K/AMUADkA88C1wfzugPfAzoE854A/hVXxnTgI2BPYr8cpgM31BPP9cBdQFbw+hZgQDbwCXBJMP1koAq4LljvTOCNWttyYI9g+DBgKLEKyD7AKuCkYF7/YNkHgY5BjH2AtcCYYJ2jgvHCYJ03gZuBHOAQYDPwcD37NBxYDRwUvL9nBO97TtwxKAH6AXl1TQv2eTFwZfBeHBGUOShY/n5gI3BwEG9uHXG8CvwNyAWGAaXAkcG8l4Fz45b9C3BXMHxSUPZeQAT4HTCj1vs8Nfhs5NVR7vb3NxI37UygGrgw2GYesEfwPucAhcS+KP5a+7MaDI8HyoPjEyb2uZnZ3GX58nM1LniPvwtUEnyu9GpBTkl2AHo1cHC+TPi/C/4Rjg3+eSPBP2l/Ygl3K7B73HojgY/r2eYwYH3c+HTgd3HjvwCer2fda4B/EyTquOmHAJ8DFjdtBk1M+HWU81fglmB4e0LaLW7+r4GHaq3zArFkvUuQrDrGzXuE+hP+ncC1taYtBA6NOwY/reO4/DRu/FvASiAUN20yMD4Yvh94sIHj3A+oAfLjpl0P3B8MnwO8HAwbsS/9Q4Lx/wJnx60XArYBu8a9z0c0UPb297d2wv+0kc/mScA7tT+rwfB4YFrcvMFAWXOXDT5Xn9X6XL2BEn6LX2rSSQ0PAT8i9o/4YK15hcRq73OC5oQNwPPBdMysg5n93cw+MbNNxGpmXe2r7cgr44a3AZ3qieMvxGqTL5rZEjO7Ipi+M/CZB/+RgU+aunNmdpCZvWKxZqeNwHl8vRlmWdzwrsD3t+9vsM+jgN5BLOvdfWsTY9kVuLTWtvoF26mr7Lqm7Qwsc/dorTL7NLKN+PXXufvmetZ/EhhpZjsTS4IOvB4X/61xsa8j9qXQ1LLr85V1zKxn0Ez3WfA5epiGm8pqf6Zyrf5zAfUtW9fnqiX7IgEl/BTg7p8QO3k7BvhnrdlrgDJgb3fvGry6uPv2pH0pMAg4yN07E0sYEEsKzY1js7tf6u67AccDvzSzI4EVQB8zi9/mLnHDW4l9KcUKNutVa9OPEGuS6ufuXYg1G9WOr/Y//UNx+9vV3Tu6+w1BLN3MrGM9sdS2DPhjrW11cPfJ9ZRd17TPgX4WnM+IK/OzRrYRv36BmeXXtb67bwBeBH5A7It/clwSXAb8rFb8ee4+o4ll1zev9vTrg2n7BJ+j02jBZ6iZ6vpc9UtwmWlNCT91nE3sp3l8zZWgVvkP4BYz6wlgZn3M7JhgkXxiXwgbghN/V7U0gODk5h7BP+AmYs0QNcTazKuBi4ITmN8FDoxbdS6wt5kNM7NcYj/j4+UTq+GWm9mBxJJaQx4GjjezY8wsbGa5ZnaYmfUNvhyLgavNLNvMRhH7cqrPP4Dzgl8ZZmYdLXYSOb+BdWqbRexL7XIzy7LYCeTjgUebsrK7LyPWBHZ9sC/7EDvek+IWe4TYyfvvBcPb3QX8xsz2BjCzLmb2/WbEXgpEgd0aWS4f2ELsc9QHuKwZZbTUm8Q+XxcEn6sT+ernSppJCT9FuPtH7l5cz+xfE2tqmRn83J5GrFYPsfbwPGK/BGYSa+5pqYHBtrcQ+2f8m7tPd/dKYifUzgTWA6cQ90vE3T8k1v4/jdiVIm98dbP8ArjGzDYDfwAebyiIIEGeSOwkaSmxWu5lfPl5/hGxk7DriH3B1W4Gi99WMXAucHsQ++JgP5os2P8TgOOIvc9/A0539w+asZkfEmtP/xx4GrjK3afGzX+G2Pu/yt3nxpX9NHAj8Ghw7OcFcTQ19m3AH4H/Bc1CI+pZ9GpiJ7g3Av/h6780W13c5+psYAOxXxVTgIpEl52u7KvNYyKtw8zuB5a7+++SHYukDzObRewKpfuSHUsqUg1fRNotMzvUzHoFTTpnELtsd0d+pWY03UEnIu3ZIGJNfJ2I3S9ysruvSG5IqUtNOiIiGUJNOiIiGaJdNen06NHD+/fvn+wwRERSxpw5c9a4e2FTlm1XCb9///4UF9d35aGIiNRmZk2+q11NOiIiGUIJX0QkQyjhi4hkiHbVhl+Xqqoqli9fTnl5ebJDaRO5ubn07duXrKysZIciImmm3Sf85cuXk5+fT//+/flqp3npx91Zu3Yty5cvZ8CAAckOR0TSTLtv0ikvL6d79+5pn+wBzIzu3btnzK8ZEWlb7T7hAxmR7LfLpH0VkbaVEgm/IdGoU7q5nC3lVckORUSkXUv5hI/Bmi2VlG6pbPVNr127lmHDhjFs2DB69epFnz59vhivrGxaeWeddRYLFy5s9dhERJqr3Z+0bUzIjIIOEdZsLqeyOpfsSLjxlZqoe/fulJSUADB+/Hg6derEr371q68s88XDgUN1f3fed5+67RaR9iH1a/jRGnqWfUQP28i6rW3TrLN48WKGDBnCeeedx/Dhw1mxYgVjx46lqKiIvffem2uuueaLZUeNGkVJSQnV1dV07dqVK664gn333ZeRI0eyevXqNolXRARSrIZ/9bPvM//zTV+fUV2GR1dRxnI6ZDdvlwbv3Jmrjt+72bHMnz+f++67j7vuuguAG264gYKCAqqrqzn88MM5+eSTGTx48FfW2bhxI4ceeig33HADv/zlL7n33nu54oorml22iEhLpH4NHyCUheGEPEpNtG36999999054IADvhifPHkyw4cPZ/jw4SxYsID58+d/bZ28vDyOOy72uNH999+fpUuXtkmsIiKQYjX8emviHsVXvc+WaDalWX3YrbBTwmPp2LHjF8OLFi3i1ltvZfbs2XTt2pXTTjutzmvps7OzvxgOh8NUV1cnPE4Rke3So4ZvIaxDdzqxjYqKciqqatq0+E2bNpGfn0/nzp1ZsWIFL7zwQpuWLyLSFClVw29Qh+6wZRUFtoV12zrSu0temxU9fPhwBg8ezJAhQ9htt904+OCD26xsEZGmalfPtC0qKvLaD0BZsGABe+21V9M2sHYx1RVlLGIXBvXuTChF71pt1j6LSEYzsznuXtSUZdOjSWe7Dj2IUE1edCubynTnrYhIvPRK+Lmd8VCEHqHNrNva+nfeioiksoQlfDMbZGYlca9NZnZxosqLFRo7edsxSSdvRUTas4QlfHdf6O7D3H0YsD+wDXg6UeV9oUN3AApsM+u2qZYvIrJdWzXpHAl85O5Nfrp6i0VysJx8utsW1m+tJNqOTkqLiCRTWyX8U4HJdc0ws7FmVmxmxaWlpa1TWnDytoNO3oqIfCHhCd/MsoETgCfqmu/uE929yN2LCgsLW6fQ3C54KIseoc2s3YGTt63RPTLAvffey8qVK1sch4hIa2iLG6+OA95291VtUFaMWezk7ZaVVFWUU16VR25W87tNbkr3yE1x7733Mnz4cHr16tXsdUVEWktbNOn8kHqacxIq/uRtAi7RfOCBBzjwwAMZNmwYv/jFL4hGo1RXV/OTn/yEoUOHMmTIECZMmMBjjz1GSUkJp5xySrN/GYiItKaE1vDNrANwFPCzVtngf6+Ale81vfzqMgqjNWwjF88OY9Rx522voXDcDc0KY968eTz99NPMmDGDSCTC2LFjefTRR9l9991Zs2YN770Xi3HDhg107dqV2267jdtvv51hw4Y1qxwRkdaU0ITv7tuA7okso0GhLCxaTdhrqI6GyAq1TlcL06ZN46233qKoKHY3c1lZGf369eOYY45h4cKFjBs3jjFjxnD00Ue3SnkiIq0htTpPa2ZNHHd89XyiNWGWR/qyR8/W6TbZ3fnpT3/Ktdde+7V57777Lv/973+ZMGECTz31FBMnTmyVMkVEdlR6da1QW3DytgNl1FSWUVbZOv3Pjx49mscff5w1a9YAsat5Pv30U0pLS3F3vv/973P11Vfz9ttvA5Cfn8/mzZtbpWwRkZZKrRp+S3Tojm9eSXfbxNqtHenbzEcg1mXo0KFcddVVjB49mmg0SlZWFnfddRfhcJizzz4bd8fMuPHGGwE466yzOOecc8jLy2P27NlfeRCKiEhbSa/ukeuz7mNqyjex0HdlUO/OhEPt+4eNukcWkabK3O6R69OxkDBR8tnM+m2681ZEMlNmJPzsjhDJpdA2s25LJe3pV42ISFtJiYS/wwnaDDr2IJcKrHobWyvbb7fJ+jISkURp9wk/NzeXtWvX7ngizCvALURhaDNrt1S0TnCtzN1Zu3Ytubm5yQ5FRNJQu79Kp2/fvixfvpxW6UmzbAtesYqVvoHNXToQbqUbsVpTbm4uffv2TXYYIpKG2n3Cz8rKYsCAAa2zsVXvw51jeLr6x3Q49GIuOWrP1tmuiEgKaPdNOq1qp71h14M5N/clHpv1MVU10WRHJCLSZjIr4QMceC49q1cyeNtsXnhffdSLSObIvIT/je/g+b35We5LPDgj8U9cFBFpLzIv4YezsKKfclD0HUo/eZ/5n29KdkQiIm0i8xI+wPAz8FAWZ2VN44EZS5MdjYhIm8jMhJ+/E7b3Sfwg8hpTSxazPgFPxBIRaW8yM+EDHHQeudGtfMen81jxsmRHIyKScJmb8PsWQZ8izst9iYdnfEy1LtEUkTSX0IRvZl3N7Ekz+8DMFpjZyESW12wHncfONcvZY/Mspi1YlexoREQSKtE1/FuB5939G8C+wIIEl9c8g0/EO/XiZ7lTue9/S5MdjYhIQiUs4ZtZZ+AQ4B4Ad6909w2JKq9FItnYAWczMvoOa5a+x7zPNiY7IhGRhElkDX83oBS4z8zeMbO7zaxj7YXMbKyZFZtZcat0kNZc+5+Jh7M5O1u1fBFJb4lM+BFgOHCnu+8HbAWuqL2Qu0909yJ3LyosLExgOPXo1BMb+n1ODr/Ga3M/ZPXm8raPQUSkDSQy4S8Hlrv7rGD8SWJfAO3PiJ+THS3ne0xj0sxPkx2NiEhCJCzhu/tKYJmZDQomHQnMT1R5O6TXUBhwCGNzp/HozI8or2q/T8QSEWmpRF+lcyEwyczeBYYBf0pweS034nwKatZwUNkbPFPyebKjERFpdQlN+O5eErTP7+PuJ7n7+kSWt0MGHo1334Pz817g7tc/0rNlRSTtZO6dtrWFQthB5zGoZhH5pW/z2qI1yY5IRKRVKeHHG/YjPLcrF+Q+z92vL0l2NCIirUoJP152R+yAczjMZ7Ns8XssWKG+8kUkfSjh13bgWAhn8bOs57n79Y+THY2ISKtRwq8tfydsn1M4Ofwqr89dwMqNuhFLRNKDEn5dRl5Alldyqk3lvhmq5YtIelDCr0vPb8DAYzg3ZxpPzVzMpvKqZEckIrLDlPDrc/BF5Nds4Njql5g8S90tiEjqU8Kvz64HQ58iLsx9ngfeWExltZ6IJSKpTQm/PmYw6mJ2qlnB/ltf418lnyU7IhGRHaKE35BB38a7D+TivOeY+OpHRKPqbkFEUpcSfkNCIezgcexes4Tea9/kxfl67q2IpC4l/Mbs8wM8vzeX5P6HO6cvVqdqIpKylPAbE8nBvnkhw6PvEf7sLWZ8tDbZEYmItIgSflMMPwPPK+CS3Gf52/TFyY5GRKRFlPCbIqcTNuLnfMvnsO6jtylZtiHZEYmINJsSflMdeC6e3ZGLcqZw+8uLkh2NiEizKeE3VV437IBzOIY3+eiDubz/+cZkRyQi0iwJTfhmttTM3jOzEjMrTmRZbWLkBVgkm3HZz3LHK2rLF5HU0hY1/MPdfZi7F7VBWYnVqSe2/1mcYK8zb95cFq3anOyIRESaTE06zXXwOCwc4YKsKarli0hKSXTCd+BFM5tjZmPrWsDMxppZsZkVl5aWJjicVtC5Nzb8dL4XfpXiuXNZUrol2RGJiDRJohP+we4+HDgOON/MDqm9gLtPdPcidy8qLCxMcDitZNTFhMz4RdYUbn9ZtXwRSQ0JTfju/nnwdzXwNHBgIstrM136Yvudxg/C05lV8i4fr9ma7IhERBqVsIRvZh3NLH/7MHA0MC9R5bW5b11K2OCCrH9zm67LF5EUkMga/k7AG2Y2F5gN/Mfdn09geW2raz9s+On8IDyd2e+UqJYvIu1ewhK+uy9x932D197u/sdElZU037qUUCjERVn/5raXVMsXkfZNl2XuiC59sP3P5HvhV5lT8jaLV+u6fBFpv5Twd9SoXxIKRbg4+1/cMk21fBFpv5Twd1Tn3tgB53Civc4H7xUz//NNyY5IRKROSvitYdQlWFYel+X8k5unfpjsaERE6qSE3xo6FWIjfs6xvMnnH8zinU/XJzsiEZGvUcJvLd+8EM/twhU5T/GXFxYmOxoRka9Rwm8teV2xb17EIcyhfMmbvLFoTbIjEhH5CiX81jTi53jHnvw+93H+/PwC3D3ZEYmIfEEJvzVld8QOvZz9fD4FK17l+Xkrkx2RiMgXlPBb2/5n4t0G8PvcJ7jphQVU10STHZGICKCE3/rCWdgRv2P36FKGrpvK48XLkx2RiAighJ8Ye38X77UPV+Y+yR1T57G1ojrZEYmIKOEnRCiEHXUNPaOrGVP2LHe//nGyIxIRUcJPmN0Phz2O4pKcZ3jstRJKN1ckOyIRyXBK+Il01DXk+TbO8af46zR1uSAiyaWEn0g7Dcb2O43TI1P53+y3+HCVuk8WkeRRwk+0w39LOJLNlTmP8qfnFiQ7GhHJYA0mfDM7LW744FrzLkhUUGklvxc26hKOZhbbPnyNVz8sTXZEIpKhGqvh/zJu+LZa837alALMLGxm75jZlGZFlk5GXoDn78y1eZP405R5uhlLRJKisYRv9QzXNV6fcUBmt2Vkd8COuoZB0SUMXftfJr+1LNkRiUgGaizhez3DdY1/jZn1Bb4N3N3MuNLP0JPxvgfw25zHueuFEjZuq0p2RCKSYRpL+N8ws3fN7L244e3jg5qw/b8ClwP1tmGY2VgzKzaz4tLSNG7fNsOOuZ5u0fWcVvUkt+gyTRFpY5FG5u/V0g2b2XeA1e4+x8wOq285d58ITAQoKipK7/6E+x0A+/6Qc999kmNmHsbCA3dhUK/8ZEclIhmiwRq+u38S/wK2AMOBHsF4Qw4GTjCzpcCjwBFm9nBrBJ3SRo8nnJXDVdkPc/Wz76vPfBFpM41dljnFzIYEw72BecSuznnIzC5uaF13/42793X3/sCpwMvuflpD62SE/F7Yob/mEN4m5+NpPPee+swXkbbRWBv+AHefFwyfBUx19+OBg2jiZZlSh4POw7sP5Lrch/nzlBL1pikibaKxhB9/KcmRwHMA7r6ZBk7E1ubu0939O80PL01FsrExf6ZPdAUnbH2S219ZnOyIRCQDNJbwl5nZhWb2f8Ta7p8HMLM8ICvRwaW13Y+Avf+Pi7Kf4YXX3+Sj0i3JjkhE0lxjCf9sYG/gTOAUd98QTB8B3JfAuDLDMX8iHMlifNYD/OFf7+kErogkVGNX6ax29/Pc/UR3fzFu+ivuflPiw0tznXcmdPiVHMI7dPr4BZ6Z+3myIxKRNNbgdfhm9kxD8939hNYNJwMd9DO8ZBJ/XPMQ3312OIft2ZMuHdRaJiKtr7Ebr0YCy4DJwCya3n+ONFU4Czv+VrrfczRnVU/izy8M4I//NzTZUYlIGmqsDb8XcCUwBLgVOApY4+6vuvuriQ4uY/Q7ECv6KWdEXuS9t6Yz55P1yY5IRNJQY234Ne7+vLufQexE7WJgupld2CbRZZLRV0HHQv6ccy9XPvkOldXqQllEWlejT7wysxwz+y7wMHA+MAH4Z6IDyzi5XQiNuZFv+BIOWfcEd07/KNkRiUiaaaxrhQeAGcSuwb/a3Q9w92vd/bM2iS7TDD4JBo3hsuynePaVN1i8Ws/AFZHW01gN/yfAnsQeYjLDzDYFr81mtinx4WUYM/j2zUSyc7g+6x/8+sl3qYnq2nwRaR2NteGH3D0/eHWOe+W7e+e2CjKjdO5N6OjrOID3GfjZP3lgxtJkRyQiaaLRNnxJguGn4wMO4Q/Zj/DgC2+wdM3WZEckImlACb89MsOOn0BuBK4L/4PLn5xLVE07IrKDlPDbq4IBhI66hlHMZcCyf/LQzMaeNyMi0jAl/Pas6Gy8/yjGZ0/i/v++zsdq2hGRHaCE356FQtiJd5ATgevDf+dXj72tq3ZEpMWU8Nu7bv0JHfMnRvAeQz9/nImvLUl2RCKSopTwU8H+Z+IDj+HK7Ed5ZuorzP9ct0CISPMlLOGbWa6ZzTazuWb2vpldnaiy0p4ZdsJtRHLzuTnrDn716GzKq2qSHZWIpJhE1vArgCPcfV9gGHCsmY1IYHnpLX8nQifcyl4s4dvrHuCG/36Q7IhEJMUkLOF7zPYHtWYFL51x3BF7HQ/DT+cXkWdZOPM/vPphabIjEpEUktA2fDMLm1kJsBqY6u6z6lhmrJkVm1lxaakSWKOOvQEv2J0JOXdxzWNvULq5ItkRiUiKSGjCD/rTHwb0BQ40syF1LDPR3YvcvaiwsDCR4aSH7I6ETr6HHraJK6ru4NLHS3QXrog0SZtcpePuG4DpwLFtUV7a23kYNno8R4Xeov+SSdz9hi7VFJHGJfIqnUIz6xoM5wGjAZ1pbC0jz8f3PIbfZz3Cf154npJlG5IdkYi0c4ms4fcGXjGzd4G3iLXhT0lgeZnFDDvpLsL5hdyRPYHLHn6Djduqkh2ViLRjibxK511338/d93H3Ie5+TaLKylgdCgh9/z76UMovyyZw6ePvqD1fROqlO21T3S4jsCP/wHGhWfRb9CD/eF3t+SJSNyX8dHDwOHzQGH6X9QjTXnyWWUvWJjsiEWmHlPDTgRl20p1Y1378LXsCv5s0nVWbypMdlYi0M0r46SKvK6FTHqR7aAvXVd/EBQ/NorI6muyoRKQdUcJPJ733JXTCBA6y+Ry74k6unTI/2RGJSDuihJ9u9j0VDvo5Z0f+y5bZD/Po7E+THZGItBNK+Ono6GuJ7jqKG3Pu4Yln/sVbS9clOyIRaQeU8NNROIvQDx4k0rkXf8+6mT889CKfbShLdlQikmRK+OmqY3dCP3qMgkglN1XfyPn3v8HWiupkRyUiSaSEn852Gkzo5HsZbB8zdu2fuXjyHD0EXSSDKeGnu0HHYkdfy5jwbPZbfDvXP7cg2RGJSJIo4WeCkRfA/mfxi8gzbHzzPh6a+UmyIxKRJFDCzwRmMOYvRHc7guuz7mHqM5OZOn9VsqMSkTamhJ8pwlmEfnA/oZ7f4K6cv3Ln5KfUh75IhlHCzyS5XQid9hQ5nbrzj/CN/OG+KSwp3dL4eiKSFpTwM03n3oRP/yddc+D26LVcdPeL6mhNJEMo4WeiwkGEf/w4fcMb+Ev51Zx39yt6WpZIBlDCz1S7HETo1EkMCi3nyg3jGXvf67oxSyTNJfIh5v3M7BUzW2Bm75vZuESVJS00cDSh7/6dotBCzlt1NT+7/03Kq2qSHZWIJEgia/jVwKXuvhcwAjjfzAYnsDxpiaEnY9+5hcNDJZy2/GoufHi2+tEXSVOJfIj5Cnd/OxjeDCwA+iSqPNkBRWfBsTdybPgtTlgynnGPvEVVjZK+SLppkzZ8M+sP7AfMaovypAVGnAdHXcPx4Zkcs2g8Fz9SrKQvkmYSnvDNrBPwFHCxu2+qY/5YMys2s+LS0tJEhyMNOXgcHHkVJ4VncPSHV/HLyXOU9EXSSEITvpllEUv2k9z9n3Ut4+4T3b3I3YsKCwsTGY40xbd+CaPHc2J4Bkct/D0XPTybimqdyBVJB4m8SseAe4AF7n5zosqRBBh1CYy+mhPCb3Li4t9xwYO6ekckHSSyhn8w8BPgCDMrCV5jElietKZRF39xIvfHS6/kPD1ARSTlRRK1YXd/A7BEbV/awIjzILsDhz5zEXnLLufcidfyt7MPo2uH7GRHJiItoDttpWHDT8e+dzcHhD/i92t+xc/ufI6VG9X3jkgqUsKXxg09mdCPH2PPyGr+sulyLrzjSRav3pzsqESkmZTwpWn2OJLwWVPYObeSiZW/YfzfHqB46bpkRyUizaCEL03Xt4jIudPI79yNu7mae++5nWfnfp7sqESkiZTwpXl67EFk7EtEeg/h9vDNzH38Ou54eRHunuzIRKQRSvjSfJ0KiZz1H3yv4/ld1iS6v/wrLn+8WNfqi7RzSvjSMtkdCH//Afxbv+LUyHROfv8Czvv786zW07NE2i0lfGm5UAg78vfw3bspinzMn0ov5LIJD/IFvREcAAAN5ElEQVTOp+uTHZmI1EEJX3bcPt8nfM4LFHbKYWL1b5k88c9MmvWJ2vVF2hklfGkdO+9H1s9fI9yviD9H/oY/ewm/ebyYskq164u0F0r40no6FRI581mi37yY0yIv8cP3x/LzCU+yePWWZEcmIijhS2sLRwgdfTWcMonBOWu4fcs47rz9Rp6as1xNPCJJpoQvibHXd8g6/39k9x7C/wtNoObpX3DZIzPYWFaV7MhEMpYSviRO113IPud5oqN+xcmR17nwwzO57JZ/MHPJ2mRHJpKRlPAlscIRQqN/T+is5+iVn82dlb9lzr2X8KdnSnSjlkgbU8KXtrHrSHIueJPoPqdyfuTffLf4NMbdch9zPlEHbCJtRQlf2k5uZ7K+eyf86AkGdKzkjm2X8dY/LuKP/5qjp2mJtAElfGl7ex5NzkWz8WGncV7kWU57+1R+e9MEps1flezIRNKaEr4kR15Xsk66Dc6Ywk5dO/DXqqspm3w6l9/3PJ9tKEt2dCJpKWEJ38zuNbPVZjYvUWVIGhjwLXIvnEX1Ib/huMjb/GHpmUy6+VJunzpfJ3VFWlkia/j3A8cmcPuSLrJyiRxxBZELZxHebRSXhyYx5vX/46qbbmLK3M90w5ZIK0lYwnf31wBdgiFNV7AbeWc8CT9+il5dO3JjxZ8oePJkLpvwgK7mEWkFSW/DN7OxZlZsZsWlpaXJDkfag4Gj6TBuFtFj/8zwvBXctH4cy+/+MVfe/S8WrtTD00VayhL5c9nM+gNT3H1IU5YvKiry4uLihMUjKah8I5Wv3YLNvBOrqeTx6GF8uOfPOP3YUexW2CnZ0YkknZnNcfeipiyb9Bq+SINyu5B99HiyLnmX6uFncUrkNa5c/CNmTziN6x56jsWrVeMXaSolfEkN+TuRe+LNhMeVULPfGZwc+R9XLP4x8247hWvufoK5yzYkO0KRdi9hTTpmNhk4DOgBrAKucvd7GlpHTTrSZJtWUPbarYTffoDs6DZerhnG/wp/wMgjv8cRe+1EKGTJjlCkTTSnSSehbfjNpYQvzbZtHRVvTiQ68+/kVa1jQbQfU3KPp+fBP+GkAwfSJS8r2RGKJJQSvmSe6gpq3n2CLa/eRpeNH7DJO/C0H8aaPU9l9KGHsk/fLpip1i/pRwlfMpc7fDqTDa/9jU5LniPi1RRH9+T1TsfS48Af8O0DBlHQMTvZUYq0GiV8EYAtpZTPmUTF7PvosnUpZZ7NVD+Aj3f+NgNHHM8Re/chNyuc7ChFdogSvkg8d1hezPo3HyB34b/Iq9nMOu/ENEawdtfj2PPAYxn1jd7kRJT8JfUo4YvUp7qCmkXTWDfzEbp8Oo1sL2e9d2I6+7O6z2j6DB/Dt/beVSd7JWUo4Ys0ReU2qhdNY+3sJ+i8/GXyarZQ5tm86XvzcdeR5A4+lv322Y9v9MrXZZ7SbinhizRXTRXRj//HmjlPk7VkGt0qlgOwNLoTxeF92dT7YAoGH8b+g/ekX0GHJAcr8iUlfJEdtfYjNr33HFsWTKVg9WxyPfZQlg+i/ZgfGcyWnQ4gf89RDNpzMIN6dyasXwCSJEr4Iq2puhL//B3Wvv8yFYtfpWD9XPKi2wBY7V15jz0o7TwEeg+j28ADGTSgP7sUdFAzkLQJJXyRRIrW4Kvmsf6DN9jy0Uw6lL5Dj4plX8z+zLuziF1Z22lPqnvsRV7fofTebQh79OpGN90DIK1MCV+krZVtoGp5CWsWzaJieQl56xbQo/wTwkQBqPIwn3pPloX6srFjf6q67Eak5x506T2Qnn37s0v3TuTn6sogab7mJPxIooMRyQh5XckaeBi9Bx725bTqCrx0IeuXlrBp2XxCpQvZa9NHFGx9h6yt1fA5UAIVnsVy78G8UCGbcnpR3qE33rkPka596dC9L/k9d6F7QQ96dsmjY3ZYXURIiynhiyRKJAfrvQ8FvfehYGTc9GgNbFzG1pUfsmH5h5SvXgIbPqXv1uV0Ln+LLuvXw3rgky9XKfNs1tKZj+jK5kg3yrK6UZlTQDS3G9ahO6GOBWR1LCCnc3dyOxWQ17mATp06k5+XRaeciO4oFkAJX6TthcLQrT8du/Wn415Hf31+dQVs+pxtaz5lU+kyytYuo3rjSnzLavLL1tC9Yh0dqj4mv3wDWRur6y2mysNsIY9Sz2Or5VJueVSEOlAVyqUqnEdNOI9oJI+aSB4ezoWsXAjnQlYOFskhlJUX+xvJJhRMC2dlE4pkEQrH/kYisb/hSCS2XChMKJxFOBwmFA4TCkdiw2aEQkbYjJCBmWEGITOM2F+ML+cBsUmx5ahrHL7ya2f7UPwPIP0a+iolfJH2JpIDBQPoUDCADns2sJw7VGyGbWup2LyWrRvXsm1jKVXbNlC9dQM12zZA5Wao2Eyocgv5VVvpVr2VSHQjWdVlZFeVk+0V5HjFF+caEqXaQ9QQwjGihIhiRGMpmyhGDRbMi01zDIfg71eHv9z9L6fzlb9xb1H88jSc/Hd0flPVddZ0a7gz+101s1W23xAlfJFUZQa5nSG3MzkFA8gBClq6rZoqqCqD6nKoLqemqoKqijKqK8qoqoyN11RXUlNZTk11FV5TSU11JV5djUeridZU4dEavKYaj9ZAdPvfGvDYX/coRKNANPZlFa0BPDbsNeCOefTLaRD89bhpX51uX4xv35G4L66vZFb/+sS4QaszDde1/o6qezs52V1aafsNU8IXEQhnxV50jo0GL0kveqatiEiGSGjCN7NjzWyhmS02sysSWZaIiDQsYQnfzMLAHcBxwGDgh2Y2OFHliYhIwxJZwz8QWOzuS9y9EngUODGB5YmISAMSmfD7AMvixpcH077CzMaaWbGZFZeWliYwHBGRzJbIhF/XRatfuybJ3Se6e5G7FxUWFiYwHBGRzJbIhL8c6Bc33pdY7yEiIpIEiUz4bwEDzWyAmWUDpwLPJLA8ERFpQEK7RzazMcBfid3Dca+7/7GR5Uv5SpdRzdIDWNPCddurdNwnSM/90j6ljnTbr13dvUnt4e2qP/wdYWbFTe0TOlWk4z5Beu6X9il1pOt+NYXutBURyRBK+CIiGSKdEv7EZAeQAOm4T5Ce+6V9Sh3pul+NSps2fBERaVg61fBFRKQBSvgiIhki5RN+unTBbGb9zOwVM1tgZu+b2bhgeoGZTTWzRcHfbsmOtbnMLGxm75jZlGB8gJnNCvbpseDGvJRhZl3N7Ekz+yA4XiPT5DhdEnz25pnZZDPLTbVjZWb3mtlqM5sXN63OY2MxE4Lc8a6ZDU9e5G0jpRN+mnXBXA1c6u57ASOA84N9uQJ4yd0HAi8F46lmHLAgbvxG4JZgn9YDZyclqpa7FXje3b8B7Ets31L6OJlZH+AioMjdhxC7WfJUUu9Y3Q8cW2tafcfmOGBg8BoL3NlGMSZNSid80qgLZndf4e5vB8ObiSWRPsT254FgsQeAk5ITYcuYWV/g28DdwbgBRwBPBouk1D6ZWWfgEOAeAHevdPcNpPhxCkSAPDOLAB2AFaTYsXL314B1tSbXd2xOBB70mJlAVzPr3TaRJkeqJ/wmdcGcasysP7AfMAvYyd1XQOxLAeiZvMha5K/A5Xz5dOnuwAZ3rw7GU+2Y7QaUAvcFzVR3m1lHUvw4uftnwE3Ap8QS/UZgDql9rLar79ikZf5oSKon/CZ1wZxKzKwT8BRwsbtvSnY8O8LMvgOsdvc58ZPrWDSVjlkEGA7c6e77AVtJseabugTt2icCA4CdgY7EmjxqS6Vj1ZhU/yw2W6on/LTqgtnMsogl+0nu/s9g8qrtPzODv6uTFV8LHAycYGZLiTW3HUGsxt81aDaA1Dtmy4Hl7j4rGH+S2BdAKh8ngNHAx+5e6u5VwD+Bb5Lax2q7+o5NWuWPpkj1hJ82XTAHbdv3AAvc/ea4Wc8AZwTDZwD/buvYWsrdf+Pufd29P7Fj87K7/xh4BTg5WCzV9mklsMzMBgWTjgTmk8LHKfApMMLMOgSfxe37lbLHKk59x+YZ4PTgap0RwMbtTT9py91T+gWMAT4EPgJ+m+x4dmA/RhH7OfkuUBK8xhBr834JWBT8LUh2rC3cv8OAKcHwbsBsYDHwBJCT7PiauS/DgOLgWP0L6JYOxwm4GvgAmAc8BOSk2rECJhM7B1FFrAZ/dn3HhliTzh1B7niP2BVKSd+HRL7UtYKISIZI9SYdERFpIiV8EZEMoYQvIpIhlPBFRDKEEr6ISIZQwpeMYmY1ZlYS92q1u2TNrH98L40i7U2k8UVE0kqZuw9LdhAiyaAavghgZkvN7EYzmx289gim72pmLwX9pb9kZrsE03cys6fNbG7w+mawqbCZ/SPoV/5FM8tL2k6J1KKEL5kmr1aTzilx8za5+4HA7cT6/CEYftDd9wEmAROC6ROAV919X2J96bwfTB8I3OHuewMbgO8leH9Emkx32kpGMbMt7t6pjulLgSPcfUnQid1Kd+9uZmuA3u5eFUxf4e49zKwU6OvuFXHb6A9M9diDNjCzXwNZ7n5d4vdMpHGq4Yt8yesZrm+ZulTEDdeg82TSjijhi3zplLi/bwbDM4j19AnwY+CNYPgl4OfwxTN7O7dVkCItpdqHZJo8MyuJG3/e3bdfmpljZrOIVYR+GEy7CLjXzC4j9qSrs4Lp44CJZnY2sZr8z4n10ijSbqkNX4Qv2vCL3H1NsmMRSRQ16YiIZAjV8EVEMoRq+CIiGUIJX0QkQyjhi4hkCCV8EZEMoYQvIpIh/j8QY3O7VWaG4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [2], 'hidden_layer_size': [64], 'activation_function': ['linear']}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, k in enumerate(list(model_info.keys())): \n",
    "    print(final_models[i])\n",
    "    plt.plot(model_info[k]['history']['loss'][2:])\n",
    "    plt.plot(model_info[k]['history']['val_loss'][2:])\n",
    "    plt.title('Mean squared error over training')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and third models both show evidence of overfitting, as training performance continued to improve as validation performance plateaued (as seen when the blue line goes below the orange line). This suggests that these models will perform worse on the out-of-sample data.\n",
    "\n",
    "Now I store and upload the predictions of each model to obtain the results on the true held out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(list(model_info.keys())):\n",
    "    predictions['gpa'] = model_info[k]['preds']\n",
    "    name = '../output/final_predictions_model_'+str(i)+'.csv'\n",
    "    predictions.to_csv(name)\n",
    "    # csvs were then uploaded to the challenge website: https://codalab.fragilefamilieschallenge.org/#participate-submit_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to compare to the predicted values for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6346324251893312\n",
      "0.1728477837956951\n",
      "0.18892284947139587\n",
      "0.2186643873589771\n",
      "0.21609889833913917\n"
     ]
    }
   ],
   "source": [
    "# Printing performance on validation set\n",
    "for k,v in model_info.items():\n",
    "    print(mean_squared_error(y_test, v['grid_obj'].predict(np.array(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all five model objects\n",
    "for k,v in model_info.items():\n",
    "    v['keras_model'].save('../output/models/'+k+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores on held out challenge set\n",
    "\n",
    "0.41737 (Submission 27)\n",
    "\n",
    "\n",
    "0.64386  (Submission 28) Unsurprising since it looks like it didn't have enough time before it stopped and also performed poorly on the test set\n",
    "\n",
    "\n",
    "0.42533  (Submission 29)\n",
    "\n",
    "\n",
    "0.43441 (Submission 30)\n",
    "\n",
    "\n",
    "0.37975 (Submission 31)\n",
    "\n",
    "The fifth model with 3 hidden layers, each consisting of 256 units, with a sigmoid activation worked best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
